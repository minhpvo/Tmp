#include "Drivers.h"
#include <iostream>
#include <string>

#include "nlohmann/json.hpp"
using namespace nlohmann;

using namespace std;
using namespace cv;
using namespace Eigen;

#define USESIFTGPU

#define SIFTGPU_DLL_RUNTIME// Load at runtime if the above macro defined comment the macro above to use static linking
#ifdef _WINDOWS
#ifdef SIFTGPU_DLL_RUNTIME
#define WIN32_LEAN_AND_MEAN
#include <windows.h>
#define FREE_MYLIB FreeLibrary
#define GET_MYPROC GetProcAddress
#endif
#else
#ifdef SIFTGPU_DLL_RUNTIME
#include <dlfcn.h>
#define FREE_MYLIB dlclose
#define GET_MYPROC dlsym
#endif
#endif

#define min(a,b) ((a) < (b) ? (a) : (b))
#define max(a,b) ((a) > (b) ? (a) : (b))

#include <unsupported/Eigen/KroneckerProduct>
#include <ceres/normal_prior.h>
#include "ceres/ceres.h"
#include "ceres/rotation.h"
using ceres::AutoDiffCostFunction;
using ceres::CostFunction;
using ceres::CauchyLoss;
using ceres::SoftLOneLoss;
using ceres::HuberLoss;
using ceres::Problem;
using ceres::Solver;

double TimeScale = 1000000.0;

int CommandParse(char *Path, SfMPara &mySfMPara)
{
	char Fname[512];
	sprintf(Fname, "%s/EnReconArg.txt", Path);
	if (IsFileExist(Fname) == 0)
	{
		printLOG("Please provide %s\n", Fname);
		exit(0);
	}

	std::string line, item;
	std::ifstream file(Fname);
	while (std::getline(file, line))
	{
		StringTrim(&line);
		if (line.empty() || line[0] == '#')
			continue;

		std::stringstream line_stream(line);
		std::getline(line_stream, item, ' ');
		StringTrim(&item);



		if (!strcmp(item.c_str(), "HeadMountedCameraWeight"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.HeadMountedCameraWeight = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "FootClampingWeight"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.FootClampingWeight = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "missingFrameInterp"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.missingFrameInterp = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "SkeletonPointFormat"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.SkeletonPointFormat = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "real2SfM"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.real2SfM = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "SyncedMode"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.SyncedMode = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "SMPLWindow"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.SMPLWindow = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "SMPLnOverlappingFrames"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.SMPLnOverlappingFrames = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "ShapeWeight"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.ShapeWeight = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "PoseWeight"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.PoseWeight = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "TemporalWeight"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.TemporalWeight = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "ContourWeight"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.ContourWeight = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "SilWeight"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.SilWeight = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "KeyPointsWeight"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.KeyPointsWeight = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "DensePoseWeight"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.DensePoseWeight = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "extractedFrames"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.extractedFrames = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "UseJpg"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.UseJpg = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "nCams"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.nCams = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "startF"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.startF = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "stopF"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.stopF = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "increF"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.increF = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "imgRescale"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.imgRescale = atof(item.c_str());
		}
		//(>-1) have a dedicated video for corpus vs. using frames from all videos for corpus
		else if (!strcmp(item.c_str(), "ExternalCorpus"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.ExternalCorpus = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "fromKeyFrameTracking"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.fromKeyFrameTracking = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "KFSample4Corpus"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.KFSample4Corpus = atoi(item.c_str());
		}

		//Feature tracking
		else if (!strcmp(item.c_str(), "interpAlgo"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.interpAlgo = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "highQualityTracking"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.highQualityTracking = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "minKFinterval"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.minKFinterval = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "maxKFinterval"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.maxKFinterval = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "minFeaturesToTrack"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.minFeaturesToTrack = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "cvPyrLevel"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.cvPyrLevel = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "trackingWinSize"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.trackingWinSize = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "nWinStep"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.nWinStep = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "kfFlowThresh"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.kfFlowThresh = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "kfSuccessConsecutiveTrackingRatio"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.kfSuccessConsecutiveTrackingRatio = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "kfSuccessRefTrackingRatio"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.kfSuccessRefTrackingRatio = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "meanSSGThresh"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.meanSSGThresh = atof(item.c_str());
		}

		//SfM correspondences
		else if (!strcmp(item.c_str(), "ec2BatchSize"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.ec2BatchSize = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "PnPMatchingForcedNearbyKeyFrameRange")) //use nn keyframes around the current frame to find corres for PnP
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.PnPMatchingForcedNearbyKeyFrameRange = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "VocabTreePath"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			sprintf(mySfMPara.VocabTreePath, "%s", item.c_str());
		}
		else if (!strcmp(item.c_str(), "MatchingMode")) //0: exhaustive, 1: sequential with loop closure, 2: 1 with learned vocab, 3: vocab, 4: 2 with learned vocab
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.MatchingMode = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "VocMatchingkNN")) //# similar images returned by vocabtree matching
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.VocMatchingkNN = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "SeqMatchingForcedNearbyImageRange")) // # close by images to match
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.SeqMatchingForcedNearbyImageRange = atoi(item.c_str());
		}

		//Geometry+BA
		else if (!strcmp(item.c_str(), "useRanSac"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.useRanSac = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "sharedIntrinsic"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.sharedIntrinsic = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "nInliersThresh"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.nInliersThresh = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "nInliersThresh2"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.nInliersThresh2 = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "maxGlobalPass"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.maxGlobalPass = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "maxPassesPerImage"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.maxPassesPerImage = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "nViewsPlusBA"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.nViewsPlusBA = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "nViewsPlusBA2"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.nViewsPlusBA2 = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "minFRatio"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.minFRatio = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "maxFratio"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.maxFratio = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "globalBA_freq"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.globalBA_freq = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "globalBA_PointsRatio"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.globalBA_PointsRatio = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "snapshot_images_freq"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.snapshot_images_freq = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "ShutterModel"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.ShutterModel = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "ShutterModel2"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.ShutterModel2 = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "distortionCorrected"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.distortionCorrected = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "fixIntrinsic"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.fixIntrinsic = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "fixDistortion"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.fixDistortion = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "fixSkew"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.fixSkew = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "fixPrism"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.fixPrism = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "fixPose"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.fixPose = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "fix3D"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.fix3D = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "fixLocal3D"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.fixLocal3D = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "BARefinementIter"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.BARefinementIter = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "LossType"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.LossType = atoi(item.c_str());
		}
		else if (!strcmp(item.c_str(), "reProjectionTrianguatlionThresh"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.reProjectionTrianguatlionThresh = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "reProjectionBAThresh"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.reProjectionBAThresh = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "ba_global_tri_min_angle"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.ba_global_tri_min_angle = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "ba_global_images_ratio"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.ba_global_images_ratio = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "ba_global_points_ratio"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.ba_global_points_ratio = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "tri_local_min_tri_angle"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.tri_local_min_tri_angle = atof(item.c_str());
		}
		else if (!strcmp(item.c_str(), "InitForwadMotionRatioThresh"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.InitForwadMotionRatioThresh = atof(item.c_str());
		}

		else if (!strcmp(item.c_str(), "underTriangulationRatio"))
		{
			while (true)
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				if (strcmp(item.c_str(), ""))
					break;
			}
			mySfMPara.underTriangulationRatio = atof(item.c_str());
		}
	}

	if (mySfMPara.nCams == -1 || mySfMPara.startF == -1 || mySfMPara.stopF == -1)
	{
		printLOG("Please specify #cameras, startF, and stopF\n");
		exit(0);
	}

	return 0;
}

//   (c)coeffs      (p)pose      (t)
//     |             |            |
//  Vs = mu + U*c   /|            |
//     |           / |            |
//    / \         /  |            |
//   |  J=Rj*Vs  /   |            |
//   |       \  /    |            |
//   |        \/     |           /
//   |        /\     |          /
//   | L=p2l(p) T=p2t(p,J)     /
//   |     |     |            /
//   |     |     |          /
//   |     |     |        /
//  Vp=Vs + Rp*L |      /
//   |           /     /
//   |          /     /
//  Vl=lbs(Vp,T)     /
//   |              /
//  Vt = Vl + dVdt*t
// dVtdc = dVldVp*dVsdc + dVldT*dTdJ*dJdVs*dVsdc (+ dVldVp*dVpdL*dLdJ*dJdVs*dVsdc == 0, dLdJ==0)
// dVtdp = dVldT*dTdp + dVldVp*dVpdL*dLdp
// dVtdt = dVdt
// dVtdc = dVldVp*U + dVldT*dTdJ*Rj*U
// dVtdp = dVldT*dTdp + dVldVp*Rp*dLdp
namespace smpl
{
	// Shape template from coefficients
	void coeffs_to_verts(const SMPLModel &smpl, const double *coeffs, double *outVerts, double *jacobian)
	{
		using namespace Eigen;
		Map< const Matrix<double, Dynamic, 1> > c(coeffs, SMPLModel::nShapeCoeffs);
		Map< Matrix<double, Dynamic, 1> > out(outVerts, SMPLModel::nVertices * 3);
		out = smpl.mu_ + smpl.U_*c; //mean + basis_shape*coeffs
		if (jacobian != 0)
		{
			Map< Matrix<double, Dynamic, Dynamic, RowMajor> >	J(jacobian, SMPLModel::nVertices * 3, SMPLModel::nShapeCoeffs);
			J = smpl.U_;
		}
	}
	// LBS warping function with derivatives. No pose regression. (LR)
	void lbs(const SMPLModel &smpl, const double *verts, const MatrixXdr& T, double *outVerts, const MatrixXdr &dVsdc, const MatrixXdr &dTdp, const MatrixXdr &dTdc, MatrixXdr &dVdc, MatrixXdr &dVdp)
	{
		const int nVertices = SMPLModel::nVertices, nShapeCoeffs = SMPLModel::nShapeCoeffs, nJoints = SMPLModel::nJoints;

		Map< const MatrixXdr >	Vs(verts, nVertices, 3);
		Map< MatrixXdr >outV(outVerts, nVertices, 3);

		dVdp.resize(nVertices * 3, nJoints * 3);
		dVdc.resize(nVertices * 3, nShapeCoeffs);
		dVdp.setZero(), dVdc.setZero();

		Map< const VectorXd > Tv(T.data(), T.rows()*T.cols());
		for (int idv = 0; idv < nVertices; idv++)
		{
			outV(idv, 0) = 0, outV(idv, 1) = 0, outV(idv, 2) = 0;
			for (int idj = 0; idj < nJoints; idj++)
			{
				if (smpl.W_(idv, idj))
				{
					double w = smpl.W_(idv, idj);
					for (int idd = 0; idd < 3; idd++)
					{
						outV(idv, idd) += w * Vs(idv, 0)*Tv(idj * 3 * 4 + idd * 4 + 0);
						outV(idv, idd) += w * Vs(idv, 1)*Tv(idj * 3 * 4 + idd * 4 + 1);
						outV(idv, idd) += w * Vs(idv, 2)*Tv(idj * 3 * 4 + idd * 4 + 2);
						outV(idv, idd) += w * Tv(idj * 3 * 4 + idd * 4 + 3);

						// The joint transforms only depend on their parents, not vice-versa (meaning dTdp is block lower-triangular).
						for (int idp = 0; idp < (idj + 1) * 3; idp++)
						{
							dVdp(idv * 3 + idd, idp) += w * Vs(idv, 0)*dTdp(idj * 3 * 4 + idd * 4 + 0, idp);
							dVdp(idv * 3 + idd, idp) += w * Vs(idv, 1)*dTdp(idj * 3 * 4 + idd * 4 + 1, idp);
							dVdp(idv * 3 + idd, idp) += w * Vs(idv, 2)*dTdp(idj * 3 * 4 + idd * 4 + 2, idp);
							dVdp(idv * 3 + idd, idp) += w * dTdp(idj * 3 * 4 + idd * 4 + 3, idp);
							// Term for LR
							//                 dVsdP = dVsdLR*dLRdP
							//                outV(idv,idd) += w*dVsdP(idv*3+0,idp)*Tv(idj*3*4 + idd*4 + 0);
							//                outV(idv,idd) += w*dVsdP(idv*3+1,idp)*Tv(idj*3*4 + idd*4 + 1);
							//                outV(idv,idd) += w*dVsdP(idv*3+2,idp)*Tv(idj*3*4 + idd*4 + 2);
						}

						for (int idc = 0; idc < nShapeCoeffs; idc++)
						{
							dVdc(idv * 3 + idd, idc) += w * dVsdc(idv * 3 + 0, idc)*Tv(idj * 3 * 4 + idd * 4 + 0);
							dVdc(idv * 3 + idd, idc) += w * dVsdc(idv * 3 + 1, idc)*Tv(idj * 3 * 4 + idd * 4 + 1);
							dVdc(idv * 3 + idd, idc) += w * dVsdc(idv * 3 + 2, idc)*Tv(idj * 3 * 4 + idd * 4 + 2);

							// These are zero (only the joint translations change with changes in c).
							//                dVdc(idv*3+idd, idc) += w*Vs(idv,0)*dTdc( idj*3*4 + idd*4 + 0, idc);
							//                dVdc(idv*3+idd, idc) += w*Vs(idv,1)*dTdc( idj*3*4 + idd*4 + 1, idc);
							//                dVdc(idv*3+idd, idc) += w*Vs(idv,2)*dTdc( idj*3*4 + idd*4 + 2, idc);
							dVdc(idv * 3 + idd, idc) += w * dTdc(idj * 3 * 4 + idd * 4 + 3, idc);
						}
					}
				}
			}
		}
		return;
	}
	// LBS warping function with derivatives.
	void lbs2(const SMPLModel &smpl, const double *verts, const MatrixXdr& T, double *outVerts, SparseMatrix<double, RowMajor> &dVdVs, SparseMatrix<double, RowMajor> &dVdT)
	{
		const int nVertices = SMPLModel::nVertices, nShapeCoeffs = SMPLModel::nShapeCoeffs, nJoints = SMPLModel::nJoints;

		Map< const MatrixXdr >	V(verts, nVertices, 3);
		Map< MatrixXdr > outV(outVerts, nVertices, 3);

		dVdT = Eigen::SparseMatrix<double, RowMajor>(); dVdT.resize(nVertices * 3, T.rows()*T.cols());
		dVdVs = Eigen::SparseMatrix<double, RowMajor>(); dVdVs.resize(nVertices * 3, nVertices * 3);

		//      SparseMatrix<double, RowMajor> Mlbs(nVertices, 4*nJoints);
		//      std::vector<Eigen::Triplet<double> > IJV_Mlbs; IJV_Mlbs.reserve(nVertices*4*4); // 4 nnz weights per-vertex max
		std::vector<Eigen::Triplet<double> > IJV_dVdT; IJV_dVdT.reserve(nVertices * 4 * 4 * 3);
		std::vector<Eigen::Triplet<double> > IJV_dVdVs;	IJV_dVdVs.reserve(nVertices * 3 * 3);
		//      dVdT.reserve(VectorXi::Constant(nVertices*3,3*4*5));
		//      Matrix<double, Dynamic, Dynamic, RowMajor> Mlbs(nVertices,4*nJoints);

		Map< const VectorXd > Tv(T.data(), T.rows()*T.cols());
		for (int idv = 0; idv < nVertices; idv++)
		{
			outV(idv, 0) = 0, outV(idv, 1) = 0, outV(idv, 2) = 0;
			for (int idj = 0; idj < nJoints; idj++)
			{
				//          Mlbs(idv, idj*4 + 0) = smpl.W_(idv, idj)*V(idv,0);
				//          Mlbs(idv, idj*4 + 1) = smpl.W_(idv, idj)*V(idv,1);
				//          Mlbs(idv, idj*4 + 2) = smpl.W_(idv, idj)*V(idv,2);
				//          Mlbs(idv, idj*4 + 3) = smpl.W_(idv, idj);
				if (smpl.W_(idv, idj))
				{
					//            IJV_Mlbs.push_back(Triplet<double>(idv, idj*4+0, smpl.W_(idv, idj)*V(idv,0)));
					//            IJV_Mlbs.push_back(Triplet<double>(idv, idj*4+1, smpl.W_(idv, idj)*V(idv,1)));
					//            IJV_Mlbs.push_back(Triplet<double>(idv, idj*4+2, smpl.W_(idv, idj)*V(idv,2)));
					//            IJV_Mlbs.push_back(Triplet<double>(idv, idj*4+3, smpl.W_(idv, idj)));
					double w = smpl.W_(idv, idj);
					for (int idd = 0; idd < 3; idd++)
					{
						//              IJV_dVdVs.push_back(Triplet<double>(idv*3+idd, idv*3+idd, w*T(idj*3+idd,0)));
						//              IJV_dVdVs.push_back(Triplet<double>(idv*3+idd, idv*3+idd, w*T(idj*3+idd,1)));
						//              IJV_dVdVs.push_back(Triplet<double>(idv*3+idd, idv*3+idd, w*T(idj*3+idd,2)));
						//              IJV_dVdVs.push_back(Triplet<double>(idv*3+0, idv*3+idd, w*Tv(idj*3*4 + idd + 0)));
						//              IJV_dVdVs.push_back(Triplet<double>(idv*3+1, idv*3+idd, w*Tv(idj*3*4 + idd + 4)));
						//              IJV_dVdVs.push_back(Triplet<double>(idv*3+2, idv*3+idd, w*Tv(idj*3*4 + idd + 4*2)));
						IJV_dVdVs.push_back(Triplet<double>(idv * 3 + idd, idv * 3 + 0, w*Tv(idj * 3 * 4 + idd * 4 + 0)));
						IJV_dVdVs.push_back(Triplet<double>(idv * 3 + idd, idv * 3 + 1, w*Tv(idj * 3 * 4 + idd * 4 + 1)));
						IJV_dVdVs.push_back(Triplet<double>(idv * 3 + idd, idv * 3 + 2, w*Tv(idj * 3 * 4 + idd * 4 + 2)));
						//              IJV_dVdVs.push_back(Triplet<double>(idv*3+idd, idv*3+idd, w*T(idj*3+idd,3)));

						//              Translation, homogeneous.
						//              IJV_dVdVs.push_back(Triplet<double>(idv*3+idd, idv*3+idd+4, w*T(idj*3+idd,3)));

						IJV_dVdT.push_back(Triplet<double>(idv * 3 + idd, idj * 3 * 4 + idd * 4 + 0, w*V(idv, 0)));
						IJV_dVdT.push_back(Triplet<double>(idv * 3 + idd, idj * 3 * 4 + idd * 4 + 1, w*V(idv, 1)));
						IJV_dVdT.push_back(Triplet<double>(idv * 3 + idd, idj * 3 * 4 + idd * 4 + 2, w*V(idv, 2)));
						IJV_dVdT.push_back(Triplet<double>(idv * 3 + idd, idj * 3 * 4 + idd * 4 + 3, w));
					}
				}
			}
		}


		//      Mlbs.setFromTriplets(IJV_Mlbs.begin(),IJV_Mlbs.end());
		dVdT.setFromTriplets(IJV_dVdT.begin(), IJV_dVdT.end());
		dVdVs.setFromTriplets(IJV_dVdVs.begin(), IJV_dVdVs.end());

		Map< VectorXd > outVv(outVerts, V.rows()*V.cols());
		outVv = dVdT * Tv; //skining * kinematics
						 //      oVx = Mlbs*Txc;
						 //      oVy = Mlbs*Tyc;
						 //      oVz = Mlbs*Tzc;
		return;
	}

	// Reconstruct shape with pose & coefficients (no translation)
	void reconstruct(const SMPLModel &smpl, const double *coeffs, const double *pose, double *outVerts)
	{
		const int nVertices = SMPLModel::nVertices, nShapeCoeffs = SMPLModel::nShapeCoeffs, nJoints = SMPLModel::nJoints;

		MatrixXdr Vt(nVertices, 3);
		Map< Matrix<double, Dynamic, 1> > Vt_vec(Vt.data(), 3 * nVertices);
		Map< const Matrix<double, Dynamic, 1> > c(coeffs, SMPLModel::nShapeCoeffs);
		Vt_vec = smpl.mu_ + smpl.U_*c; //mean + basis_shape*coeffs

		Matrix<double, nJoints, 3, RowMajor> J = (smpl.J_regl_*Vt);  //joints = J_reg*Vt

		const int num_tldr = (nJoints) * 3 * 4 + (nJoints - 1) * 3 * 3;
		VectorXd transforms_and_lrot(3 * nJoints * 4 + 3 * (nJoints - 1) * 3);
		Map< Matrix<double, 3 * nJoints, 4, RowMajor> > transforms(transforms_and_lrot.data());
		Map< Matrix<double, 3 * (nJoints - 1), 3, RowMajor>  > lrot(transforms_and_lrot.data() + 3 * nJoints * 4);

		//kinematic chain
		ceres::AutoDiffCostFunction < PoseToTransforms, nJoints * 3 * 4 + (nJoints - 1) * 3 * 3, nJoints * 3, nJoints * 3 > p2t(new PoseToTransforms(smpl));
		const double * parameters[2] = { pose, J.data() };
		double * residuals = transforms_and_lrot.data();
		p2t.Evaluate(parameters, residuals, NULL);

		Map< VectorXd > lrot_vec(lrot.data(), lrot.rows()*lrot.cols());
		Matrix<double, Dynamic, 1> Vs_vec(3 * nVertices);
		Vs_vec = Vt_vec + (smpl.pose_regl_*lrot_vec); //v + pose dependent

		SparseMatrix<double, RowMajor> dVdVs, dVdT;
		lbs2(smpl, Vs_vec.data(), transforms, outVerts, dVdVs, dVdT);
	}
	void reconstruct(const SMPLModel &smpl, const double *coeffs, const double *pose, double *outVerts, MatrixXdr &dVdc, MatrixXdr &dVdp)
	{
		const int nVertices = SMPLModel::nVertices, nShapeCoeffs = SMPLModel::nShapeCoeffs, nJoints = SMPLModel::nJoints;

		MatrixXdr Vt(nVertices, 3);
		Map< Matrix<double, Dynamic, 1> > Vt_vec(Vt.data(), 3 * nVertices);
		Map< MatrixXdr > outV(outVerts, nVertices, 3);
		Map< const Matrix<double, Dynamic, 1> > c(coeffs, nShapeCoeffs);

		Vt_vec = smpl.mu_ + smpl.U_*c;

		Matrix<double, nJoints, 3, RowMajor> J;
		Map< Matrix<double, Dynamic, 1> > J_vec(J.data(), nJoints * 3);
		J_vec = smpl.J_mu_ + smpl.dJdc_*c;

		const int num_t = nJoints * 3 * 4;
		Matrix<double, Dynamic, 3 * nJoints, RowMajor> dTdp(num_t, 3 * nJoints);
		Matrix<double, Dynamic, 3 * nJoints, RowMajor> dTdJ(num_t, 3 * nJoints);
		VectorXd transforms(3 * nJoints * 4);

		ceres::AutoDiffCostFunction < PoseToTransformsNoLR, nJoints * 3 * 4, nJoints * 3, nJoints * 3 > p2t(new PoseToTransformsNoLR(smpl));
		const double * parameters[2] = { pose, J.data() };
		double * residuals = transforms.data();
		double * jacobians[2] = { dTdp.data(), dTdJ.data() };
		p2t.Evaluate(parameters, residuals, jacobians);

		Matrix<double, Dynamic, nShapeCoeffs, RowMajor> dTdc = dTdJ * smpl.dJdc_;
		lbs(smpl, Vt_vec.data(), transforms, outVerts, smpl.U_, dTdp, dTdc, dVdc, dVdp);
	}
	void reconstruct2(const SMPLModel &smpl, const double *coeffs, const double *pose, double *outVerts, MatrixXdr &dVdc, MatrixXdr &dVdp)
	{
		const int nVertices = SMPLModel::nVertices, nShapeCoeffs = SMPLModel::nShapeCoeffs, nJoints = SMPLModel::nJoints;

		MatrixXdr Vt(nVertices, 3);
		MatrixXdr dVtdc(nVertices * 3, nShapeCoeffs);
		Map< MatrixXdr >outV(outVerts, nVertices, 3);

		coeffs_to_verts(smpl, coeffs, Vt.data(), dVtdc.data());
		Matrix<double, nJoints, 3, RowMajor> J = (smpl.J_regl_*Vt);
		const SparseMatrix<double, RowMajor> &dJdVt = smpl.J_regl_bigl_;

		const int num_tldr = nJoints * 3 * 4 + (nJoints - 1) * 3 * 3;
		Matrix<double, Dynamic, Dynamic, RowMajor> dTLRdP(num_tldr, 3 * nJoints);
		Matrix<double, Dynamic, Dynamic, RowMajor> dTLRdJ(num_tldr, 3 * nJoints);
		VectorXd transforms_and_lrot(3 * nJoints * 4 + 3 * (nJoints - 1) * 3);

		Map< Matrix<double, 3 * nJoints, 4, RowMajor> >	transforms(transforms_and_lrot.data());
		Map< Matrix<double, 3 * (nJoints - 1), 3, RowMajor>  > lrot(transforms_and_lrot.data() + 3 * nJoints * 4);
		Map< Matrix<double, Dynamic, Dynamic, RowMajor> > dTdp(dTLRdP.data(), (nJoints) * 3 * 4, 3 * nJoints);
		Map< Matrix<double, Dynamic, Dynamic, RowMajor> > dLRdP(dTLRdP.data() + (nJoints) * 3 * 4 * 3 * nJoints, (nJoints - 1) * 3 * 3, 3 * nJoints);
		Map< Matrix<double, Dynamic, Dynamic, RowMajor> > dTdJ(dTLRdJ.data(), (nJoints) * 3 * 4, 3 * nJoints);
		Map< Matrix<double, Dynamic, Dynamic, RowMajor> >dLRdJ(dTLRdJ.data() + (nJoints) * 3 * 4 * 3 * nJoints, (nJoints - 1) * 3 * 3, 3 * nJoints); // This is zero.

		ceres::AutoDiffCostFunction < PoseToTransforms, (nJoints) * 3 * 4 + (nJoints - 1) * 3 * 3, (nJoints) * 3, (nJoints) * 3 > p2t(new PoseToTransforms(smpl));
		const double * parameters[2] = { pose, J.data() };
		double * residuals = transforms_and_lrot.data();
		double * jacobians[2] = { dTLRdP.data(), dTLRdJ.data() };
		p2t.Evaluate(parameters, residuals, jacobians);

		Map< VectorXd > lrot_vec(lrot.data(), lrot.rows()*lrot.cols());
		Matrix<double, Dynamic, 1> Vs_vec(3 * nVertices);
		Map< Matrix<double, Dynamic, 1> > Vt_vec(Vt.data(), 3 * nVertices);
		Vs_vec = Vt_vec + (smpl.pose_regl_*lrot_vec);

		const Matrix<double, Dynamic, Dynamic, RowMajor> &dVsdc = dVtdc;

		//      Matrix<double, 3, nVertices, RowMajor>
		//        shape_vertices = base_vertices + pose_regl_*localrot;

		const Matrix<double, Dynamic, Dynamic, Eigen::RowMajor> &dVsdLR = smpl.pose_regl_;
		SparseMatrix<double, RowMajor> dVdVs;
		SparseMatrix<double, RowMajor> dVdT;


		Matrix<double, Dynamic, Dynamic, Eigen::RowMajor> dJdc = dJdVt * dVtdc; // Precompute
		lbs2(smpl, Vs_vec.data(), transforms, outVerts, dVdVs, dVdT);

		dVdc = dVdVs * dVsdc + dVdT * dTdJ*dJdc;
		dVdp = dVdT * dTdp + dVdVs * dVsdLR*dLRdP;
	}
}
bool ReadSMPLData(char *Path, smpl::SMPLModel &smpl)
{
	const int nVertices = smpl::SMPLModel::nVertices, nShapeCoeffs = smpl::SMPLModel::nShapeCoeffs, nJoints = smpl::SMPLModel::nJoints, naJoints = smpl::SMPLModel::naJoints;

	char Fname[512];
	int width, height;
	ifstream fin;
	FILE *fp = 0;

	sprintf(Fname, "%s/J_regl_25_big.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	MatrixXd temp4 = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>(height, width); //72xnV
	MatrixXd tempX = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>(51, width); //51xnV

	int mask_[] = { 0,	1,	2,	6,	7,	8	,9	,10	,11,	12,	13	,14	,15	,16	,17,	18,	19	,20	,21,	22	,23	,24,	25,	26	,27	,28	,29,	30,	31,	32	,33,	34	,35,	36,	37	,38,	39	,40	,41,	42,	43	,44	,45,	46	,47	,48	,49,	50	,51	,52,	53 };
	vector<bool> mask(height);
	for (int ii = 0; ii < height; ii++)
		mask[ii] = false;

	for (int ii = 0; ii < (sizeof(mask_) / sizeof(*mask_)); ii++)
		mask[mask_[ii]] = true;
	int cnt = 0;
	for (int ii = 0; ii < height; ii++)
	{
		if (mask[ii])
			cnt++;
	}
	cnt = 0;
	for (int j = 0; j < height; j++)
	{
		for (int i = 0; i < width; i++)
		{
			fin.read(reinterpret_cast<char *>(&temp4(j, i)), sizeof(double));
			if (mask[j])
				tempX(cnt, i) = temp4(j, i);
		}
		if (mask[j])
			cnt++;
	}
	fin.close();

	smpl.J_regl_17_bigl_col_ = tempX.sparseView();
	smpl.J_regl_25_bigl_col_ = temp4.sparseView();

	/*sprintf(Fname, "%s/Mosh_pose_MinMax.txt", Path);
	fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	for (int i = 0; i < 72; i++)
		fscanf(fp, "%lf ", &smpl.minPose[i]);
	for (int i = 0; i < 72; i++)
		fscanf(fp, "%lf ", &smpl.maxPose[i]);
	fclose(fp);

	sprintf(Fname, "%s/Mosh_pose_mu.txt", Path); fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	for (int i = 0; i < 72; i++)
		fscanf(fp, "%lf ", &smpl.Mosh_pose_prior_mu[i]);
	fin.close();

	sprintf(Fname, "%s/Mosh_pose_A.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	smpl.Mosh_pose_prior_A = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&smpl.Mosh_pose_prior_A(j, i)), sizeof(double));
	fin.close();

	sprintf(Fname, "%s/Mosh_dV_A.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	smpl.Mosh_dV_prior_A = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&smpl.Mosh_dV_prior_A(j, i)), sizeof(double));
	fin.close();*/

	sprintf(Fname, "%s/std_smpl_J.txt", Path); fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	double temp[naJoints], maxv = 0;
	for (int i = 0; i < naJoints; i++)
	{
		fscanf(fp, "%lf ", &temp[i]);
		maxv = max(maxv, temp[i]);
	}
	fin.close();
	for (int i = 0; i < naJoints; i++)
		smpl.Mosh_asmpl_J_istd[i] = 1.0 / (temp[i] / maxv);
	/*sprintf(Fname, "%s/Mosh_pose_iCov.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	smpl.Mosh_pose_prior_iCov = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&smpl.Mosh_pose_prior_iCov(j, i)), sizeof(double));
	fin.close();*/

	double sqrt_idet[8], max_sqrt_idet = 0.1;
	/*for (int ii = 0; ii < 8; ii++)
	{
		sprintf(Fname, "%s/GMM_icovar_%d.dat", Path, ii);
		fin.open(Fname, ios::binary);
		if (!fin.is_open())
		{
			printLOG("Cannot load %s\n", Fname);
			return false;
		}
		fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
		smpl.GMM_pose_prior_iCov[ii] = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(height, width);
		for (int j = 0; j < height; ++j)
			for (int i = 0; i < width; i++)
				fin.read(reinterpret_cast<char *>(&smpl.GMM_pose_prior_iCov[ii](j, i)), sizeof(double));
		fin.close();

		sprintf(Fname, "%s/GMM_A_%d.dat", Path, ii);
		fin.open(Fname, ios::binary);
		if (!fin.is_open())
		{
			printLOG("Cannot load %s\n", Fname);
			return false;
		}
		fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
		smpl.GMM_pose_prior_A[ii] = MatrixXd::Zero(height + 3, width + 3);
		for (int j = 3; j < 3 + height; ++j)
			for (int i = 3; i < 3 + width; i++)
				fin.read(reinterpret_cast<char *>(&smpl.GMM_pose_prior_A[ii](j, i)), sizeof(double));
		fin.close();

		sqrt_idet[ii] = sqrt(smpl.GMM_pose_prior_iCov[ii].determinant());
		max_sqrt_idet = max(sqrt_idet[ii], max_sqrt_idet);
	}

	sprintf(Fname, "%s/GMM_mu.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	smpl.GMM_pose_prior_mu = MatrixXd::Zero(width + 3, height); //agument the root
	for (int j = 0; j < height; ++j)
		for (int i = 3; i < 3 + width; i++)
			fin.read(reinterpret_cast<char *>(&smpl.GMM_pose_prior_mu(i, j)), sizeof(double));
	fin.close();

	sprintf(Fname, "%s/GMM_w.txt", Path); fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	smpl.GMM_pose_prior_w = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(8, 1);
	for (int i = 0; i < 8; i++)
		fscanf(fp, "%lf ", &smpl.GMM_pose_prior_w(i, 0));
	fclose(fp);

	for (int i = 0; i < 8; i++)
		smpl.GMM_pose_prior_w(i, 0) = smpl.GMM_pose_prior_w(i, 0) * (sqrt_idet[i] / max_sqrt_idet);*/

	sprintf(Fname, "%s/pose_prior_A.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	smpl.pose_prior_A = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&smpl.pose_prior_A(j, i)), sizeof(double));
	fin.close();

	sprintf(Fname, "%s/pose_prior_mu.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	smpl.pose_prior_mu = Eigen::Matrix<double, Eigen::Dynamic, 1>(height* width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&smpl.pose_prior_mu(j, i)), sizeof(double));
	fin.close();

	sprintf(Fname, "%s/v_template.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	smpl.mu_ = Eigen::Matrix<double, Eigen::Dynamic, 1>(height * width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&smpl.mu_(j*width + i)), sizeof(double));
	fin.close();

	sprintf(Fname, "%s/weights.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	smpl.W_ = Eigen::Matrix<double, Eigen::Dynamic, nJoints, Eigen::RowMajor>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&smpl.W_(j, i)), sizeof(double));
	fin.close();

	sprintf(Fname, "%s/U.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	smpl.U_ = Eigen::Matrix<double, Eigen::Dynamic, nShapeCoeffs, Eigen::RowMajor>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&smpl.U_(j, i)), sizeof(double));
	fin.close();

	//sprintf(Fname, "%s/pose_reg.dat", Path);
	//fin.open(Fname, ios::binary);
	//if (!fin.is_open())
	//return false;
	//fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	//smpl.pose_regl_ = Eigen::Matrix<double, nVertices * 3, Eigen::Dynamic, Eigen::RowMajor>(height, width);
	//for (int j = 0; j < height; ++j)
	//for (int i = 0; i < width; i++)
	//fin.read(reinterpret_cast<char *>(&smpl.pose_regl_(j, i)), sizeof(double));
	//fin.close();

	smpl.pose_regl_ = Eigen::Matrix<double, nVertices * 3, Eigen::Dynamic, Eigen::RowMajor>(nVertices * 3, 207);
	smpl.pose_regl_.setZero(); //deactivate for now

	sprintf(Fname, "%s/kintree_table.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	smpl.kintree_table_ = Eigen::Matrix<int, 2, Eigen::Dynamic>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&smpl.kintree_table_(j, i)), sizeof(int));
	fin.close();

	for (int idt = 0; idt < smpl.kintree_table_.cols(); idt++)
		smpl.id_to_col_[smpl.kintree_table_(1, idt)] = idt;
	for (int idt = 1; idt < smpl.kintree_table_.cols(); idt++)
		smpl.parent_[idt] = smpl.id_to_col_[smpl.kintree_table_(0, idt)];


	sprintf(Fname, "%s/J_regressor.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	MatrixXd temp1 = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&temp1(j, i)), sizeof(double));
	fin.close();
	smpl.J_regl_ = temp1.sparseView();

	sprintf(Fname, "%s/J_regressor_big.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	MatrixXd temp2 = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&temp2(j, i)), sizeof(double));
	fin.close();
	smpl.J_regl_bigl_ = temp2.sparseView();

	sprintf(Fname, "%s/J_regl_18_big.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	MatrixXd temp3 = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&temp3(j, i)), sizeof(double));
	fin.close();
	smpl.J_regl_14_bigl_col_ = temp3.sparseView();



	sprintf(Fname, "%s/J_regl_abig.dat", Path);
	fin.open(Fname, ios::binary);
	if (!fin.is_open())
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	fin.read(reinterpret_cast<char *>(&height), sizeof(int)), fin.read(reinterpret_cast<char *>(&width), sizeof(int));
	MatrixXd temp5 = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>(height, width);
	for (int j = 0; j < height; ++j)
		for (int i = 0; i < width; i++)
			fin.read(reinterpret_cast<char *>(&temp5(j, i)), sizeof(double));
	fin.close();
	smpl.J_regl_abigl_ = temp5.sparseView();

	Point3i f;
	fp = fopen("smpl/faces.txt", "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	else
	{
		Point3i f;
		while (fscanf(fp, "%d %d %d ", &f.x, &f.y, &f.z) != EOF)
			smpl.vFaces.push_back(f);
		fclose(fp);
		smpl.faces_ = Eigen::Matrix<int, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>(smpl.vFaces.size(), 3);
		for (int j = 0; j < smpl.vFaces.size(); ++j)
			smpl.faces_(j, 0) = smpl.vFaces[j].x, smpl.faces_(j, 1) = smpl.vFaces[j].y, smpl.faces_(j, 2) = smpl.vFaces[j].z;

		FILE *fp = fopen("smpl/Vconnections.txt", "r");
		if (fp == NULL)
		{
			smpl.vConnections.clear();
			for (int j = 0; j < smpl.vFaces.size(); ++j)
			{
				bool found = false;
				for (int i = 0; i < smpl.vConnections.size() && !found; i++)
					if (smpl.vConnections[i].x == smpl.vFaces[j].x && smpl.vConnections[i].y == smpl.vFaces[j].y)
						found = true;
				if (!found)
					smpl.vConnections.push_back(Point2i(smpl.vFaces[j].x, smpl.vFaces[j].y));

				found = false;
				for (int i = 0; i < smpl.vConnections.size() && !found; i++)
					if (smpl.vConnections[i].x == smpl.vFaces[j].x && smpl.vConnections[i].y == smpl.vFaces[j].z)
						found = true;
				if (!found)
					smpl.vConnections.push_back(Point2i(smpl.vFaces[j].x, smpl.vFaces[j].z));

				found = false;
				for (int i = 0; i < smpl.vConnections.size() && !found; i++)
					if (smpl.vConnections[i].x == smpl.vFaces[j].y && smpl.vConnections[i].y == smpl.vFaces[j].z)
						found = true;
				if (!found)
					smpl.vConnections.push_back(Point2i(smpl.vFaces[j].y, smpl.vFaces[j].z));
			}
			smpl.connections_ = Eigen::Matrix<int, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>(smpl.vConnections.size(), 2);
			for (int j = 0; j < smpl.vConnections.size(); ++j)
				smpl.connections_(j, 0) = smpl.vConnections[j].x, smpl.connections_(j, 1) = smpl.vConnections[j].y;

			fp = fopen("smpl/Vconnections.txt", "w");
			for (int j = 0; j < smpl.vConnections.size(); ++j)
				fprintf(fp, "%d %d\n", smpl.vConnections[j].x, smpl.vConnections[j].y);
			fclose(fp);
		}
		else
		{
			Point2i c;
			while (fscanf(fp, "%d %d ", &c.x, &c.y) != EOF)
				smpl.vConnections.push_back(c);
			fclose(fp);

			smpl.connections_ = Eigen::Matrix<int, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>(smpl.vConnections.size(), 2);
			for (int j = 0; j < smpl.vConnections.size(); ++j)
				smpl.connections_(j, 0) = smpl.vConnections[j].x, smpl.connections_(j, 1) = smpl.vConnections[j].y;
		}
	}

	/*//same as SMPL_2_UV_PID.txt
	fp = fopen("smpl/partId.txt", "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	else
	{
		smpl.vDensePosePartId.resize(nVertices);
		for (int vid = 0; vid < nVertices; vid++)
			fscanf(fp, "%d ", &smpl.vDensePosePartId[vid]);
		fclose(fp);
	}*/

	smpl.vDensePosePartId.resize(nVertices);
	smpl.vUV.resize(nVertices);

	float U, V;
	int smplVid, PartId;
	fp = fopen("smpl/SMPL_2_UV_PID.txt", "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	else
	{
		while (fscanf(fp, "%d %f %f %d ", &smplVid, &U, &V, &PartId) != EOF)
			smpl.vUV[smplVid].x = U * 255.0, smpl.vUV[smplVid].y = V * 255.0, smpl.vDensePosePartId[smplVid] = PartId;
		fclose(fp);
	}

	// Precompute
	smpl.J_mu_ = smpl.J_regl_bigl_*smpl.mu_;
	smpl.dJdc_ = smpl.J_regl_bigl_*smpl.U_;

	return true;
}
vector<int> RasterizeMesh4OccludingContour(double *P, int width, int height, double*vXYZ, int nVertices, vector<Point3i> &vfaces, vector<Point2i> &vConnections, bool *hit)
{
	bool memCreated = false;
	if (hit == NULL)
	{
		memCreated = true;
		hit = new bool[width*height];
		for (int ii = 0; ii < width*height; ii++)
			hit[ii] = 0;
	}

	vector<Point2f> vuv; vuv.reserve(nVertices);
	for (int vid3 = 0; vid3 < nVertices * 3; vid3 += 3)
	{
		Point3d xyz(vXYZ[vid3], vXYZ[vid3 + 1], vXYZ[vid3 + 2]);

		double numX = P[0] * xyz.x + P[1] * xyz.y + P[2] * xyz.z + P[3],
			numY = P[4] * xyz.x + P[5] * xyz.y + P[6] * xyz.z + P[7],
			denum = P[8] * xyz.x + P[9] * xyz.y + P[10] * xyz.z + P[11];
		Point2f uv(numX / denum, numY / denum);
		if (uv.x<0 || uv.x>width - 1 || uv.y<0 || uv.y>height - 1)
			uv.x = 0, uv.y = 0;
		vuv.push_back(uv);
	}

	for (int fid = 0; fid < vfaces.size(); fid++)
	{
		int vid1 = vfaces[fid].x, vid2 = vfaces[fid].y, vid3 = vfaces[fid].z;
		Point2f uv1 = vuv[vid1], uv2 = vuv[vid2], uv3 = vuv[vid3];
		if (uv1.x < 1 || uv2.x < 1 || uv3.x < 1)
			continue;
		int maxX = min((int)(max(max(max(0, uv1.x), uv2.x), uv3.x)) + 1, width - 1);
		int minX = max((int)(min(min(min(width - 1, uv1.x), uv2.x), uv3.x)) + 1, 0);
		int maxY = min((int)(max(max(max(0, uv1.y), uv2.y), uv3.y)) + 1, height - 1);
		int minY = max((int)(min(min(min(height - 1, uv1.y), uv2.y), uv3.y)) + 1, 0);
		for (int jj = minY; jj <= maxY; jj++)
			for (int ii = minX; ii < maxX; ii++)
				if (PointInTriangle(uv1, uv2, uv3, Point2f(ii, jj)))
					hit[ii + jj * width] = 1;
	}

	vector<int> occludingcontour;
	for (int con = 0; con < vConnections.size(); con++)
	{
		int vid1 = vConnections[con].x, vid2 = vConnections[con].y;
		if (vuv[vid1].x < 1 || vuv[vid2].x < 1)
			continue;
		Point2f muv = 0.5*(vuv[vid1] + vuv[vid2]);

		Point2f normal(-(vuv[vid1].y - vuv[vid2].y), vuv[vid1].x - vuv[vid2].x);
		double norm = sqrt(normal.x*normal.x + normal.y*normal.y);
		normal.x = normal.x / norm, normal.y = normal.y / norm;

		Point2i right((int)(muv.x + normal.x + 0.5), (int)(muv.y + normal.y + 0.5));
		Point2i left((int)(muv.x - normal.x + 0.5), (int)(muv.y - normal.y + 0.5));
		if (hit[right.x + right.y*width] && hit[left.x + left.y*width])
			continue;
		else
			occludingcontour.push_back(vid1), occludingcontour.push_back(vid2);
	}

	sort(occludingcontour.begin(), occludingcontour.end());
	std::vector<int>::iterator it = unique(occludingcontour.begin(), occludingcontour.end());
	occludingcontour.resize(std::distance(occludingcontour.begin(), it));

	if (memCreated)
		delete[]hit;
	return occludingcontour;
}
vector<int> RasterizeMesh4OccludingContour(Point2d *vuv, int nVertices, int width, int height, vector<Point3i> &vfaces, vector<Point2i> &vConnections, bool *hit)
{
	bool memCreated = false;
	if (hit == NULL)
	{
		memCreated = true;
		hit = new bool[width*height];
	}
	for (int ii = 0; ii < width*height; ii++)
		hit[ii] = 0;

	omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic, 4)
	for (int fid = 0; fid < vfaces.size(); fid++)
	{
		int vid1 = vfaces[fid].x, vid2 = vfaces[fid].y, vid3 = vfaces[fid].z;
		Point2f uv1 = vuv[vid1], uv2 = vuv[vid2], uv3 = vuv[vid3];
		if (uv1.x < 1 || uv2.x < 1 || uv3.x < 1)
			continue;
		int maxX = min((int)(max(max(max(0, uv1.x), uv2.x), uv3.x)) + 1, width - 1);
		int minX = max((int)(min(min(min(width - 1, uv1.x), uv2.x), uv3.x)) + 1, 0);
		int maxY = min((int)(max(max(max(0, uv1.y), uv2.y), uv3.y)) + 1, height - 1);
		int minY = max((int)(min(min(min(height - 1, uv1.y), uv2.y), uv3.y)) + 1, 0);
		for (int jj = minY; jj <= maxY; jj++)
			for (int ii = minX; ii < maxX; ii++)
				if (PointInTriangle(uv1, uv2, uv3, Point2f(ii, jj)))
					hit[ii + jj * width] = 1;
	}

	vector<int> occludingcontour;
#pragma omp parallel for schedule(dynamic, 4)
	for (int con = 0; con < vConnections.size(); con++)
	{
		int vid1 = vConnections[con].x, vid2 = vConnections[con].y;
		if (vuv[vid1].x < 3 || vuv[vid1].x >width - 3 || vuv[vid1].y<3 || vuv[vid1].y>height - 3 || vuv[vid2].x < 3 || vuv[vid2].x >width - 3 || vuv[vid2].y<3 || vuv[vid2].y>height - 3)
			continue;
		Point2f muv = 0.5*(vuv[vid1] + vuv[vid2]);

		Point2f normal(-(vuv[vid1].y - vuv[vid2].y), vuv[vid1].x - vuv[vid2].x);
		double norm = sqrt(normal.x*normal.x + normal.y*normal.y);
		normal.x = normal.x / norm, normal.y = normal.y / norm;

		Point2i right((int)(muv.x + normal.x + 0.5), (int)(muv.y + normal.y + 0.5));
		Point2i left((int)(muv.x - normal.x + 0.5), (int)(muv.y - normal.y + 0.5));
		if (hit[right.x + right.y*width] && hit[left.x + left.y*width])
			continue;
		else
		{
#pragma omp critical
			occludingcontour.push_back(vid1), occludingcontour.push_back(vid2);
		}
	}

	sort(occludingcontour.begin(), occludingcontour.end());
	std::vector<int>::iterator it = unique(occludingcontour.begin(), occludingcontour.end());
	occludingcontour.resize(std::distance(occludingcontour.begin(), it));

	bool debug = false;
	if (debug)
	{
		SaveDataToImage("C:/temp/mask.png", hit, width, height);
		FILE *fp = fopen("C:/temp/uv.txt", "w");
		for (int ii = 0; ii < occludingcontour.size(); ii++)
			fprintf(fp, "%.3f %.3f\n", vuv[occludingcontour[ii]].x, vuv[occludingcontour[ii]].y);
		fclose(fp);
	}

	if (memCreated)
		delete[]hit;
	return occludingcontour;
}


int GenerateADOBECONDORjob(const char *DataName, char *DockerPath, char *command, int jobID, int numCore)
{
	char Fname[4096];
	sprintf(Fname, "%s/%s", DockerPath, DataName); makeDir(Fname);

	//Gen .condor file
	sprintf(Fname, "%s/%s/%.6d.condor", DockerPath, DataName, jobID); FILE *fp = fopen(Fname, "w");
	fprintf(fp, "condor_job_size = %d\n", numCore);
	fprintf(fp, "Getenv = True\n");
	fprintf(fp, "universe = docker\n\n");
	fprintf(fp, "docker_image = docker.io/minhpvo/all:v1\n");
	fprintf(fp, "Executable = ./%s/%.6d.sh\n", DataName, jobID);
	fprintf(fp, "Arguments = $(Process) $(condor_job_size)\n\n");
	fprintf(fp, "LogDir = log\n");
	fprintf(fp, "Output = $(LogDir)/docker.$(Cluster).$(Process).out\n");
	fprintf(fp, "Error = $(LogDir)/docker.$(Cluster).$(Process).err\n");
	fprintf(fp, "should_transfer_files = no\n");
	fprintf(fp, "transfer_executable = false\n");
	fprintf(fp, "Queue $(condor_job_size)\n");
	fclose(fp);

	//Gen .sh file
	sprintf(Fname, "%s/%s/%.6d.sh", DockerPath, DataName, jobID); fp = fopen(Fname, "w");
	fprintf(fp, "#!/bin/bash -f\n");
	fprintf(fp, "host=$(echo $(hostname) | grep -o 'ilcomp[0-9a-z][0-9a-z]*')\n");
	fprintf(fp, "slot=$(echo $_CONDOR_SLOT | grep -o '[0-9]*')\n");
	fprintf(fp, "echo \"on $host, slot $slot\"\n");
	fprintf(fp, "echo \"$1 out of $2 job\"\n\n");
	fprintf(fp, "# info\n");
	fprintf(fp, "lsb_release -a\n");
	fprintf(fp, "nvidia-smi -L\n");
	fprintf(fp, "echo $USER\n");
	fprintf(fp, "echo \"home folder $HOME\"\n");
	fprintf(fp, "wd=$(pwd)\n");
	fprintf(fp, "echo \"current folder $wd\"\n\n");
	fprintf(fp, "# uid\n");
	fprintf(fp, "echo \"$USER:x : $(id - u) : $(id - g)::$HOME:/bin/bash\" >>/etc/passwd\n");
	fprintf(fp, "id\n\n");
	fprintf(fp, "# ssh\n");
	fprintf(fp, "export HOME=$HOME\n");
	fprintf(fp, "cp $HOME/.ssh/authorized_keys /home/$USER/.ssh/authorized_keys\n");
	fprintf(fp, "sshd=$(which sshd)\n");
	fprintf(fp, "portssh=2000\n");
	fprintf(fp, "portssh2=$(($portssh-2000+2000*$slot))\n");
	fprintf(fp, "$sshd -p $portssh -f ${wd}/config/ssh_config -o HostKey=${wd}/config/ssh_host_dsa_key -o HostKey=${wd}/config/ssh_host_rsa_key -o AllowUsers = ${USER}\n");
	fprintf(fp, "echo \"[ssh] running on ${host} -p ${portssh2}\"\n\n");
	fprintf(fp, "# notebook\n");
	fprintf(fp, "portnt=2001\n");
	fprintf(fp, "portnt2=$(($portnt-2000+2000*$slot))\n");
	fprintf(fp, "export JUPYTER_CONFIG_DIR=${wd}/config\n");
	fprintf(fp, "unset XDG_RUNTIME_DIR\n");
	fprintf(fp, "jupyter notebook --port=${portnt} &\n");
	fprintf(fp, "echo \"[notebook] running on https ://${host}:${portnt2}\"\n");
	fprintf(fp, "\n#Actual job\n");
	fprintf(fp, "%s\n\n", command); //must be the the the directory where condor_submit is being called
									//fprintf(fp, "exit\n");
	fprintf(fp, "while true\n");
	fprintf(fp, "do\n");
	fprintf(fp, "echo .\n");
	fprintf(fp, "sleep 100\n");
	fprintf(fp, "done\n");
	fclose(fp);

	sprintf(Fname, "chmod +x %s/%s/%.6d.sh", DockerPath, DataName, jobID); system(Fname);

	//submit
	//printLOG("Submit job %.6d: %s\n", jobID, command);
	//sprintf(Fname, "condor_submit %s/job_%.6d.condor", Path); system(Fname);
	//mySleep(100);

	return 0;
}

int MousePosX, MousePosY, clicked;
static void onMouse(int event, int x, int y, int, void*)
{
	if (event == EVENT_LBUTTONDBLCLK)
	{
		clicked = 1, MousePosX = x, MousePosY = y;
		printLOG("Selected: %d %d\n", x, y);
		cout << "\a";
	}
}

int SequenceSaverViewer(char *Path, int cid)
{
	char Fname[2000];
	int WBlock = 1920, HBlock = 1080, nBlockX = 1, nchannels = 3;
	int vStart = 0, vStop = 1, vRun = 0, tStart = 1, tStop = 2000, tRun = 0;

	//Create display window
	namedWindow("Sequence", CV_WINDOW_NORMAL);
	cvSetWindowProperty("Sequence", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
	createTrackbar("Save", "Sequence", &vRun, vStop, NULL);
	createTrackbar("Time", "Sequence", &tRun, tStop - 1, NULL);

	sprintf(Fname, "%s/%d/c", Path, cid); makeDir(Fname);

	int ovRun = -1, otRun = -1;
	Mat Img;
	while (waitKey(17) != 27)
	{
		cvSetTrackbarPos("Save", "Sequence", vRun);
		cvSetTrackbarPos("Time", "Sequence", tRun);
		sprintf(Fname, "%s/%d/d/%.4d.png", Path, cid, tRun);
		if (tRun != otRun)
		{
			otRun = tRun;
			Img = imread(Fname);
			if (Img.empty() == 0)
				imshow("Sequence", Img);
		}
		if (vRun != ovRun)
		{
			ovRun = vRun,
				sprintf(Fname, "%s/%d/c/%.4d.png", Path, cid, tRun); imwrite(Fname, Img);
		}
	}

	return 0;
}
int SpaceTimeDomeViewer(char *Path)
{
	char Fname[2000];
	int WBlock = 1920, HBlock = 1080, nBlockX = 1, nchannels = 3;
	int vStart = 0, vStop = 40, vRun = vStart + 1, tStart = 960, tStop = 1000, tRun = tStart + 1;

	//Create display window
	namedWindow("Sequence", CV_WINDOW_NORMAL);
	cvSetWindowProperty("Sequence", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
	createTrackbar("Space", "Sequence", &vRun, vStop, NULL);
	createTrackbar("Time", "Sequence", &tRun, tStop - 1, NULL);

	Mat Img;
	int ovRun = -1, otRun = -1;
	while (waitKey(17) != 27)
	{
		cvSetTrackbarPos("Space", "Sequence", vRun), cvSetTrackbarPos("Time", "Sequence", tRun);
		sprintf(Fname, "%s/%.8d/%.8d_00_%.2d.png", Path, tRun, tRun, vRun);
		if (vRun != ovRun || tRun != otRun)
		{
			ovRun = vRun, otRun = tRun;
			Img = imread(Fname);
			if (!Img.empty())
				imshow("Sequence", Img);
		}
	}

	return 0;
}
static void drawArrows(Mat& frame, Point2f  prevPts, Point2f nextPts, Scalar line_color, int line_thickness)
{
	Point p = prevPts;
	Point q = nextPts;

	double angle = atan2((double)p.y - q.y, (double)p.x - q.x);
	double hypotenuse = sqrt((double)(p.y - q.y)*(p.y - q.y) + (double)(p.x - q.x)*(p.x - q.x));

	// Here we lengthen the arrow by a factor of three.
	q.x = (int)(p.x - 1 * hypotenuse * cos(angle));
	q.y = (int)(p.y - 1 * hypotenuse * sin(angle));

	// Now we draw the main line of the arrow.
	line(frame, p, q, line_color, line_thickness);

	// Now draw the tips of the arrow. I do some scaling so that the  tips look proportional to the main line of the arrow.

	p.x = (int)(2.0*cos(angle + CV_PI / 8) + q.x);
	p.y = (int)(2.0*sin(angle + CV_PI / 8) + q.y);
	line(frame, p, q, line_color, line_thickness);

	p.x = (int)(2.0*cos(angle - CV_PI / 8) + q.x);
	p.y = (int)(2.0*sin(angle - CV_PI / 8) + q.y);
	line(frame, p, q, line_color, line_thickness);
}
void VisualizeCleanMatches(char *Path, int view1, int view2, int timeID, double fractionMatchesDisplayed, int frameTimeStamp1, int frameTimeStamp2)
{
	char Fname[512];
	if (timeID < 0)
		sprintf(Fname, "%s/Corpus/M_%.2d_%.2d.txt", Path, view1, view2);
	else
		sprintf(Fname, "%s/Dynamic/%d.4d/M_%.2d_%.2d.txt", Path, timeID, view1, view2);

	vector<Point2i> PairWiseMatchID; PairWiseMatchID.reserve(10000);
	int id1, id2, npts;
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return;
	}
	fscanf(fp, "%d ", &npts);
	PairWiseMatchID.reserve(npts);
	while (fscanf(fp, "%d %d ", &id1, &id2) != EOF)
		PairWiseMatchID.push_back(Point2i(id1, id2));
	fclose(fp);

	if (timeID < 0)
		sprintf(Fname, "%s/Corpus/%.4d.kpts", Path, view1);
	else
		sprintf(Fname, "%s/%d/%.4d.kpts", Path, view1, timeID - frameTimeStamp1);

	bool readsucces = false;
	vector<KeyPoint> keypoints1; keypoints1.reserve(MaxNFeatures);
	readsucces = ReadKPointsBinarySIFT(Fname, keypoints1);
	if (!readsucces)
	{
		printLOG("%s does not have SIFT points. Please precompute it!\n", Fname);
		return;
	}

	if (timeID < 0)
		sprintf(Fname, "%s/Corpus/%.4d.kpts", Path, view2);
	else
		sprintf(Fname, "%s/%d/%.4d.kpts", Path, view2, timeID - frameTimeStamp2);
	vector<KeyPoint> keypoints2; keypoints2.reserve(MaxNFeatures);
	readsucces = ReadKPointsBinarySIFT(Fname, keypoints2);
	if (!readsucces)
	{
		printLOG("%s does not have SIFT points. Please precompute it!\n", Fname);
		return;
	}

	vector<int> CorresID;
	for (int i = 0; i < PairWiseMatchID.size(); ++i)
		CorresID.push_back(PairWiseMatchID[i].x), CorresID.push_back(PairWiseMatchID[i].y);

	int nchannels = 3;
	if (timeID < 0)
	{
		sprintf(Fname, "%s/Corpus/%.4d.jpg", Path, view1);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/Corpus/%.4d.png", Path, view1);
	}
	else
	{
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, view1, timeID - frameTimeStamp1);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.png", Path, view1, timeID - frameTimeStamp1);
	}
	Mat Img1 = imread(Fname, nchannels == 3 ? 1 : 0);
	if (Img1.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return;
	}
	if (timeID < 0)
	{
		sprintf(Fname, "%s/Corpus/%.4d.jpg", Path, view2);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/Corpus/%.4d.png", Path, view2);
	}
	else
	{
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, view2, timeID - frameTimeStamp2);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.png", Path, view2, timeID - frameTimeStamp2);
	}
	Mat Img2 = imread(Fname, nchannels == 3 ? 1 : 0);
	if (Img2.empty() == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return;
	}

	cv::Mat correspond(max(Img1.rows, Img2.rows), Img1.cols + Img2.cols, CV_8UC3);
	cv::Rect rect1(0, 0, Img1.cols, Img1.rows);
	cv::Rect rect2(Img1.cols, 0, Img1.cols, Img1.rows);

	Img1.copyTo(correspond(rect1));
	Img2.copyTo(correspond(rect2));

	DisplayImageCorrespondence(correspond, Img1.cols, 0, keypoints1, keypoints2, CorresID, fractionMatchesDisplayed);

	return;
}
void VisualizeCleanMatches2(char *Path, int view1, int view2, int timeID, double fractionMatchesDisplayed)
{
	char Fname[512];
	vector<KeyPoint> keypoints1, keypoints2;
	int pid, fid1, fid2; float u, v, s, a;

	sprintf(Fname, "%s/Dynamic/K2_%d_%.4d.txt", Path, view1, timeID);
	if (IsFileExist(Fname) == 0)
		return;
	FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d %f %f %f %f", &pid, &fid1, &u, &v, &s, &a) != EOF)
		keypoints1.push_back(KeyPoint(u, v, s));
	fclose(fp);

	sprintf(Fname, "%s/Dynamic/K2_%d_%.4d.txt", Path, view2, timeID);
	if (IsFileExist(Fname) == 0)
		return;
	fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d %f %f %f %f", &pid, &fid2, &u, &v, &s, &a) != EOF)
		keypoints2.push_back(KeyPoint(u, v, s));
	fclose(fp);

	if ((int)keypoints1.size() == 0 || (int)keypoints2.size() == 0)
		return;

	vector<int> CorresID;
	for (int i = 0; i < (int)keypoints2.size(); ++i)
		CorresID.push_back(i), CorresID.push_back(i);

	int nchannels = 3;
	sprintf(Fname, "%s/%d/%.4d.jpg", Path, view1, fid1);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/%d/%.4d.png", Path, view1, fid1);
	Mat Img1 = imread(Fname, nchannels == 3 ? 1 : 0);
	if (Img1.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return;
	}

	sprintf(Fname, "%s/%d/%.4d.jpg", Path, view2, fid2);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/%d/%.4d.png", Path, view2, fid2);
	Mat Img2 = imread(Fname, nchannels == 3 ? 1 : 0);
	if (Img2.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return;
	}

	cv::Mat correspond(max(Img1.rows, Img2.rows), Img1.cols + Img2.cols, CV_8UC3);
	cv::Rect rect1(0, 0, Img1.cols, Img1.rows);
	cv::Rect rect2(Img1.cols, 0, Img1.cols, Img1.rows);

	Img1.copyTo(correspond(rect1));
	Img2.copyTo(correspond(rect2));

	DisplayImageCorrespondence(correspond, Img1.cols, 0, keypoints1, keypoints2, CorresID, fractionMatchesDisplayed);

	return;
}
int VisualizePnPMatches(char *Path, int cameraID, int timeID)
{
	char Fname[512];
	Corpus CorpusInfo;
	sprintf(Fname, "%s/Corpus", Path);	ReadCorpusInfo(Fname, CorpusInfo, false, false);

	int npts, threeDid, ptsCount = 0;
	double u, v, scale;
	sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, cameraID, timeID); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return -1;
	}
	fscanf(fp, "%d ", &npts);
	vector<int> threeDidVec;
	Point2d *pts = new Point2d[npts];
	Point3d *t3D = new Point3d[npts];
	while (fscanf(fp, "%d %lf %lf ", &threeDid, &u, &v, &scale) != EOF)
	{
		threeDidVec.push_back(threeDid);
		pts[ptsCount].x = u, pts[ptsCount].y = v;
		ptsCount++;
	}
	fclose(fp);

	printLOG("Reading corpus images....\n");
	Mat Img;
	Mat *CorpusImg = new Mat[CorpusInfo.nCameras];
	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
	{
		sprintf(Fname, "%s/Corpus/%.4d.png", Path, ii);	 CorpusImg[ii] = imread(Fname);
		if (CorpusImg[ii].empty())
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
	}
	sprintf(Fname, "%s/%d/%.4d.png", Path, cameraID, timeID);	Img = imread(Fname);
	if (Img.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}

	Scalar colors(0, 0, 255);
	namedWindow("PnPTest", CV_WINDOW_NORMAL);
	cv::Mat BImage(Img.rows, Img.cols * 2, Img.type());
	for (int ii = 0; ii < threeDidVec.size(); ii++)
	{
		threeDid = threeDidVec[ii];
		int viewID = CorpusInfo.viewIdAll3D[threeDid][0];
		Point2d uv = CorpusInfo.uvAll3D[threeDid][0];

		Img.copyTo(BImage(cv::Rect(0, 0, Img.cols, Img.rows)));
		CorpusImg[viewID].copyTo(BImage(cv::Rect(Img.cols, 0, Img.cols, Img.rows)));

		circle(BImage, cv::Point(pts[ii].x, pts[ii].y), 3, colors[0], 8);
		circle(BImage, cv::Point(uv.x + Img.cols, uv.y), 3, colors[0], 8);

		imshow("PnPTest", BImage);
		waitKey(-1);
	}

	return 0;
}
int VisualizeKeyFrameCorpusFeatures(char *Path, double resizeFactor)
{
	char Fname[512];

	static cv::Scalar colors[] = { Scalar(0, 0, 255), Scalar(0, 128, 255), Scalar(0, 255, 255), Scalar(0, 255, 0), Scalar(255, 128, 0), Scalar(255, 255, 0), Scalar(255, 0, 0), Scalar(255, 0, 255), Scalar(255, 255, 255) };

	int threeDid, twoDid;
	double x, y, z, u, v, s = 1.0;
	vector<int> threeDidVec;
	vector<float> Vscale;
	vector<Point2f> Vuv;
	Mat img, rimg;

	CvSize size;

	//namedWindow("Inliers", CV_WINDOW_NORMAL);

	bool firstTime = true;
	VideoWriter writer;

	int keyFrameID = 0;
	while (true)
	{
		int fromKeyFrameTrackingStep = 0;
		threeDidVec.clear(), Vuv.clear(), Vscale.clear();
		Point2f uv; float s;
		sprintf(Fname, "%s/Corpus/CorpusK_%.4d.txt", Path, keyFrameID); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			break;
		while (fscanf(fp, "%d %f %f %f %d", &threeDid, &uv.x, &uv.y, &s, &twoDid) != EOF)
		{
			threeDidVec.push_back(threeDid);
			Vuv.push_back(uv);
			Vscale.push_back(s);
		}
		fclose(fp);


		sprintf(Fname, "%s/Corpus/%.4d.png", Path, keyFrameID);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/Corpus/%.4d.jpg", Path, keyFrameID);
			if (IsFileExist(Fname) == 0)
				break;
		}
		img = imread(Fname);
		if (firstTime)
		{
			firstTime = false;
			size.width = (int)(resizeFactor*img.cols), size.height = (int)(resizeFactor*img.rows);
			printLOG(Fname, "%s/Vis", Path); makeDir(Fname);
			sprintf(Fname, "%s/Vis/kCorpusMatchingVis.avi", Path);
			writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
		}

		for (int ii = 0; ii < (int)Vuv.size(); ii++)
			circle(img, Vuv[ii], (int)(Vscale[ii] + 0.5), colors[threeDidVec[ii] % 9], 2);
		//sprintf(Fname, "%s/%d/CorpusMatchingVis/%.4d.jpg", Path, camID, fid); imwrite(Fname, img);

		CvPoint text_origin = { img.cols / 30, img.cols / 30 };
		sprintf(Fname, "Frame %d: %d", keyFrameID, (int)Vuv.size());
		putText(img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * img.cols / 640, CV_RGB(255, 0, 0), 3);
		//imshow("Inliers", img); waitKey(1);
		resize(img, rimg, Size((int)(resizeFactor* img.cols), (int)(resizeFactor*img.rows)), 0, 0, INTER_AREA);
		writer << rimg;

		printLOG("%d..", keyFrameID);
		keyFrameID++;
	}
	writer.release();

	//destroyAllWindows();

	return 0;
}
int VisualizeCorpusFeaturesAcrossVideoCamera(char *Path, int nCams, int startF, int stopF, int increF)
{
	char Fname[512];

	static cv::Scalar colors[] = { Scalar(0, 0, 255), Scalar(0, 128, 255), Scalar(0, 255, 255), Scalar(0, 255, 0), Scalar(255, 128, 0), Scalar(255, 255, 0), Scalar(255, 0, 0), Scalar(255, 0, 255), Scalar(255, 255, 255) };

	int threeDid, gpid, lpid;
	Point3d xyz; Point2d uv; double s = 1.0;
	vector<int> threeDidVec; vector<double> Vscale;
	vector<Point2d> Vuv; vector<Point3d> Vxyz;
	Mat img;

	CvSize size;

	//namedWindow("Inliers", CV_WINDOW_NORMAL);
	for (int camID = 0; camID < nCams; camID++)
	{
		printLOG("Working on Cam %d\n", camID);
		//sprintf(Fname, "%s/%d/CorpusMatchingVis", Path, camID); makeDir(Fname);
		bool firstTime = false;
		VideoWriter writer;
		for (int fid = startF; fid <= stopF; fid += increF)
		{
			int fromKeyFrameTrackingStep = 0;
			threeDidVec.clear(), Vuv.clear(), Vxyz.clear(), Vscale.clear();

			sprintf(Fname, "%s/%d/PnPf/Inliers_%.4d.txt", Path, camID, fid);
			if (IsFileExist(Fname) == 0)
				continue;

			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d %lf %lf %lf %lf %lf %lf ", &gpid, &lpid, &xyz.x, &xyz.y, &xyz.z, &uv.x, &uv.y, &s) != EOF)
			{
				threeDidVec.push_back(lpid);
				Vuv.push_back(uv);
				Vscale.push_back(s);
			}
			fclose(fp);

			sprintf(Fname, "%s/%d/%.4d.jpg", Path, camID, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid);
				if (IsFileExist(Fname) == 0)
					continue;
			}
			img = imread(Fname);
			if (img.empty() == 0 && !firstTime)
			{
				firstTime = true;
				size.width = img.cols, size.height = img.rows;
				if (fromKeyFrameTrackingStep == 0)
					sprintf(Fname, "%s/Vis/CorpusMatchingVis_%d.avi", Path, camID);
				else
					sprintf(Fname, "%s/Vis/gCorpusMatchingVis_%d.avi", Path, camID);
				writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 60, size);
			}

			for (int ii = 0; ii < (int)Vuv.size(); ii++)
				circle(img, Vuv[ii], max(1, (int)(Vscale[ii] + 0.5)), colors[threeDidVec[ii] % 9], 2), circle(img, Vuv[ii], 1, colors[threeDidVec[ii] % 9], 1);
			//sprintf(Fname, "%s/%d/CorpusMatchingVis/%.4d.jpg", Path, camID, fid); imwrite(Fname, img);

			CvPoint text_origin = { img.cols / 30, img.cols / 30 };
			sprintf(Fname, "Frame %d/%d: %d", camID, fid, Vuv.size());
			putText(img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * img.cols / 640, CV_RGB(255, 0, 0), 3);
			//imshow("Inliers", img); waitKey(1);
			writer << img;
		}
		writer.release();
	}

	//destroyAllWindows();

	return 0;
}
int VisualizeTracking(char *Path, int viewID, int startF, int increF, double fps, double trackingTime, int module, int drawScale, int trueStartF, int DenseDriven)
{
	char Fname[512];
	int pid, fid, nf;
	Point2f uv;
	float s;
	Mat colorImg(1080, 1920, CV_8UC3, Scalar(0, 0, 0));

	static cv::Scalar colors[] = { Scalar(0, 0, 255), Scalar(0, 128, 255), Scalar(0, 255, 255), Scalar(0, 255, 0), Scalar(255, 128, 0), Scalar(255, 255, 0), Scalar(255, 0, 0), Scalar(255, 0, 255), Scalar(255, 255, 255) };

	char *InsertC;
	if (DenseDriven == 0)
		InsertC = "";
	else
		InsertC = "D";

	namedWindow("X", cv::WINDOW_NORMAL);
	cvSetWindowProperty("X", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);

	CvPoint text_origin = { colorImg.cols / 30, colorImg.rows / 2 };
	sprintf(Fname, "Working on frame %d of cam %d", startF, viewID);
	putText(colorImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * colorImg.cols / 320, CV_RGB(255, 0, 0), 3);
	imshow("X", colorImg);  waitKey(1);
	if (module == 0)
	{
		sprintf(Fname, "%s/%d/%.4d%s", Path, viewID, startF, InsertC); makeDir(Fname);
		int maxPts = 50000;
		//draw fore-track images
		{
			int trueStartF;
			sprintf(Fname, "%s/Track2D/%sFT_%d_%.4d.txt", Path, InsertC, viewID, startF); FILE *fp = fopen(Fname, "r");
			if (IsFileExist(Fname) == 0)
				return 1;
			fscanf(fp, "%d %d %d %d", &maxPts, &pid, &nf, &trueStartF);
			fclose(fp);

			int ForeTrackRange = (int)(fps*trackingTime);
			Mat *ForeImage = new Mat[ForeTrackRange + 1];
			for (int ii = 0; ii < ForeTrackRange + 1; ii++)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, ii *increF + trueStartF);
				if (IsFileExist(Fname) == 0)
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, ii *increF + trueStartF);
				ForeImage[ii] = imread(Fname, 0);
				if (ForeImage[ii].empty())
				{
					ForeTrackRange = ii;
					break;
				}
			}

			Point2f *ForeTrackUV = new Point2f[ForeTrackRange*maxPts];
			float *scale = new float[ForeTrackRange*maxPts];
			for (int ii = 0; ii < ForeTrackRange*maxPts; ii++)
				ForeTrackUV[ii] = Point2f(-1, -1);

			sprintf(Fname, "%s/Track2D/%sFT_%d_%.4d.txt", Path, InsertC, viewID, startF);   fp = fopen(Fname, "r");
			int ptsCount = 0;
			vector<int> orgID; orgID.reserve(5000);
			fscanf(fp, "%d ", &maxPts);
			while (fscanf(fp, "%d %d ", &pid, &nf) != EOF)
			{
				orgID.push_back(pid);
				for (int ii = 0; ii < nf; ii++)
				{
					fscanf(fp, "%d %f %f %f ", &fid, &uv.x, &uv.y, &s);
					float dummy;	fscanf(fp, "%f %f %f %f %f ", &dummy, &dummy, &dummy, &dummy, &dummy);
					//if (nf > ForeTrackRange / 6)
					ForeTrackUV[ptsCount*ForeTrackRange + (fid - trueStartF) / increF] = uv, scale[ptsCount*ForeTrackRange + (fid - trueStartF) / increF] = s;
				}
				ptsCount++;
			}
			fclose(fp);


			vector<Point2i> pointstack;
			for (int fid = 0; fid < ForeTrackRange; fid++)
			{
				int nvalid = 0;
				for (int pid = 0; pid < ptsCount; pid++)
					if (ForeTrackUV[pid*ForeTrackRange + fid].x > 0.0 && ForeTrackUV[pid*ForeTrackRange + fid].y > 0.0)
						nvalid++;

				if (nvalid == 0)
					break;

				cvtColor(ForeImage[fid], colorImg, CV_GRAY2BGR);
				if (fid == 0)
				{
					for (int pid = 0; pid < ptsCount; pid++)
						if (ForeTrackUV[pid*ForeTrackRange + fid].x > 0.0 && ForeTrackUV[pid*ForeTrackRange + fid].y > 0.0)
							circle(colorImg, ForeTrackUV[pid*ForeTrackRange + fid], 1, colors[orgID[pid] % 9], 2);
				}
				else
				{
					for (int pid = 0; pid < maxPts; pid++)
					{
						pointstack.clear();
						for (int fid2 = 10; fid2 > -1; fid2--)
						{
							if (ForeTrackUV[pid*ForeTrackRange + fid].x < 0 || ForeTrackUV[pid*ForeTrackRange + fid].y < 0)
								continue;
							if (fid - fid2 >= 0 && ForeTrackUV[pid*ForeTrackRange + fid - fid2].x > 0.0 && ForeTrackUV[pid*ForeTrackRange + fid - fid2].y > 0.0)
								pointstack.push_back(ForeTrackUV[pid*ForeTrackRange + fid - fid2]);
						}

						for (int ii = 0; ii < (int)pointstack.size() - 1; ii++)
							line(colorImg, pointstack[ii], pointstack[ii + 1], colors[pid % 9], 1, CV_AA);
					}
				}
				if (drawScale == 1)
				{
					for (int pid = 0; pid < ptsCount; pid++)
						if (ForeTrackUV[pid*ForeTrackRange + fid].x > 0.0 && ForeTrackUV[pid*ForeTrackRange + fid].y > 0.0)
							circle(colorImg, ForeTrackUV[pid*ForeTrackRange + fid], (int)(3.0*scale[pid*ForeTrackRange + fid] + 0.5), colors[pid % 9], 1);
				}
				sprintf(Fname, "%s/%d/%.4d%s/F_%.4d.jpg", Path, viewID, startF, InsertC, fid*increF + trueStartF);
				imwrite(Fname, colorImg);

				imshow("X", colorImg); waitKey(1);
			}

			delete[]scale;
			delete[]ForeImage;
			delete[]ForeTrackUV;
		}

		//draw back-track images
		{
			int trueStartF;
			sprintf(Fname, "%s/Track2D/%sBT_%d_%.4d.txt", Path, InsertC, viewID, startF);  FILE *fp = fopen(Fname, "r");
			if (IsFileExist(Fname) == 0)
				return 1;
			fscanf(fp, "%d %d %d %d", &maxPts, &pid, &nf, &trueStartF);
			fclose(fp);

			int BackTrackRange = (int)(fps*trackingTime);
			Mat *BackImage = new Mat[BackTrackRange + 1];
			for (int ii = 0; ii < BackTrackRange + 1; ii++)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, -ii * increF + trueStartF);
				if (IsFileExist(Fname) == 0)
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, -ii * increF + trueStartF);
				BackImage[ii] = imread(Fname, 0);
				if (BackImage[ii].empty())
				{
					BackTrackRange = ii;
					break;
				}
			}

			Point2f *BackTrackUV = new Point2f[BackTrackRange*maxPts];
			float *scale = new float[BackTrackRange*maxPts];
			for (int ii = 0; ii < BackTrackRange*maxPts; ii++)
				BackTrackUV[ii] = Point2f(-1, -1);

			sprintf(Fname, "%s/Track2D/%sBT_%d_%.4d.txt", Path, InsertC, viewID, startF);  fp = fopen(Fname, "r");
			int ptsCount = 0;
			vector<int> orgID; orgID.reserve(5000);
			fscanf(fp, "%d ", &maxPts);
			while (fscanf(fp, "%d %d", &pid, &nf) != EOF)
			{
				orgID.push_back(pid);
				for (int ii = 0; ii < nf; ii++)
				{
					fscanf(fp, "%d %f %f %f ", &fid, &uv.x, &uv.y, &s);
					float dummy;	fscanf(fp, "%f %f %f %f %f ", &dummy, &dummy, &dummy, &dummy, &dummy);
					//if (nf > BackTrackRange / 6)
					BackTrackUV[ptsCount*BackTrackRange + (-fid + trueStartF) / increF] = uv, scale[ptsCount*BackTrackRange + (-fid + trueStartF) / increF] = s;
				}
				ptsCount++;
			}
			fclose(fp);

			vector<Point2i> pointstack;
			for (int fid = 0; fid < BackTrackRange; fid++)
			{
				int nvalid = 0;
				for (int pid = 0; pid < ptsCount; pid++)
					if (BackTrackUV[pid*BackTrackRange + fid].x > 0.0 && BackTrackUV[pid*BackTrackRange + fid].y > 0.0)
						nvalid++;

				if (nvalid == 0)
					break;

				cvtColor(BackImage[fid], colorImg, CV_GRAY2BGR);
				if (fid == 0)
				{
					for (int pid = 0; pid < ptsCount; pid++)
						if (BackTrackUV[pid*BackTrackRange + fid].x > 0.0 && BackTrackUV[pid*BackTrackRange + fid].y > 0.0)
							circle(colorImg, BackTrackUV[pid*BackTrackRange + fid], 1, colors[orgID[pid] % 9], 2);
				}
				else
				{
					for (int pid = 0; pid < ptsCount; pid++)
					{
						pointstack.clear();
						for (int fid2 = 10; fid2 > -1; fid2--)
						{
							if (BackTrackUV[pid*BackTrackRange + fid].x < 0 || BackTrackUV[pid*BackTrackRange + fid].y < 0)
								continue;
							if (fid - fid2 >= 0 && BackTrackUV[pid*BackTrackRange + fid - fid2].x > 0.0 && BackTrackUV[pid*BackTrackRange + fid - fid2].y > 0.0)
								pointstack.push_back(BackTrackUV[pid*BackTrackRange + fid - fid2]);
						}

						for (int ii = 0; ii < (int)pointstack.size() - 1; ii++)
							line(colorImg, pointstack[ii], pointstack[ii + 1], colors[pid % 9], 1, CV_AA);
					}
				}
				if (drawScale == 1)
				{
					for (int pid = 0; pid < ptsCount; pid++)
						if (BackTrackUV[pid*BackTrackRange + fid].x > 0.0 && BackTrackUV[pid*BackTrackRange + fid].y > 0.0)
							circle(colorImg, BackTrackUV[pid*BackTrackRange + fid], (int)(3.0*scale[pid*BackTrackRange + fid] + 0.5), colors[pid % 9], 1);
				}
				sprintf(Fname, "%s/%d/%d%s/B_%.4d.jpg", Path, viewID, startF, InsertC, -fid * increF + trueStartF);
				//imwrite(Fname, colorImg);
				imshow("X", colorImg); waitKey(1);
			}

			delete[]scale;
			delete[]BackImage;
			delete[]BackTrackUV;
		}
	}
	else if (module == 1)
	{
		sprintf(Fname, "%s/%d/%d%s", Path, viewID, startF, InsertC); makeDir(Fname);
		sprintf(Fname, "%s/Track2D/C_%d_%.4d.txt", Path, viewID, startF);
		FILE *fp = fopen(Fname, "r");
		if (IsFileExist(Fname) == 0)
			return 1;
		int npts; fscanf(fp, "%d ", &npts);

		int TrackRange = fps * trackingTime;
		Point2f *TrackUV = new Point2f[2 * TrackRange*npts];
		for (int ii = 0; ii < 2 * TrackRange*npts; ii++)
			TrackUV[ii] = Point2f(-1, -1);

		int pCount = 0;
		while (fscanf(fp, "%d %d", &pid, &nf) != EOF)
		{
			for (int ii = 0; ii < nf; ii++)
			{
				float dummy;	fscanf(fp, "%d %f %f %f %f %f %f %f %f ", &fid, &uv.x, &uv.y, &s, &dummy, &dummy, &dummy, &dummy, &dummy);
				int lFid = (fid - trueStartF) / increF + TrackRange;
				if (lFid<0 || lFid>TrackRange * 2)
					printLOG("Out of range @(%d, %d)\n", pid, fid);
				TrackUV[pCount * 2 * TrackRange + lFid] = uv;
			}
			pCount++;
		}
		fclose(fp);


		Mat *Img = new Mat[2 * TrackRange + 1];
		for (int ii = -TrackRange; ii <= TrackRange; ii++)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, ii*increF + trueStartF);
			if (IsFileExist(Fname) == 0)
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, ii *increF + trueStartF);
			Img[ii + TrackRange] = imread(Fname, 0);
			if (Img[ii + TrackRange].empty())
				continue;
		}

		//foreward plot
		vector<Point2i> pointstack;
		for (int fid = TrackRange; fid < 2 * TrackRange; fid++)
		{
			int nvalid = 0;
			for (int pid = 0; pid < npts; pid++)
				if (TrackUV[pid * 2 * TrackRange + fid].x > 0.0 && TrackUV[pid * 2 * TrackRange + fid].y > 0.0)
					nvalid++;

			if (nvalid == 0)
				continue;

			cvtColor(Img[fid], colorImg, CV_GRAY2BGR);
			if (fid == TrackRange)
			{
				for (int pid = 0; pid < npts; pid++)
				{
					if (TrackUV[pid * 2 * TrackRange + fid].x > 0.0 && TrackUV[pid * 2 * TrackRange + fid].y > 0.0)
						circle(colorImg, TrackUV[pid * 2 * TrackRange + fid], 1, colors[pid % 9], 2);
				}
			}
			else
			{
				for (int pid = 0; pid < npts; pid++)
				{
					pointstack.clear();
					for (int fid2 = 10; fid2 > -1; fid2--)
					{
						if (TrackUV[pid * 2 * TrackRange + fid].x < 0 || TrackUV[pid * 2 * TrackRange + fid].y < 0)
							continue;
						if (fid - fid2 >= fps * trackingTime && TrackUV[pid * 2 * TrackRange + fid - fid2].x > 0.0 && TrackUV[pid * 2 * TrackRange + fid - fid2].y > 0.0)
							pointstack.push_back(TrackUV[pid * 2 * TrackRange + fid - fid2]);
					}
					for (int ii = 0; ii < (int)pointstack.size() - 1; ii++)
						line(colorImg, pointstack[ii], pointstack[ii + 1], colors[pid % 9], 1, CV_AA);
				}
			}
			sprintf(Fname, "%s/%d/%d/F_%.4d.jpg", Path, viewID, startF, (fid - TrackRange)*increF + trueStartF);
			//imwrite(Fname, colorImg);
			imshow("X", colorImg); waitKey(5);
		}

		//backward
		for (int fid = TrackRange; fid >= 0; fid--)
		{
			int nvalid = 0;
			for (int pid = 0; pid < npts; pid++)
				if (TrackUV[pid * 2 * TrackRange + fid].x > 0.0 && TrackUV[pid * 2 * TrackRange + fid].y > 0.0)
					nvalid++;

			if (nvalid == 0)
				continue;

			cvtColor(Img[fid], colorImg, CV_GRAY2BGR);
			if (fid == TrackRange)
			{
				for (int pid = 0; pid < npts; pid++)
				{
					if (TrackUV[pid * 2 * TrackRange + fid].x > 0.0 && TrackUV[pid * 2 * TrackRange + fid].y > 0.0)
						circle(colorImg, TrackUV[pid * 2 * TrackRange + fid], 1, colors[pid % 9], 2);
				}
			}
			else
			{
				for (int pid = 0; pid < npts; pid++)
				{
					pointstack.clear();
					for (int fid2 = 10; fid2 >= 0; fid2--)
					{
						if (TrackUV[pid * 2 * TrackRange + fid].x < 0 || TrackUV[pid * 2 * TrackRange + fid].y < 0)
							continue;

						if (TrackRange - fid - fid2 >= 0 && TrackUV[pid * 2 * TrackRange + fid + fid2].x > 0.0 && TrackUV[pid * 2 * TrackRange + fid + fid2].y > 0.0)
							pointstack.push_back(TrackUV[pid * 2 * TrackRange + fid + fid2]);
					}
					for (int ii = 0; ii < (int)pointstack.size() - 1; ii++)
						line(colorImg, pointstack[ii], pointstack[ii + 1], colors[pid % 9], 1, CV_AA);
				}
			}
			sprintf(Fname, "%s/%d/%d/B_%.4d.jpg", Path, viewID, startF, (fid - TrackRange)*increF + trueStartF);
			//imwrite(Fname, colorImg);
			imshow("X", colorImg); waitKey(5);
		}

		delete[]Img;
		delete[]TrackUV;
	}
	else if (module == 2) //Harris tracking
	{
		sprintf(Fname, "%s/%d/%.4d", Path, viewID, startF); makeDir(Fname);
		int maxPts = 50000;
		//draw fore-track images
		{
			int trueStartF;
			sprintf(Fname, "%s/Harris//FT_%d_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "r");
			if (IsFileExist(Fname) == 0)
				return 1;
			fscanf(fp, "%d ", &maxPts);
			while (fscanf(fp, "%d %d", &pid, &nf) != EOF)
			{
				fscanf(fp, "%d %f %f %f ", &trueStartF, &uv.x, &uv.y, &s);
				break;
			}
			fclose(fp);

			int ForeTrackRange = (int)(fps*trackingTime);
			Mat *ForeImage = new Mat[ForeTrackRange + 1];
			for (int ii = 0; ii < ForeTrackRange + 1; ii++)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, ii *increF + trueStartF);
				if (IsFileExist(Fname) == 0)
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, ii *increF + trueStartF);
				ForeImage[ii] = imread(Fname, 0);
				if (ForeImage[ii].empty())
				{
					ForeTrackRange = ii;
					break;
				}
			}

			Point2f *ForeTrackUV = new Point2f[ForeTrackRange*maxPts];
			float *scale = new float[ForeTrackRange*maxPts];
			for (int ii = 0; ii < ForeTrackRange*maxPts; ii++)
				ForeTrackUV[ii] = Point2f(-1, -1);

			sprintf(Fname, "%s/Harris/FT_%d_%.4d.txt", Path, viewID, startF);   fp = fopen(Fname, "r");
			int ptsCount = 0;
			vector<int> orgID; orgID.reserve(5000);
			fscanf(fp, "%d ", &maxPts);
			while (fscanf(fp, "%d %d ", &pid, &nf) != EOF)
			{
				orgID.push_back(pid);
				bool pass = false;
				for (int ii = 0; ii < nf; ii++)
				{
					fscanf(fp, "%d %f %f %f ", &fid, &uv.x, &uv.y, &s);
					//if (nf > ForeTrackRange / 6)
					//if (ii == 0 && uv.x > 1242 && uv.x < 1603 && uv.y >810 && uv.y < 951)
					pass = true;
					ForeTrackUV[ptsCount*ForeTrackRange + (fid - trueStartF) / increF] = uv, scale[ptsCount*ForeTrackRange + (fid - trueStartF) / increF] = s;
				}
				//if(pass)
				ptsCount++;
			}
			fclose(fp);


			vector<Point2i> pointstack;
			for (int fid = 0; fid < ForeTrackRange; fid++)
			{
				int nvalid = 0;
				for (int pid = 0; pid < ptsCount; pid++)
					if (ForeTrackUV[pid*ForeTrackRange + fid].x > 0.0 && ForeTrackUV[pid*ForeTrackRange + fid].y > 0.0)
						nvalid++;

				if (nvalid == 0)
					break;

				cvtColor(ForeImage[fid], colorImg, CV_GRAY2BGR);
				//colorImg = ForeImage[fid].clone();
				if (fid == 0)
				{
					for (int pid = 0; pid < ptsCount; pid++)
						if (ForeTrackUV[pid*ForeTrackRange + fid].x > 0.0 && ForeTrackUV[pid*ForeTrackRange + fid].y > 0.0)
							circle(colorImg, ForeTrackUV[pid*ForeTrackRange + fid], 1, colors[orgID[pid] % 9], 2);
					//circle(colorImg, ForeTrackUV[pid*ForeTrackRange + fid], 1, colors[7], 2);
				}
				else
				{
					for (int pid = 0; pid < maxPts; pid++)
					{
						pointstack.clear();
						for (int fid2 = 18; fid2 > -1; fid2--)
						{
							if (ForeTrackUV[pid*ForeTrackRange + fid].x < 0 || ForeTrackUV[pid*ForeTrackRange + fid].y < 0)
								continue;
							if (fid - fid2 >= 0 && ForeTrackUV[pid*ForeTrackRange + fid - fid2].x > 0.0 && ForeTrackUV[pid*ForeTrackRange + fid - fid2].y > 0.0)
								pointstack.push_back(ForeTrackUV[pid*ForeTrackRange + fid - fid2]);
						}

						for (int ii = 0; ii < (int)pointstack.size() - 1; ii++)
							//line(colorImg, pointstack[ii], pointstack[ii + 1], colors[orgID[pid] % 9], 1, CV_AA);
							line(colorImg, pointstack[ii], pointstack[ii + 1], colors[7], 1, CV_AA);
					}
				}
				if (drawScale == 1)
				{
					for (int pid = 0; pid < ptsCount; pid++)
						if (ForeTrackUV[pid*ForeTrackRange + fid].x > 0.0 && ForeTrackUV[pid*ForeTrackRange + fid].y > 0.0)
							circle(colorImg, ForeTrackUV[pid*ForeTrackRange + fid], (int)(3.0*scale[pid*ForeTrackRange + fid] + 0.5), colors[pid % 9], 1);
				}
				sprintf(Fname, "%s/%d/%d%s/F_%.4d.jpg", Path, viewID, startF, InsertC, fid*increF + trueStartF);
				//sprintf(Fname, "C:/temp/F_%.4d.jpg", fid*increF + trueStartF);
				imwrite(Fname, colorImg);
			}

			delete[]scale;
			delete[]ForeImage;
			delete[]ForeTrackUV;
		}

		//draw back-track images
		{
			int trueStartF;
			sprintf(Fname, "%s/Harris//BT_%d_%.4d.txt", Path, viewID, startF);  FILE *fp = fopen(Fname, "r");
			if (IsFileExist(Fname) == 0)
				return 1;
			fscanf(fp, "%d ", &maxPts);
			while (fscanf(fp, "%d %d", &pid, &nf) != EOF)
			{
				fscanf(fp, "%d %f %f %f ", &trueStartF, &uv.x, &uv.y, &s);
				break;
			}
			fclose(fp);

			int BackTrackRange = (int)(fps*trackingTime);
			Mat *BackImage = new Mat[BackTrackRange + 1];
			for (int ii = 0; ii < BackTrackRange + 1; ii++)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, -ii * increF + trueStartF);
				if (IsFileExist(Fname) == 0)
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, -ii * increF + trueStartF);
				BackImage[ii] = imread(Fname, 0);
				if (BackImage[ii].empty())
				{
					BackTrackRange = ii;
					break;
				}
			}

			Point2f *BackTrackUV = new Point2f[BackTrackRange*maxPts];
			float *scale = new float[BackTrackRange*maxPts];
			for (int ii = 0; ii < BackTrackRange*maxPts; ii++)
				BackTrackUV[ii] = Point2f(-1, -1);

			sprintf(Fname, "%s/Harris//BT_%d_%.4d.txt", Path, viewID, startF);  fp = fopen(Fname, "r");
			int ptsCount = 0;
			vector<int> orgID; orgID.reserve(5000);
			fscanf(fp, "%d ", &maxPts);
			while (fscanf(fp, "%d %d", &pid, &nf) != EOF)
			{
				orgID.push_back(pid);
				bool pass = false;
				for (int ii = 0; ii < nf; ii++)
				{
					fscanf(fp, "%d %f %f %f ", &fid, &uv.x, &uv.y, &s);
					//if (nf > BackTrackRange / 6)
					//if (ii == 0 && uv.x > 319 && uv.x < 1042 && uv.y >726 && uv.y < 1036)
					pass = true;
					BackTrackUV[ptsCount*BackTrackRange + (-fid + trueStartF) / increF] = uv, scale[ptsCount*BackTrackRange + (-fid + trueStartF) / increF] = s;
				}
				if (pass)
					ptsCount++;
			}
			fclose(fp);

			vector<Point2i> pointstack;
			for (int fid = 0; fid < BackTrackRange; fid++)
			{
				int nvalid = 0;
				for (int pid = 0; pid < ptsCount; pid++)
					if (BackTrackUV[pid*BackTrackRange + fid].x > 0.0 && BackTrackUV[pid*BackTrackRange + fid].y > 0.0)
						nvalid++;

				if (nvalid == 0)
					break;

				cvtColor(BackImage[fid], colorImg, CV_GRAY2BGR);
				//colorImg = BackImage[fid].clone();
				if (fid == 0)
				{
					for (int pid = 0; pid < ptsCount; pid++)
						if (BackTrackUV[pid*BackTrackRange + fid].x > 0.0 && BackTrackUV[pid*BackTrackRange + fid].y > 0.0)
							circle(colorImg, BackTrackUV[pid*BackTrackRange + fid], 1, colors[orgID[pid] % 9], 2);
					//circle(colorImg, BackTrackUV[pid*BackTrackRange + fid], 1, colors[7], 2);
				}
				else
				{
					for (int pid = 0; pid < ptsCount; pid++)
					{
						pointstack.clear();
						for (int fid2 = 10; fid2 > -1; fid2--)
						{
							if (BackTrackUV[pid*BackTrackRange + fid].x < 0 || BackTrackUV[pid*BackTrackRange + fid].y < 0)
								continue;
							if (fid - fid2 >= 0 && BackTrackUV[pid*BackTrackRange + fid - fid2].x > 0.0 && BackTrackUV[pid*BackTrackRange + fid - fid2].y > 0.0)
								pointstack.push_back(BackTrackUV[pid*BackTrackRange + fid - fid2]);
						}

						for (int ii = 0; ii < (int)pointstack.size() - 1; ii++)
							line(colorImg, pointstack[ii], pointstack[ii + 1], colors[orgID[pid] % 9], 1, CV_AA);
						//line(colorImg, pointstack[ii], pointstack[ii + 1], colors[7], 1, CV_AA);
					}
				}
				if (drawScale == 1)
				{
					for (int pid = 0; pid < ptsCount; pid++)
						if (BackTrackUV[pid*BackTrackRange + fid].x > 0.0 && BackTrackUV[pid*BackTrackRange + fid].y > 0.0)
							circle(colorImg, BackTrackUV[pid*BackTrackRange + fid], (int)(3.0*scale[pid*BackTrackRange + fid] + 0.5), colors[pid % 9], 1);
				}
				sprintf(Fname, "%s/%d/%d%s/B_%.4d.jpg", Path, viewID, startF, InsertC, -fid * increF + trueStartF);
				//sprintf(Fname, "C:/temp/B_%.4d.jpg", -fid*increF + trueStartF);
				imwrite(Fname, colorImg);
			}

			delete[]scale;
			delete[]BackImage;
			delete[]BackTrackUV;
		}
	}
	text_origin.x = colorImg.cols / 30, text_origin.y = colorImg.rows / 30;
	sprintf(Fname, "Finish with frame %d of cam %d", startF, viewID);
	putText(colorImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * colorImg.cols / 320, CV_RGB(0, 255, 0), 2);
	imshow("X", colorImg);  waitKey(1);

	return 0;
}
int VisualizeTrackingFull(char *Path, int viewID, int startF, int stopF, int increF, int drawScale, int extractedImages, double resizeFactor, int writeImage)
{
	char Fname[512];
	printLOG("Drawing 2D trajectories for camera #%d ...\n", viewID);
	sprintf(Fname, "%s/Vis/Features", Path), makeDir(Fname);
	if (writeImage)
		sprintf(Fname, "%s/Vis/Features/%d", Path, viewID), makeDir(Fname);
	Mat colorImg;

	static cv::Scalar colors[] = { Scalar(0, 0, 255), Scalar(0, 128, 255), Scalar(0, 255, 255), Scalar(0, 255, 0), Scalar(255, 128, 0), Scalar(255, 255, 0), Scalar(255, 0, 0), Scalar(255, 0, 255), Scalar(255, 255, 255) };

	sprintf(Fname, "%s/Track2D/Ultimate_%d.txt", Path, viewID); FILE *fp = fopen(Fname, "r");
	if (IsFileExist(Fname) == 0)
		return 1;
	int npts; fscanf(fp, "%d ", &npts);
	int TrackRange = (stopF - startF + increF) / increF;
	Point2f *TrackUV = new Point2f[TrackRange *npts];
	float *TrackS = new float[TrackRange *npts];
	for (int ii = 0; ii < TrackRange *npts; ii++)
		TrackUV[ii] = Point2f(-1, -1);

	int pid, fid, nf, ptsCount = 0;
	Point2f uv; float s, a, w0, w1, w2, w3;

	while (fscanf(fp, "%d %d", &pid, &nf) != EOF)
	{
		for (int ii = 0; ii < nf; ii++)
		{
			fscanf(fp, "%d %f %f %f %f %f %f %f %f ", &fid, &uv.x, &uv.y, &s, &a, &w0, &w1, &w2, &w3);
			if (fid<startF || fid>stopF)
				continue;
			TrackUV[pid * TrackRange + (fid - startF) / increF] = uv * resizeFactor;
			TrackS[pid * TrackRange + (fid - startF) / increF] = s * resizeFactor;
		}
	}
	fclose(fp);


	Mat *Img = new Mat[TrackRange + 1];
	if (extractedImages == 1)
	{
		Mat img;
		for (int fid = startF; fid <= startF + TrackRange; fid += increF)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, fid);
				if (IsFileExist(Fname) == 0)
					continue;
			}
			if (resizeFactor == 1.0)
				Img[(fid - startF) / increF] = imread(Fname, 0);
			else
			{
				img = imread(Fname, 0);
				resize(img, Img[(fid - startF) / increF], Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, CV_INTER_LINEAR);
			}
		}
	}
	else
	{
		int rotateImage = 0;
		sprintf(Fname, "%s/RotationInfo.txt", Path); FILE *fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int cid, code;
			while (fscanf(fp, "%d %d", &cid, &code) != EOF)
			{
				if (cid == viewID)
				{
					rotateImage = code;
					break;
				}
			}
			fclose(fp);
		}

		sprintf(Fname, "%s/%d/x.mp4", Path, viewID);
		cv::VideoCapture cap = VideoCapture(Fname);
		if (!cap.isOpened())
		{
			sprintf(Fname, "%s/%d/x.mov", Path, viewID);
			cap.open(Fname);
			if (!cap.isOpened())
			{
				printLOG("Cannot load %s\n", Fname);
				return 1;
			}
		}
		Mat img, grayImg, rImg;
		int fid = 0;
		while (true)
		{
			cap >> img;
			if (img.empty())
				break;
			if (fid < startF)
			{
				fid++;
				continue;
			}

			if (fid >= startF && fid <= stopF && (fid - startF) % increF == 0)
			{
				cvtColor(img, grayImg, CV_BGR2GRAY);

				if (rotateImage == 1) //flip updown
				{
					int width = img.cols, height = img.rows;
					for (int jj = 0; jj < height / 2; jj++)
						for (int ii = 0; ii < width; ii++)
						{
							char buf = grayImg.data[ii + jj * width];
							grayImg.data[ii + jj * width] = grayImg.data[width - 1 - ii + (height - 1 - jj)*width];
							grayImg.data[(width - 1 - ii) + (height - 1 - jj)*width] = buf;
						}

				}
				if (resizeFactor == 1.0)
					Img[(fid - startF) / increF] = grayImg;
				else
					resize(grayImg, Img[(fid - startF) / increF], Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, CV_INTER_LINEAR);
			}
			if (fid > stopF)
				break;
			fid++;
		}
		cap.release();
	}

	int firstWrite = 1;
	CvSize size;  VideoWriter writer;
	sprintf(Fname, "%s/Vis/Features/%d", Path, viewID);
	vector<Point2i> pointstack;
	vector<int> FirstTime(npts);
	for (int ii = 0; ii < npts; ii++)
		FirstTime[ii] = 0;
	for (int fid = 0; fid < TrackRange; fid++)
	{
		int nvalid = 0;
		for (int pid = 0; pid < npts; pid++)
			if (TrackUV[pid * TrackRange + fid].x > 0.0 && TrackUV[pid * TrackRange + fid].y > 0.0)
				nvalid++;

		if (nvalid == 0)
			continue;

		cvtColor(Img[fid], colorImg, CV_GRAY2BGR);
		for (int pid = 0; pid < npts; pid++)
		{
			if (TrackUV[pid * TrackRange + fid].x > 0.0 && TrackUV[pid * TrackRange + fid].y > 0.0)
			{
				if (FirstTime[pid] == 0)
				{
					FirstTime[pid] = 1;
					if (drawScale == 0)
						circle(colorImg, TrackUV[pid * TrackRange + fid], 1, colors[pid % 9], 2);
				}
				else
				{
					pointstack.clear();
					for (int fid2 = 10 * increF; fid2 > -1; fid2 -= increF)
					{
						if (TrackUV[pid * TrackRange + fid].x < 0 || TrackUV[pid * TrackRange + fid].y < 0)
							continue;
						if (fid - fid2 >= 0 && TrackUV[pid * TrackRange + fid - fid2].x > 0.0 && TrackUV[pid * TrackRange + fid - fid2].y > 0.0)
							pointstack.push_back(TrackUV[pid * TrackRange + fid - fid2]);
					}
					for (int ii = 0; ii < (int)pointstack.size() - 1; ii++)
						line(colorImg, pointstack[ii], pointstack[ii + 1], colors[pid % 9], 1, CV_AA);
				}

				if (drawScale == 1)
					circle(colorImg, TrackUV[pid * TrackRange + fid], (int)(3.0*TrackS[pid * TrackRange + fid] + 0.5), colors[pid % 9], 1);
			}
		}
		CvPoint text_origin = { colorImg.cols / 40, colorImg.cols / 40 }; sprintf(Fname, "%.4d", fid*increF + startF);
		putText(colorImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 2.0, Scalar(0, 0, 255), 1);

		if (firstWrite == 1)
		{
			firstWrite = 0;
			size.width = colorImg.cols, size.height = colorImg.rows;
			sprintf(Fname, "%s/Vis/Features/%d.avi", Path, viewID), writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 20, size);
		}
		if (writeImage)
			sprintf(Fname, "%s/Vis/Features/%d/%.4d.jpg", Path, viewID, fid*increF + startF), imwrite(Fname, colorImg);
		writer << colorImg;
	}
	writer.release();

	delete[]Img;
	delete[]TrackUV;
	delete[]TrackS;

	return 0;
}
int VisualizeTrackingErr(char *Path, int viewID, int startF, int increF, int fps, int trackingTime)
{
	char Fname[512];
	int pid, fid, nf;
	Point2f uv, euv;
	Mat colorImg;

	Mat colorMapSource = Mat::zeros(256, 1, CV_8U);
	for (unsigned int i = 0; i <= 255; i++)
		colorMapSource.at<uchar>(i, 0) = i;
	Mat colorMap; applyColorMap(colorMapSource, colorMap, COLORMAP_JET);

	sprintf(Fname, "%s/%d/TrajVis", Path, viewID); makeDir(Fname);
	sprintf(Fname, "%s/Track2D/UltimateErrTri_%.4d.txt", Path, viewID);
	FILE *fp = fopen(Fname, "r");
	if (IsFileExist(Fname) == 0)
		return 1;
	int npts; fscanf(fp, "%d ", &npts);

	int TrackRange = fps * trackingTime;
	Point2f *TrackUV = new Point2f[TrackRange *npts];
	Point2f *TrackEUV = new Point2f[TrackRange *npts];
	for (int ii = 0; ii < TrackRange *npts; ii++)
		TrackUV[ii] = Point2f(-1, -1);

	int  ptsCount = 0;
	//sprintf(Fname, "C:/temp/Tri_%.4d.txt", viewID); FILE *fp2 = fopen(Fname, "w+");
	while (fscanf(fp, "%d %d", &pid, &nf) != EOF)
	{
		for (int ii = 0; ii < nf; ii++)
		{
			fscanf(fp, "%d %f %f %f %f ", &fid, &uv.x, &uv.y, &euv.x, &euv.y);
			if (fid<startF || fid>startF + TrackRange)
				continue;
			TrackUV[ptsCount * TrackRange + fid - startF] = uv;
			TrackEUV[ptsCount * TrackRange + fid - startF] = euv;
			//fprintf(fp2, "%d %.3f %.3f\n", fid, euv.x, euv.y);
		}
		ptsCount++;
	}
	fclose(fp);
	//fclose(fp2);


	Mat *Img = new Mat[TrackRange + 1];
	for (int fid = 0; fid <= TrackRange; fid += increF)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, fid*increF + startF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, fid *increF + startF);
		Img[fid] = imread(Fname, 0);
		if (Img[fid].empty())
			continue;
	}

	vector<Point2i> pointstack;
	vector<int> FirstTime(npts);
	for (int ii = 0; ii < npts; ii++)
		FirstTime[ii] = 0;
	for (int fid = 0; fid < TrackRange; fid += increF)
	{
		int nvalid = 0;
		for (int pid = 0; pid < npts; pid++)
			if (TrackUV[pid * TrackRange + fid].x > 0.0 && TrackUV[pid * TrackRange + fid].y > 0.0)
				nvalid++;

		if (nvalid == 0)
			continue;

		cvtColor(Img[fid], colorImg, CV_GRAY2BGR);
		for (int pid = 0; pid < npts; pid++)
		{
			if (TrackUV[pid * TrackRange + fid].x > 0.0 && TrackUV[pid * TrackRange + fid].y > 0.0)
			{
				double err = sqrt(pow(TrackEUV[pid * TrackRange + fid].x, 2) + pow(TrackEUV[pid * TrackRange + fid].y, 2));
				double additive = fid < 300 ? 0.0 : pow(2.0*fid / 550, 2.0);
				int colorIdx = (int)min((err + additive) / 15 * 255 + 0.5, 255.0);
				colorIdx = colorIdx > 90 ? 255 : 0;
				Point3f  PointColor;
				PointColor.x = colorMap.at<Vec3b>(colorIdx, 0)[0]; //red
				PointColor.y = colorMap.at<Vec3b>(colorIdx, 0)[1]; //green
				PointColor.z = colorMap.at<Vec3b>(colorIdx, 0)[2];	//blue

				circle(colorImg, TrackUV[pid * TrackRange + fid], 1, cvScalar(PointColor.x, PointColor.y, PointColor.z), 2);
			}
		}
		sprintf(Fname, "%s/%d/TrajVis/ErrTri_%.4d.jpg", Path, viewID, fid + startF);
		imwrite(Fname, colorImg);
	}
	delete[]Img;
	delete[]TrackUV;
	delete[]TrackEUV;

	return 0;
}
int VisualizeInliersHarrisTracking(char *Path, int CamID, int startF, int increF, int TrackRange)
{
	char Fname[512];
	printLOG(Fname, "(%d, %4d)... ", CamID, startF);
	Mat colorImg;

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));

	TrackRange = TrackRange / increF;
	int TrackLength = 2 * TrackRange + 1;
	int npts, pid, fid, nf, ptsCount = 0;
	float x, y, z, s;  Point2f uv;

	sprintf(Fname, "%s/%d/Harris/Inliers_%.4d.txt", Path, CamID, startF); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
		return 1;
	fscanf(fp, "%d ", &npts);

	Point2f *TrackUV = new Point2f[TrackLength *npts];
	for (int ii = 0; ii < TrackLength *npts; ii++)
		TrackUV[ii] = Point2f(-1, -1);

	vector<int> orgID;
	for (int ii = 0; ii < npts; ii++)
	{
		fscanf(fp, "%d %d %f %f %f ", &pid, &nf, &x, &y, &z);
		for (int ii = 0; ii < nf; ii++)
		{
			fscanf(fp, "%d %f %f %f ", &fid, &uv.x, &uv.y, &s);
			if (fid<startF - TrackRange || fid>startF + TrackRange)
				continue;
			TrackUV[pid * TrackLength + (fid - startF + TrackRange) / increF] = uv;
		}
		orgID.push_back(pid);
	}
	fclose(fp);

	Mat *Img = new Mat[TrackLength];
	for (int fid = -TrackRange; fid <= TrackRange; fid += increF)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, CamID, startF + fid);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, CamID, startF + fid);
		Img[(fid + TrackRange) / increF] = imread(Fname, 0);
		if (Img[(fid + TrackRange) / increF].empty())
			continue;
	}

	vector<Point2i> pointstack;
	vector<int> FirstTime(npts);
	for (int ii = 0; ii < npts; ii++)
		FirstTime[ii] = 0;

	//namedWindow("X", WINDOW_NORMAL);
	//cvSetWindowProperty("X", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
	sprintf(Fname, "%s/Harris_Inliers_%d_%.4d.avi", Path, CamID, startF);
	CvSize size; size.width = Img[TrackRange].cols, size.height = Img[TrackRange].rows;
	VideoWriter writer;  writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
	for (int fid = 0; fid < TrackLength; fid++)
	{
		int nvalid = 0;
		for (int pid = 0; pid < npts; pid++)
			if (TrackUV[pid * TrackLength + fid].x > 0.0 && TrackUV[pid * TrackLength + fid].y > 0.0)
				nvalid++;

		if (nvalid == 0)
			continue;

		cvtColor(Img[fid], colorImg, CV_GRAY2BGR);
		for (int pid = 0; pid < npts; pid++)
		{
			if (TrackUV[pid * TrackLength + fid].x > 0.0 && TrackUV[pid * TrackLength + fid].y > 0.0)
			{
				if (FirstTime[pid] == 0)
					FirstTime[pid] = 1;
				else
				{
					pointstack.clear();
					for (int fid2 = 10 * increF; fid2 > -1; fid2 -= increF)
					{
						if (TrackUV[pid * TrackLength + fid].x < 0 || TrackUV[pid * TrackLength + fid].y < 0)
							continue;
						if (fid - fid2 >= 0 && TrackUV[pid * TrackLength + fid - fid2].x > 0.0 && TrackUV[pid * TrackLength + fid - fid2].y > 0.0)
							pointstack.push_back(TrackUV[pid * TrackLength + fid - fid2]);
					}
					for (int ii = 0; ii < (int)pointstack.size() - 1; ii++)
						line(colorImg, pointstack[ii], pointstack[ii + 1], colors[pid % 9], 1, CV_AA);
					circle(colorImg, TrackUV[pid * TrackLength + fid], 1, colors[orgID[pid] % 9], 2);

					CvPoint text_origin = { MyFtoI(TrackUV[pid * TrackLength + fid].x), MyFtoI(TrackUV[pid * TrackLength + fid].y) };
					sprintf(Fname, "%d", orgID[pid]);
					putText(colorImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5, CV_RGB(255, 0, 0), 2);
				}
			}
		}

		CvPoint text_origin = { colorImg.cols / 30, colorImg.cols / 30 };
		sprintf(Fname, "Frame %d/%d", CamID, startF - TrackRange + fid * increF);
		putText(colorImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * colorImg.cols / 640, CV_RGB(255, 0, 0), 3);
		writer << colorImg;
		//sprintf(Fname, "C:/temp/%d_%d.png", CamID, startF - TrackRange + fid*increF);  imwrite(Fname, colorImg);
		//imshow("X", colorImg); waitKey(30);
	}
	writer.release();

	delete[]Img;
	delete[]TrackUV;
	return 0;
}
int VisualizeKeyFrameFormationTracking(char *Path, int viewID, int startF, int vis)
{
	//vis: 0-show frame
	//vis: 1-write video
	//vis: 2-write image
	char Fname[512];
	int pid, fid, nf;
	Point2f uv;
	float u, v, s;
	Mat colorImg(1080, 1920, CV_8UC3, Scalar(0, 0, 0));

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));

	namedWindow("X", cv::WINDOW_NORMAL);
	cvSetWindowProperty("X", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);

	CvPoint text_origin = { colorImg.cols / 30, colorImg.rows / 2 };
	sprintf(Fname, "Working on frame %d of cam %d", startF, viewID);
	putText(colorImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * colorImg.cols / 320, CV_RGB(255, 0, 0), 3);
	imshow("X", colorImg);  waitKey(1);

	sprintf(Fname, "%s/Vis/%d", Path, viewID); makeDir(Fname);
	int maxPts = 50000, n;
	//draw fore-track images
	{
		int maxnf = 0;
		vector<int> TrackletID;
		vector<vector<Point2f> >ForeTrackUV;

		bool hasCache = false;
		sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.dat", Path, viewID, startF);
		if (IsFileExist(Fname) == 1)
		{
			ifstream fin;
			fin.open(Fname, ios::binary);
			fin.read(reinterpret_cast<char *>(&n), sizeof(int));
			for (int jj = 0; jj < n; jj++)
			{
				fin.read(reinterpret_cast<char *>(&pid), sizeof(int));
				fin.read(reinterpret_cast<char *>(&nf), sizeof(int));

				maxnf = max(maxnf, nf);
				vector<Point2f> Tracklet(nf);
				for (int ii = 0; ii < nf; ii++)
				{
					fin.read(reinterpret_cast<char *>(&u), sizeof(float));
					fin.read(reinterpret_cast<char *>(&v), sizeof(float));
					fin.read(reinterpret_cast<char *>(&s), sizeof(float));
					Tracklet[ii].x = u, Tracklet[ii].y = v;
				}
				TrackletID.push_back(pid);
				ForeTrackUV.push_back(Tracklet);
			}
			fin.close();
			hasCache = true;
		}
		else
		{
			sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.txt", Path, viewID, startF);
			if (IsFileExist(Fname) == 1)
			{
				FILE *fp = fopen(Fname, "r");
				while (fscanf(fp, "%d %d ", &pid, &nf) != EOF)
				{
					maxnf = max(maxnf, nf);
					vector<Point2f> Tracklet(nf);
					for (int ii = 0; ii < nf; ii++)
						fscanf(fp, "%f %f %f ", &Tracklet[ii].x, &Tracklet[ii].y, &s);
					TrackletID.push_back(pid);
					ForeTrackUV.push_back(Tracklet);
				}
				fclose(fp);
			}
			hasCache = true;
		}
		if (!hasCache)
			return 1;

		Mat gray, *ForeImage = new Mat[maxnf];
		for (int ii = 0; ii < maxnf; ii++)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, ii + startF);
			if (IsFileExist(Fname) == 0)
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, ii + startF);
			gray = imread(Fname, 0);
			if (gray.empty())
				break;
			cvtColor(gray, ForeImage[ii], CV_GRAY2BGR);

			CvPoint text_origin = { gray.cols / 30, gray.cols / 30 };
			sprintf(Fname, "%d", ii + startF);
			putText(ForeImage[ii], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * gray.cols / 640, CV_RGB(255, 0, 0), 3);
		}

		vector<Point2i> pointstack;
		for (int tid = 0; tid < (int)ForeTrackUV.size(); tid++)
		{
			for (int fid = 0; fid < (int)ForeTrackUV[tid].size(); fid++)
			{
				if (fid == 0)
					circle(ForeImage[fid], ForeTrackUV[tid][fid], 1, colors[TrackletID[tid] % 9], 2);
				else
				{
					pointstack.clear();
					for (int fid2 = 10; fid2 > -1; fid2--)
						if (fid - fid2 >= 0)
							pointstack.push_back(ForeTrackUV[tid][fid - fid2]);

					for (int ii = 0; ii < (int)pointstack.size() - 1; ii++)
						line(ForeImage[fid], pointstack[ii], pointstack[ii + 1], colors[TrackletID[tid] % 9], 1, CV_AA);
				}
			}
		}

		if (vis == 0)
		{
			for (int ii = 0; ii < maxnf; ii++)
				imshow("X", ForeImage[ii]), waitKey(30);
		}
		else if (vis == 1)
		{
			sprintf(Fname, "%s/Vis/%d/%.4d_F.avi", Path, viewID, startF);
			VideoWriter writer; writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 20, cvSize(ForeImage[0].cols, ForeImage[0].rows));
			for (int ii = 0; ii < maxnf; ii++)
				writer << ForeImage[ii];
			writer.release();
		}
		else
		{
			for (int ii = 0; ii < maxnf; ii++)
			{
				sprintf(Fname, "%s/Vis/%d/FT_%.4d.png", Path, viewID, startF + ii);
				imwrite(Fname, ForeImage[ii]);
			}
		}

		delete[]ForeImage;
	}

	//draw back-track images
	{
		int maxnf = 0;
		vector<int> TrackletID;
		vector<vector<Point2f> >BackTrackUV;
		bool hasCache = false;

		sprintf(Fname, "%s/cTrack2D/LBT_%d_%.4d.dat", Path, viewID, startF);
		if (IsFileExist(Fname) == 1)
		{
			ifstream fin;
			fin.open(Fname, ios::binary);
			int n;  fin.read(reinterpret_cast<char *>(&n), sizeof(int));
			for (int jj = 0; jj < n; jj++)
			{
				fin.read(reinterpret_cast<char *>(&pid), sizeof(int));
				fin.read(reinterpret_cast<char *>(&nf), sizeof(int));

				maxnf = max(maxnf, nf);
				vector<Point2f> Tracklet(nf);
				for (int ii = 0; ii < nf; ii++)
				{
					fin.read(reinterpret_cast<char *>(&u), sizeof(float));
					fin.read(reinterpret_cast<char *>(&v), sizeof(float));
					fin.read(reinterpret_cast<char *>(&s), sizeof(float));
					Tracklet[ii].x = u, Tracklet[ii].y = v;
				}
				TrackletID.push_back(pid);
				BackTrackUV.push_back(Tracklet);
			}
			fin.close();
			hasCache = true;
		}
		else
		{
			sprintf(Fname, "%s/cTrack2D/LBT_%d_%.4d.txt", Path, viewID, startF);
			if (IsFileExist(Fname) == 1)
			{
				FILE *fp = fopen(Fname, "r");
				while (fscanf(fp, "%d %d ", &pid, &nf) != EOF)
				{
					maxnf = max(maxnf, nf);
					vector<Point2f> Tracklet(nf);
					for (int ii = 0; ii < nf; ii++)
						fscanf(fp, "%f %f %f ", &Tracklet[ii].x, &Tracklet[ii].y, &s);
					TrackletID.push_back(pid);
					BackTrackUV.push_back(Tracklet);
				}
				fclose(fp);
			}
			hasCache = true;
		}
		if (!hasCache)
			return 1;

		Mat gray, *BackImage = new Mat[maxnf];
		for (int ii = 0; ii < maxnf; ii++)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, -ii + startF);
			if (IsFileExist(Fname) == 0)
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, -ii + startF);
			gray = imread(Fname, 0);
			if (gray.empty())
				break;
			cvtColor(gray, BackImage[ii], CV_GRAY2BGR);

			CvPoint text_origin = { gray.cols / 30, gray.cols / 30 };
			sprintf(Fname, "%d", -ii + startF);
			putText(BackImage[ii], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * gray.cols / 640, CV_RGB(255, 0, 0), 3);
		}

		vector<Point2i> pointstack;
		for (int tid = 0; tid < (int)BackTrackUV.size(); tid++)
		{
			for (int fid = 0; fid < (int)BackTrackUV[tid].size(); fid++)
			{
				if (fid == 0)
					circle(BackImage[fid], BackTrackUV[tid][fid], 1, colors[TrackletID[tid] % 9], 2);
				else
				{
					pointstack.clear();
					for (int fid2 = 10; fid2 > -1; fid2--)
						if (fid - fid2 >= 0)
							pointstack.push_back(BackTrackUV[tid][fid - fid2]);

					for (int ii = 0; ii < (int)pointstack.size() - 1; ii++)
						line(BackImage[fid], pointstack[ii], pointstack[ii + 1], colors[TrackletID[tid] % 9], 1, CV_AA);
				}
			}
		}

		if (vis == 0)
		{
			for (int ii = 0; ii < maxnf; ii++)
				imshow("X", BackImage[ii]), waitKey(30);
		}
		else if (vis == 1)
		{
			sprintf(Fname, "%s/Vis/%d/%.4d_B.avi", Path, viewID, startF);
			VideoWriter writer; writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 20, cvSize(BackImage[0].cols, BackImage[0].rows));
			for (int ii = 0; ii < maxnf; ii++)
				writer << BackImage[ii];
			writer.release();
		}
		else
		{
			for (int ii = 0; ii < maxnf; ii++)
			{
				sprintf(Fname, "%s/Vis/%d/BT_%.4d.png", Path, viewID, startF - ii);
				imwrite(Fname, BackImage[ii]);
			}
		}

		delete[]BackImage;
	}

	text_origin.x = colorImg.cols / 30, text_origin.y = colorImg.rows / 30;
	sprintf(Fname, "Finish with frame %d of cam %d", startF, viewID);
	putText(colorImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * colorImg.cols / 320, CV_RGB(0, 255, 0), 2);
	imshow("X", colorImg);  waitKey(1);

	return 0;
}
int VisualizeProjectedSMPLBody(char *Path, int nCams, int startF, int stopF, int increF, int PointFormat, int maxPeople, double resizeFactor, int WriteVideo, int debug)
{
	char Fname[512];
	sprintf(Fname, "%s/Vis/FitBody", Path), makeDir(Fname);
	sprintf(Fname, "%s/Vis/FitBody/Wrdp_1d", Path), makeDir(Fname);

	static cv::Scalar colors[] = { Scalar(0, 0, 255), Scalar(0, 128, 255), Scalar(0, 255, 255), Scalar(0, 255, 0), Scalar(255, 128, 0), Scalar(255, 255, 0), Scalar(255, 0, 0), Scalar(255, 0, 255), Scalar(255, 255, 255) };
	vector<Point3i> vcolors;
	vcolors.push_back(Point3i(0, 0, 255)), vcolors.push_back(Point3i(0, 128, 255)), vcolors.push_back(Point3i(0, 255, 255)), vcolors.push_back(Point3i(0, 255, 0)),
		vcolors.push_back(Point3i(255, 128, 0)), vcolors.push_back(Point3i(255, 255, 0)), vcolors.push_back(Point3i(255, 0, 0)), vcolors.push_back(Point3i(255, 0, 255)), vcolors.push_back(Point3i(255, 255, 255));
	int selected;  double fps;

	omp_set_num_threads(omp_get_max_threads());

	Point3d *CamTimeInfo = new Point3d[nCams];
	for (int ii = 0; ii < nCams; ii++)
		CamTimeInfo[ii].x = 1.0, CamTimeInfo[ii].y = 0.0;
	sprintf(Fname, "%s/FMotionPriorSync.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		double temp;
		while (fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp) != EOF)
		{
			CamTimeInfo[selected].x = 1.0 / fps;
			CamTimeInfo[selected].y = temp;
			CamTimeInfo[selected].z = 1.0;
		}
		fclose(fp);
	}
	else
	{
		sprintf(Fname, "%s/FGeoSync.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			double temp;
			while (fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp) != EOF)
			{
				CamTimeInfo[selected].x = 1.0 / fps;
				CamTimeInfo[selected].y = temp;
				CamTimeInfo[selected].z = 1.0;
			}
			fclose(fp);
		}
		else
		{
			double fps; int temp;
			sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				while (fscanf(fp, "%d %lf %d ", &selected, &fps, &temp) != EOF)
				{
					CamTimeInfo[selected].x = 1.0 / fps;
					CamTimeInfo[selected].y = temp;
					CamTimeInfo[selected].z = 1.0;
				}
				fclose(fp);
			}
			else
				printLOG("Cannot load time stamp info. Assume no frame offsets!");
		}
	}

	int refCid = 0;
	double earliest = DBL_MAX;
	for (int ii = 0; ii < nCams; ii++)
		if (earliest > CamTimeInfo[ii].y)
			earliest = CamTimeInfo[ii].y, refCid = ii;

	int cid, dummy, nPeople = 0;
	/*printLOG("Reading all people 3D skeleton: ");
	vector<HumanSkeleton3D *> vSkeletons;
	while (true)
	{
		printLOG("%d..", nPeople);

		int nvalidFrames = 0;
		HumanSkeleton3D *Skeletons = new HumanSkeleton3D[(stopF - startF) / increF + 1];
		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int nvis, nValidJoints = 0, temp = (refFid - startF) / increF;
			sprintf(Fname, "%s/People/@%d/%d/m_%.4d.txt", Path, increF, nPeople, refFid); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				int rfid, pid, nvis, dummy; float fdummy;
				for (int jid = 0; jid < PointFormat; jid++)
				{
					int temp = (refFid - startF) / increF;
					fscanf(fp, "%lf %lf %lf %lf %d ", &Skeletons[temp].pt3d[jid].x, &Skeletons[temp].pt3d[jid].y, &Skeletons[temp].pt3d[jid].z, &avg_error, &nvis);
					for (int kk = 0; kk < nvis; kk++)
					{
						fscanf(fp, "%d %d %lf %lf %lf %d", &cid, &rfid, &u, &v, &s, &dummy);
						Skeletons[temp].vViewID_rFid[jid].push_back(Point2i(cid, rfid));
						Skeletons[temp].vPt2D[jid].push_back(Point2d(u, v));
						Skeletons[temp].vConf[jid].push_back(s);
					}

					if (abs(Skeletons[temp].pt3d[jid].x) + abs(Skeletons[temp].pt3d[jid].y) + abs(Skeletons[temp].pt3d[jid].z) > 1e-16)
						Skeletons[temp].validJoints[jid] = 1, nValidJoints++;
					else
						Skeletons[temp].validJoints[jid] = 0;
				}
				fclose(fp);

				if (nValidJoints < PointFormat / 3)
					Skeletons[temp].valid = 0;
				else
					Skeletons[temp].valid = 1;

				nvalidFrames++;
			}
		}
		if (nvalidFrames == 0)
		{
			printLOG("\n");
			break;
		}

		vSkeletons.push_back(Skeletons);
		nPeople++;
	}*/
	nPeople = maxPeople;

	const int nVertices = smpl::SMPLModel::nVertices, nShapeCoeffs = smpl::SMPLModel::nShapeCoeffs, nJointsSMPL = smpl::SMPLModel::nJoints;
	MatrixXdr outV(nVertices, 3);
	SparseMatrix<double, ColMajor> eye3(3, 3); eye3.setIdentity();
	SparseMatrix<double, ColMajor> dVdt = Eigen::kroneckerProduct(VectorXd::Ones(nVertices), eye3);

	MatrixXdr *AllV = new MatrixXdr[maxPeople];
	for (int pi = 0; pi < maxPeople; pi++)
		AllV[pi].resize(nVertices, 3);

	VideoData *VideoInfo = new VideoData[nCams];
	for (int cid = 0; cid < nCams; cid++)
	{
		if (ReadVideoDataI(Path, VideoInfo[cid], cid, -1, -1) == 1)
			continue;
	}

	smpl::SMPLModel smplMaster;
	if (!ReadSMPLData("smpl", smplMaster))
		printLOG("Check smpl Path.\n");

	int *firstTime = new int[nCams];
	VideoWriter *writer = new VideoWriter[nCams];
	for (int ii = 0; ii < nCams; ii++)
		firstTime[ii] = 1;

	Mat img, rimg, mask, blend;
	smpl::SMPLParams params;
	vector<int> vpid(maxPeople);
	vector<smpl::SMPLParams>Vparams(maxPeople);
	Point2d joints2D[25];
	Point2d *vuv = new Point2d[nVertices];
	Point3f *allVertices = new Point3f[nVertices*maxPeople];
	for (int refFid = startF; refFid <= stopF; refFid += 4)
	{
		printLOG("%d..", refFid);
		if ((refFid - startF) % 30 == 29)
			printLOG("\n");

		int temp = (refFid - startF) / increF;

		for (int ii = 0; ii < nPeople; ii++)
			vpid[ii] = false;
		for (int pid = 0; pid < maxPeople; pid++)
		{
			sprintf(Fname, "%s/FitBody/@%d/Wj/%d/%.2d_%.4d_%.1f.txt", Path, increF, pid, 0, refFid, TimeScale*refFid); //window based
			if (IsFileExist(Fname) == 0)
				continue;
			FILE *fp = fopen(Fname, "r");
			fscanf(fp, "%lf %lf %lf %lf ", &Vparams[pid].scale, &Vparams[pid].t(0), &Vparams[pid].t(1), &Vparams[pid].t(2));
			for (int ii = 0; ii < nJointsSMPL; ii++)
				fscanf(fp, "%lf %lf %lf ", &Vparams[pid].pose(ii, 0), &Vparams[pid].pose(ii, 1), &Vparams[pid].pose(ii, 2));
			for (int ii = 0; ii < nShapeCoeffs; ii++)
				fscanf(fp, "%lf ", &Vparams[pid].coeffs(ii));
			//Vparams[pid].pose(15, 0) = 0.3, Vparams[pid].pose(15, 1) = 0, Vparams[pid].pose(15, 2) = 0;//up straight face
			fclose(fp);

			vpid[pid] = true;
		}
		int cnt = 0;
		for (int pid = 0; pid < maxPeople; pid++)
			if (vpid[pid])
				cnt++;
		if (cnt == 0)
			continue;

#pragma omp parallel for schedule(dynamic,1)
		for (int pid = 0; pid < maxPeople; pid++)
		{
			if (!vpid[pid])
				continue;

			reconstruct(smplMaster, Vparams[pid].coeffs.data(), Vparams[pid].pose.data(), AllV[pid].data());
			Map<VectorXd> V_vec(AllV[pid].data(), AllV[pid].size());
			V_vec = V_vec * Vparams[pid].scale + dVdt * Vparams[pid].t;

			for (int ii = 0; ii < nVertices; ii++)
				allVertices[ii + pid * nVertices] = Point3f(AllV[pid](ii, 0), AllV[pid](ii, 1), AllV[pid](ii, 2));
		}

		for (int cid = 0; cid < nCams; cid++)
		{
			double ts = 1.0*refFid / CamTimeInfo[refCid].x;
			int rfid = MyFtoI((ts - CamTimeInfo[cid].y / CamTimeInfo[refCid].x) * CamTimeInfo[cid].x);
			int width = VideoInfo[cid].VideoInfo[rfid].width, height = VideoInfo[cid].VideoInfo[rfid].height;

			if (!VideoInfo[cid].VideoInfo[rfid].valid)
				continue;

			sprintf(Fname, "%s/%d/%.4d.png", Path, cid, rfid); img = imread(Fname);
			if (img.empty() == 1)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, rfid); img = imread(Fname);
				if (img.empty() == 1)
					continue;
			}

			if (firstTime[cid] == 1 && WriteVideo)
			{
				firstTime[cid] = 0;
				CvSize size;
				size.width = (int)(resizeFactor*img.cols), size.height = (int)(resizeFactor*img.rows);
				sprintf(Fname, "%s/Vis/FitBody/Wjs_%d_%d_%d.avi", Path, cid, startF, stopF), writer[cid].open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 30, size);
			}

			for (int pid = 0; pid < nPeople; pid++)
			{
				CameraData *camI = VideoInfo[cid].VideoInfo;
				if (camI[rfid].valid != 1)
					continue;

				/*bool visible = 0;
				int bottomID = -1; double bottomY = 0;
				HumanSkeleton3D *Body0 = &vSkeletons[pid][temp];
				for (int jid = 0; jid < PointFormat; jid++)
				{
					joints2D[jid] = Point2d(0, 0);
					if (Body0[0].validJoints[jid] > 0)
					{
						Point3d xyz = Body0[0].pt3d[jid];
						if (camI[rfid].LensModel == RADIAL_TANGENTIAL_PRISM)
						{
							ProjectandDistort(xyz, &joints2D[jid], camI[rfid].P);
							if (joints2D[jid].x < -camI[rfid].width / 10 || joints2D[jid].x > 11 * camI[rfid].width / 10 || joints2D[jid].y < -camI[rfid].height / 10 || joints2D[jid].y > 11 * camI[rfid].height / 10)
								continue;

							if (camI[rfid].ShutterModel == GLOBAL_SHUTTER)
								ProjectandDistort(xyz, &joints2D[jid], camI[rfid].P, camI[rfid].K, camI[rfid].distortion);
							else if (camI[rfid].ShutterModel == ROLLING_SHUTTER)
								CayleyDistortionProjection(camI[rfid].intrinsic, camI[rfid].distortion, camI[rfid].rt, camI[rfid].wt, joints2D[jid], xyz, width, height);
						}
						else
						{
							FisheyeProjectandDistort(xyz, &joints2D[jid], camI[rfid].P, camI[rfid].K, camI[rfid].distortion);
							if (joints2D[jid].x < -camI[rfid].width / 10 || joints2D[jid].x > 11 * camI[rfid].width / 10 || joints2D[jid].y < -camI[rfid].height / 10 || joints2D[jid].y > 11 * camI[rfid].height / 10)
								continue;

							if (camI[rfid].ShutterModel == GLOBAL_SHUTTER)
								FisheyeProjectandDistort(xyz, &joints2D[jid], camI[rfid].P, camI[rfid].K, camI[rfid].distortion);
							else if (camI[rfid].ShutterModel == ROLLING_SHUTTER)
								CayleyFOVProjection2(camI[rfid].intrinsic, camI[rfid].distortion, camI[rfid].rt, camI[rfid].wt, joints2D[jid], xyz, width, height);
						}

						if (joints2D[jid].y > bottomY)
							bottomY = joints2D[jid].y, bottomID = jid;
					}
				}
				if (debug == 1)
				{
					Draw2DCoCoJoints(img, joints2D, PointFormat, 2, 1.0, &colors[pid % 8]);
					sprintf(Fname, "%s/Vis/FitBody/x.jpg", Path), imwrite(Fname, img);
				}
				//if (bottomID > 13 || bottomID < 8)
				//	continue;*/

				/*for (int ii = 0; ii < nVertices; ii++)
				{
				Point2d uv;
				Point3d xyz(allVertices[nVertices*pid+ii].x, allVertices[nVertices*pid + ii].y, allVertices[nVertices*pid + ii].z);

				if (VideoInfo[cid].VideoInfo[rfid].LensModel == RADIAL_TANGENTIAL_PRISM)
				CayleyDistortionProjection(VideoInfo[cid].VideoInfo[rfid].intrinsic, VideoInfo[cid].VideoInfo[rfid].distortion, VideoInfo[cid].VideoInfo[rfid].rt, VideoInfo[cid].VideoInfo[rfid].wt, uv, xyz, width, height);
				else
				CayleyFOVProjection2(VideoInfo[cid].VideoInfo[rfid].intrinsic, VideoInfo[cid].VideoInfo[rfid].distortion, VideoInfo[cid].VideoInfo[rfid].rt, VideoInfo[cid].VideoInfo[rfid].wt, uv, xyz, width, height);

				int x = (int)(uv.x + 0.5), y = (int)(uv.y + 0.5);
				circle(img, Point2i(x, y), 1, colors[vpid[pid] % 9], 1);
				}*/


#pragma omp parallel for schedule(dynamic,1)
				for (int ii = 0; ii < nVertices; ii++)
				{
					Point3d xyz(allVertices[nVertices*pid + ii].x, allVertices[nVertices*pid + ii].y, allVertices[nVertices*pid + ii].z);
					if (camI[rfid].LensModel == RADIAL_TANGENTIAL_PRISM)
					{
						ProjectandDistort(xyz, &vuv[ii], camI[rfid].P);
						if (vuv[ii].x < -camI[rfid].width / 10 || vuv[ii].x > 11 * camI[rfid].width / 10 || vuv[ii].y < -camI[rfid].height / 10 || vuv[ii].y > 11 * camI[rfid].height / 10)
							continue;

						if (camI[rfid].ShutterModel == GLOBAL_SHUTTER)
							ProjectandDistort(xyz, &vuv[ii], camI[rfid].P, camI[rfid].K, camI[rfid].distortion);
						else if (camI[rfid].ShutterModel == ROLLING_SHUTTER)
							CayleyDistortionProjection(camI[rfid].intrinsic, camI[rfid].distortion, camI[rfid].rt, camI[rfid].wt, vuv[ii], xyz, width, height);
					}
					else
					{
						FisheyeProjectandDistort(xyz, &vuv[ii], camI[rfid].P, camI[rfid].K, camI[rfid].distortion);
						if (vuv[ii].x < -camI[rfid].width / 10 || vuv[ii].x > 11 * camI[rfid].width / 10 || vuv[ii].y < -camI[rfid].height / 10 || vuv[ii].y > 11 * camI[rfid].height / 10)
							continue;

						if (camI[rfid].ShutterModel == GLOBAL_SHUTTER)
							FisheyeProjectandDistort(xyz, &vuv[ii], camI[rfid].P, camI[rfid].K, camI[rfid].distortion);
						else if (camI[rfid].ShutterModel == ROLLING_SHUTTER)
							CayleyFOVProjection2(camI[rfid].intrinsic, camI[rfid].distortion, camI[rfid].rt, camI[rfid].wt, vuv[ii], xyz, width, height);
					}
				}

				for (int ii = 0; ii < smplMaster.vFaces.size(); ii++)
				{
					Point2d uv[3] = { vuv[smplMaster.vFaces[ii].x],vuv[smplMaster.vFaces[ii].y],vuv[smplMaster.vFaces[ii].z] };
					if (uv[0].x > 10 && uv[0].y > 10 && uv[0].x < width - 10 && uv[0].y < height - 10 && uv[1].x >10 && uv[1].y > 10 && uv[1].x < width - 10 && uv[1].y < height - 10)
						cv::line(img, uv[0], uv[1], colors[pid], 1, CV_AA);
					if (uv[1].x > 10 && uv[1].y > 10 && uv[1].x < width - 10 && uv[1].y < height - 10 && uv[2].x >10 && uv[2].y > 10 && uv[2].x < width - 10 && uv[2].y < height - 10)
						cv::line(img, uv[0], uv[2], colors[pid], 1, CV_AA);
					if (uv[0].x > 10 && uv[0].y > 10 && uv[0].x < width - 10 && uv[0].y < height - 10 && uv[2].x >10 && uv[2].y > 10 && uv[2].x < width - 10 && uv[2].y < height - 10)
						cv::line(img, uv[1], uv[2], colors[pid], 1, CV_AA);
				}
				if (debug == 1)
					sprintf(Fname, "%s/Vis/FitBody/x.jpg", Path), imwrite(Fname, img);
			}

			CvPoint text_origin = { width / 30, height / 30 };
			sprintf(Fname, "Real: %d", rfid, refFid), putText(img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*img.cols / 640, colors[0], 3);
			resize(img, rimg, Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
			if (WriteVideo)
				writer[cid] << rimg;
			else
				//sprintf(Fname, "%s/Vis/FitBody/%d/%.4d_%.4d.jpg", Path, cid, rfid, refFid), imwrite(Fname, rimg);
				sprintf(Fname, "%s/Vis/FitBody/Wjs/%.2d_%.4d_%.4d.jpg", Path, cid, rfid, refFid), imwrite(Fname, rimg);
		}
	}

	for (int ii = 0; ii < nCams; ii++)
		writer[ii].release();

	delete[]vuv, delete[]allVertices;

	return 0;
}
Mat DrawTitleImages(vector<Mat>& Img, double desiredRatio)
{
	int width = Img[0].cols, height = Img[0].rows;
	int nimages = (int)Img.size();

	double bestRatioDif = 9e9;  int bestTitleW = 1;
	for (int TitleW = 1; TitleW <= nimages; TitleW++)
	{
		int bWidth = width * TitleW, bHeight = (int)(ceil(1.0*nimages / bestTitleW))*height;
		double ratio = 1.0*bWidth / bHeight;
		double ratioDif = abs(ratio - desiredRatio);
		if (ratioDif < bestRatioDif)
		{
			bestRatioDif = ratioDif;
			bestTitleW = TitleW;
		}
	}

	int bestTitleH = (int)(ceil(1.0*nimages / bestTitleW));
	Mat bImg(height*bestTitleH, width*bestTitleW, Img[0].channels() == 3 ? CV_8UC3 : CV_8UC1, Scalar(0, 0, 0));
	for (int ii = 0; ii < nimages; ii++)
	{
		int x = ii % bestTitleW, y = ii / bestTitleW;
		Rect rect(width*x, height*y, width, height);
		if (Img[ii].empty() == 0)
			Img[ii].copyTo(bImg(rect));
	}

	return bImg;
}
int VisualizeComparisionSlider(char *Path, char *Path1, char *Path2, char *Path3, vector<int> &sCams, int startF, int stopF)
{
	int slider = 0, maxSlider = 70, fid = startF, ofid = startF, oslider = slider;
	namedWindow("Comparison", CV_WINDOW_NORMAL);
	createTrackbar("Slider", "Comparison", &slider, maxSlider, NULL);
	cvSetTrackbarPos("Slider", "Comparison", slider);
	createTrackbar("Frame", "Comparison", &fid, stopF, NULL);
	cvSetTrackbarPos("Frame", "Comparison", fid);

	char Fname[512];
	vector<Mat> vImg(sCams.size());
	VideoCapture *capture = new VideoCapture[sCams.size()];
	for (int ii = 0; ii < (int)sCams.size(); ii++)
	{
		sprintf(Fname, "%s/Vis/SkeletonBA/%d_31_1999.avi", Path, sCams[ii]);
		capture[ii].open(Fname);
		if (!capture[ii].isOpened())  // if not success, exit program
		{
			printLOG("Cannot open %s\n", Fname);
			return -1;
		}
		int width = capture[ii].get(CV_CAP_PROP_FRAME_WIDTH);
		int height = capture[ii].get(CV_CAP_PROP_FRAME_HEIGHT);
		int nframes = capture[ii].get(CV_CAP_PROP_FRAME_COUNT);
	}

	bool autoplay = true, autoslide = false;
	int cnt = 0, scnt = 0;
	Mat img, simg, img1, img2, bimg, bimg2;
	while (true)
	{
		sprintf(Fname, "%s/%.4d.png", Path1, fid);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%.4d.jpg", Path1, fid);
			if (IsFileExist(Fname) == 0)
			{
				fid++;
				continue;
			}
		}
		img1 = imread(Fname);

		sprintf(Fname, "%s/%.4d.png", Path2, fid);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%.4d.jpg", Path2, fid);
			if (IsFileExist(Fname) == 0)
			{
				fid++;
				continue;
			}
		}
		img2 = imread(Fname);
		int w = img1.cols, h = img1.rows;

		if (cnt == 0)
		{
			int width = capture[0].get(CV_CAP_PROP_FRAME_WIDTH);
			int height = capture[0].get(CV_CAP_PROP_FRAME_HEIGHT);
			int rw = w / sCams.size(), rh = height * rw / width;
			bimg2 = Mat::zeros(img2.rows + rh, img2.cols, CV_8UC3);

			for (int ii = 0; ii < sCams.size(); ii++)
			{
				if (capture[ii].read(img))
				{
					resize(img, simg, Size(rw, rh), 0, 0, INTER_AREA);
					vImg[ii] = simg.clone();
				}
			}
			cnt++;
		}


		bimg = img1.clone();
		int posX = slider * (w - 1) / maxSlider;
		if (slider != maxSlider)
		{
			Rect rect(posX, 0, w - 1 - posX, h - 1);
			img2(rect).copyTo(bimg(rect));
			cv::line(bimg, Point2i(posX, 0), Point2i(posX, h - 1), cv::Scalar(255, 255, 255), 2);
		}

		if (sCams.size() > 0)
		{
			Rect rect(0, 0, w, h);
			bimg.copyTo(bimg2(rect));

			for (int ii = 0; ii < sCams.size(); ii++)
			{
				Rect rect(vImg[ii].cols*ii, h, vImg[ii].cols, vImg[ii].rows);
				vImg[ii].copyTo(bimg2(rect));
			}
			imshow("Comparison", bimg2);
		}
		else
			imshow("Comparison", bimg);

		int key = waitKey(1);
		if (key == 27)//esc
			break;
		else if (key == 13)//enter
			autoplay = !autoplay;
		else if (key == 32)//space
		{
			autoslide = !autoslide;
			if (autoslide)
				scnt = 0;
		}
		else if (key == 119) //w
		{
			fid++;
			if (fid > stopF)
				fid = stopF;
		}
		else if (key == 115 && sCams.size() == 0) //s
		{
			fid--;
			if (fid < startF)
				fid = startF;
		}
		else if (key == 100)//d
			slider = min(slider++, maxSlider);
		else if (key == 97)//a
			slider = max(slider--, 0);

		if (autoplay)
		{
			fid++;
			if (fid > stopF)
				fid = stopF;
		}
		if (autoslide)
		{
			if (scnt < maxSlider)
				slider = min(slider++, maxSlider);
			else if (scnt < 2 * maxSlider)
				slider = max(slider--, 0);
			else
				autoslide = false;
			scnt++;
		}

		bool change = false;
		if (ofid != fid)
		{
			ofid = fid, change = true;
			for (int ii = 0; ii < sCams.size(); ii++)
			{
				if (capture[ii].read(img))
				{
					resize(img, simg, Size(vImg[ii].cols, vImg[ii].rows), 0, 0, INTER_AREA);
					vImg[ii] = simg.clone();
				}
			}
		}
		if (oslider != slider)
			oslider = slider, change = true;


		if (change)
		{
			sprintf(Fname, "%s/%.4d.png", Path3, cnt);
			if (sCams.size() == 0)
				imwrite(Fname, bimg);
			else
				imwrite(Fname, bimg2);
			cnt++;
		}
		cvSetTrackbarPos("Slider", "Comparison", slider);
		cvSetTrackbarPos("Frame", "Comparison", fid);
	}

	return 0;
}

static float distancePointLine(const cv::Point2d point, const cv::Vec3d & line)
{
	//Line is given as a*x + b*y + c = 0
	return std::abs(line(0)*point.x + line(1)*point.y + line(2)) / std::sqrt(line(0)*line(0) + line(1)*line(1));
}
static void drawEpipolarLines(const std::string& title, Mat F, const cv::Mat& img1, const cv::Mat& img2, const std::vector<Point2d> points1, const std::vector<Point2d> points2, const float inlierDistance)
{
#ifdef _WINDOWS
	CV_Assert(img1.size() == img2.size() && img1.type() == img2.type());
	cv::Mat outImg(img1.rows, img1.cols * 2, CV_8UC3);
	cv::Rect rect1(0, 0, img1.cols, img1.rows);
	cv::Rect rect2(img1.cols, 0, img1.cols, img1.rows);

	if (img1.type() == CV_8U)
	{
		cv::cvtColor(img1, outImg(rect1), CV_GRAY2BGR);
		cv::cvtColor(img2, outImg(rect2), CV_GRAY2BGR);
	}
	else
	{
		img1.copyTo(outImg(rect1));
		img2.copyTo(outImg(rect2));
	}

	cout << F << endl;

	vector<Point2f> _points1, _points2;
	for (int ii = 0; ii < (int)points1.size(); ii++)
		_points1.push_back(points1[ii]), _points2.push_back(points2[ii]);
	std::vector<cv::Vec3f> epilines1, epilines2;
	cv::computeCorrespondEpilines((_points1), 1, F, epilines1); //Index starts with 1
	cv::computeCorrespondEpilines((_points2), 2, F, epilines2);

	CV_Assert(points1.size() == points2.size() && points2.size() == epilines1.size() && epilines1.size() == epilines2.size());

	cv::RNG rng(0);
	for (size_t i = 0; i < points1.size(); i++)
	{
		if (inlierDistance > 0)
			if (distancePointLine(points1[i], epilines2[i]) > inlierDistance || distancePointLine(points2[i], epilines1[i]) > inlierDistance)
				continue;

		cv::Scalar color(rng(256), rng(256), rng(256));

		cv::line(outImg(rect2), cv::Point(0, -epilines1[i][2] / epilines1[i][1]), cv::Point(img1.cols, -(epilines1[i][2] + epilines1[i][0] * img1.cols) / epilines1[i][1]), color);
		cv::circle(outImg(rect1), points1[i], 3, color, -1, CV_AA);

		cv::line(outImg(rect1), cv::Point(0, -epilines2[i][2] / epilines2[i][1]), cv::Point(img2.cols, -(epilines2[i][2] + epilines2[i][0] * img2.cols) / epilines2[i][1]), color);
		cv::circle(outImg(rect2), points2[i], 3, color, -1, CV_AA);
	}

	namedWindow(title, CV_WINDOW_NORMAL);
	setWindowProperty(title, CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
	imshow(title, outImg);
	waitKey(0);

	destroyWindow(title.c_str());
#endif
}
int VisualizeAllViewsEpipolarGeometry(char *Path, int fid, Corpus &CorpusInfo)
{
	char Fname[512];

	int nPeople = 4, minInliers = 10, npts = 14 * nPeople;
	double thresh = 100.0;

	int nCams = CorpusInfo.nCameras;
	ReadIntrinsicResults(Path, CorpusInfo.camera);

	double *CamTimeStamp = new double[nCams];
	for (int ii = 0; ii < nCams; ii++)
		CamTimeStamp[ii] = 0.0;
	sprintf(Fname, "%s/FGeoSync.txt", Path);
	if (IsFileExist(Fname) == 1)
	{
		int selected;
		FILE *fp = fopen(Fname, "r");
		for (int ii = 0; ii < nCams; ii++)
		{
			fscanf(fp, "%d ", &selected);
			fscanf(fp, "%lf ", &CamTimeStamp[selected]);
		}
		fclose(fp);
	}

	for (int ii = 0; ii < nCams; ii++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, ii, fid - (int)CamTimeStamp[ii]);
		CorpusInfo.camera[ii].viewID = ii, CorpusInfo.camera[ii].frameID = fid;
		CorpusInfo.camera[ii].filename = Fname;
	}

	CorpusInfo.n3dPoints = npts;
	CorpusInfo.xyz.resize(npts);
	for (int pid = 0; pid < npts; pid++)
	{
		CorpusInfo.viewIdAll3D.push_back(vector<int>());
		CorpusInfo.uvAll3D.push_back(vector<Point2d>());
	}
	for (int cid = 0; cid < nCams; cid++)
	{
		sprintf(Fname, "%s/JBC/%d/%d.txt", Path, fid, cid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		int pid; float u, v, s;
		while (fscanf(fp, "%d %f %f %f ", &pid, &u, &v, &s) != EOF)
		{
			CorpusInfo.viewIdAll3D[pid].push_back(cid);
			CorpusInfo.uvAll3D[pid].push_back(Point2d(u, v));
		}
		fclose(fp);
	}


	vector<int> inliers, id, id2;
	vector<Point2d> pts, pts1, pts2;
	vector<Point3d> P3D;

	//Initialize the SfM
	Point2i bestPair;
	CameraData BestCam1, BestCam2;
	double minCost = 9e9;
	for (int jj = 0; jj < nCams - 1; jj++)
	{
		for (int ii = jj + 1; ii < nCams; ii++)
		{
			pts1.clear(), pts2.clear(), id.clear();
			for (int pid = 0; pid < CorpusInfo.n3dPoints; pid++)
			{
				for (int kk = 0; kk < CorpusInfo.viewIdAll3D[pid].size(); kk++)
				{
					if (CorpusInfo.viewIdAll3D[pid][kk] == jj)
					{
						for (int ll = 0; ll < CorpusInfo.viewIdAll3D[pid].size(); ll++)
						{
							if (CorpusInfo.viewIdAll3D[pid][ll] == ii)
							{
								pts1.push_back(CorpusInfo.uvAll3D[pid][kk]);
								pts2.push_back(CorpusInfo.uvAll3D[pid][ll]);
								id.push_back(pid);
								break;
							}
						}
						break;
					}
					if (CorpusInfo.viewIdAll3D[pid][kk] == ii)
					{
						for (int ll = 0; ll < CorpusInfo.viewIdAll3D[pid].size(); ll++)
						{
							if (CorpusInfo.viewIdAll3D[pid][ll] == jj)
							{
								pts2.push_back(CorpusInfo.uvAll3D[pid][kk]);
								pts1.push_back(CorpusInfo.uvAll3D[pid][ll]);
								id.push_back(pid);
								break;
							}
						}
						break;
					}
				}
			}

			printLOG("\nWorking on (%d, %d)\n", jj, ii);
			CameraData Cam1, Cam2;
			CopyCamereInfo(CorpusInfo.camera[jj], Cam1);
			CopyCamereInfo(CorpusInfo.camera[ii], Cam2);

			if (pts1.size() < minInliers || pts2.size() < minInliers)
				continue;

			LensCorrectionPoint(pts1, Cam1.K, Cam1.distortion);
			LensCorrectionPoint(pts2, Cam2.K, Cam2.distortion);

			Mat cvInliers, cvK1 = Mat(3, 3, CV_64F, Cam1.K), cvK2 = Mat(3, 3, CV_64F, Cam2.K);

			Mat E = findEssentialMat(pts1, pts2, cvK1, cvK2, 8, 0.99, thresh, cvInliers);
			int ninliers = 0;
			for (int ii = 0; ii < cvInliers.cols; ii++)
				if (cvInliers.at<bool>(ii))
					ninliers++;

			Mat F = cvK2.t().inv()*E*cvK1.inv();

			Mat img1 = imread(Cam1.filename), img2 = imread(Cam2.filename);
			char Fname[512]; sprintf(Fname, "%d-%d", Cam1.viewID, Cam2.viewID);
			drawEpipolarLines(Fname, F, img1, img2, pts1, pts2);
		}
	}

	return 0;
}
int VisualizeAllViewsEpipolarGeometry(char *Path, vector<int> &sCams, int startF, int stopF)
{
#ifdef _WINDOWS
	char Fname[512];

	int numCams = *std::max_element(std::begin(sCams), std::end(sCams)) + 1;
	int *frameTimeStamp = new int[numCams];
	for (int ii = 0; ii < numCams; ii++)
		frameTimeStamp[ii] = 0;

	sprintf(Fname, "%s/InitSync.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int selected, ts; double fps;
		for (int ii = 0; ii < numCams; ii++)
		{
			fscanf(fp, "%d %lf %d ", &selected, &fps, &ts);
			frameTimeStamp[selected] = ts;
		}
		fclose(fp);
	}
	else
		printLOG("Cannot load time stamp info. Assume no frame offsets!");

	//Read calib info
	VideoData *VideoInfo = new VideoData[numCams];
	for (auto cid : sCams)
	{
		//if (ReadVideoDataI(Path, VideoInfo[cid], cid, startF, stopF) == 1)
			//return 1;

		VideoInfo[cid].VideoInfo = new CameraData[stopF + 1];

		double intrinsic[5];
		sprintf(Fname, "%s/calib.json", Path);
		if (!IsFileExist(Fname))
			return -1;
		else
		{
			std::ifstream ifs(Fname);
			json calib_json;
			ifs >> calib_json;

			auto Devices = calib_json["Devices"][cid];
			intrinsic[0] = Devices["CameraModel"]["Parameters"][0],
				intrinsic[1] = Devices["CameraModel"]["Parameters"][1],
				intrinsic[2] = 0,
				intrinsic[3] = Devices["CameraModel"]["Parameters"][2],
				intrinsic[4] = Devices["CameraModel"]["Parameters"][3];
		}

		int deviceId = 0;
		sprintf(Fname, "%s/pose_%d.json", Path, cid);
		if (!IsFileExist(Fname))
			return -1;

		std::ifstream ifs(Fname);
		json pose_json;
		ifs >> pose_json;
		for (auto pose_ : pose_json)
		{
			int fid = std::round((double)(pose_["fid"])) - 1; // first frame is indexed 1 while the extracted frames is indexed 0
			if (fid > stopF)
				break;
			CameraData *camI = &VideoInfo[cid].VideoInfo[fid];

			double qw = pose_["qwxyz"][0], qx = pose_["qwxyz"][1], qy = pose_["qwxyz"][2], qz = pose_["qwxyz"][3];
			for (int ii = 0; ii < 3; ii++)
				camI->camCenter[ii] = pose_["txyz"][ii];

			camI->Quat[0] = qw, camI->Quat[1] = qx, camI->Quat[2] = qy, camI->Quat[3] = qz;
			Quaternion2Rotation(camI->Quat, camI->invR);
			mat_transpose(camI->invR, camI->R, 3, 3);
			GetTfromC(camI->R, camI->camCenter, camI->T);
			GetrtFromRT(camI->rt, camI->R, camI->T);

			camI->viewID = cid;
			camI->frameID = fid;

			for (int ii = 0; ii < 5; ii++)
				camI->intrinsic[ii] = intrinsic[ii];
			GetKFromIntrinsic(camI[0]);
		}
	}

	//Create display window
	bool NeedToReadImage = true;
	int oCams[2] = { 0, 0 }, nCams[2] = { 0,0 }, oFrames[2] = { startF, startF }, nFrames[2] = { startF, startF }, oMouseX = -1, oMouseY = -1;

	namedWindow("VideoSequences", CV_WINDOW_NORMAL);
	if (numCams > 1)
	{
		createTrackbar("CamI", "VideoSequences", &oCams[0], numCams - 1, NULL);
		createTrackbar("CamJ", "VideoSequences", &oCams[1], numCams - 1, NULL);
	}
	createTrackbar("FrameID1", "VideoSequences", &oFrames[0], stopF - 1, NULL);
	createTrackbar("FrameID2", "VideoSequences", &oFrames[1], stopF - 1, NULL);


	vector<Mat> vImg(2);
	sprintf(Fname, "%s/%d/Corrected/%.4d.png", Path, oCams[0], oFrames[0] - frameTimeStamp[oCams[0]]);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/%d/Corrected/%.4d.jpg", Path, oCams[0], oFrames[0] - frameTimeStamp[oCams[0]]);
		if (IsFileExist(Fname) == 0)
		{
			printLOG("Cannot load %s\n", Fname);
			exit(1);
		}
	}
	vImg[0] = imread(Fname);

	sprintf(Fname, "%s/%d/Corrected/%.4d.png", Path, oCams[1], oFrames[1] - frameTimeStamp[oCams[1]]);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/%d/Corrected/%.4d.jpg", Path, oCams[1], oFrames[1] - frameTimeStamp[oCams[1]]);
		if (IsFileExist(Fname) == 0)
		{
			printLOG("Cannot load %s\n", Fname);
			exit(1);
		}
	}
	vImg[1] = imread(Fname);

	Mat bImg = DrawTitleImages(vImg, 2.0);

	double Fmat[9];
	CameraData *CamI = &VideoInfo[oCams[0]].VideoInfo[oFrames[0]];
	CameraData *CamJ = &VideoInfo[oCams[1]].VideoInfo[oFrames[1]];
	computeFmat(VideoInfo[oCams[0]].VideoInfo[oFrames[0]].K, VideoInfo[oCams[1]].VideoInfo[oFrames[1]].K,
		VideoInfo[oCams[0]].VideoInfo[oFrames[0]].R, VideoInfo[oCams[0]].VideoInfo[oFrames[0]].T,
		VideoInfo[oCams[1]].VideoInfo[oFrames[1]].R, VideoInfo[oCams[1]].VideoInfo[oFrames[1]].T, Fmat);

	Mat cvFmat = Mat(3, 3, CV_64F, &Fmat);
	namedWindow("VideoSequences", CV_WINDOW_NORMAL);
	setMouseCallback("VideoSequences", onMouse);
	oMouseX = MousePosX, oMouseY = MousePosY;

	cv::RNG rng(0);

	while (true)
	{
		if (numCams > 1)
		{
			setTrackbarPos("CamI", "VideoSequences", oCams[0]);
			setTrackbarPos("CamJ", "VideoSequences", oCams[1]);
		}
		setTrackbarPos("FrameID1", "VideoSequences", oFrames[0]);
		setTrackbarPos("FrameID2", "VideoSequences", oFrames[1]);

		imshow("VideoSequences", bImg);
		if (waitKey(1) == 27)
			break;

		if (nFrames[0] != oFrames[0] || nFrames[1] != oFrames[1] || nCams[0] != oCams[0] || nCams[1] != oCams[1])
		{
			nFrames[0] = oFrames[0], nFrames[1] = oFrames[1], nCams[0] = oCams[0], nCams[1] = oCams[1];

			sprintf(Fname, "%s/%d/Corrected/%.4d.png", Path, oCams[0], oFrames[0] - frameTimeStamp[oCams[0]]);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/Corrected/%.4d.jpg", Path, oCams[0], oFrames[0] - frameTimeStamp[oCams[0]]);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n", Fname);
					exit(1);
				}
			}
			vImg[0] = imread(Fname);

			sprintf(Fname, "%s/%d/Corrected/%.4d.png", Path, oCams[1], oFrames[1] - frameTimeStamp[oCams[1]]);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/Corrected/%.4d.jpg", Path, oCams[1], oFrames[1] - frameTimeStamp[oCams[1]]);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n", Fname);
					exit(1);
				}
			}
			vImg[1] = imread(Fname);

			printLOG("%d, %d: \n", oFrames - frameTimeStamp[oCams[0]], oFrames - frameTimeStamp[oCams[1]]);
			bImg = DrawTitleImages(vImg, 2.0);

			computeFmat(VideoInfo[oCams[0]].VideoInfo[oFrames[0]].K, VideoInfo[oCams[1]].VideoInfo[oFrames[1]].K,
				VideoInfo[oCams[0]].VideoInfo[oFrames[0]].R, VideoInfo[oCams[0]].VideoInfo[oFrames[0]].T,
				VideoInfo[oCams[1]].VideoInfo[oFrames[1]].R, VideoInfo[oCams[1]].VideoInfo[oFrames[1]].T, Fmat);
		}

		if (oMouseX != MousePosX || oMouseY != MousePosY)
			oMouseX = MousePosX, oMouseY = MousePosY;
		else
			continue;

		cv::Scalar color(rng(256), rng(256), rng(256));
		cv::Rect rect1(0, 0, vImg[0].cols, vImg[0].rows);
		cv::Rect rect2(vImg[0].cols, 0, vImg[1].cols, vImg[1].rows);

		Point2f pt1(oMouseX, oMouseY);
		double numX = Fmat[0] * pt1.x + Fmat[1] * pt1.y + Fmat[2];
		double numY = Fmat[3] * pt1.x + Fmat[4] * pt1.y + Fmat[5];
		double denum = Fmat[6] * pt1.x + Fmat[7] * pt1.y + Fmat[8];
		double epilines1[3] = { numX / denum, numY / denum, 1 };
		Point2i pt2(0, -(int)(epilines1[2] / epilines1[1])), pt3(vImg[0].cols, -(int)((epilines1[2] + epilines1[0] * vImg[0].cols) / epilines1[1]));
		cv::line(bImg(rect2), pt2, pt3, color);
		cv::circle(bImg(rect1), pt1, 3, color, -1, CV_AA);
		cout << "\a";
	}

	cv::destroyWindow("VideoSequences");
#endif
	return 0;
}
int VisualizeAllViewsEpipolarGeometry(char *Path, int nViews, int startF, int stopF)
{
#ifdef _WINDOWS
	char Fname[512];

	Corpus CorpusInfo;
	CorpusInfo.nCameras = nViews;
	CorpusInfo.camera = new CameraData[nViews];

	double dummy;
	sprintf(Fname, "%s/intrinsic.txt", Path);
	FILE *fp = fopen(Fname, "r");
	for (int ii = 0; ii < nViews; ii++)
	{
		double *intrinsic = CorpusInfo.camera[ii].intrinsic;

		fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf ", &intrinsic[0], &dummy, &intrinsic[3], &dummy,
			&dummy, &intrinsic[1], &intrinsic[4], &dummy,
			&dummy, &dummy, &dummy, &dummy,
			&dummy, &dummy, &dummy, &dummy);
	}
	fclose(fp);

	sprintf(Fname, "%s/extrinsic.txt", Path);
	fp = fopen(Fname, "r");
	for (int ii = 0; ii < nViews; ii++)
	{
		double *R = CorpusInfo.camera[ii].R;
		double *T = CorpusInfo.camera[ii].T;

		fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf  ", &R[0], &R[1], &R[2], &T[0],
			&R[3], &R[4], &R[5], &T[1],
			&R[6], &R[7], &R[8], &T[2],
			&dummy, &dummy, &dummy, &dummy);
		int a = 0;
	}
	fclose(fp);

	for (int ii = 0; ii < nViews; ii++)
	{
		GetKFromIntrinsic(CorpusInfo.camera[ii]);
		AssembleP(CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].R, CorpusInfo.camera[ii].T, CorpusInfo.camera[ii].P);

		for (int jj = 0; jj < 7; jj++)
			CorpusInfo.camera[ii].distortion[jj] = 0.0;
	}

	//Create display window
	bool NeedToReadImage = true;
	int oCams[2] = { 0, 1 }, nCams[2] = { 0,1 }, oMouseX = -1, oMouseY = -1;

	namedWindow("VideoSequences", CV_WINDOW_NORMAL);
	if (nViews > 1)
	{
		createTrackbar("CamI", "VideoSequences", &nCams[0], nViews - 1, NULL);
		createTrackbar("CamJ", "VideoSequences", &nCams[1], nViews - 1, NULL);
	}


	vector<Mat> vImg(2);
	sprintf(Fname, "%s/%d.png", Path, oCams[0]);
	if (IsFileExist(Fname) == 0)
	{
		printLOG("Cannot load %s\n", Fname);
		exit(1);
	}
	vImg[0] = imread(Fname);

	sprintf(Fname, "%s/%d.png", Path, oCams[1]);
	if (IsFileExist(Fname) == 0)
	{
		printLOG("Cannot load %s\n", Fname);
		exit(1);
	}
	vImg[1] = imread(Fname);

	Mat bImg = DrawTitleImages(vImg, 2.0);

	double Fmat[9];
	{
		CameraData *CamI = &CorpusInfo.camera[oCams[0]];
		CameraData *CamJ = &CorpusInfo.camera[oCams[1]];
		computeFmat(CamI[0].K, CamJ[0].K, CamI[0].R, CamI[0].T, CamJ[0].R, CamJ[0].T, Fmat);
	}

	Mat cvFmat = Mat(3, 3, CV_64F, &Fmat);
	namedWindow("VideoSequences", CV_WINDOW_NORMAL);
	setMouseCallback("VideoSequences", onMouse);
	oMouseX = MousePosX, oMouseY = MousePosY;

	cv::RNG rng(0);

	while (true)
	{
		if (nViews > 1)
		{
			setTrackbarPos("CamI", "VideoSequences", nCams[0]);
			setTrackbarPos("CamJ", "VideoSequences", nCams[1]);
		}

		imshow("VideoSequences", bImg);
		if (waitKey(1) == 27)
			break;

		if (nCams[0] != oCams[0] || nCams[1] != oCams[1])
		{
			oCams[0] = nCams[0], oCams[1] = nCams[1];

			sprintf(Fname, "%s/%d.png", Path, oCams[0]);
			if (IsFileExist(Fname) == 0)
			{
				printLOG("Cannot load %s\n", Fname);
				exit(1);
			}
			vImg[0] = imread(Fname);

			sprintf(Fname, "%s/%d.png", Path, oCams[1]);
			if (IsFileExist(Fname) == 0)
			{
				printLOG("Cannot load %s\n", Fname);
				exit(1);
			}
			vImg[1] = imread(Fname);

			bImg = DrawTitleImages(vImg, 2.0);

			CameraData *CamI = &CorpusInfo.camera[oCams[0]];
			CameraData *CamJ = &CorpusInfo.camera[oCams[1]];
			computeFmat(CamI[0].K, CamJ[0].K, CamI[0].R, CamI[0].T, CamJ[0].R, CamJ[0].T, Fmat);
		}

		if (oMouseX != MousePosX || oMouseY != MousePosY)
			oMouseX = MousePosX, oMouseY = MousePosY;
		else
			continue;

		cv::Scalar color(rng(256), rng(256), rng(256));
		cv::Rect rect1(0, 0, vImg[0].cols, vImg[0].rows);
		cv::Rect rect2(vImg[0].cols, 0, vImg[1].cols, vImg[1].rows);

		Point2f pt1(oMouseX, oMouseY);
		double numX = Fmat[0] * pt1.x + Fmat[1] * pt1.y + Fmat[2];
		double numY = Fmat[3] * pt1.x + Fmat[4] * pt1.y + Fmat[5];
		double denum = Fmat[6] * pt1.x + Fmat[7] * pt1.y + Fmat[8];
		double epilines1[3] = { numX / denum, numY / denum, 1 };
		Point2i pt2(0, -(int)(epilines1[2] / epilines1[1])), pt3(vImg[0].cols, -(int)((epilines1[2] + epilines1[0] * vImg[0].cols) / epilines1[1]));
		cv::line(bImg(rect2), pt2, pt3, color);
		cv::circle(bImg(rect1), pt1, 3, color, -1, CV_AA);
		cout << "\a";
	}

	cv::destroyWindow("VideoSequences");
#endif
	return 0;
}
int VisualizeAllTwoViewsTriangulation(char *Path, vector<int> &sCams, int startF, int stopF)
{
	char Fname[512];

	int numCams = *std::max_element(std::begin(sCams), std::end(sCams)) + 1;
	int *frameTimeStamp = new int[numCams];
	for (int ii = 0; ii < numCams; ii++)
		frameTimeStamp[ii] = 0;

	sprintf(Fname, "%s/InitSync.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int selected, ts; double fps;
		for (int ii = 0; ii < numCams; ii++)
		{
			fscanf(fp, "%d %lf %d ", &selected, &fps, &ts);
			frameTimeStamp[selected] = ts;
		}
		fclose(fp);
	}
	else
		printLOG("Cannot load time stamp info. Assume no frame offsets!");

	//Read calib info
	VideoData *VideoInfo = new VideoData[numCams];
	for (auto cid : sCams)
	{
		if (ReadVideoDataI(Path, VideoInfo[cid], cid, startF, stopF) == 1)
			return 1;
	}

	//Create display window
	bool NeedToReadImage = true;
	int oCams[2] = { 0, 1 }, nCams[2] = { 0, 1 }, oFrames = startF, nFrames = startF, oMouseX = -1, oMouseY = -1;

	namedWindow("CameraPair", CV_WINDOW_NORMAL);
	createTrackbar("CamI", "CameraPair", &oCams[0], numCams - 1, NULL);
	createTrackbar("CamJ", "CameraPair", &oCams[1], numCams - 1, NULL);
	createTrackbar("FrameID", "CameraPair", &oFrames, stopF - 1, NULL);
	cvSetTrackbarPos("CamI", "CameraPair", oCams[0]);
	cvSetTrackbarPos("CamJ", "CameraPair", oCams[1]);
	cvSetTrackbarPos("FrameID", "CameraPair", oFrames);

	vector<Mat> vImg(2);
	sprintf(Fname, "%s/%d/%.4d.png", Path, oCams[0], oFrames - frameTimeStamp[oCams[0]]);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, oCams[0], oFrames - frameTimeStamp[oCams[0]]);
		if (IsFileExist(Fname) == 0)
		{
			printLOG("Cannot load %s\n", Fname);
			exit(1);
		}
	}
	vImg[0] = imread(Fname);

	sprintf(Fname, "%s/%d/%.4d.png", Path, oCams[1], oFrames - frameTimeStamp[oCams[1]]);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, oCams[1], oFrames - frameTimeStamp[oCams[1]]);
		if (IsFileExist(Fname) == 0)
		{
			printLOG("Cannot load %s\n", Fname);
			exit(1);
		}
	}
	vImg[1] = imread(Fname);

	Mat bImg = DrawTitleImages(vImg, 2.0);

	namedWindow("CameraPair", CV_WINDOW_NORMAL);
	setMouseCallback("CameraPair", onMouse);

	cv::RNG rng(0);
	cv::Scalar color(rng(256), rng(256), rng(256));
	vector<Point2d> StereoPair;

	while (true)
	{
		if (nFrames != oFrames || nCams[0] != oCams[0] || nCams[1] != oCams[1])
		{
			nFrames = oFrames, nCams[0] = oCams[0], nCams[1] = oCams[1];

			sprintf(Fname, "%s/%d/%.4d.png", Path, oCams[0], oFrames - frameTimeStamp[oCams[0]]);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, oCams[0], oFrames - frameTimeStamp[oCams[0]]);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n", Fname);
					exit(1);
				}
			}
			vImg[0] = imread(Fname);

			sprintf(Fname, "%s/%d/%.4d.png", Path, oCams[1], oFrames - frameTimeStamp[oCams[1]]);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, oCams[1], oFrames - frameTimeStamp[oCams[1]]);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n", Fname);
					exit(1);
				}
			}
			vImg[1] = imread(Fname);

			printLOG("%d, %d: \n", oFrames - frameTimeStamp[oCams[0]], oFrames - frameTimeStamp[oCams[1]]);
			bImg = DrawTitleImages(vImg, 2.0);
		}

		if (oMouseX != MousePosX || oMouseY != MousePosY)
		{
			oMouseX = MousePosX, oMouseY = MousePosY;
			if (oMouseX < vImg[0].cols && oMouseX>0 && oMouseY < vImg[0].cols && oMouseY > 0)
			{
				StereoPair.push_back(Point2f(oMouseX, oMouseY));
				cv::circle(bImg, StereoPair[0], 3, color, -1, CV_AA);
			}
			if (StereoPair.size() == 1 && oMouseX < vImg[0].cols * 2 && oMouseX>vImg[0].cols && oMouseY < vImg[0].cols && oMouseY > 0)
			{
				StereoPair.push_back(Point2f(oMouseX - vImg[0].cols, oMouseY));
				cv::circle(bImg, Point2f(oMouseX, oMouseY), 3, color, -1, CV_AA);
			}
		}

		if (StereoPair.size() == 2)
		{
			CameraData *CamI = &VideoInfo[oCams[0]].VideoInfo[oFrames - frameTimeStamp[oCams[0]]];
			CameraData *CamJ = &VideoInfo[oCams[1]].VideoInfo[oFrames - frameTimeStamp[oCams[1]]];

			if (CamI[0].LensModel == RADIAL_TANGENTIAL_PRISM)
				LensCorrectionPoint(&StereoPair[0], CamI[0].K, CamI[0].distortion);
			else
				FishEyeCorrectionPoint(&StereoPair[0], CamI[0].K, CamI[0].distortion[0]);
			if (CamJ[0].LensModel == RADIAL_TANGENTIAL_PRISM)
				LensCorrectionPoint(&StereoPair[1], CamJ[1].K, CamJ[0].distortion);
			else
				FishEyeCorrectionPoint(&StereoPair[1], CamJ[0].K, CamJ[0].distortion[0]);

			double P[24];
			if (CamI[0].ShutterModel == 0)
				for (int kk = 0; kk < 12; kk++)
					P[kk] = CamI[0].P[kk];
			else
				AssembleP_RS(StereoPair[0], CamI[0], P);

			if (CamI[0].ShutterModel == 0)
				for (int kk = 0; kk < 12; kk++)
					P[kk + 12] = CamJ[0].P[kk];
			else
				AssembleP_RS(StereoPair[1], CamJ[0], P + 12);

			Point3d WC;
			TwoViewTriangulation(&StereoPair[0], &StereoPair[1], P, P + 12, &WC);

			double finalerror = 0.0;
			for (int ll = 0; ll < 2; ll++)
			{
				double num1 = P[ll * 12 + 0] * WC.x + P[ll * 12 + 1] * WC.y + P[ll * 12 + 2] * WC.z + P[ll * 12 + 3];
				double num2 = P[ll * 12 + 4] * WC.x + P[ll * 12 + 5] * WC.y + P[ll * 12 + 6] * WC.z + P[ll * 12 + 7];
				double denum = P[ll * 12 + 8] * WC.x + P[ll * 12 + 9] * WC.y + P[ll * 12 + 10] * WC.z + P[ll * 12 + 11];

				finalerror += pow(StereoPair[ll].x - num1 / denum, 2) + pow(StereoPair[ll].y - num2 / denum, 2);
			}
			finalerror = sqrt(finalerror / 2);
			printLOG("%f %f %f Error: %f\n", WC.x, WC.y, WC.z, finalerror);

			color = Scalar(rng(256), rng(256), rng(256));
			StereoPair.clear();
		}

		imshow("CameraPair", bImg);
		if (waitKey(1) == 27)
			break;
	}

	destroyWindow("CameraPair");

	return 0;
}
int VisualizeSiftMatchAllPairs(char *Path, int nCams, int fid, int *frameTimeStamp)
{
	char Fname[512];
	int npairs;
	Point2i matchPair;
	Mat Img1, Img2;

	vector<SiftKeypoint> kpts1, kpts2;

	vector<Point2i> SRawPairWiseMatchID;
	for (int jj = 0; jj < nCams - 1; jj++)
	{
		if (fid < 0)
			sprintf(Fname, "%s/%.4d.jpg", Path, jj);
		else
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, jj, fid - frameTimeStamp[jj]);
		if (IsFileExist(Fname) == 0)
		{
			if (fid < 0)
				sprintf(Fname, "%s/%.4d.png", Path, jj);
			else
				sprintf(Fname, "%s/%d/%.4d.png", Path, jj, fid - frameTimeStamp[jj]);
		}

		Img1 = imread(Fname);
		if (Img1.empty() == 1)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}

		if (fid < 0)
			sprintf(Fname, "%s%.4d.sift", Path, jj);
		else
			sprintf(Fname, "%s/%d/%.4d.sift", Path, jj, fid - frameTimeStamp[jj]);

		kpts1.clear();
		if (readVisualSFMSiftGPU(Fname, kpts1) == 1)
			continue;
		if (kpts1.size() == 0)
			continue;

		for (int ii = jj + 1; ii < nCams; ii++)
		{
			SRawPairWiseMatchID.clear();
			if (fid < 0)
				sprintf(Fname, "%s/Dynamic/M_%.2d_%.2d.txt", Path, jj, ii);
			else
				sprintf(Fname, "%s/Dynamic/%.4d/M_%.2d_%.2d.txt", Path, fid, jj, ii);
			FILE *fp = fopen(Fname, "r");
			fscanf(fp, "%d ", &npairs);
			for (int i = 0; i < npairs; i++)
			{
				fscanf(fp, "%d %d ", &matchPair.x, &matchPair.y);
				SRawPairWiseMatchID.push_back(matchPair);
			}
			fclose(fp);

			if (SRawPairWiseMatchID.size() < 15)
				continue;

			if (fid < 0)
				sprintf(Fname, "%s/%.4d.jpg", Path, ii);
			else
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, ii, fid - frameTimeStamp[ii]);
			if (IsFileExist(Fname) == 0)
			{
				if (fid < 0)
					sprintf(Fname, "%s/%.4d.png", Path, ii);
				else
					sprintf(Fname, "%s/%d/%.4d.png", Path, ii, fid - frameTimeStamp[ii]);
			}
			Img2 = imread(Fname);
			if (Img2.empty() == 1)
			{
				printLOG("Cannot load %s\n", Fname);
				continue;
			}

			if (fid < 0)
				sprintf(Fname, "%s%.4d.sift", Path, ii);
			else
				sprintf(Fname, "%s/%d/%.4d.sift", Path, ii, fid - frameTimeStamp[ii]);
			kpts2.clear();
			if (readVisualSFMSiftGPU(Fname, kpts2) == 1)
				continue;
			if (kpts2.size() == 0)
				continue;

			Mat correspond(max(Img1.rows, Img2.rows), Img1.cols + Img2.cols, CV_8UC3, Scalar(0, 0, 0));
			Rect rect1(0, 0, Img1.cols, Img1.rows);
			Img1.copyTo(correspond(rect1));
			Rect rect2(Img1.cols, 0, Img2.cols, Img2.rows);
			Img2.copyTo(correspond(rect2));

			vector<Scalar> colors;
			colors.push_back(Scalar(0, 0, 255));
			colors.push_back(Scalar(0, 128, 255));
			colors.push_back(Scalar(0, 255, 255));
			colors.push_back(Scalar(0, 255, 0));
			colors.push_back(Scalar(255, 128, 0));
			colors.push_back(Scalar(255, 255, 0));
			colors.push_back(Scalar(255, 0, 0));
			colors.push_back(Scalar(255, 0, 255));
			colors.push_back(Scalar(255, 255, 255));
			for (int i = 0; i < (int)SRawPairWiseMatchID.size(); i++)
			{
				int id1 = SRawPairWiseMatchID[i].x, id2 = SRawPairWiseMatchID[i].y;
				int x1 = (int)kpts1[id1].x, y1 = (int)kpts1[id1].y;
				int x2 = (int)kpts2[id2].x + Img1.cols, y2 = (int)kpts2[id2].y;
				cv::circle(correspond, Point2i(x1, y1), 1, colors[i % 9], 3), cv::circle(correspond, Point2i(x2, y2), 1, colors[i % 9], 3);
				cv::line(correspond, Point2i(x1, y1), Point2i(x2, y2), colors[i % 9], 2);
			}

			namedWindow("Correspondence", CV_WINDOW_NORMAL);
			cv::Point2i text_origin = { correspond.rows / 20, correspond.cols / 20 };
			sprintf(Fname, "%d_%d vs. %d_%d: %d", jj, fid - frameTimeStamp[jj], ii, fid - frameTimeStamp[ii], SRawPairWiseMatchID.size()), putText(correspond, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*correspond.cols / 640, colors[0], 3);
			cv::imshow("Correspondence", correspond);
			cv::waitKey(100);
		}
	}

	return 0;
}

int VisualizeSfMMatchTable(char *Path, int nviews)
{
	vector<int> cumulativePts;
	ReadCumulativePointsVisualSfm(Path, nviews, cumulativePts);
	int totalPts = cumulativePts[nviews];

	char Fname[512]; sprintf(Fname, "%s/View_ID_PM.txt", Path); FILE *fp = fopen(Fname, "r");
	int nviewsi, viewi, np, pi, n3D = 0;
	while (fscanf(fp, "%d ", &nviewsi) != EOF)
	{
		for (int ii = 0; ii < nviewsi; ii++)
			fscanf(fp, "%d %d ", &viewi, &viewi);
		n3D++;
	}
	fclose(fp);

	vector<int>*PViewIdAll3D = new vector<int>[n3D];
	vector<int>*PPidAll3D = new vector<int>[n3D];

	n3D = 0;
	printLOG("\nReading Matching table....");
	sprintf(Fname, "%s/View_ID_PM.txt", Path);  fp = fopen(Fname, "r");
	while (fscanf(fp, "%d ", &nviewsi) != EOF)
	{
		PViewIdAll3D[n3D].reserve(nviewsi);
		PPidAll3D[n3D].reserve(nviewsi);
		for (int ii = 0; ii < nviewsi; ii++)
		{
			fscanf(fp, "%d %d ", &viewi, &pi);
			PViewIdAll3D[n3D].push_back(viewi);
			PPidAll3D[n3D].push_back(pi);
		}
		n3D++;
	}
	fclose(fp);
	printLOG("...Done\n");

	//Read all sift points
	printLOG("Reading SIFT keys....");
	vector<KeyPoint> *AllKeys = new vector < KeyPoint >[nviews];
	for (int ii = 0; ii < nviews; ii++)
	{
		sprintf(Fname, "%s/%.4d.sift", Path, ii);
		readVisualSFMSiftGPU(Fname, AllKeys[ii]);// ReadKPointsBinarySIFT(Fname, AllKeys[ii]);
	}
	printLOG("...Done\n");

	//Read all the images
	vector<Mat> allImages(nviews);
	for (int ii = 0; ii < nviews; ii++)
	{
		sprintf(Fname, "%s/%.4d.jpg", Path, ii);
		allImages[ii] = imread(Fname);
	}

	namedWindow("VisualizeSfMMatchTable", CV_WINDOW_NORMAL);
	cvSetWindowProperty("VisualizeSfMMatchTable", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
	int pointID = 0, opointID = 0;  createTrackbar("Control", "VisualizeSfMMatchTable", &pointID, n3D - 1, NULL);

	cvSetTrackbarPos("Control", "VisualizeSfMMatchTable", pointID);
	vector<Mat> vImg;
	while (waitKey(17) != 27)
	{
		if (pointID == opointID)
			continue;
		if (pointID > n3D)
			pointID = n3D - 1;

		vImg.clear();
		for (int ii = 0; ii < PViewIdAll3D[pointID].size(); ii++)
		{
			int vid = PViewIdAll3D[pointID][ii];
			if (allImages[vid].cols < 1)
				continue;
			vImg.push_back(allImages[vid]);
			int pid = PPidAll3D[pointID][ii];
			Point2f uv = AllKeys[vid][pid].pt;
			circle(vImg.back(), uv, 2, Scalar(rand() % 255, rand() % 255, rand() % 255), 2);
		}
		Mat img = DrawTitleImages(vImg);
		sprintf(Fname, "%d", pointID); CvPoint text_origin = { img.cols / 20, img.rows / 20 };
		putText(img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * 640 / img.cols, CV_RGB(255, 0, 0), 2);
		imshow("VisualizeSfMMatchTable", img);
	}

	return 0;
}
int VisualizeSfMMatchPair(char *Path)
{
	char Fname[512];
	sprintf(Fname, "%s/tMatch.txt", Path);
	FILE *fp = fopen(Fname, "r");
	int nmatches, vid1, vid2, p1, p2;
	vector<Point2i> matches;
	fscanf(fp, "%d %d %d ", &vid1, &vid2, &nmatches);
	for (int ii = 0; ii < nmatches; ii++)
	{
		fscanf(fp, "%d %d ", &p1, &p2);
		matches.push_back(Point2i(p1, p2));
	}
	fclose(fp);

	//Read all sift points
	printLOG("Reading SIFT keys....");
	vector<KeyPoint> AllKeys[2];
	sprintf(Fname, "%s/%.4d.sift", Path, vid1), readVisualSFMSiftGPU(Fname, AllKeys[0]);
	sprintf(Fname, "%s/%.4d.sift", Path, vid2), readVisualSFMSiftGPU(Fname, AllKeys[1]);
	printLOG("...Done\n");

	//Read all the images
	vector<Mat> allImages(2);
	sprintf(Fname, "%s/%.4d.jpg", Path, vid1), allImages[0] = imread(Fname);
	sprintf(Fname, "%s/%.4d.jpg", Path, vid2), allImages[1] = imread(Fname);

	namedWindow("VisualizeSfMMatchPair", CV_WINDOW_NORMAL);
	cvSetWindowProperty("VisualizeSfMMatchPair", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
	int per = 0, oper = 0;  createTrackbar("Control", "VisualizeSfMMatchPair", &per, 10, NULL);

	cvSetTrackbarPos("Control", "VisualizeSfMMatchPair", per);
	vector<Mat> vImg;
	while (waitKey(17) != 27)
	{
		if (per == oper)
			continue;
		if (per > 9)
			per = 9;

		vImg.clear();
		vImg.push_back(allImages[0]), vImg.push_back(allImages[1]);
		Mat img = DrawTitleImages(vImg);

		for (int ii = matches.size()*per / 10; ii < matches.size()*(per + 1) / 10; ii++)
		{
			Point2i pid = matches[ii];
			Point2f uv1 = AllKeys[0][pid.x].pt, uv2 = AllKeys[1][pid.y].pt;
			uv2.x += img.cols / 2;
			int r = rand() % 255, g = rand() % 255, b = rand() % 255;
			//circle(img, uv1, 2, Scalar(r, g, b), 2);
			//circle(img, uv2, 2, Scalar(r, g, b), 2);
			line(img, uv1, uv2, Scalar(r, g, b), 2);
		}
		imshow("VisualizeSfMMatchPair", img);
	}

	return 0;
}
int VisualizeSfMCorpusFeatures(char *Path)
{
	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));
	char Fname[512];

	Corpus CorpusInfo;
	sprintf(Fname, "%s/Corpus", Path);
	ReadCorpusInfo(Fname, CorpusInfo, false, true);


	vector <vector<int> > viewIdAll3D; //3D -> visiable views index
	vector <vector<int> > pointIdAll3D; //3D -> 2D index in those visible views
	vector<vector<Point2d> > uvAll3D; //3D -> uv of that point in those visible views

	vector<Mat > allImages(CorpusInfo.nCameras);
	for (int cid = 0; cid < CorpusInfo.nCameras; cid++)
	{
		sprintf(Fname, "%s/Corpus/%.4d.png", Path, cid);
		allImages[cid] = imread(Fname);
	}

	for (int pid = 0; pid < CorpusInfo.n3dPoints; pid++)
	{
		for (int cid = 0; cid < CorpusInfo.viewIdAll3D[pid].size(); cid++)
		{
			Point2d uv = CorpusInfo.uvAll3D[pid][cid];
			circle(allImages[CorpusInfo.viewIdAll3D[pid][cid]], uv, 2, colors[pid % 8], 2);
		}
	}

	CvSize size;
	size.width = allImages[0].cols, size.height = allImages[0].rows;

	sprintf(Fname, "%s/Vis/CorpusFeatures.avi", Path);
	VideoWriter writer; writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
	for (int cid = 0; cid < CorpusInfo.nCameras; cid++)
	{
		CvPoint text_origin = { allImages[cid].cols / 30, allImages[cid].cols / 30 };
		sprintf(Fname, "%d", cid);
		putText(allImages[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * allImages[cid].cols / 640, CV_RGB(255, 0, 0), 3);
		writer << allImages[cid];
	}
	writer.release();

	return 0;
}
int Visualize_VideoKeyFrame2CorpusSfM_Inliers(char *Path, int selectedCamId, int startF, int stopF, double resizeFactor)
{
	char Fname[512];

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));

	Mat img, rImg;
	bool firstTime = true;
	VideoWriter writer;

	for (int fid = startF; fid <= stopF; fid++)
	{
		sprintf(Fname, "%s/%d/PnP/KF_Inliers_%.4d.txt", Path, selectedCamId, fid);
		if (IsFileExist(Fname) == 1)
		{
			printLOG("%d...", fid);
			float x, y, z, u, v, s;
			int globalCorpusP3DId, localCorpusP3DId, p2DId;
			vector<int> vglobalCorpusP3DId, vlocalCorpusP3DId;
			vector<float > vu, vv;
			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d %f %f %f %d %f %f %f", &globalCorpusP3DId, &localCorpusP3DId, &x, &y, &z, &p2DId, &u, &v, &s) != EOF)
			{
				vglobalCorpusP3DId.push_back(globalCorpusP3DId);
				vlocalCorpusP3DId.push_back(localCorpusP3DId);
				vu.push_back(u), vv.push_back(v);
			}
			fclose(fp);

			sprintf(Fname, "%s/%d/%.4d.png", Path, selectedCamId, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, selectedCamId, fid);
				if (IsFileExist(Fname) == 0)
					continue;
			}
			img = imread(Fname);

			if (resizeFactor == 1.0)
				rImg = img;
			else
				resize(img, rImg, Size(resizeFactor* img.cols, resizeFactor*img.rows));

			CvPoint text_origin = { rImg.cols / 30,rImg.cols / 30 };
			sprintf(Fname, "%d", fid);
			putText(rImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 *rImg.cols / 640, CV_RGB(255, 0, 0), 3);

			for (int pid = 0; pid < vglobalCorpusP3DId.size(); pid++)
			{
				if (vglobalCorpusP3DId[pid] == -1)
					circle(rImg, Point2i(vu[pid] * resizeFactor, vv[pid] * resizeFactor), 1, colors[vlocalCorpusP3DId[pid] % 8], 2);
				else
					circle(rImg, Point2i(vu[pid] * resizeFactor, vv[pid] * resizeFactor), 1, colors[vlocalCorpusP3DId[pid] % 8], 3);
			}

			if (firstTime)
			{
				firstTime = !firstTime;
				CvSize size;
				size.width = rImg.cols, size.height = rImg.rows;
				sprintf(Fname, "%s/Vis/VideoKeyFrame2CorpusSfM_%d.avi", Path, selectedCamId);
				writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
			}
			writer << rImg;
		}
	}
	writer.release();

	return 0;
}

int VisualizeIntraReAssignedPeople(char *Path, int sCamId, int startF, int stopF)
{
	char Fname[512];

	int nf, sf, pid, tid;
	float score;
	vector<int> VstartFInstance;
	vector<vector<int> >trackletVec;

	sprintf(Fname, "%s/%d/Tracklet_%d_%d.txt", Path, sCamId, startF, stopF); FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
	{
		vector<int> PersonId(nf);
		for (int fid = 0; fid < nf; fid++)
			fscanf(fp, "%d ", &PersonId[fid]);
		trackletVec.push_back(PersonId);
		VstartFInstance.push_back(sf);
	}
	fclose(fp);

	vector<int> PersonId;
	sprintf(Fname, "%s/%d/Identity_%d_%d.txt", Path, sCamId, startF, stopF); fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d %f ", &tid, &pid, &score) != EOF)
		PersonId.push_back(pid);
	fclose(fp);

	if (PersonId.size() != trackletVec.size())
	{
		printLOG("Problem with the people ID\n");
		return 0;
	}
	else
	{
		int currentNewPeople = 0;
		for (int ii = 0; ii < (int)PersonId.size(); ii++)
			if (PersonId[ii] == -1)
				PersonId[ii] = currentNewPeople, currentNewPeople++;
	}

	//Visualize the tracker
	double resizeFactor = 0.4;
	vector<Mat> allImages;
	vector<vector<Point2f> *> allPoses;

	int increP = 10;
	printLOG("Reading images: ");
	for (int fid = startF; fid <= stopF; fid++)
	{
		vector<Point2f> *PoseI = new vector<Point2f>[1];
		sprintf(Fname, "%s/Pose/%d/%d.txt", Path, sCamId, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		float u, v, s;
		while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
			PoseI[0].push_back(Point2f(u, v));
		fclose(fp);
		allPoses.push_back(PoseI);

		sprintf(Fname, "%s/%d/%.4d.jpg", Path, sCamId, fid);
		Mat img = imread(Fname);
		if (img.empty())
			continue;
		resize(img, img, Size((int)(resizeFactor* img.cols), (int)(resizeFactor*img.rows)), 0, 0, INTER_AREA);
		allImages.push_back(img);
		if (100 * (fid - startF) / (stopF - startF) > increP)
			printLOG("%d%%..", increP), increP += 10;
	}
	printLOG("100%%\n");
	if (allImages.size() == 0)
		return 0;

	for (int id = 0; id < (int)trackletVec.size(); id++)
	{
		for (int tid = 0; tid < trackletVec[id].size(); tid++)
		{
			int fid = VstartFInstance[id] + tid;
			if (fid - startF > allImages.size() - 1)
				continue;

			int pid = trackletVec[id][tid];
			CvPoint text_origin = { MyFtoI(resizeFactor*(allPoses[fid - startF][0][pid * 15 + 1].x - 10)), MyFtoI(resizeFactor*(allPoses[fid - startF][0][pid * 15 + 1].y - 10)) };
			sprintf(Fname, "%d", PersonId[id]);
			putText(allImages[fid - startF], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*allImages[fid - startF].cols / 640, CV_RGB(0, 255, 0), 1);
		}
	}

	for (int fid = startF; fid <= stopF; fid++)
	{
		if (fid - startF > allImages.size() - 1)
			continue;
		sprintf(Fname, "%s/%d/A_%.4d.jpg", Path, sCamId, fid);
		imwrite(Fname, allImages[fid - startF]);
	}

	return 0;
}
int VisualizeExtraReassignedPeoplePerTriplet(char *Path, vector<int> &sCams, vector<int> &TimeStamp, int startF, int stopF, int increF, int mode)
{
	char Fname[512];
	double resizeFactor = 0.4;
	int nJoints = 18;

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));
	sprintf(Fname, "%s/MultiviewReID/Vis", Path); makeDir(Fname);

	if (mode == 0) //raw
	{
		//vector<Mat> vBimg;
		for (int fid = startF; fid <= stopF; fid += increF)
		{
			int cidI, cidJ, cidK, pidI, pidJ, pidK, nasso, bestnAsso = 0; float score;
			vector<int> Triplet;  vector<vector<int> > BestPeoplePairing, PeopleParing;
			vector<Mat> allImages; Mat img, bImg;
			vector<vector<Point2f> > allPoses;

			int maxCams = 0;
			for (int ii = 0; ii < sCams.size(); ii++)
				maxCams = max(sCams[ii], maxCams);
			allImages.resize(maxCams + 1);

			for (int ii = 0; ii < sCams.size(); ii++)
			{
				int cid = sCams[ii];

				vector<Point2f> PoseI;
				sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, fid - TimeStamp[cid]);  FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				float u, v, s;
				while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					PoseI.push_back(Point2f(u, v));
				fclose(fp);
				allPoses.push_back(PoseI);

				sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid - TimeStamp[cid]);
				if (IsFileExist(Fname) == 0)
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid - TimeStamp[cid]);
				Mat img = imread(Fname);
				if (img.empty())
					continue;
				resize(img, img, Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
				allImages[cid] = img.clone();
			}

			int count = -1;
			vector<Mat> vImg;
			sprintf(Fname, "%s/MultiviewReID/T_%d.txt", Path, fid); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%d %d %d %d %f ", &cidK, &cidJ, &cidI, &nasso, &score) != EOF)
			{
				count++;
				PeopleParing.clear();
				for (int ii = 0; ii < nasso; ii++)
				{
					fscanf(fp, "%d %d %d ", &pidK, &pidJ, &pidI);
					vector<int> pairing;
					pairing.push_back(pidK), pairing.push_back(pidJ), pairing.push_back(pidI);
					PeopleParing.push_back(pairing);
				}

				if (PeopleParing.size() < 3)
					continue;

				Triplet.clear();  Triplet.push_back(cidK), Triplet.push_back(cidJ), Triplet.push_back(cidI);

				vImg.clear();
				for (size_t ii = 0; ii < Triplet.size(); ii++)
				{
					int cid = Triplet[ii];
					img = allImages[cid].clone();
					if (img.empty() == 1)
						continue;
					for (int tid = 0; tid < nasso; tid++)
					{
						int pid = PeopleParing[tid][ii];
						for (int jid = 0; jid < nJoints; jid++)
						{
							if (allPoses[cid][pid * nJoints + jid].x < 1)
								continue;

							CvPoint text_origin = { (int)(resizeFactor*(allPoses[cid][pid * nJoints + jid].x - 10)), (int)(resizeFactor*(allPoses[cid][pid * nJoints + jid].y - 10)) };
							sprintf(Fname, "%d", tid), putText(img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*allImages[cid].cols / 640, colors[tid % 9], 3);
							break;
						}
					}

					sprintf(Fname, "%d", cid); CvPoint text_origin = { img.cols / 20, img.rows / 20 };
					putText(img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * 640 / img.cols, CV_RGB(255, 0, 0), 2);
					vImg.push_back(img);
				}

				Mat bImg = DrawTitleImages(vImg);
				sprintf(Fname, "%s/MultiviewReID/Vis/%.4d_%d.jpg", Path, fid, count);  imwrite(Fname, bImg);
			}
			fclose(fp);
		}

		/*CvSize size;
		size.width = 1920, size.height = 1080;
		VideoWriter writer; writer.open("G:/NEA/x.avi", CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
		Mat img = imread("G:/NEA/0/0040.png");
		for (int ii = 0; ii < 100; ii++)
		writer << img;
		writer.release();*/
	}
	else //with cycle consistency
	{
		for (int fid = startF; fid <= stopF; fid += increF)
		{
			vector<int> usefulImg;  vector<vector<Point2i> >CamIDPeopleID;
			vector<Mat> allImages; Mat img, bImg;
			vector<vector<Point2f> > allPoses;

			int maxCams = 0;
			for (int ii = 0; ii < sCams.size(); ii++)
				maxCams = max(sCams[ii], maxCams);
			allImages.resize(maxCams + 1);

			for (int ii = 0; ii < sCams.size(); ii++)
			{
				int cid = sCams[ii];

				vector<Point2f> PoseI;
				sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, fid - TimeStamp[cid]);  FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				float u, v, s;
				while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					PoseI.push_back(Point2f(u, v));
				fclose(fp);
				allPoses.push_back(PoseI);

				sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid - TimeStamp[cid]);
				if (IsFileExist(Fname) == 0)
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid - TimeStamp[cid]);
				Mat img = imread(Fname);
				if (img.empty())
					continue;
				resize(img, img, Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
				allImages[cid] = img.clone();
			}

			int cid, pid, nasso;
			sprintf(Fname, "%s/MultiviewReID/%d.txt", Path, fid); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			int allCamAssociation;  fscanf(fp, "%d ", &allCamAssociation);
			CamIDPeopleID.clear();
			for (int kk = 0; kk < allCamAssociation; kk++)
			{
				fscanf(fp, "%d ", &nasso);
				vector<Point2i> cid_pid;
				for (int jj = 0; jj < nasso; jj++)
				{
					fscanf(fp, "%d %d ", &cid, &pid);
					cid_pid.push_back(Point2i(cid, pid));
					usefulImg.push_back(cid);
				}
				if (nasso > 0)
					CamIDPeopleID.push_back(cid_pid);
			}
			fclose(fp);

			sort(usefulImg.begin(), usefulImg.end());
			std::vector<int>::iterator it = unique(usefulImg.begin(), usefulImg.end());
			usefulImg.resize(std::distance(usefulImg.begin(), it));

			for (size_t tid = 0; tid < CamIDPeopleID.size(); tid++)
			{
				for (size_t aid = 0; aid < CamIDPeopleID[tid].size(); aid++)
				{
					int cid = CamIDPeopleID[tid][aid].x, pid = CamIDPeopleID[tid][aid].y;
					for (int jid = 0; jid < nJoints; jid++)
					{
						if (allPoses[cid][pid * nJoints + jid].x < 1)
							continue;

						CvPoint text_origin = { MyFtoI(resizeFactor*(allPoses[cid][pid * nJoints + jid].x - 10)),MyFtoI(resizeFactor*(allPoses[cid][pid * nJoints + jid].y - 10)) };
						sprintf(Fname, "%d", tid), putText(allImages[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*allImages[cid].cols / 640, colors[tid % 9], 1);
						break;
					}
				}
			}

			for (size_t ii = 0; ii < usefulImg.size(); ii++)
				sprintf(Fname, "%s/MultiviewReID/Vis/%.4d_%d.jpg", Path, fid, usefulImg[ii]), imwrite(Fname, allImages[usefulImg[ii]]);
			int a = 0;
		}
		int a = 0;
	}

	return 0;
}
int VisualizeExtraReassignedPeople(char *Path, int nCams, int startF, int stopF)
{
	char Fname[512];
	double resizeFactor = 0.4;
	int nJoints = 18;

	Mat bImg;
	for (int fid = startF; fid <= stopF; fid++)
	{
		printLOG("%d ..", fid);
		int cid, pid, nasso, nvisibles;
		vector<Mat> allImages;
		vector<vector<Point2f> > allPoses;

		for (int ii = 0; ii < nCams; ii++)
		{
			vector<Point2f> PoseI;
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, ii, fid);  FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				break;
			float u, v, s;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				PoseI.push_back(Point2f(u, v));
			fclose(fp);
			allPoses.push_back(PoseI);

			sprintf(Fname, "%s/%d/%.4d.jpg", Path, ii, fid);
			Mat img = imread(Fname);
			if (img.empty())
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, ii, fid);
				img = imread(Fname);
				if (img.empty())
					break;;
			}
			resize(img, img, Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
			allImages.push_back(img);
		}
		if (allPoses.size() != nCams)
			continue;

		vector<vector<Point2i> > ReliableAssosID;
		sprintf(Fname, "%s/MultiviewReID/%d.txt", Path, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		fscanf(fp, "%d ", &nasso);
		for (int ii = 0; ii < nasso; ii++)
		{
			fscanf(fp, "%d ", &nvisibles);
			vector<Point2i> assosID;
			for (int jj = 0; jj < nvisibles; jj++)
			{
				fscanf(fp, "%d %d  ", &cid, &pid);
				assosID.push_back(Point2i(cid, pid));
			}
			ReliableAssosID.push_back(assosID);
		}
		fclose(fp);

		for (size_t ii = 0; ii < ReliableAssosID.size(); ii++)
		{
			vector<Point2i> assosID = ReliableAssosID[ii];
			for (size_t jj = 0; jj < assosID.size(); jj++)
			{
				int cid = assosID[jj].x, pid = assosID[jj].y;
				CvPoint text_origin = { MyFtoI(resizeFactor*(allPoses[cid][pid * nJoints + 1].x - 10)),MyFtoI(resizeFactor*(allPoses[cid][pid * nJoints + 1].y - 10)) };
				sprintf(Fname, "%d", ii), putText(allImages[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*allImages[cid].cols / 640, CV_RGB(0, 255, 0), 2);
			}
		}
		if (ReliableAssosID.size() > 0)
		{
			int width = allImages[0].cols, height = allImages[0].rows;
			bImg = Mat::zeros(height * 2, width * 2, CV_8UC3);
			for (int ii = 0; ii < nCams; ii++)
			{
				int x = (ii / 2), y = (ii % 2);
				allImages[ii].copyTo(bImg(Rect(x*width, y*height, width, height)));
			}
			sprintf(Fname, "%s/MultiviewReID/%.4d.jpg", Path, fid), imwrite(Fname, bImg);
		}
	}
	return 0;
}
int VisualizeReIDPerCam(char *Path, vector<int> &vCams, vector<int> &TimeStamp, int startF, int stopF, int increF)
{
	char Fname[512];
	sprintf(Fname, "%s/Vis/AllPairDescMatch", Path); makeDir(Fname);

	int nCams = TimeStamp.size(), nJoints = 18, nBestMatches = 3, dummy;
	float resizeFactor = 0.33, detectionThresh = 0.5, simThresh = 0.5, ratioTestThresh = 0.8, u, v, s;
	vector<Point2f> *AllPts = new vector<Point2f>[nJoints*nCams];
	Mat *allImages = new Mat[nCams];


	struct C2C {
		int nPj;
		vector<Point2f> *Pj2Pi;
	};
	vector<Mat> vImg;
	C2C *C2C_Matches = new C2C[nCams*nCams];
	vector<Point2f> JI[100], IJ[100];

	CvSize size;
	int fps = 10;
	VideoWriter writer;

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));

	int id_dummy[30]; float s_dummy[30];
	Mat Img, bImg, bImg2;
	bool firstFrame = true;
	size_t nf = 0;
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		printLOG("%d (%d) ..", fid, nf);

		for (auto cid : vCams)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid - TimeStamp[cid]);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid - TimeStamp[cid]);
				if (IsFileExist(Fname) == 0)
					continue;
			}
			allImages[cid] = imread(Fname);

			AllPts[cid].clear();
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, fid - TimeStamp[cid]); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				s < detectionThresh ? AllPts[cid].push_back(Point2d(0, 0)) : AllPts[cid].push_back(Point2d(u, v));
			fclose(fp);

			/*for (int pid = 0; pid < AllPts[cid].size() / nJoints; pid++)
			{
			for (int jid = 0; jid < nJoints; jid++)
			{
			if (AllPts[cid][pid * nJoints + jid].x < 1)
			continue;

			CvPoint text_origin = { (AllPts[cid][pid * nJoints + jid].x - 10), (AllPts[cid][pid * nJoints + jid].y - 10) };
			sprintf(Fname, "%d", pid), putText(allImages[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0*allImages[cid].cols / 640, colors[0], 3);
			break;
			}
			}*/
		}

		for (size_t jj = 0; jj < vCams.size() - 1; jj++) //for image J
		{
			for (size_t ii = jj + 1; ii < vCams.size(); ii++) //for image I
			{
				int cidJ = vCams[jj], cidI = vCams[ii], nPeopleJ = AllPts[cidJ].size() / nJoints, nPeopleI = AllPts[cidI].size() / nJoints;
				sprintf(Fname, "%s/MP/Matches/%d_%d_%d.txt", Path, fid, cidJ, cidI); FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				C2C_Matches[cidI + cidJ * nCams].nPj = nPeopleJ, C2C_Matches[cidJ + cidI * nCams].nPj = nPeopleI;
				C2C_Matches[cidI + cidJ * nCams].Pj2Pi = new vector<Point2f>[nPeopleJ];
				C2C_Matches[cidJ + cidI * nCams].Pj2Pi = new vector<Point2f>[nPeopleI];
				/*for (int kk = 0; kk < nPeopleJ; kk++) //for pJ in image J
				{
				int count = 0;
				for (int ll = 0; ll < nPeopleI; ll++)
				{
				fscanf(fp, "%d %d %f ", &dummy, &dummy, &s);
				if (s > simThresh)
				{
				id_dummy[count] = ll, s_dummy[count] = -s;
				count++;
				}
				}

				Quick_Sort_Float(s_dummy, id_dummy, 0, count - 1); // sort all pI in image I
				for (int tt = 0; tt < min(nBestMatches, count); tt++)
				{
				C2C_Matches[cidI + cidJ*nCams].Pj2Pi[kk].push_back(id_dummy[tt]);
				if (tt + 1 < count && abs(s_dummy[tt]) * ratioTestThresh > abs(s_dummy[tt + 1]))
				break;
				}
				}
				fclose(fp);*/


				for (int kk = 0; kk < nPeopleJ; kk++)
					JI[kk].clear();
				for (int ll = 0; ll < nPeopleI; ll++)
					IJ[ll].clear();
				for (int kk = 0; kk < nPeopleJ; kk++) //for pJ in image J
				{
					for (int ll = 0; ll < nPeopleI; ll++)
					{
						int j, i;  fscanf(fp, "%d %d %f ", &j, &i, &s);
						if (s > simThresh)
							JI[kk].push_back((Point2f(i, s))), IJ[ll].push_back(Point2f(j, s));
					}
				}
				fclose(fp);

				//j 2 i
				for (int kk = 0; kk < nPeopleJ; kk++) //for pJ in image J
				{
					for (int ll = 0; ll < JI[kk].size(); ll++)
						s_dummy[ll] = -JI[kk][ll].y, id_dummy[ll] = JI[kk][ll].x;

					Quick_Sort_Float(s_dummy, id_dummy, 0, (int)JI[kk].size() - 1); // sort all pI in image I
					for (int ll = 0; ll < min(nBestMatches, (int)JI[kk].size()); ll++)
					{
						C2C_Matches[cidI + cidJ * nCams].Pj2Pi[kk].push_back(Point2f(id_dummy[ll], -s_dummy[ll]));
						if (ll + 1 < IJ[kk].size() - 1 && abs(s_dummy[ll]) * ratioTestThresh > abs(s_dummy[ll + 1]))
							break;
					}
				}

				//i 2 j
				for (int kk = 0; kk < nPeopleI; kk++) //for pJ in image J
				{
					for (int ll = 0; ll < IJ[kk].size(); ll++)
						s_dummy[ll] = -IJ[kk][ll].y, id_dummy[ll] = IJ[kk][ll].x;

					Quick_Sort_Float(s_dummy, id_dummy, 0, IJ[kk].size() - 1); // sort all pI in image I
					for (int ll = 0; ll < min(nBestMatches, (int)IJ[kk].size()); ll++)
					{
						C2C_Matches[cidJ + cidI * nCams].Pj2Pi[kk].push_back(Point2f(id_dummy[ll], -s_dummy[ll]));
						if (ll + 1 < IJ[kk].size() - 1 && abs(s_dummy[ll]) * ratioTestThresh > abs(s_dummy[ll + 1]))
							break;
					}
				}
			}
		}

		for (size_t ii = 0; ii < vCams.size(); ii++) //for image I
		{
			int cidI = vCams[ii], nPeopleI = (int)AllPts[cidI].size() / nJoints;
			for (int pidI = 0; pidI < nPeopleI; pidI++) //for all people in image I
			{
				vImg.clear();
				for (size_t cid = 0; cid < nCams; cid++)
					vImg.push_back(allImages[cid].clone());

				float minX = 9e9, minY = 9e9, maxX = 0, maxY = 0;
				for (int jid = 0; jid < nJoints; jid++)
					if (AllPts[cidI][pidI*nJoints + jid].x > 0)
						minX = min(minX, AllPts[cidI][pidI*nJoints + jid].x), maxX = max(maxX, AllPts[cidI][pidI*nJoints + jid].x), minY = min(minY, AllPts[cidI][pidI*nJoints + jid].y), maxY = max(maxY, AllPts[cidI][pidI*nJoints + jid].y);
				rectangle(vImg[cidI], Point2i(minX - vImg[cidI].cols / 50, minY - vImg[cidI].cols / 50), Point2i(maxX + vImg[cidI].rows / 50, maxY + vImg[cidI].rows / 50), colors[7], 8, 8, 0);

				for (int jid = 0; jid < nJoints; jid++)
				{
					if (AllPts[cidI][pidI*nJoints + jid].x < 1)
						continue;

					CvPoint text_origin = { MyFtoI(AllPts[cidI][pidI*nJoints + jid].x - 10), MyFtoI(AllPts[cidI][pidI*nJoints + jid].y + 10) };
					sprintf(Fname, "%d", pidI), putText(vImg[cidI], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0*vImg[cidI].cols / 640, colors[0], 3);
					break;
				}
				//sprintf(Fname, "%s/MP/%d.jpg", Path, cidI);  imwrite(Fname, vImg[cidI]);

				//just draw all the detected BB so that we know other people are detected or now
				for (size_t jj = 0; jj < vCams.size(); jj++) //draw nBestMatches-NN in all other images
				{
					int cidJ = vCams[jj], nPeopleJ = (int)AllPts[cidJ].size() / nJoints;
					if (cidJ == cidI)
						continue;
					for (int pidJ = 0; pidJ < nPeopleJ; pidJ++) //for all people in image I
					{
						minX = 9e9, minY = 9e9, maxX = 0, maxY = 0;
						for (int jid = 0; jid < nJoints; jid++)
							if (AllPts[cidJ][pidJ*nJoints + jid].x > 0)
								minX = min(minX, AllPts[cidJ][pidJ*nJoints + jid].x), maxX = max(maxX, AllPts[cidJ][pidJ*nJoints + jid].x), minY = min(minY, AllPts[cidJ][pidJ*nJoints + jid].y), maxY = max(maxY, AllPts[cidJ][pidJ*nJoints + jid].y);
						rectangle(vImg[cidJ], Point2i(minX - vImg[cidJ].cols / 50, minY - vImg[cidJ].cols / 50), Point2i(maxX + vImg[cidJ].rows / 50, maxY + vImg[cidJ].rows / 50), colors[8], 8, 8, 0);
					}
				}

				for (size_t jj = 0; jj < vCams.size(); jj++) //draw nBestMatches-NN in all other images
				{
					int cidJ = vCams[jj];
					if (cidJ == cidI)
						continue;

					C2C *cj2ci = &C2C_Matches[cidJ + cidI * nCams];

					for (size_t kk = 0; kk < cj2ci[0].Pj2Pi[pidI].size(); kk++)
					{
						int pidJ = cj2ci[0].Pj2Pi[pidI][kk].x;
						minX = 9e9, minY = 9e9, maxX = 0, maxY = 0;
						for (int jid = 0; jid < nJoints; jid++)
							if (AllPts[cidJ][pidJ*nJoints + jid].x > 0)
								minX = min(minX, AllPts[cidJ][pidJ*nJoints + jid].x), maxX = max(maxX, AllPts[cidJ][pidJ*nJoints + jid].x), minY = min(minY, AllPts[cidJ][pidJ*nJoints + jid].y), maxY = max(maxY, AllPts[cidJ][pidJ*nJoints + jid].y);
						rectangle(vImg[cidJ], Point2i(minX - vImg[cidJ].cols / 50, minY - vImg[cidJ].cols / 50), Point2i(maxX + vImg[cidJ].rows / 50, maxY + vImg[cidJ].rows / 50), colors[kk], 8, 8, 0);

						for (int jid = 0; jid < nJoints; jid++)
						{
							if (AllPts[cidJ][pidJ*nJoints + jid].x < 1)
								continue;

							CvPoint text_origin = { MyFtoI(AllPts[cidJ][pidJ*nJoints + jid].x - vImg[cidJ].cols / 50 - 100), MyFtoI(AllPts[cidJ][pidJ*nJoints + jid].y + 20 + vImg[cidJ].rows / 50) };
							sprintf(Fname, "%.2f", cj2ci[0].Pj2Pi[pidI][kk].y), putText(vImg[cidJ], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, .8*vImg[cidJ].cols / 640, colors[kk], 3);
							break;
						}
						//sprintf(Fname, "%s/MP/%d.jpg", Path, cidJ);  imwrite(Fname, vImg[cidJ]);
					}
				}
				bImg = DrawTitleImages(vImg);
				resize(bImg, bImg2, Size(resizeFactor* bImg.cols, resizeFactor*bImg.rows), 0, 0, INTER_AREA);
				CvPoint text_origin = { bImg2.cols / 20, bImg2.cols / 20 };
				sprintf(Fname, "%d", fid); putText(bImg2, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*bImg2.cols / 640, colors[0], 2);

				sprintf(Fname, "%s/Vis/AllPairDescMatch/%.4d_%.4d.jpg", Path, fid, nf);  imwrite(Fname, bImg2);
				nf++;
				if (firstFrame)
				{
					firstFrame = !firstFrame;
					size.width = bImg2.cols, size.height = bImg2.rows;
					//sprintf(Fname, "%s/MP/DescAsso.avi", Path, fid); writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
				}
				//writer << bImg2;
			}
		}

		for (size_t jj = 0; jj < vCams.size() - 1; jj++)
			for (size_t ii = 0; ii < vCams.size(); ii++)
				if (ii != jj)
					delete[]C2C_Matches[vCams[ii] + vCams[jj] * nCams].Pj2Pi;
	}
	printLOG("\nGenerated %d frames\n", nf);
	//writer.release();

	delete[]C2C_Matches, delete[]allImages, delete[]AllPts;

	return 0;
}
int Visualize_Spacetime_ReassignedPeople(char *Path, vector<int> &vCams, vector<int> &TimeStamp, int startF, int stopF, int increF)
{
	char Fname[512];
	sprintf(Fname, "%s/Vis/MultiviewTracklet", Path); makeDir(Fname);

	double resizeFactor = 0.4;
	const int nJoints = 18;
	int nCams = (int)TimeStamp.size();
	vector<Mat> *allImages = new vector<Mat>[nCams];
	Mat img;  int width, height;

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));

	for (auto cid : vCams)
	{
		int nf, pid, fid;
		vector<vector<Point2i> >MergedTrackletVec;
		sprintf(Fname, "%s/%d/MergedTracklets_%d_%d.txt", Path, cid, startF, stopF); FILE * fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%d ", &nf) != EOF)
		{
			vector<Point2i> tracklet;
			for (int f = 0; f < nf; f++)
			{
				fscanf(fp, "%d %d", &fid, &pid);
				tracklet.push_back(Point2i(fid, pid));
			}
			MergedTrackletVec.push_back(tracklet);
		}
		fclose(fp);

		vector<vector<Point2f> *> allPoses;
		printLOG("Reading images from Cam %d: ", cid);
		int increP = 10;
		for (int fid = startF; fid <= stopF; fid++)
		{
			vector<Point2f> *PoseI = new vector<Point2f>[1];
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, fid + TimeStamp[cid]); //refF = fid- TS
			FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			float u, v, s;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				PoseI[0].push_back(Point2f(u, v));
			fclose(fp);
			allPoses.push_back(PoseI);

			sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid); img = imread(Fname);
			if (img.empty())
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid); img = imread(Fname);
				if (img.empty())
				{
					printLOG("Cannot load %s\n", Fname);
					continue;
				}
			}

			resize(img, img, Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
			width = img.cols, height = img.rows;
			allImages[cid].push_back(img);
			if (100 * (fid - startF) / (stopF - startF) > increP)
				printLOG("%d%%..", increP), increP += 10;
		}
		printLOG("100%%\n");
		if (allImages[cid].size() == 0)
			return 0;

		for (int tid = 0; tid < (int)MergedTrackletVec.size(); tid++)
		{
			for (int id = 0; id < MergedTrackletVec[tid].size(); id++)
			{
				int fid = MergedTrackletVec[tid][id].x;
				if (fid - startF > allImages[cid].size() - 1)
					continue;

				int pid = MergedTrackletVec[tid][id].y;

				float minX = 9e9, minY = 9e9, maxX = 0, maxY = 0;
				for (int jid = 0; jid < nJoints; jid++)
				{
					float x = resizeFactor * allPoses[fid - startF][0][pid * nJoints + jid].x, y = resizeFactor * allPoses[fid - startF][0][pid * nJoints + jid].y;
					if (x > 0)
						minX = min(minX, x), maxX = max(maxX, x), minY = min(minY, y), maxY = max(maxY, y);
				}
				rectangle(allImages[cid][fid - startF], Point2i(minX - allImages[cid][fid - startF].cols / 50, minY - allImages[cid][fid - startF].cols / 50),
					Point2i(maxX + allImages[cid][fid - startF].rows / 50, maxY + allImages[cid][fid - startF].rows / 50), colors[tid], 1, 8, 0);

				CvPoint text_origin = { MyFtoI(minX),MyFtoI(minY + allImages[cid][fid - startF].rows / 30) };
				sprintf(Fname, "%d", tid); putText(allImages[cid][fid - startF], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*allImages[cid][fid - startF].cols / 640, colors[tid], 1);
			}
		}

		/*sprintf(Fname, "%s/%d/Tracklet", Path, cid); makeDir(Fname);
		for (int fid = startF; fid <= stopF; fid++)
		{
		if (fid - startF > allImages[cid].size() - 1)
		continue;
		sprintf(Fname, "%s/%d/Tracklet/ST_%.4d.jpg", Path, cid, fid);
		imwrite(Fname, allImages[cid][fid - startF]);
		}*/
	}

	Mat bImg;  vector<Mat> vImg;
	CvSize size;  VideoWriter writer;
	for (int fid = startF; fid <= stopF; fid++)
	{
		vImg.clear();
		for (auto cid : vCams)
			vImg.push_back(allImages[cid][fid - startF]);
		bImg = DrawTitleImages(vImg);

		if (fid == startF)
		{
			sprintf(Fname, "%s/Vis/MultiviewTracklet/%d_%d.avi", Path, startF, stopF);
			size.width = bImg.cols, size.height = bImg.rows;
			writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
		}
		CvPoint text_origin = { bImg.cols / 40, bImg.rows / 40 };
		sprintf(Fname, "%.4d", fid); putText(bImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*bImg.cols / 640, colors[0], 1);

		writer << bImg;
		if (0)
			sprintf(Fname, "%s/Vis/MultiviewTracklet/%.4d.jpg", Path, fid), imwrite(Fname, bImg);
	}
	writer.release();

	delete[]allImages;

	return 0;
}

int VisualizePerPersonPerFrameKnnDescTemporalMatching(char *Path, int cid, int knn, int startF, int stopF, int increF, int VisIncreF, int rangeF)
{
	//Lets take the manually created merged_trackets to pin-point the people and compute knn of those people. Using the manually labeled data is not needed but it helps with visualization.
	char Fname[512];
	sprintf(Fname, "%s/Vis/TemporalMatching", Path); makeDir(Fname);
	sprintf(Fname, "%s/Vis/TemporalMatching/%d", Path, cid); makeDir(Fname);

	const int nJoints = 18, descSize = 256;
	struct PDesc {
		float desc[descSize];
	};
	struct TL_BR {
		Point2i tl, br;
	};

	printLOG("Working on camera %d...", cid);

	float resizeFactor = 0.5;
	vector<int> nPDesc(stopF + 1);
	vector<PDesc*> allPDesc(stopF + 1);
	float desc, norm, descI[descSize];  vector<float> descPerF;
	descPerF.reserve(descSize * 20);

	//read all desc temporally
	printLOG("Reading desc...");
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		descPerF.clear();
		sprintf(Fname, "%s/MP/%d/Desc/%.4d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		while (fscanf(fp, "%f ", &desc) != EOF)
		{
			descI[0] = desc, norm = desc * desc;
			for (int ii = 0; ii < descSize - 1; ii++)
				fscanf(fp, "%f ", &desc), descI[ii + 1] = desc, norm += desc * desc;

			norm = sqrt(norm);
			for (int ii = 0; ii < descSize; ii++)
				descI[ii] /= norm;

			for (int ii = 0; ii < descSize; ii++)
				descPerF.push_back(descI[ii]);
		}
		fclose(fp);

		int np = (int)descPerF.size() / descSize;
		nPDesc[fid] = np;
		allPDesc[fid] = new PDesc[np];
		for (int pid = 0; pid < np; pid++)
			for (int ii = 0; ii < descSize; ii++)
				allPDesc[fid][pid].desc[ii] = descPerF[pid*descSize + ii];
	}

	Mat img;
	vector<Mat> allImg; allImg.resize(stopF + 1);
	vector<Point2f *> allLM; allLM.resize(stopF + 1);
	printLOG("Reading images and landmarks:\n ");
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid); img = imread(Fname);
		if (img.empty() == 1)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid); img = imread(Fname);
			if (img.empty() == 1)
				continue;
		}
		resize(img, allImg[fid], Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
		if (fid % 100 == 0)
			printLOG("%d/%d..", fid, stopF - startF + 1);

		sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;

		float s;
		int np = nPDesc[fid];
		allLM[fid] = new Point2f[np*nJoints];
		for (int ii = 0; ii < np*nJoints; ii++)
			fscanf(fp, "%f %f %f ", &allLM[fid][ii].x, &allLM[fid][ii].y, &s);
		fclose(fp);
	}
	printLOG("Done\n ");

	PDesc pdesc;
	vector<Point2i> descPos; descPos.reserve((rangeF * 2 + 1) * 20);//maxpeople = 20
	vector<PDesc> descPool; descPool.reserve((rangeF * 2 + 1) * 20);//maxpeople = 20
	double *Score = new double[(rangeF * 2 + 1) * 20];
	int *Id = new int[(rangeF * 2 + 1) * 20];
	vector<Mat> vImg; Mat sImg;
	printLOG("Creating Knn: ");
	for (int fid = startF; fid <= stopF; fid += VisIncreF)
	{
		printLOG("%d..", fid);
		//form the pool of desc in rangeF
		descPos.clear(), descPool.clear();
		for (int fidi = -rangeF * 2; fidi <= rangeF * 2; fidi += 2)
		{
			if (fid + fidi > 0 && fid + fidi < stopF && nPDesc[fid + fidi]>0)
			{
				for (int pid = 0; pid < nPDesc[fid + fidi]; pid++)
				{
					Point2f tl, br;  tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
					for (size_t jid = 0; jid < nJoints; jid++)
						if (allLM[fid + fidi][pid*nJoints + jid].x > 0)
							tl.x = min(tl.x, allLM[fid + fidi][pid*nJoints + jid].x), tl.y = min(tl.y, allLM[fid + fidi][pid*nJoints + jid].y),
							br.x = max(br.x, allLM[fid + fidi][pid*nJoints + jid].x), br.y = max(br.y, allLM[fid + fidi][pid*nJoints + jid].y);
					if (br.x - tl.x < allImg[fid].cols / 40 || br.y - tl.y < allImg[fid].cols / 40) //do not consider small bb
						continue;

					descPos.push_back(Point2i(fid + fidi, pid));
					for (int ii = 0; ii < descSize; ii++)
						pdesc.desc[ii] = allPDesc[fid + fidi][pid].desc[ii];
					descPool.push_back(pdesc);
				}
			}
		}

		//compute knn
		for (int pid = 0; pid < nPDesc[fid]; pid++)
		{
			vImg.clear();
			for (size_t di = 0; di < descPool.size(); di++)
			{
				double score = 0.0;
				for (int ii = 0; ii < descSize; ii++)
					score += allPDesc[fid][pid].desc[ii] * descPool[di].desc[ii];
				Score[di] = -score, Id[di] = di;
			}
			Quick_Sort_Double(Score, Id, 0, (int)descPool.size() - 1);

			for (int ii = 0; ii < min(knn + 1, (int)descPool.size()); ii++)
			{
				int fidi = descPos[Id[ii]].x, pidi = descPos[Id[ii]].y;
				Point2f tl, br;  tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (size_t jid = 0; jid < nJoints; jid++)
				{
					if (allLM[fidi][pidi*nJoints + jid].x > 0)
						tl.x = min(tl.x, allLM[fidi][pidi*nJoints + jid].x), tl.y = min(tl.y, allLM[fidi][pidi*nJoints + jid].y), br.x = max(br.x, allLM[fidi][pidi*nJoints + jid].x), br.y = max(br.y, allLM[fidi][pidi*nJoints + jid].y);
				}
				tl.x = tl.x - allImg[fidi].cols / 25, tl.y = tl.y - allImg[fidi].cols / 25, br.x = br.x + allImg[fidi].cols / 25, br.y = br.y + allImg[fidi].cols / 25;
				tl.x = max(tl.x, 0.f), tl.y = max(tl.y, 0.f), br.x = min(br.x, 1.0f*allImg[fidi].cols / resizeFactor - 1), br.y = min(br.y, 1.0f*allImg[fidi].rows / resizeFactor - 1);
				tl.x *= resizeFactor, tl.y *= resizeFactor, br.x *= resizeFactor, br.y *= resizeFactor;

				Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
				Mat croppedImage = allImg[fidi](myROI);
				resize(croppedImage.clone(), sImg, Size(96, 192));

				Rect rect(0, 0, 96, 192); Mat eImg(220, 96, CV_8UC3, Scalar(255, 255, 255)); sImg.copyTo(eImg(rect));
				if (ii == 0)
				{
					CvPoint text_origin = { 0, 220 - 15 }; sprintf(Fname, "%d:%d", fid, pid);
					putText(eImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.35, Scalar(0, 0, 255), 1);
				}
				else
				{
					CvPoint text_origin = { 0, 220 - 15 }; sprintf(Fname, "%d:%d %.2f", fidi, pidi, -Score[ii]);
					putText(eImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.35, Scalar(0, 0, 255), 1);
				}
				vImg.push_back(eImg.clone());
			}
			Mat bImg = DrawTitleImages(vImg, 96.0*knn / 192.0);
			rectangle(bImg, Point2i(0, 0), Point2i(96, 192), Scalar(0, 255, 0), 2);
			sprintf(Fname, "%s/Vis/TemporalMatching/%d/%d_%d.jpg", Path, cid, fid, pid); imwrite(Fname, bImg);
		}
	}

	delete[]Id, delete[]Score;
	for (int ii = 0; ii < stopF + 1; ii++)
		delete[]allLM[ii], delete[]allPDesc[ii];

	return 0;
}
int VisualizePerPersonAllFramesKnnDescTemporalMatching(char *Path, int cid, int startF, int stopF)
{
	char Fname[512];

	int nf, fid, pid;
	vector < vector<Point2i> > MergedTrackletVec;
	sprintf(Fname, "%s/%d/MergedTracklets_%d_%d.txt", Path, cid, startF, stopF); FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d ", &nf) != EOF)
	{
		vector<Point2i> PersonTtrack;
		for (int ii = 0; ii < nf; ii++)
		{
			fscanf(fp, "%d %d ", &fid, &pid);
			PersonTtrack.push_back(Point2i(fid, pid));
		}
		MergedTrackletVec.push_back(PersonTtrack);
	}
	fclose(fp);

	Mat img;
	for (size_t tid = 0; tid < MergedTrackletVec.size(); tid++)
	{
		int first = 1, count = 0;
		CvSize size;  VideoWriter writer;
		for (auto fidpid : MergedTrackletVec[tid])
		{
			sprintf(Fname, "%s/Vis/TemporalMatching/%d/%d_%d.jpg", Path, cid, fidpid.x, fidpid.y); img = imread(Fname);
			if (img.empty() == 0)
			{
				if (first == 1)
				{
					first = 0;
					sprintf(Fname, "%s/Vis/TemporalMatching/%d_%d.avi", Path, cid, tid);
					size.width = img.cols, size.height = img.rows;	writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 5, size);
				}
				//sprintf(Fname, "%s/Vis/TemporalMatching/%d_%d_%d.jpg", Path, cid, tid, count); imwrite(Fname, img); count++;
				writer << img;
			}
		}
		writer.release();
	}

	return 0;
}

int VisualizeAllViewsDescMatchPerTimeInstance(char *Path, vector<int> &vCams, vector<int> &TimeStamp, int startF, int stopF, int increF, int debug)
{
	char Fname[512];
	sprintf(Fname, "%s/Vis", Path); makeDir(Fname);
	sprintf(Fname, "%s/Vis/AllViewsDescMatchPerTimeInstance", Path); makeDir(Fname);

	int nCams = TimeStamp.size(), nJoints = 18, dummy;
	float resizeFactor = 0.25, u, v, s;
	vector<Point2f> *AllPts = new vector<Point2f>[nJoints*nCams];
	Mat *allImages = new Mat[nCams];


	struct C2C {
		int nPj;
		vector<Point2f> *Pj2Pi;
	};
	vector<Mat> vImg;
	C2C *C2C_Matches = new C2C[nCams*nCams];
	vector<Point2f> JI[100], IJ[100];

	CvSize size;
	VideoWriter writer;

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));

	Mat colorMapSource = Mat::zeros(256, 1, CV_8U);
	for (unsigned int i = 0; i <= 255; i++)
		colorMapSource.at<uchar>(i, 0) = i;
	Mat colorMap; applyColorMap(colorMapSource, colorMap, COLORMAP_AUTUMN);

	int id_dummy[30]; float s_dummy[30];
	Mat Img, bImg, bImg2;
	bool firstFrame = true;
	size_t nf = 0;
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		printLOG("%d (%d) ..", fid, nf);
		for (auto cid : vCams)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid - TimeStamp[cid]);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid - TimeStamp[cid]);
				if (IsFileExist(Fname) == 0)
					continue;
			}
			allImages[cid] = imread(Fname);

			AllPts[cid].clear();
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, fid - TimeStamp[cid]); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				AllPts[cid].push_back(Point2d(u, v));
			fclose(fp);
		}

		sprintf(Fname, "%s/MP/MatchesInstances/%.4d.txt", Path, fid); FILE *fp = fopen(Fname, "r");
		int nMatches, cid, pid; float score;
		vector<int> vCid, vPid; vector<float> vScore; vector<Mat> vImg(nCams);
		while (fscanf(fp, "%d %d %d ", &nMatches, &cid, &pid) != EOF)
		{
			vImg.clear(); vCid.clear(), vPid.clear(), vScore.clear();
			for (int ii = 0; ii < nCams; ii++)
				vImg.push_back(allImages[ii].clone());

			vCid.push_back(cid), vPid.push_back(pid), vScore.push_back(1);
			for (int ii = 0; ii < nMatches - 1; ii++)
			{
				fscanf(fp, "%d %d %f ", &cid, &pid, &score);
				vCid.push_back(cid), vPid.push_back(pid), vScore.push_back(score);
			}

			for (int ii = 0; ii < nMatches; ii++)
			{
				cid = vCid[ii], pid = vPid[ii];
				float minX = 9e9, minY = 9e9, maxX = 0, maxY = 0;
				for (int jid = 0; jid < nJoints; jid++)
					if (AllPts[cid][pid*nJoints + jid].x > 0)
						minX = min(minX, AllPts[cid][pid*nJoints + jid].x), maxX = max(maxX, AllPts[cid][pid*nJoints + jid].x), minY = min(minY, AllPts[cid][pid*nJoints + jid].y), maxY = max(maxY, AllPts[cid][pid*nJoints + jid].y);

				if (ii == 0)
					rectangle(vImg[cid], Point2i(minX - vImg[0].cols / 50, minY - vImg[0].cols / 50), Point2i(maxX + vImg[0].rows / 50, maxY + vImg[0].rows / 50), colors[3], 16, 8, 0);
				else
				{
					//rectangle(vImg[cid], Point2i(minX - vImg[0].cols / 50, minY - vImg[0].cols / 50), Point2i(maxX + vImg[0].rows / 50, maxY + vImg[0].rows / 50), colors[min(ii - 1, 6)], 8, 8, 0);
					//rectangle(vImg[cid], Point2i(minX - vImg[0].cols / 50, minY - vImg[0].cols / 50), Point2i(maxX + vImg[0].rows / 50, maxY + vImg[0].rows / 50), Scalar(0, 0, 255.0*pow(vScore[ii], 5)), 16.0 * vScore[ii], 8, 0);
					int colorIdx = (int)(1.0*(ii - 1) / (nMatches - 1 + 0.00001)* 255.0 + 0.5);
					Point3f PointColor(colorMap.at<Vec3b>(colorIdx, 0)[0],
						colorMap.at<Vec3b>(colorIdx, 0)[1], //green
						colorMap.at<Vec3b>(colorIdx, 0)[2]);	//red
					rectangle(vImg[cid], Point2i(minX - vImg[0].cols / 50, minY - vImg[0].cols / 50), Point2i(maxX + vImg[0].rows / 50, maxY + vImg[0].rows / 50), Scalar(PointColor.x, PointColor.y, PointColor.z), 32.0 * pow(vScore[ii], 10), 8, 0);
					CvPoint text_origin = { MyFtoI(minX), MyFtoI(minY - vImg[cid].rows / 20) };
					sprintf(Fname, "%.2f", vScore[ii]), putText(vImg[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0*allImages[cid].cols / 640, Scalar(PointColor.x, PointColor.y, PointColor.z), 5);
				}

				/*if (ii > 0)
				{
				for (int jid = 0; jid < nJoints; jid++)
				{
				if (AllPts[cid][pid * nJoints + jid].x < 1)
				continue;

				CvPoint text_origin = { (AllPts[cid][pid * nJoints + jid].x - 100), (AllPts[cid][pid * nJoints + jid].y + 20) };
				//sprintf(Fname, "%.2f", vScore[ii]), putText(vImg[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0*allImages[cid].cols / 640, colors[min(ii - 1, 6)], 3);
				//sprintf(Fname, "%.2f", vScore[ii]), putText(vImg[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0*allImages[cid].cols / 640, Scalar(0, 0, 255.0*pow(vScore[ii], 5)), 5);
				int colorIdx = (int)(1.0*ii / nMatches* 255.0 + 0.5);
				Point3f PointColor;
				PointColor.z = colorMap.at<Vec3b>(colorIdx, 0)[0] ; //blue
				PointColor.y = colorMap.at<Vec3b>(colorIdx, 0)[1] ; //green
				PointColor.x = colorMap.at<Vec3b>(colorIdx, 0)[2] ;	//red
				sprintf(Fname, "%.2f", vScore[ii]), putText(vImg[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0*allImages[cid].cols / 640, Scalar(PointColor.z, PointColor.y, PointColor.x), 5);
				break;
				}
				}*/
			}
			bImg = DrawTitleImages(vImg);
			resize(bImg, bImg2, Size(resizeFactor* bImg.cols, resizeFactor*bImg.rows), 0, 0, INTER_AREA);
			CvPoint text_origin = { bImg2.cols - bImg2.cols / 6, bImg2.rows - bImg2.rows / 20 };
			sprintf(Fname, "Frame %.4d", fid); putText(bImg2, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*bImg2.cols / 640, colors[0], 2);

			//namedWindow("X", CV_WINDOW_NORMAL);
			//cvSetWindowProperty("X", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
			//imshow("X", bImg2); waitKey(0);
			if (debug == 1)
			{
				sprintf(Fname, "%s/Vis/AllViewsDescMatchPerTimeInstance/%.4d_%d_%d.jpg", Path, fid, vCid[0], vPid[0]);
				imwrite(Fname, bImg2);
			}
			if (nf == 0)
			{
				CvSize size; size.width = bImg2.cols, size.height = bImg2.rows;
				sprintf(Fname, "%s/Vis/AllViewsDescMatchPerTimeInstance_%d_%d.avi", Path, startF, stopF); writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 30, size);
			}
			writer << bImg2;
			nf++;
		}
	}
	printLOG("\nGenerated %d frames\n", nf);
	writer.release();

	delete[]C2C_Matches, delete[]allImages, delete[]AllPts;

	return 0;
}
int VisualizeOneTrackedPersonAllViewsDescMatch(char *Path, int cid, vector<int> &TimeStamp, int startF, int stopF, int increF)
{
	char Fname[512];
	int nf, sf, pid, fid;
	vector<int> vStartF;
	vector<vector<int> > tracklet;
	sprintf(Fname, "%s/%d/Tracklet_%d_%d.txt", Path, cid, startF, stopF); FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
	{
		vStartF.push_back(sf);
		vector<int> vpid;
		for (int ii = 0; ii < nf; ii++)
		{
			fscanf(fp, "%d ", &pid);
			vpid.push_back(pid);
		}
		tracklet.push_back(vpid);
	}
	fclose(fp);


	CvSize size;
	VideoWriter writer;
	Mat img;

	sprintf(Fname, "%s/Vis/AllViewsDescMatchPerTimeInstanceClip/%d", Path, cid); makeDir(Fname);

	//namedWindow("X", CV_WINDOW_NORMAL);
	//cvSetWindowProperty("X", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
	for (size_t tid = 0; tid < tracklet.size(); tid++)
	{
		int firstTime = 1;
		for (size_t lfid = 0; lfid < tracklet[tid].size(); lfid++)
		{
			pid = tracklet[tid][lfid], fid = vStartF[tid] + lfid + TimeStamp[cid];
			sprintf(Fname, "%s/Vis/AllViewsDescMatchPerTimeInstance/%.4d_%d_%d.jpg", Path, fid, cid, pid);  img = imread(Fname);
			if (img.empty() == 1)
				continue;

			//imshow("X", img); waitKey(0);
			if (firstTime == 1)
			{
				firstTime = 0;
				size.width = img.cols, size.height = img.rows;
				sprintf(Fname, "%s/Vis/AllViewsDescMatchPerTimeInstanceClip/%d/%d.avi", Path, cid, tid); writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
			}
			writer << img;
		}
		writer.release();
	}

	return 0;
}
int VisualizePerPersonAllFramesKnnDescPoolingSpatiolMatching(char *Path, int cid, vector<int> &TimeStamp, int startF, int stopF)
{
	char Fname[512];

	int nf, fid, pid;
	vector < vector<Point2i> > MergedTrackletVec;
	sprintf(Fname, "%s/%d/MergedTracklets_%d_%d.txt", Path, cid, startF, stopF); FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d ", &nf) != EOF)
	{
		vector<Point2i> PersonTtrack;
		for (int ii = 0; ii < nf; ii++)
		{
			fscanf(fp, "%d %d ", &fid, &pid);
			PersonTtrack.push_back(Point2i(fid, pid));
		}
		MergedTrackletVec.push_back(PersonTtrack);
	}
	fclose(fp);

	Mat img;
	for (size_t tid = 0; tid < MergedTrackletVec.size(); tid++)
	{
		int first = 1, count = 0;
		CvSize size;  VideoWriter writer;
		for (auto fidpid : MergedTrackletVec[tid])
		{
			sprintf(Fname, "%s/Vis/SpatioMatching/%d/%d_%d.jpg", Path, cid, fidpid.x + TimeStamp[cid], fidpid.y); img = imread(Fname);
			if (img.empty() == 0)
			{
				if (first == 1)
				{
					first = 0;
					sprintf(Fname, "%s/Vis/SpatioMatching/%d_%d.avi", Path, cid, tid);
					size.width = img.cols, size.height = img.rows;	writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 5, size);
				}
				//sprintf(Fname, "%s/Vis/TemporalMatching/%d_%d_%d.jpg", Path, cid, tid, count); imwrite(Fname, img); count++;
				writer << img;
			}
		}
		writer.release();
	}

	return 0;
}
int VisualizeProjected3DSkeleton(char *Path, int nCams, int startF, int stopF, int increF, bool withBA, double resizeFactor, int debug)
{
	char Fname[512];
	const int nJoints = 25;

	if (withBA)
		sprintf(Fname, "%s/Vis/SkeletonBA", Path);
	else
		sprintf(Fname, "%s/Vis/Skeleton", Path);
	makeDir(Fname);
	if (debug == 1)
	{
		for (int ii = 0; ii < nCams; ii++)
		{
			if (withBA)
				sprintf(Fname, "%s/Vis/SkeletonBA/%d", Path, ii);
			else
				sprintf(Fname, "%s/Vis/Skeleton/%d", Path, ii);
			makeDir(Fname);
		}
	}
	static cv::Scalar colors[] = { Scalar(0, 0, 255), Scalar(0, 128, 255), Scalar(0, 255, 255), Scalar(0, 255, 0), Scalar(255, 128, 0), Scalar(255, 255, 0), Scalar(255, 0, 0), Scalar(255, 0, 255), Scalar(255, 255, 255) };

	int width, height;
	CvSize size;
	Mat Img, rImg;

	Point3d *CamTimeInfo = new Point3d[nCams];
	for (int ii = 0; ii < nCams; ii++)
		CamTimeInfo[ii].x = 1.0, CamTimeInfo[ii].y = 0.0;
	sprintf(Fname, "%s/FMotionPriorSync.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int selected;
		double fps, temp;
		while (fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp) != EOF)
		{
			CamTimeInfo[selected].x = 1.0 / fps;
			CamTimeInfo[selected].y = temp;
			CamTimeInfo[selected].z = 1.0;
		}
		fclose(fp);
	}
	else
	{
		sprintf(Fname, "%s/FGeoSync.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int selected;
			double fps, temp;
			while (fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp) != EOF)
			{
				CamTimeInfo[selected].x = 1.0 / fps;
				CamTimeInfo[selected].y = temp;
				CamTimeInfo[selected].z = 1.0;
			}
			fclose(fp);
		}
		else
		{
			int selected, temp;
			double fps;
			sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				while (fscanf(fp, "%d %lf %d ", &selected, &fps, &temp) != EOF)
				{
					CamTimeInfo[selected].x = 1.0 / fps;
					CamTimeInfo[selected].y = temp;
					CamTimeInfo[selected].z = 1.0;
				}
				fclose(fp);
			}
			else
				printLOG("Cannot load time stamp info. Assume no frame offsets!");
		}
	}

	int refCid = 0;
	double earliest = DBL_MAX;
	for (int ii = 0; ii < nCams; ii++)
		if (earliest > CamTimeInfo[ii].y)
			earliest = CamTimeInfo[ii].y, refCid = ii;

	printLOG("Reading all people 3D skeleton: ");
	double u, v, s, avg_error;
	int cid, dummy, nPeople = 0;
	vector<HumanSkeleton3D *> vSkeletons;
	while (true)
	{
		printLOG("%d..", nPeople);

		int nvalidFrames = 0;
		HumanSkeleton3D *Skeletons = new HumanSkeleton3D[(stopF - startF) / increF + 1];
		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int nvis, nValidJoints = 0, temp = (refFid - startF) / increF;
			sprintf(Fname, "%s/People/@%d/%d/m_%.4d.txt", Path, increF, nPeople, refFid); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				int rfid, pid, nvis, dummy; float fdummy;
				for (int jid = 0; jid < nJoints; jid++)
				{
					int temp = (refFid - startF) / increF;
					fscanf(fp, "%lf %lf %lf %lf %d ", &Skeletons[temp].pt3d[jid].x, &Skeletons[temp].pt3d[jid].y, &Skeletons[temp].pt3d[jid].z, &avg_error, &nvis);
					for (int kk = 0; kk < nvis; kk++)
					{
						fscanf(fp, "%d %d %lf %lf %lf %d", &cid, &rfid, &u, &v, &s, &dummy);
						//fscanf(fp, "%d %lf %lf %lf", &cid, &u, &v, &s);

						Skeletons[temp].vViewID_rFid[jid].push_back(Point2i(cid, rfid));
						Skeletons[temp].vPt2D[jid].push_back(Point2d(u, v));
						Skeletons[temp].vConf[jid].push_back(s);
					}

					if (abs(Skeletons[temp].pt3d[jid].x) + abs(Skeletons[temp].pt3d[jid].y) + abs(Skeletons[temp].pt3d[jid].z) > 1e-16)
						Skeletons[temp].validJoints[jid] = 1, nValidJoints++;
					else
						Skeletons[temp].validJoints[jid] = 0;
				}
				fclose(fp);

				if (nValidJoints < nJoints / 3)
					Skeletons[temp].valid = 0;
				else
					Skeletons[temp].valid = 1;

				nvalidFrames++;
			}
		}
		if (nvalidFrames == 0)
		{
			printLOG("\n");
			break;
		}

		vSkeletons.push_back(Skeletons);
		nPeople++;
	}

	VideoData *VideoInfo = new VideoData[nCams];
	for (int cid = 0; cid < nCams; cid++)
		if (ReadVideoDataI(Path, VideoInfo[cid], cid, -1, -1) == 1)
			continue;

	int *firstTime = new int[nCams];
	VideoWriter *writer = new VideoWriter[nCams];
	for (int ii = 0; ii < nCams; ii++)
		firstTime[ii] = 1;

	Mat img, rimg, mask, blend;
	vector<int> vpid(nPeople);
	Point2d joints2D[25];
	vector<Point2f> *Vuv = new vector<Point2f>[nPeople];
	for (int refFid = startF; refFid <= stopF; refFid += increF)
	{
		printLOG("%d..", refFid);
		if ((refFid - startF) % 30 == 29)
			printLOG("\n");

		int temp = (refFid - startF) / increF;
		for (int cid = 0; cid < nCams; cid++)
		{
			double ts = 1.0*refFid / CamTimeInfo[refCid].x;
			int rfid = MyFtoI((ts - CamTimeInfo[cid].y / CamTimeInfo[refCid].x) * CamTimeInfo[cid].x);
			rfid = rfid / increF * increF;// ((int)(1.0*rfid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation

			int width = VideoInfo[cid].VideoInfo[rfid].width, height = VideoInfo[cid].VideoInfo[rfid].height;
			CameraData *camI = VideoInfo[cid].VideoInfo;
			if (camI[rfid].valid != 1)
				continue;

			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, rfid); img = imread(Fname);
			if (img.empty() == 1)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, cid, rfid); img = imread(Fname);
				if (img.empty() == 1)
					continue;
			}

			if (firstTime[cid] == 1)
			{
				firstTime[cid] = 0;
				CvSize size;
				size.width = (int)(resizeFactor*img.cols), size.height = (int)(resizeFactor*img.rows);
				sprintf(Fname, "%s/Vis/SkeletonBA/%d_%d_%d.avi", Path, cid, startF, stopF), writer[cid].open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 30, size);
			}

			for (int pid = 0; pid < nPeople; pid++)
			{
				HumanSkeleton3D *Body0 = &vSkeletons[pid][temp];

				bool visible = 0;
				int bottomID = -1; double bottomY = 0;
				for (int jid = 0; jid < nJoints; jid++)
				{
					joints2D[jid] = Point2d(0, 0);
					if (Body0[0].validJoints[jid] > 0)
					{
						Point3d xyz = Body0[0].pt3d[jid];
						if (camI[rfid].LensModel == RADIAL_TANGENTIAL_PRISM)
						{
							ProjectandDistort(xyz, &joints2D[jid], camI[rfid].P);
							if (joints2D[jid].x < -camI[rfid].width / 10 || joints2D[jid].x > 11 * camI[rfid].width / 10 || joints2D[jid].y < -camI[rfid].height / 10 || joints2D[jid].y > 11 * camI[rfid].height / 10)
								continue;

							if (camI[rfid].ShutterModel == GLOBAL_SHUTTER)
								ProjectandDistort(xyz, &joints2D[jid], camI[rfid].P, camI[rfid].K, camI[rfid].distortion);
							else if (camI[rfid].ShutterModel == ROLLING_SHUTTER)
								CayleyDistortionProjection(camI[rfid].intrinsic, camI[rfid].distortion, camI[rfid].rt, camI[rfid].wt, joints2D[jid], xyz, width, height);
						}
						else
						{
							FisheyeProjectandDistort(xyz, &joints2D[jid], camI[rfid].P, camI[rfid].K, camI[rfid].distortion);
							if (joints2D[jid].x < -camI[rfid].width / 10 || joints2D[jid].x > 11 * camI[rfid].width / 10 || joints2D[jid].y < -camI[rfid].height / 10 || joints2D[jid].y > 11 * camI[rfid].height / 10)
								continue;

							if (camI[rfid].ShutterModel == GLOBAL_SHUTTER)
								FisheyeProjectandDistort(xyz, &joints2D[jid], camI[rfid].P, camI[rfid].K, camI[rfid].distortion);
							else if (camI[rfid].ShutterModel == ROLLING_SHUTTER)
								CayleyFOVProjection2(camI[rfid].intrinsic, camI[rfid].distortion, camI[rfid].rt, camI[rfid].wt, joints2D[jid], xyz, width, height);
						}

						if (joints2D[jid].y > bottomY)
							bottomY = joints2D[jid].y, bottomID = jid;
					}
				}
				//if (bottomID > 13 || bottomID < 8)
					//continue;

				Draw2DCoCoJoints(img, joints2D, nJoints, 2, 1.0, &colors[pid % 8]);
				if (debug == 1)
					sprintf(Fname, "%s/Vis/SkeletonBA/x.jpg", Path), imwrite(Fname, img);
			}

			CvPoint text_origin = { width / 30, height / 30 };
			sprintf(Fname, "Real: %d Ref: %d", rfid, refFid), putText(img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*img.cols / 640, colors[0], 3);
			resize(img, rimg, Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
			writer[cid] << rimg;
		}
	}

	for (int ii = 0; ii < nCams; ii++)
		writer[ii].release();

	return 0;
}

int VisualizeAllTracklets(char *Path, vector<int> sCams, int refStartF, int refStopF, int startF, int stopF)
{
	char Fname[512];

	int nf, sf, pid, nJoints = 18, ntracklets = 0;
	vector<Point2i> tracklet;
	vector<vector<Point2i> > trackletVec;

	sprintf(Fname, "%s/Vis/AllTracklets", Path), makeDir(Fname);
	for (auto cid : sCams)
	{
		printLOG("(%d: ", cid);
		trackletVec.clear();
		sprintf(Fname, "%s/%d/Tracklet_%d_%d.txt", Path, cid, refStartF, refStopF); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
		{
			tracklet.clear();
			for (int f = 0; f < nf; f++)
			{
				fscanf(fp, "%d ", &pid);
				tracklet.push_back(Point2i(sf + f, pid));
			}
			trackletVec.push_back(tracklet);
		}
		fclose(fp);

		vector<Point2f> *allP = new vector<Point2f>[stopF + 1];
		for (int fid = startF; fid <= stopF; fid++)
		{
			float u, v, s;
			sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				allP[fid].push_back(Point2f(u, v));
			fclose(fp);
		}
		allP[200].size();

		vector<Mat> allImages;
		for (int fid = 0; fid < startF; fid++)
			allImages.push_back(Mat());
		for (int fid = startF; fid <= stopF; fid++)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid);
				if (IsFileExist(Fname) == 0)
					continue;
			}
			allImages.push_back(imread(Fname));
		}

		Mat sImg;
		for (int tid = 0; tid < trackletVec.size(); tid++)
		{
			VideoWriter writer;
			CvSize size = cvSize(96 * 2, 192 * 2 + 20);
			sprintf(Fname, "%s/Vis/AllTracklets/%.3d_c%d_t%d_n%d.avi", Path, tid + ntracklets, cid, tid, trackletVec[tid].size()), writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 60, size);

			for (int f = 0; f < trackletVec[tid].size(); f++)
			{
				int fid = trackletVec[tid][f].x, pid = trackletVec[tid][f].y;
				if (allImages.size() <= fid || allImages[fid].cols == 0 || allP[fid].size() == 0)
					continue;

				Point2f tl(9e9, 9e9), br(0, 0);
				for (size_t jid = 0; jid < nJoints; jid++)
				{
					if (allP[fid][pid*nJoints + jid].x > 0)
						tl.x = min(tl.x, allP[fid][pid*nJoints + jid].x), tl.y = min(tl.y, allP[fid][pid*nJoints + jid].y), br.x = max(br.x, allP[fid][pid*nJoints + jid].x), br.y = max(br.y, allP[fid][pid*nJoints + jid].y);
				}
				tl.x = max(tl.x - allImages[fid].cols / 30, 0), tl.y = max(tl.y - allImages[fid].cols / 30, 0), br.x = min(br.x + allImages[fid].cols / 30, allImages[fid].cols), br.y = min(br.y + allImages[fid].cols / 30, allImages[fid].rows);

				Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
				Mat croppedImage = allImages[fid](myROI);
				resize(croppedImage.clone(), sImg, Size(96 * 2, 192 * 2 + 20));
				CvPoint text_origin = { 10, 192 * 2 }; sprintf(Fname, "%d_%d", fid, pid);
				putText(sImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 255), 1);
				writer << sImg;
			}
			writer.release();
		}
		ntracklets += trackletVec.size();
		printLOG("%d)..", ntracklets);
	}
	return 0;
}


int SparsePointTrackingDriver(char *Path, int viewID, int startF, int rangeF)
{
	char Fname[512];

	int width, height, length, nchannels = 3;
	unsigned char *Img = 0; float *sImg = 0;
	vector<float*> FImgPara, BImgPara; Mat view;

	int hsubset = 11, nscales = 2, scaleStep = 2, MatchAglo = 3, InterpAlgo = 1, Convergence_Criteria = 0, IterMax = 20, Analysis_Speed = 0, DisplacementThresh = 1;
	double Gsigma = 1.0, ZNCCThreshold = 0.8, PSSDab_thresh = 0.02;
	LKParameters LKArg(hsubset, nscales, scaleStep, MatchAglo, InterpAlgo, Gsigma, Convergence_Criteria, IterMax, Analysis_Speed, ZNCCThreshold, PSSDab_thresh, DisplacementThresh);
	int TimgS = 2 * (hsubset + nscales * scaleStep) + 1, Tlength = TimgS * TimgS;
	double *Timg = new double[Tlength*nchannels], *CorrelBuf = new double[6 * Tlength*nchannels];

	int id, x, y;

	sprintf(Fname, "%s/%d_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "r");
	vector<Point2d*> allpts;
	while (fscanf(fp, "%d ", &id) != EOF)
	{
		Point2d *pts = new Point2d[2 * rangeF + 1];
		int count = 0;
		for (int ii = 0; ii < 2 * rangeF + 1; ii++)
		{
			fscanf(fp, "%d %d %d ", &id, &x, &y);
			pts[ii].x = x, pts[ii].y = y;
			if (x > 0 && y > 0)
				count++;
		}
		if (count > 0)
			allpts.push_back(pts);
	}
	fclose(fp);

	int npts = (int)allpts.size();
	vector<Point2d> *FTracks = new vector<Point2d>[npts], *BTracks = new vector<Point2d>[npts];
	for (int ii = 0; ii < npts; ii++)
	{
		for (int jj = 0; jj <= rangeF; jj++)
			FTracks[ii].push_back(allpts[ii][rangeF + jj]);
		for (int jj = 0; jj <= rangeF; jj++)
			BTracks[ii].push_back(allpts[ii][rangeF - jj]);
	}

	Point2d bestfPt; double bestDistance;

	//Backward
	for (int fid = startF; fid >= startF - rangeF; fid--)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, fid);
		view = imread(Fname, nchannels == 1 ? 0 : 1);
		if (view.data == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		width = view.cols, height = view.rows, length = width * height;
		if (Img == NULL)
			Img = new unsigned char[length*nchannels];
		if (sImg == NULL)
			sImg = new float[length*nchannels];
		for (int kk = 0; kk < nchannels; kk++)
			for (int jj = 0; jj < height; jj++)
				for (int ii = 0; ii < width; ii++)
					Img[ii + jj * width + kk * length] = (char)view.data[nchannels*ii + jj * nchannels*width + kk];

		float *Para = new float[length*nchannels];
		for (int kk = 0; kk < nchannels; kk++)
		{
			Gaussian_smooth(Img + kk * length, sImg + kk * length, height, width, 255.0, 1.0);
			Generate_Para_Spline(sImg + kk * length, Para + kk * length, width, height, LKArg.InterpAlgo);
		}
		BImgPara.push_back(Para);
	}

	for (int pid = 0; pid < npts; pid++)
	{
		for (int fid = 1; fid <= rangeF; fid++)
		{
			bestDistance = 9e9;
			for (int sID = 0; sID < LKArg.nscales; sID++)
			{
				LKArg.hsubset = hsubset + sID * LKArg.scaleStep;

				//Forward
				Point2d fPt = BTracks[pid][fid];
				double score1 = TemplateMatching(BImgPara[0], BImgPara[fid], width, height, width, height, nchannels, BTracks[pid][0], fPt, LKArg, false, Timg, CorrelBuf);

				//Backward
				Point2d bPt = BTracks[pid][0];
				double score2 = TemplateMatching(BImgPara[fid], BImgPara[0], width, height, width, height, nchannels, fPt, bPt, LKArg, false, Timg, CorrelBuf);

				double distance = sqrt(pow(bPt.x - BTracks[pid][0].x, 2) + pow(bPt.y - BTracks[pid][0].y, 2));
				if (distance < bestDistance && score1>ZNCCThreshold && score2 > ZNCCThreshold)
					bestfPt = fPt, bestDistance = distance;
			}
			if (bestDistance < DisplacementThresh)
				BTracks[pid][fid] = bestfPt;
		}
	}

	//Forward
	for (int fid = startF; fid <= startF + rangeF; fid++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, fid);
		view = imread(Fname, nchannels == 1 ? 0 : 1);
		if (view.data == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		width = view.cols, height = view.rows, length = width * height;
		if (Img == NULL)
			Img = new unsigned char[length*nchannels];
		if (sImg == NULL)
			sImg = new float[length*nchannels];
		for (int kk = 0; kk < nchannels; kk++)
			for (int jj = 0; jj < height; jj++)
				for (int ii = 0; ii < width; ii++)
					Img[ii + jj * width + kk * length] = (char)view.data[nchannels*ii + jj * nchannels*width + kk];

		float *Para = new float[length*nchannels];
		for (int kk = 0; kk < nchannels; kk++)
		{
			Gaussian_smooth(Img + kk * length, sImg + kk * length, height, width, 255.0, 1.0);
			Generate_Para_Spline(sImg + kk * length, Para + kk * length, width, height, LKArg.InterpAlgo);
		}
		FImgPara.push_back(Para);
	}

	for (int pid = 0; pid < npts; pid++)
	{
		for (int fid = 1; fid <= rangeF; fid++)
		{
			bestDistance = 9e9;
			for (int sID = 0; sID < LKArg.nscales; sID++)
			{
				LKArg.hsubset = hsubset + sID * LKArg.scaleStep;

				//Forward
				Point2d fPt = FTracks[pid][fid];
				double score1 = TemplateMatching(FImgPara[0], FImgPara[fid], width, height, width, height, nchannels, FTracks[pid][0], fPt, LKArg, false, Timg, CorrelBuf);

				//Backward
				Point2d bPt = FTracks[pid][0];
				double score2 = TemplateMatching(FImgPara[fid], FImgPara[0], width, height, width, height, nchannels, fPt, bPt, LKArg, false, Timg, CorrelBuf);

				double distance = sqrt(pow(bPt.x - FTracks[pid][0].x, 2) + pow(bPt.y - FTracks[pid][0].y, 2));
				if (distance < bestDistance && score1>ZNCCThreshold && score2 > ZNCCThreshold)
					bestfPt = fPt, bestDistance = distance;
			}
			if (bestDistance < DisplacementThresh)
				FTracks[pid][fid] = bestfPt;
		}
	}

	sprintf(Fname, "%s/Track2D", Path); makeDir(Fname);
	sprintf(Fname, "%s/Track2D/FT_%d_%.4d.txt", Path, viewID, startF);  fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", npts);
	for (int pid = 0; pid < npts; pid++)
	{
		fprintf(fp, "%d %d ", pid, rangeF + 1);
		for (int fid = 0; fid <= rangeF; fid++)
			fprintf(fp, "%d %.2f %.2f 1.0 ", startF + fid, FTracks[pid][fid].x, FTracks[pid][fid].y);
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/Track2D/BT_%d_%.4d.txt", Path, viewID, startF);  fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", npts);
	for (int pid = 0; pid < npts; pid++)
	{
		fprintf(fp, "%d %d ", pid, rangeF + 1);
		for (int fid = 0; fid <= rangeF; fid++)
			fprintf(fp, "%d %.2f %.2f 1.0 ", startF - fid, BTracks[pid][fid].x, BTracks[pid][fid].y);
		fprintf(fp, "\n");
	}
	fclose(fp);

	delete[]Img, delete[]sImg, delete[]Timg, delete[]CorrelBuf;
	return 0;
}
int SparsePointMatchingDriver(char *Path, vector<int> &viewID, int startF)
{
	char Fname[512];

	int nCams = (int)viewID.size();
	int width, height, length, nchannels = 3;

	int hsubset = 11, nscales = 2, scaleStep = 2, MatchAglo = 3, InterpAlgo = 1, Convergence_Criteria = 0, IterMax = 20, Analysis_Speed = 0, DisplacementThresh = 1;
	double Gsigma = 1.0, ZNCCThreshold = 0.8, PSSDab_thresh = 0.02;
	LKParameters LKArg(hsubset, nscales, scaleStep, MatchAglo, InterpAlgo, Gsigma, Convergence_Criteria, IterMax, Analysis_Speed, ZNCCThreshold, PSSDab_thresh, DisplacementThresh);
	int TimgS = 2 * (hsubset + nscales * scaleStep) + 1, Tlength = TimgS * TimgS;
	double *Timg = new double[Tlength*nchannels], *CorrelBuf = new double[6 * Tlength*nchannels];

	int id; double x, y;
	vector<Point2d> *pts = new vector<Point2d>[nCams];
	for (int cid = 0; cid < nCams; cid++)
	{
		sprintf(Fname, "%s/s%d_%.4d.txt", Path, viewID[cid], startF); FILE *fp = fopen(Fname, "r");
		fscanf(fp, "%d ", &id);
		while (fscanf(fp, "%lf %lf ", &x, &y) != EOF)
			pts[cid].push_back(Point2d(x, y));
		fclose(fp);
	}

	unsigned char *Img = 0; float *sImg = 0;
	vector<float*>ImgPara;; Mat view;
	for (int cid = 0; cid < nCams; cid++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID[cid], startF);
		view = imread(Fname, nchannels == 1 ? 0 : 1);
		if (view.data == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		width = view.cols, height = view.rows, length = width * height;
		if (Img == NULL)
			Img = new unsigned char[length*nchannels];
		if (sImg == NULL)
			sImg = new float[length*nchannels];
		for (int kk = 0; kk < nchannels; kk++)
			for (int jj = 0; jj < height; jj++)
				for (int ii = 0; ii < width; ii++)
					Img[ii + jj * width + kk * length] = (char)view.data[nchannels*ii + jj * nchannels*width + kk];

		float *Para = new float[length*nchannels];
		for (int kk = 0; kk < nchannels; kk++)
		{
			Gaussian_smooth(Img + kk * length, sImg + kk * length, height, width, 255.0, 1.0);
			Generate_Para_Spline(sImg + kk * length, Para + kk * length, width, height, LKArg.InterpAlgo);
		}
		ImgPara.push_back(Para);
	}


	int npts = (int)pts[0].size();
	Point2d bestfPt; double bestDistance;
	for (int cid = 1; cid < nCams; cid++)
	{
		for (int pid = 0; pid < npts; pid++)
		{
			bestDistance = 9e9;
			for (int sID = 0; sID < LKArg.nscales; sID++)
			{
				LKArg.hsubset = hsubset + sID * LKArg.scaleStep;

				//Forward
				Point2d fPt = pts[cid][pid];
				double score1 = TemplateMatching(ImgPara[0], ImgPara[cid], width, height, width, height, nchannels, pts[0][pid], fPt, LKArg, false, Timg, CorrelBuf);

				//Backward
				Point2d bPt = pts[0][pid];
				double score2 = TemplateMatching(ImgPara[cid], ImgPara[0], width, height, width, height, nchannels, fPt, bPt, LKArg, false, Timg, CorrelBuf);

				double distance = sqrt(pow(bPt.x - pts[0][pid].x, 2) + pow(bPt.y - pts[0][pid].y, 2));
				if (distance < bestDistance && score1>ZNCCThreshold && score2 > ZNCCThreshold)
					bestfPt = fPt, bestDistance = distance;
			}
			if (bestDistance < DisplacementThresh)
				pts[cid][pid] = bestfPt;
			else
				pts[cid][pid] = Point2d(-1, -1);
		}
	}

	for (int cid = 0; cid < nCams; cid++)
	{
		sprintf(Fname, "%s/rs_%d_%.4d.txt", Path, viewID[cid], startF);  FILE *fp = fopen(Fname, "w+");
		for (int pid = 0; pid < npts; pid++)
			fprintf(fp, "%.2f %.2f\n", pts[cid][pid].x, pts[cid][pid].y);
		fclose(fp);
	}

	delete[]Img, delete[]sImg, delete[]Timg, delete[]CorrelBuf;
	return 0;
}

//Feature extraction and matching: scale is the radius of the blob
int vfFeatPair(char *Fname1, char *Fname2, const float nndrRatio, const double fractionMatchesDisplayed)
{
	int npts1 = 0, npts2 = 0;
	CovFeature CovF1, CovF2;

	double start;
	char Fname[512], Fnameb[512];

	Mat descriptors1, descriptors2;
	vector<KeyPoint> kpts1, kpts2;
	sprintf(Fname, "%s.kpts", Fname1); sprintf(Fnameb, "%s.desc", Fname1);
	if (IsFileExist(Fname) && IsFileExist(Fnameb))
	{
		ReadKPointsBinarySIFT(Fname, kpts1);
		descriptors1 = ReadDescriptorBinarySIFT(Fnameb);

		npts1 = (int)kpts1.size();
		CovF1.Kpts = new double[npts1 * 6];
		for (int ii = 0; ii < npts1; ii++)
			CovF1.Kpts[6 * ii] = kpts1[ii].pt.x, CovF1.Kpts[6 * ii + 1] = kpts1[ii].pt.y;
	}
	else
	{
		printLOG("Running feature detection ...\n");
		start = omp_get_wtime();
		sprintf(Fname, "%s.png", Fname1);
		if (VLCOVDET(Fname, CovF1, npts1) == 1)
			return 1;
		else
			printLOG("%s: %d features ... %.2fs \n", Fname1, npts1, omp_get_wtime() - start);

		descriptors1 = Mat::eye(npts1, 128, CV_32F);
		for (int ii = 0; ii < npts1; ii++)
			for (int jj = 0; jj < 128; jj++)
				descriptors1.at<float>(ii, jj) = CovF1.Desc[ii * 128 + jj];
	}
	/*{
	vector<KeyPoint> keys;
	vector<float> descriptors; descriptors.reserve(128 * npts1);
	for (int kk = 0; kk < npts1; kk++)
	{
	double maxis1 = pow(CovF1.Kpts[6*kk + 2], 2) + pow(CovF1.Kpts[6*kk + 3], 2);
	double maxis2 = pow(CovF1.Kpts[6*kk + 4], 2) + pow(CovF1.Kpts[6*kk + 5], 2);

	keys.push_back(KeyPoint(CovF1.Kpts[6*kk], CovF1.Kpts[6*kk + 1], sqrt(max(maxis1, maxis2))));
	for (int ll = 0; ll < 128; ll++)
	descriptors.push_back(CovF1.Desc[kk * 128 + ll]); //vlfeat covdet desc has been normalized to 1.0
	}

	WriteKPointsBinarySIFT("C:/temp/0/K0.dat", keys);
	WriteDescriptorBinarySIFT("C:/temp/0/D0.dat", descriptors);
	}*/

	sprintf(Fname, "%s.kpts", Fname2); sprintf(Fnameb, "%s.desc", Fname2);
	if (IsFileExist(Fname) && IsFileExist(Fnameb))
	{
		ReadKPointsBinarySIFT(Fname, kpts2);
		descriptors2 = ReadDescriptorBinarySIFT(Fnameb);

		npts2 = (int)kpts2.size();
		CovF2.Kpts = new double[npts2 * 6];
		for (int ii = 0; ii < npts2; ii++)
			CovF2.Kpts[6 * ii] = kpts2[ii].pt.x, CovF2.Kpts[6 * ii + 1] = kpts2[ii].pt.y;
	}
	else
	{
		start = omp_get_wtime();
		sprintf(Fname, "%s.png", Fname2);
		if (VLCOVDET(Fname, CovF2, npts2) == 1)
			return 1;
		else
			printLOG("%s: %d features .... %.2fs \n\n", Fname2, npts2, omp_get_wtime() - start);

		descriptors2 = Mat::eye(npts2, 128, CV_32F);
		for (int ii = 0; ii < npts2; ii++)
			for (int jj = 0; jj < 128; jj++)
				descriptors2.at<float>(ii, jj) = CovF2.Desc[ii * 128 + jj];
	}
	/*{
	float *fKpts = new float[npts2 * 4];
	unsigned char *Desc = new unsigned char[npts2 * 128];
	for (int ii = 0; ii < min(npts2, 100000); ii++)
	{
	double maxis1 = pow(CovF2.Kpts[6 * ii + 2], 2) + pow(CovF2.Kpts[6 * ii + 3], 2);
	double maxis2 = pow(CovF2.Kpts[6 * ii + 4], 2) + pow(CovF2.Kpts[6 * ii + 5], 2);

	fKpts[4 * ii] = (float)CovF2.Kpts[6 * ii];
	fKpts[4 * ii + 1] = (float)CovF2.Kpts[6 * ii + 1];
	fKpts[4 * ii + 2] = (float)sqrt(max(maxis1, maxis2));
	fKpts[4 * ii + 3] = 1.0f;
	}
	for (int ii = 0; ii < min(npts2, 100000); ii++)
	for (int jj = 0; jj < 128; jj++)
	Desc[ii * 128 + jj] = (unsigned char)(int)(floor)(CovF2.Desc[ii * 128 + jj] * 512);

	writeVisualSFMSiftGPU("C:/temp/X/Corpus/0._sift", fKpts, Desc, min(npts2, 100000));
	}
	return 0;*/

	const int ninlierThesh = 50;
	bool BinaryDesc = false, useBFMatcher = false; // SET TO TRUE TO USE BRUTE FORCE MATCHER
	const int knn = 2, ntrees = 4, maxLeafCheck = 128;

	printLOG("Running feature matching...\n");
	start = omp_get_wtime();
	/*Mat descriptors1(npts1, 128, CV_32F), descriptors2(npts2, 128, CV_32F);
	for (int ii = 0; ii < npts1; ii++)
	for (int jj = 0; jj < 128; jj++)
	descriptors1.at<float>(ii, jj) = CovF1.Desc[ii * 128 + jj];
	for (int ii = 0; ii < npts2; ii++)
	for (int jj = 0; jj < 128; jj++)
	descriptors2.at<float>(ii, jj) = CovF2.Desc[ii * 128 + jj];*/

	//Finding nearest neighbor
	Mat indices, dists;
	vector<vector<DMatch> > matches;
	vector<Point2i> RawPairWiseMatchID; RawPairWiseMatchID.reserve(10000);
	if (BinaryDesc)
	{
		//printLOG("Binary descriptors detected...\n");// ORB, Brief, BRISK, FREAK
		if (useBFMatcher)
		{
			cv::BFMatcher matcher(cv::NORM_HAMMING); // use cv::NORM_HAMMING2 for ORB descriptor with WTA_K == 3 or 4 (see ORB constructor)
			matcher.knnMatch(descriptors2, descriptors1, matches, knn);
		}
		else
		{
			// Create Flann LSH index
			cv::flann::Index flannIndex(descriptors1, cv::flann::LshIndexParams(12, 20, 2), cvflann::FLANN_DIST_HAMMING);
			flannIndex.knnSearch(descriptors2, indices, dists, knn, cv::flann::SearchParams());
		}
	}
	else
	{
		if (useBFMatcher)
		{
			cv::BFMatcher matcher(cv::NORM_L2);
			matcher.knnMatch(descriptors2, descriptors1, matches, knn);
		}
		else
		{
			// Create Flann KDTree index
			cv::flann::Index flannIndex(descriptors1, cv::flann::KDTreeIndexParams(ntrees));//, cvflann::FLANN_DIST_EUCLIDEAN);
			flannIndex.knnSearch(descriptors2, indices, dists, knn, cv::flann::SearchParams(maxLeafCheck));
		}
	}

	// Find correspondences by NNDR (Nearest Neighbor Distance Ratio)
	if (!useBFMatcher)
	{
		for (int i = 0; i < descriptors2.rows; ++i)
		{
			int ind1 = indices.at<int>(i, 0);
			if (indices.at<int>(i, 0) >= 0 && indices.at<int>(i, 1) >= 0 && dists.at<float>(i, 0) <= nndrRatio * dists.at<float>(i, 1))
				RawPairWiseMatchID.push_back(Point2i(ind1, i));
		}
	}
	else
	{
		for (unsigned int i = 0; i < matches.size(); ++i)
			if (matches.at(i).size() == 2 && matches.at(i).at(0).distance <= nndrRatio * matches.at(i).at(1).distance)
				RawPairWiseMatchID.push_back(Point2i(matches.at(i).at(0).trainIdx, i));
	}
	printLOG("%d matches found... in %.2fs\n", RawPairWiseMatchID.size(), omp_get_wtime() - start);

	KeyPoint key;
	vector<int> CorresID;
	vector<Point2d> Keys1, Keys2;
	for (int i = 0; i < npts1; i++)
		Keys1.push_back(Point2d(CovF1.Kpts[6 * i], CovF1.Kpts[6 * i + 1]));
	for (int i = 0; i < npts2; i++)
		Keys2.push_back(Point2d(CovF2.Kpts[6 * i], CovF2.Kpts[6 * i + 1]));
	for (int i = 0; i < RawPairWiseMatchID.size(); ++i)
		CorresID.push_back(RawPairWiseMatchID[i].x), CorresID.push_back(RawPairWiseMatchID[i].y);

	int nchannels = 3;
	sprintf(Fname, "%s.png", Fname1);
	Mat Img1 = imread(Fname, nchannels == 3 ? 1 : 0);
	if (Img1.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	sprintf(Fname, "%s.png", Fname2);
	Mat Img2 = imread(Fname, nchannels == 3 ? 1 : 0);
	if (Img2.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}

	cv::Mat correspond(max(Img1.rows, Img2.rows), Img1.cols + Img2.cols, CV_8UC3);
	cv::Rect rect1(0, 0, Img1.cols, Img1.rows);
	cv::Rect rect2(Img1.cols, 0, Img1.cols, Img1.rows);

	Img1.copyTo(correspond(rect1));
	Img2.copyTo(correspond(rect2));

	DisplayImageCorrespondence(correspond, Img1.cols, 0, Keys1, Keys2, CorresID, fractionMatchesDisplayed);

	return 0;
}
int vlSiftPair(char *Path, char *Fname1, char *Fname2, float nndrRatio, double density, bool useBFMatcher)
{
	char Fname[512];
	const int knn = 2, ntrees = 4, maxLeafCheck = 128;
	vector<KeyPoint> kpts1, kpts2;
	Mat desc1, desc2;

	//sprintf(Fname, "%s/%s.sift", Path, Fname1); readVisualSFMSiftGPU(Fname, kpts1, desc1);
	//sprintf(Fname, "%s/0/K%s.dat", Path, Fname1);  ReadKPointsBinarySIFT(Fname, kpts1);
	//sprintf(Fname, "%s/0/D%s.dat", Path, Fname1);  desc1 = ReadDescriptorBinarySIFT(Fname);
	//sprintf(Fname, "%s/%s.sift", Path, Fname2);	readVisualSFMSiftGPU(Fname, kpts2, desc2);
	SiftFeature SF;
	int npts = 0;
	sprintf(Fname, "%s/%s.jpg", Path, Fname1);
	VLSIFT(Fname, SF, npts);
	desc1 = Mat(npts, 128, CV_32F);
	for (int kk = 0; kk < npts; kk++)
	{
		kpts1.push_back(KeyPoint(SF.Kpts[4 * kk], SF.Kpts[4 * kk + 1], SF.Kpts[4 * kk + 2]));
		double norm = 0.0;
		for (int ll = 0; ll < 128; ll++)
			norm += pow(SF.Desc[kk * 128 + ll], 2);
		norm = sqrt(norm);
		for (int ll = 0; ll < 128; ll++)
			desc1.at<float>(kk, ll) = SF.Desc[kk * 128 + ll] / norm;
	}

	npts = 0;
	sprintf(Fname, "%s/%s.jpg", Path, Fname2);
	VLSIFT(Fname, SF, npts);
	desc2 = Mat(npts, 128, CV_32F);
	for (int kk = 0; kk < npts; kk++)
	{
		kpts2.push_back(KeyPoint(SF.Kpts[4 * kk], SF.Kpts[4 * kk + 1], SF.Kpts[4 * kk + 2]));
		double norm = 0.0;
		for (int ll = 0; ll < 128; ll++)
			norm += pow(SF.Desc[kk * 128 + ll], 2);
		norm = sqrt(norm);
		for (int ll = 0; ll < 128; ll++)
			desc2.at<float>(kk, ll) = SF.Desc[kk * 128 + ll] / norm;
	}
	/*SiftFeatureDetector detector;
	SiftDescriptorExtractor extractor;

	double start = omp_get_wtime();
	sprintf(Fname, "%s/%s.png", Path, Fname1);
	Mat img = imread(Fname, 0);
	detector.detect(img, kpts1);
	extractor.compute(img, kpts1, desc1);
	for (int kk = 0; kk < kpts1.size(); kk++)
	{
	double norm = 0.0;
	for (int ll = 0; ll < 128; ll++)
	norm += pow(desc1.at<float>(kk, ll), 2);
	norm = sqrt(norm);
	for (int ll = 0; ll < 128; ll++)
	desc1.at<float>(kk, ll) /= norm;
	}
	printLOG("View 1: %d points .... %.2fs\n", kpts1.size(), omp_get_wtime() - start);

	start = omp_get_wtime();
	sprintf(Fname, "%s/%s.png", Path, Fname2);
	img = imread(Fname, 0);
	detector.detect(img, kpts2);
	extractor.compute(img, kpts2, desc2);
	for (int kk = 0; kk < kpts2.size(); kk++)
	{
	double norm = 0.0;
	for (int ll = 0; ll < 128; ll++)
	norm += pow(desc2.at<float>(kk, ll), 2);
	norm = sqrt(norm);
	for (int ll = 0; ll < 128; ll++)
	desc2.at<float>(kk, ll) /= norm;
	}
	printLOG("View 2: %d points .... %.2fs\n", kpts2.size(), omp_get_wtime() - start);*/

	//Finding nearest neighbor
	Mat indices, dists;
	//vector<vector<DMatch> > matches;
	vector<Point2i> RawPairWiseMatchID; RawPairWiseMatchID.reserve(10000);
	vector<Point2i> SRawPairWiseMatchID; SRawPairWiseMatchID.reserve(10000);
	if (useBFMatcher)
	{
		//cv::BFMatcher matcher(cv::NORM_L2);
		//matcher.knnMatch(desc2, desc1, matches, knn);
		RawPairWiseMatchID = MatchTwoViewSIFTBruteForce(desc1, desc2);

		//for (unsigned int i = 0; i < matches.size(); ++i)
		//	if (matches.at(i).at(0).distance <= nndrRatio * matches.at(i).at(1).distance)
		//		RawPairWiseMatchID.push_back(Point2i(matches.at(i).at(0).trainIdx, i));
	}
	else
	{
		// Create Flann KDTree index
		cv::flann::Index flannIndex(desc1, cv::flann::KDTreeIndexParams(ntrees));//, cvflann::FLANN_DIST_EUCLIDEAN);
		flannIndex.knnSearch(desc2, indices, dists, knn, cv::flann::SearchParams(maxLeafCheck));

		for (int i = 0; i < desc2.rows; ++i)
		{
			int ind1 = indices.at<int>(i, 0);
			if (indices.at<int>(i, 0) >= 0 && indices.at<int>(i, 1) >= 0 && dists.at<float>(i, 0) <= nndrRatio * dists.at<float>(i, 1))
				RawPairWiseMatchID.push_back(Point2i(ind1, i));
		}

		//To remove the nonsense case of every point matchces to 1 point-->IT HAPPENED
		SRawPairWiseMatchID.push_back(RawPairWiseMatchID.at(0));
		for (int i = 1; i < min((int)RawPairWiseMatchID.size(), 50000); i++)
			if (RawPairWiseMatchID.at(i).x != RawPairWiseMatchID.at(i - 1).x)
				SRawPairWiseMatchID.push_back(RawPairWiseMatchID.at(i));

		RawPairWiseMatchID = SRawPairWiseMatchID;
	}

	int num_match = (int)RawPairWiseMatchID.size();
	printLOG("Found %d matches\n", num_match);

	int nchannels = 3;
	sprintf(Fname, "%s/%s.png", Path, Fname1);
	Mat Img1 = imread(Fname, nchannels == 3 ? 1 : 0);
	if (Img1.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	sprintf(Fname, "%s/%s.png", Path, Fname2);
	Mat Img2 = imread(Fname, nchannels == 3 ? 1 : 0);
	if (Img2.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}

	cv::Mat correspond(max(Img1.rows, Img2.rows), Img1.cols + Img2.cols, CV_8UC3);
	cv::Rect rect1(0, 0, Img1.cols, Img1.rows);
	cv::Rect rect2(Img1.cols, 0, Img1.cols, Img1.rows);

	Img1.copyTo(correspond(rect1));
	Img2.copyTo(correspond(rect2));


	vector<int>CorresID;
	vector<Point2d> keypoints1, keypoints2;
	CorresID.reserve(2 * num_match);
	keypoints1.reserve(num_match);
	keypoints2.reserve(num_match);
	for (int i = 0; i < num_match; ++i)
	{
		CorresID.push_back(i), CorresID.push_back(i);
		keypoints1.push_back(Point2d(kpts1[RawPairWiseMatchID[i].x].pt.x, kpts1[RawPairWiseMatchID[i].x].pt.y));
		keypoints2.push_back(Point2d(kpts2[RawPairWiseMatchID[i].y].pt.x, kpts2[RawPairWiseMatchID[i].y].pt.y));
	}

	DisplayImageCorrespondence(correspond, Img1.cols, 0, keypoints1, keypoints2, CorresID, density);

	//USAC config
	bool USEPROSAC = false, USESPRT = true, USELOSAC = true;
	ConfigParamsFund cfg;
	cfg.common.confThreshold = 0.99, cfg.common.minSampleSize = 7, cfg.common.inlierThreshold = 5.0;
	cfg.common.maxHypotheses = 850000, cfg.common.maxSolutionsPerSample = 3;
	cfg.common.prevalidateSample = true, cfg.common.prevalidateModel = true, cfg.common.testDegeneracy = true;
	cfg.common.randomSamplingMethod = USACConfig::SAMP_UNIFORM, cfg.common.verifMethod = USACConfig::VERIF_SPRT, cfg.common.localOptMethod = USACConfig::LO_LOSAC;

	if (USEPROSAC)
		cfg.prosac.maxSamples, cfg.prosac.beta, cfg.prosac.nonRandConf, cfg.prosac.minStopLen;
	if (USESPRT)
		cfg.sprt.tM = 200.0, cfg.sprt.mS = 2.38, cfg.sprt.delta = 0.05, cfg.sprt.epsilon = 0.15;
	if (USELOSAC)
		cfg.losac.innerSampleSize = 15, cfg.losac.innerRansacRepetitions = 5, cfg.losac.thresholdMultiplier = 2.0, cfg.losac.numStepsIterative = 4;

	int ninliers = 0;
	double Fmat[9];
	vector<int>Inliers; Inliers.reserve(num_match);
	cfg.common.numDataPoints = num_match;
	USAC_FindFundamentalMatrix(cfg, keypoints1, keypoints2, Fmat, Inliers, ninliers);
	printLOG("Fmat test: %d/%d matches \n", ninliers, num_match);

	return 0;
}
int SiftGPUPair(char *Fname1, char *Fname2, const float nndrRatio, const double fractionMatchesDisplayed)
{
#ifdef _WINDOWS
	// Allocation size to the largest width and largest height 1920x1080
	// Maximum working dimension. All the SIFT octaves that needs a larger texture size will be skipped. maxd = 2560 <-> 768MB of graphic memory.
	char * argv[] = { "-fo", "-1", "-v", "0", "-tc", "7680", "-nomc", "-p", "1920x1080", "-maxd", "4096", "-mo", "1", "-da" }; //one orienation and smaller expected # feats
																															   //-fo -1    staring from -1 octave
																															   //-v 1      only print out # feature and overall time
																															   //-loweo    add a (.5, .5) offset
																															   //-tc <num> set a soft limit to number of detected features
																															   //-m,       up to 2 orientations for each feature (change to single orientation by using -m 1)
																															   //-s        enable subpixel subscale (disable by using -s 0)
																															   //"-cuda", "[device_id]"  : cuda implementation (fastest for smaller images). CUDA-implementation allows you to create multiple instances for multiple threads. Checkout src\TestWin\MultiThreadSIFT
																															   // "-Display", "display_name" (for OPENGL) to select monitor/GPU (XLIB/GLUT) on windows the display name would be something like \\.\DISPLAY4
																															   //Only the following parameters can be changed after initialization (by calling ParseParam):-dw, -ofix, -ofix-not, -fo, -unn, -maxd, -b
																															   //to change other parameters at runtime, you need to first unload the dynamically loaded libaray reload the libarary, then create a new siftgpu instance

																															   //Init SiftGPU: START
#ifdef _WINDOWS
#ifdef _DEBUG
	HMODULE  hsiftgpu = LoadLibrary("siftgpu_d.dll");
#else
	HMODULE  hsiftgpu = LoadLibrary("siftgpu.dll");
#endif
#else
	void * hsiftgpu = dlopen("libsiftgpu.so", RTLD_LAZY);
#endif

	if (hsiftgpu == NULL)
		return 0;

	SiftGPU* (*pCreateNewSiftGPU)(int) = NULL;
	SiftMatchGPU* (*pCreateNewSiftMatchGPU)(int) = NULL;
	pCreateNewSiftGPU = (SiftGPU* (*) (int)) GET_MYPROC(hsiftgpu, "CreateNewSiftGPU");
	pCreateNewSiftMatchGPU = (SiftMatchGPU* (*)(int)) GET_MYPROC(hsiftgpu, "CreateNewSiftMatchGPU");
	SiftGPU* sift = pCreateNewSiftGPU(1);

	int argc = sizeof(argv) / sizeof(char*);
	sift->ParseParam(argc, argv);
	if (sift->CreateContextGL() != SiftGPU::SIFTGPU_FULL_SUPPORTED)
		return 0;
	//Init SiftGPU: END

	//SIFT DECTION: START
	int numKeys1, numKeys2, descriptorSize = SIFTBINS;
	vector<float > desc1, desc2; desc1.reserve(MaxNFeatures * descriptorSize), desc2.reserve(MaxNFeatures * descriptorSize);
	vector<uchar > descU1, descU2; descU1.reserve(MaxNFeatures * descriptorSize), descU2.reserve(MaxNFeatures * descriptorSize);
	vector<SiftGPU::SiftKeypoint> keys1, keys2; keys1.reserve(MaxNFeatures), keys2.reserve(MaxNFeatures);

	int totalPts = 0;
	char Fname[512];

	double start;
	std::string Fname1Str(Fname1);
	std::size_t found = Fname1Str.find(".");
	std::string NameOnly1 = Fname1Str.substr(0, found);
	std::string NameSift1 = NameOnly1 + ".sift";

	if (IsFileExist(NameSift1.c_str()) == 0)
	{
		if (sift->RunSIFT(Fname1)) //You can have at most one OpenGL-based SiftGPU (per process)--> no omp can be used
		{
			//sprintf(Fname, "%s/%.4d.sift", Path, ii);sift->SaveSIFT(Fname);
			numKeys1 = sift->GetFeatureNum();
			keys1.resize(numKeys1);    desc1.resize(descriptorSize * numKeys1);
			sift->GetFeatureVector(&keys1[0], &desc1[0]);

			descU1.resize(numKeys1 * 128);
			RootL1DescNorm(&desc1[0], &descU1[0], numKeys1, 128);
			writeVisualSFMSiftGPU(NameSift1.c_str(), keys1, &descU1[0]);
			printLOG("#%d sift deteced...\n", numKeys1);
		}
		delete sift;

		//Without this, sometimes, the descriptor does not output anything meaningful
		sift = pCreateNewSiftGPU(1);
		sift->ParseParam(argc, argv);
		if (sift->CreateContextGL() != SiftGPU::SIFTGPU_FULL_SUPPORTED)
			return 0;
	}

	std::string Fname2Str(Fname2);
	found = Fname2Str.find(".");
	std::string NameOnly2 = Fname2Str.substr(0, found);
	std::string NameSift2 = NameOnly2 + ".sift";
	if (IsFileExist(NameSift2.c_str()) == 0)
	{
		if (sift->RunSIFT(Fname2)) //You can have at most one OpenGL-based SiftGPU (per process)--> no omp can be used
		{
			//sprintf(Fname, "%s/%.4d.sift", Path, ii);sift->SaveSIFT(Fname);
			numKeys2 = sift->GetFeatureNum();
			keys2.resize(numKeys2);    desc2.resize(descriptorSize * numKeys2);
			sift->GetFeatureVector(&keys2[0], &desc2[0]);

			descU2.resize(numKeys2 * 128);
			RootL1DescNorm(&desc2[0], &descU2[0], numKeys2, 128);
			writeVisualSFMSiftGPU(NameSift2.c_str(), keys2, &descU2[0]);
			printLOG("#%d sift deteced...\n", numKeys2);
		}
	}
	//SIFT DECTION: ENDS

	///SIFT MATCHING: START
	bool useCPU = true;
	start = omp_get_wtime();
	vector<Point2i> RawPairWiseMatchID; RawPairWiseMatchID.reserve(10000);
	if (useCPU)
	{
		keys1.clear(), keys2.clear();

		bool BinaryDesc = false, useBFMatcher = true; // SET TO TRUE TO USE BRUTE FORCE MATCHER
		const int knn = 2, ntrees = 4, maxLeafCheck = 128;

		printLOG("Running feature matching...\n");
		Mat descriptors1; readVisualSFMSiftGPU(NameSift1.c_str(), keys1, descriptors1);
		if (descriptors1.rows == 1)
			return 1;

		Mat descriptors2; readVisualSFMSiftGPU(NameSift2.c_str(), keys2, descriptors2);
		if (descriptors2.rows == 1)
			return 1;

		//Finding nearest neighbor
		Mat indices, dists;
		/*vector<vector<DMatch> > matches;
		if (BinaryDesc)
		{
		//printLOG("Binary descriptors detected...\n");// ORB, Brief, BRISK, FREAK
		if (useBFMatcher)
		{
		cv::BFMatcher matcher(cv::NORM_HAMMING); // use cv::NORM_HAMMING2 for ORB descriptor with WTA_K == 3 or 4 (see ORB constructor)
		matcher.knnMatch(descriptors2, descriptors1, matches, knn);
		}
		else
		{
		// Create Flann LSH index
		cv::flann::Index flannIndex(descriptors1, cv::flann::LshIndexParams(12, 20, 2), cvflann::FLANN_DIST_HAMMING);
		flannIndex.knnSearch(descriptors2, indices, dists, knn, cv::flann::SearchParams());
		}
		}
		else
		{
		if (useBFMatcher)
		{
		cv::BFMatcher matcher(cv::NORM_L2);
		matcher.knnMatch(descriptors2, descriptors1, matches, knn);
		}
		else
		{
		// Create Flann KDTree index
		cv::flann::Index flannIndex(descriptors1, cv::flann::KDTreeIndexParams(ntrees));//, cvflann::FLANN_DIST_EUCLIDEAN);
		flannIndex.knnSearch(descriptors2, indices, dists, knn, cv::flann::SearchParams(maxLeafCheck));
		}
		}

		// Find correspondences by NNDR (Nearest Neighbor Distance Ratio)
		if (!useBFMatcher)
		{
		for (int i = 0; i < descriptors2.rows; ++i)
		{
		int ind1 = indices.at<int>(i, 0);
		if (indices.at<int>(i, 0) >= 0 && indices.at<int>(i, 1) >= 0 && dists.at<float>(i, 0) <= nndrRatio * dists.at<float>(i, 1))
		RawPairWiseMatchID.push_back(Point2i(ind1, i));
		}
		}
		else
		{
		for (unsigned int i = 0; i < matches.size(); ++i)
		if (matches.at(i).size() == 2 && matches.at(i).at(0).distance <= nndrRatio * matches.at(i).at(1).distance)
		RawPairWiseMatchID.push_back(Point2i(matches.at(i).at(0).trainIdx, i));
		}*/
		//Finding nearest neighbor
		///Mat indices, dists;
		//vector<vector<DMatch> > matches;
		if (useBFMatcher)
		{
			//cv::BFMatcher matcher(cv::NORM_L2);
			//matcher.knnMatch(desc2, desc1, matches, knn);
			RawPairWiseMatchID = MatchTwoViewSIFTBruteForce(descriptors1, descriptors2);
		}
		else
		{
			// Create Flann KDTree index
			cv::flann::Index flannIndex(desc1, cv::flann::KDTreeIndexParams(ntrees));//, cvflann::FLANN_DIST_EUCLIDEAN);
			flannIndex.knnSearch(desc2, indices, dists, knn, cv::flann::SearchParams(maxLeafCheck));
		}

		// Find correspondences by NNDR (Nearest Neighbor Distance Ratio)
		if (useBFMatcher)
		{
			;//for (unsigned int i = 0; i < matches.size(); ++i)
			 //	if (matches.at(i).at(0).distance <= nndrRatio * matches.at(i).at(1).distance)
			 //		RawPairWiseMatchID.push_back(Point2i(matches.at(i).at(0).trainIdx, i));
		}
		else
		{
			for (int i = 0; i < descriptors2.rows; ++i)
			{
				int ind1 = indices.at<int>(i, 0);
				if (indices.at<int>(i, 0) >= 0 && indices.at<int>(i, 1) >= 0 && dists.at<float>(i, 0) <= nndrRatio * dists.at<float>(i, 1))
					RawPairWiseMatchID.push_back(Point2i(ind1, i));
			}

			//To remove the nonsense case of every point matchces to 1 point-->IT HAPPENED
			vector<Point2i> SRawPairWiseMatchID; SRawPairWiseMatchID.reserve(10000);
			SRawPairWiseMatchID.push_back(RawPairWiseMatchID.at(0));
			for (int i = 1; i < min((int)RawPairWiseMatchID.size(), 50000); i++)
				if (RawPairWiseMatchID.at(i).x != RawPairWiseMatchID.at(i - 1).x)
					SRawPairWiseMatchID.push_back(RawPairWiseMatchID.at(i));

			RawPairWiseMatchID = SRawPairWiseMatchID;
		}
	}
	else
	{
		///SIFT MATCHING: START
		SiftMatchGPU* matcher = pCreateNewSiftMatchGPU(8192 * 2);
		matcher->VerifyContextGL(); //must call once
		int(*match_buf)[2] = new int[50000][2];

		start = omp_get_wtime();
		//Finding nearest neighbor. call matcher->SetMaxSift() to change the limit before calling setdescriptor if you want change maxMatch
		matcher->SetDescriptors(0, numKeys1, &desc1[0]); //image 1
		matcher->SetDescriptors(1, numKeys2, &desc2[0]); //image 2

														 //enumerate all the feature matches
		int num_match = matcher->GetSiftMatch(numKeys1, match_buf, 0.7f, nndrRatio);
		for (int i = 0; i < num_match; ++i)
			RawPairWiseMatchID.push_back(Point2i(match_buf[i][0], match_buf[i][1]));
		///SIFT MATCHING: ENDS
	}

	KeyPoint key;
	vector<int> CorresID;
	vector<Point2d> Keys1, Keys2;
	for (int i = 0; i < RawPairWiseMatchID.size(); ++i)
	{
		int id1 = RawPairWiseMatchID[i].x, id2 = RawPairWiseMatchID[i].y;
		Keys1.push_back(Point2d(keys1[id1].x - 0.5, keys1[id1].y - 0.5));
		Keys2.push_back(Point2d(keys2[id2].x - 0.5, keys2[id2].y - 0.5));
	}

	printLOG("%d matches found... in %.2fs\n", Keys1.size(), omp_get_wtime() - start);

	/*//double K[9] = { 1727.9421, 0, 942.0952, 0, 1723.0802, 560.5131, 0, 0, 1 };
	//double distortion[7] = { -2.0042915154148783e-001, 2.0168718385268081e-001, 1.0014015360398033e-001, 0, 0, 0, 0 };
	//LensCorrectionPoint(Keys1, K, distortion);
	//LensCorrectionPoint(Keys2, K, distortion);

	Mat cvInliers, cvK = Mat(3, 3, CV_64F, K);
	Mat E = findEssentialMat(Keys1, Keys2, cvK, cvK, 8, 0.99, 2.0, 100, cvInliers);
	int ninliers = 0, pmatches = (int)Keys1.size();
	for (int ii = 0; ii < cvInliers.cols; ii++)
	if (cvInliers.at<bool>(ii))
	ninliers++;

	Mat R_5pt, rvec_5pt, tvec_5pt;
	recoverPose(E, Keys1, Keys2, R_5pt, tvec_5pt, cvK, cvK, noArray());

	Rodrigues(R_5pt, rvec_5pt);
	std::cout << "5-pt-nister rvec: " << std::endl;
	std::cout << rvec_5pt << std::endl;
	std::cout << "5-pt-nister tvec: " << std::endl;
	std::cout << tvec_5pt << std::endl;*/

	//USAC config
	bool USEPROSAC = false, USESPRT = true, USELOSAC = true;
	ConfigParamsFund cfg;
	cfg.common.confThreshold = 0.99, cfg.common.minSampleSize = 7, cfg.common.inlierThreshold = 5.0;
	cfg.common.maxHypotheses = 850000, cfg.common.maxSolutionsPerSample = 3;
	cfg.common.prevalidateSample = true, cfg.common.prevalidateModel = true, cfg.common.testDegeneracy = true;
	cfg.common.randomSamplingMethod = USACConfig::SAMP_UNIFORM, cfg.common.verifMethod = USACConfig::VERIF_SPRT, cfg.common.localOptMethod = USACConfig::LO_LOSAC;

	if (USEPROSAC)
		cfg.prosac.maxSamples, cfg.prosac.beta, cfg.prosac.nonRandConf, cfg.prosac.minStopLen;
	if (USESPRT)
		cfg.sprt.tM = 200.0, cfg.sprt.mS = 2.38, cfg.sprt.delta = 0.05, cfg.sprt.epsilon = 0.15;
	if (USELOSAC)
		cfg.losac.innerSampleSize = 15, cfg.losac.innerRansacRepetitions = 5, cfg.losac.thresholdMultiplier = 2.0, cfg.losac.numStepsIterative = 4;

	int ninliers = 0, pmatches = (int)Keys1.size();
	double Fmat[9];
	vector<int>Inliers; Inliers.reserve(pmatches);
	cfg.common.numDataPoints = pmatches;
	USAC_FindFundamentalMatrix(cfg, Keys1, Keys2, Fmat, Inliers, ninliers);
	printLOG("Fmat test: %d/%d matches \n", ninliers, pmatches);

	int nchannels = 3;
	IplImage *Img1 = cvLoadImage(Fname1, nchannels == 3 ? 1 : 0);
	if (Img1->imageData == NULL)
	{
		printLOG("Cannot load %s\n", Fname1);
		return 1;
	}
	IplImage *Img2 = cvLoadImage(Fname2, nchannels == 3 ? 1 : 0);
	if (Img2->imageData == NULL)
	{
		printLOG("Cannot load %s\n", Fname2);
		return 1;
	}

	IplImage* correspond = cvCreateImage(cvSize(Img1->width + Img2->width, max(Img1->height, Img2->height)), 8, nchannels);
	cvSetImageROI(correspond, cvRect(0, 0, Img1->width, Img1->height));	cvCopy(Img1, correspond);
	cvSetImageROI(correspond, cvRect(Img1->width, 0, correspond->width, Img2->height));	cvCopy(Img2, correspond);
	cvResetImageROI(correspond);

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));
	for (int ii = 0; ii < pmatches; ii++)
	{
		if (Inliers[ii] == 0)
			continue;
		int x1 = (int)Keys1[ii].x, y1 = (int)Keys1[ii].y;
		int x2 = (int)Keys2[ii].x + Img1->width, y2 = (int)Keys2[ii].y + 0;
		//cvLine(correspond, cvPoint(x1, y1), cvPoint(x2, y2), colors[ii % 9], 1);
		cvCircle(correspond, cvPoint(x1, y1), 1, colors[ii % 9], 2), cvCircle(correspond, cvPoint(x2, y2), 1, colors[ii % 9], 2);
	}

	namedWindow("Correspondence", CV_WINDOW_NORMAL);
	cvShowImage("Correspondence", correspond);
	cvWaitKey(-1);
	printLOG("Images closed\n");

	delete sift;
	FREE_MYLIB(hsiftgpu);
#endif

	return 0;
}

void ExtractSiftGPU(char *Path, int cid, int fid, Mat &Img, vector<SiftKeypoint> &Feat, vector<uchar>& descriptorsU, SiftGPU* sift)
{
	if (sift == 0)
	{
		printLOG("Fail to ini SiftGPU for %d_%.4d\n", cid, fid);
		return;
	}

	sift->RunSIFT(Img.cols, Img.rows, Img.data, GL_LUMINANCE, GL_UNSIGNED_BYTE);
	int numKeys = min(sift->GetFeatureNum(), 50000);

	Feat.clear(); Feat.resize(numKeys), descriptorsU.resize(numKeys * 128);
	vector<float > descriptors;  descriptors.resize(128 * numKeys);


	sift->GetFeatureVector(&Feat[0], &descriptors[0]);

	int dummy = numKeys - 1;

	float t;
	SiftKeypoint tempkey;
	for (int ii = 0; ii < numKeys / 2; ii++)
		for (int jj = 0; jj < 128; jj++)
			descriptors[ii * 128 + jj] = descriptors[ii * 128 + jj] * 512; //visualsfm requires it to be normalzie to 512
	RootL1DescNorm(&descriptors[0], &descriptorsU[0], numKeys, 128);

	//loading mask
	char Fname[512];  sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, fid);
	if (IsFileExist(Fname) == 1)
	{
		Mat mask = Mat::zeros(Img.rows, Img.cols, CV_8U);

		const int nJoints = 18;
		float u, v, s, minU, maxU, minV, maxV;
		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
		{
			minU = (float)9e9, maxU = 0.f, minV = (float)9e9, maxV = 0.f;
			if (s > 0.1)
				minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
			for (int j = 1; j < nJoints; j++)
			{
				fscanf(fp, "%f %f %f ", &u, &v, &s);
				if (s > 0.1)
					minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
			}
			minU = max(minU - mask.cols / 50, 0.f), maxU = min(maxU + mask.cols / 50, 1.f*mask.cols - 1);
			minV = max(minV - mask.rows / 50, 0.f), maxV = min(maxV + mask.rows / 50, 1.f*mask.rows - 1);
			for (int i = minU; i < maxU; i++)
				for (int j = minV; j < maxV; j++)
					mask.data[i + j * mask.cols] = 255;
		}
		fclose(fp);

		int keyCount = 0;
		for (int ii = 0; ii < numKeys; ii++)
		{
			int x = Feat[ii].x, y = Feat[ii].y;
			if (mask.data[x + y * mask.cols] == (uchar)255)
				continue;

			Feat[keyCount].x = Feat[ii].x, Feat[keyCount].y = Feat[ii].y, Feat[keyCount].s = Feat[ii].s, Feat[keyCount].o = Feat[ii].o;
			for (int jj = 0; jj < 128; jj++)
				descriptorsU[128 * keyCount + jj] = descriptorsU[128 * ii + jj];

			keyCount++;
		}

		if (keyCount < numKeys)
		{
			printLOG("Clean %d/%d points for %s\n", numKeys - keyCount, numKeys, Fname);
			Feat.resize(keyCount); numKeys = keyCount;
		}
	}

	return;
}
void ExtractSiftGPU(char *Path, vector<int> &nviews, int startF, int stopF, int increF, int HistogramEqual, bool ROOTL1)
{
	// Allocation size to the largest width and largest height 1920x1080
	// Maximum working dimension. All the SIFT octaves that needs a larger texture size will be skipped. maxd = 2560 <-> 768MB of graphic memory.
	//-fo -1    staring from -1 octave
	//-v 1      only print out # feature and overall time
	//-loweo    add a (.5, .5) offset
	//-tc <num> set a soft limit to number of detected features
	//-m,       up to 2 orientations for each feature (change to single orientation by using -m 1)
	//-s        enable subpixel subscale (disable by using -s 0)
	//"-cuda", "[device_id]"  : cuda implementation (fastest for smaller images). CUDA-implementation allows you to create multiple instances for multiple threads. Checkout src\TestWin\MultiThreadSIFT
	// "-Display", "display_name" (for OPENGL) to select monitor/GPU (XLIB/GLUT) on windows the display name would be something like \\.\DISPLAY4
	//Only the following parameters can be changed after initialization (by calling ParseParam):-dw, -ofix, -ofix-not, -fo, -unn, -maxd, -b
	//to change other parameters at runtime, you need to first unload the dynamically loaded libaray reload the libarary, then create a new siftgpu instance
	char * argv[] = { "-fo", "-1", "-v", "0", "-tc", "7680", "-nomc", "-p", "1920x1080", "-maxd", "2048", "-mo", "1", "-da" }; //one orienation and smaller expected # feats
#ifdef USESIFTGPU
																															   //Init SiftGPU: START
#ifdef _WINDOWS
#ifdef _DEBUG
	HMODULE  hsiftgpu = LoadLibrary("siftgpu_d.dll");
#else
	HMODULE  hsiftgpu = LoadLibrary("siftgpu.dll");
#endif
#else
	void * hsiftgpu = dlopen("libsiftgpu.so", RTLD_LAZY);
#endif

	if (hsiftgpu == NULL)
		return;

	SiftGPU* (*pCreateNewSiftGPU)(int) = NULL;
	pCreateNewSiftGPU = (SiftGPU* (*) (int)) GET_MYPROC(hsiftgpu, "CreateNewSiftGPU");
	SiftGPU* sift = pCreateNewSiftGPU(1);

	int argc = sizeof(argv) / sizeof(char*);
	sift->ParseParam(argc, argv);
	if (sift->CreateContextGL() != SiftGPU::SIFTGPU_FULL_SUPPORTED)
		return;
	//Init SiftGPU: END

	//SIFT DECTION: START
	int numKeys, descriptorSize = SIFTBINS;
	vector<float > descriptors; descriptors.reserve(MaxNFeatures * descriptorSize);
	vector<SiftGPU::SiftKeypoint> keys; keys.reserve(MaxNFeatures);
	vector<Point3i> Vrgb; Vrgb.reserve(MaxNFeatures);

	Mat cvImg, cvGray, equalizedImg;
	char Fname[512];
	double start = omp_get_wtime();
	SiftKeypoint tempkey;
	float tempdesc[128];
	if (nviews.size() == 0)
	{
		int jpemode = 0;
		float *fKpts = new float[50000 * 4];
		unsigned char *Desc = new unsigned char[50000 * 128];

		sprintf(Fname, "%s/Corpus/Size", Path); makeDir(Fname);
		for (int frameID = startF; frameID <= stopF; frameID++)
		{
			sprintf(Fname, "%s/Corpus/%.4d.sift", Path, frameID);
			if (IsFileExist(Fname) == 1)
			{
				printLOG("found %s. Skip compuation\n", Fname);
				continue;
			}

			double start = omp_get_wtime();
			sprintf(Fname, "%s/Corpus/%.4d.png", Path, frameID);
			if (IsFileExist(Fname) == 0)
				jpemode = 1, sprintf(Fname, "%s/Corpus/%.4d.jpg", Path, frameID);

			cvImg = imread(Fname, IMREAD_COLOR);
			if (HistogramEqual == 1)
			{
				cvtColor(cvImg, cvGray, CV_BGR2GRAY);
				equalizeHist(cvGray, equalizedImg);
			}
			else
				cvtColor(cvImg, equalizedImg, CV_BGR2GRAY);

			//if (sift->RunSIFT(Fname)) //You can have at most one OpenGL-based SiftGPU (per process)--> no omp can be used
			if (sift->RunSIFT(equalizedImg.cols, equalizedImg.rows, equalizedImg.data, GL_LUMINANCE, GL_UNSIGNED_BYTE))
			{
				numKeys = sift->GetFeatureNum();
				keys.resize(numKeys);    descriptors.resize(descriptorSize * numKeys);
				sift->GetFeatureVector(&keys[0], &descriptors[0]);
				numKeys = min(numKeys, 50000);

				//reverse the scale ordering for visualSfM
				int dummy = numKeys - 1;
				for (int ii = 0; ii < numKeys / 2; ii++)
				{
					tempkey.x = keys[ii].x, tempkey.y = keys[ii].y, tempkey.s = keys[ii].s, tempkey.o = keys[ii].o;
					keys[ii].x = keys[dummy - ii].x, keys[ii].y = keys[dummy - ii].y, keys[ii].s = keys[dummy - ii].s, keys[ii].o = keys[dummy - ii].o;
					keys[dummy - ii].x = tempkey.x, keys[dummy - ii].y = tempkey.y, keys[dummy - ii].s = tempkey.s, keys[dummy - ii].o = tempkey.o;

					for (int jj = 0; jj < 128; jj++)
					{
						tempdesc[jj] = descriptors[ii * 128 + jj];
						descriptors[ii * 128 + jj] = descriptors[(dummy - ii) * 128 + jj];
						descriptors[(dummy - ii) * 128 + jj] = tempdesc[jj];
					}
				}

				vector<bool> validID;
				for (int j = 0; j < numKeys; ++j)
					validID.push_back(1);

				//normalization
				if (ROOTL1)
					RootL1DescNorm(&descriptors[0], Desc, numKeys, 128);
				else
					RootL2DescNorm(&descriptors[0], Desc, numKeys, 128);

				//for visualsfm
				int keyCount = 0;
				for (int ii = 0; ii < numKeys; ii++)
				{
					if (validID[dummy - ii] == 0)
						continue;
					fKpts[4 * keyCount] = keys[ii].x, fKpts[4 * keyCount + 1] = keys[ii].y, fKpts[4 * keyCount + 2] = keys[ii].s, fKpts[4 * keyCount + 3] = keys[ii].o;
					for (int jj = 0; jj < 128; jj++)
						Desc[keyCount * 128 + jj] = Desc[ii * 128 + jj];
					keyCount++;
				}
				if (keyCount < numKeys)
					printLOG("\nClean %d/%d points for %s\n", numKeys - keyCount, numKeys, Fname);
				sprintf(Fname, "%s/Corpus/%.4d.sift", Path, frameID); writeVisualSFMSiftGPU(Fname, fKpts, Desc, keyCount);

				/*//Getting color info
				Vrgb.clear();
				keyCount = 0;
				for (int kk = 0; kk < numKeys; kk++)
				{
				if (validID[kk] == 1)
				{
				fKpts[4 * keyCount] -= 0.5, fKpts[4 * keyCount + 1] -= 0.5;
				int x = (int)fKpts[4 * keyCount], y = (int)fKpts[4 * keyCount + 1];
				int id = x + y*cvImg.cols;
				Point3i rgb;
				rgb.z = cvImg.data[3 * id + 0];//b
				rgb.y = cvImg.data[3 * id + 1];//g
				rgb.x = cvImg.data[3 * id + 2];//r
				Vrgb.push_back(rgb);
				keyCount++;
				}
				}
				sprintf(Fname, "%s/Corpus/%.4d.rgb", Path, frameID); WriteRGBBinarySIFT(Fname, Vrgb);*/

				printLOG("Frame %d: %d points ... Wrote to files. Take %.2fs\n", frameID, numKeys, omp_get_wtime() - start);

				sprintf(Fname, "%s/Corpus/Size/%.4d.txt", Path, frameID); FILE *fp = fopen(Fname, "w");
				fprintf(fp, "%d %d\n", cvImg.cols, cvImg.rows); fclose(fp);

				//Without this, sometimes, the descriptor does not output anything meaningful
				/*sift = pCreateNewSiftGPU(1);
				#ifdef _WINDOWS
				sift->ParseParam(argc, argv2);
				#else
				sift->ParseParam(argc, argv);
				#endif
				if (sift->CreateContextGL() != SiftGPU::SIFTGPU_FULL_SUPPORTED)
				return 0;*/
			}
			else
				printLOG("%s\n", Fname);
		}
	}
	else
	{
		int jpgmode = 0;
		float *fKpts = new float[50000 * 4];
		unsigned char *Desc = new unsigned char[50000 * 128];

		vector<bool> validID;
		for (int ii = 0; ii < nviews.size(); ii++)
		{
			int viewID = nviews[ii];
			for (int frameID = startF; frameID <= stopF; frameID += increF)
			{
				keys.clear(), descriptors.clear();

				if (frameID < 0)
					continue;

				sprintf(Fname, "%s/%d/%.4d.sift", Path, viewID, frameID);
				if (IsFileExist(Fname) == 1)
				{
					printLOG("found %s. Skip compuation\n", Fname);
					continue;
				}

				double start = omp_get_wtime();
				sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, frameID);
				if (IsFileExist(Fname) == 0)
				{
					jpgmode = 1, sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, frameID);
					if (IsFileExist(Fname) == 0)
						continue;
				}

				cvImg = imread(Fname, IMREAD_COLOR);
				if (HistogramEqual == 1)
				{
					cvtColor(cvImg, cvGray, CV_BGR2GRAY);
					equalizeHist(cvGray, equalizedImg);
				}
				else
					cvtColor(cvImg, equalizedImg, CV_BGR2GRAY);

				//if (sift->RunSIFT(Fname)) //You can have at most one OpenGL-based SiftGPU (per process)--> no omp can be used
				if (sift->RunSIFT(equalizedImg.cols, equalizedImg.rows, equalizedImg.data, GL_LUMINANCE, GL_UNSIGNED_BYTE))
				{
					numKeys = sift->GetFeatureNum();
					keys.resize(numKeys);
					descriptors.resize(descriptorSize * numKeys);
					sift->GetFeatureVector(&keys[0], &descriptors[0]);

					validID.clear();
					sprintf(Fname, "%s/MP/%d/%d.txt", Path, viewID, frameID); FILE *fp = fopen(Fname, "r");
					if (fp != NULL)
					{
						//creating rect block mask
						const int nJoints = 18;
						float u, v, s, minU, maxU, minV, maxV;
						Mat mask = Mat::zeros(cvImg.rows, cvImg.cols, CV_8U);

						while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
						{
							minU = (float)9e9, maxU = 0.f, minV = (float)9e9, maxV = 0.f;
							if (s > 0.1)
								minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
							for (int j = 1; j < nJoints; j++)
							{
								fscanf(fp, "%f %f %f ", &u, &v, &s);
								if (s > 0.1)
									minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
							}
							minU = max(minU - cvImg.cols / 50, 0.f), maxU = min(maxU + cvImg.cols / 50, 1.f*cvImg.cols - 1);
							minV = max(minV - cvImg.rows / 50, 0.f), maxV = min(maxV + cvImg.rows / 50, 1.f*cvImg.rows - 1);
							for (int i = minU; i < maxU; i++)
								for (int j = minV; j < maxV; j++)
									mask.data[i + j * mask.cols] = 255;
						}
						fclose(fp);

						for (int j = 0; j < numKeys; ++j)
						{
							int x = keys[j].x, y = keys[j].y;
							if ((int)mask.data[x + y * mask.cols] != 255)
								validID.push_back(1);
							else
								validID.push_back(0);
						}
					}
					else
						for (int i = 0; i < numKeys; i++)
							validID.push_back(1);

					//for visualsfm
					int keyCount = 0;
					for (int ii = 0; ii < numKeys; ii++)
					{
						fKpts[4 * keyCount] = keys[ii].x, fKpts[4 * keyCount + 1] = keys[ii].y, fKpts[4 * keyCount + 2] = keys[ii].s, fKpts[4 * keyCount + 3] = keys[ii].o;
						for (int jj = 0; jj < 128; jj++)
							Desc[keyCount * 128 + jj] = (unsigned char)(int)(floor)(descriptors[ii * 128 + jj] * 512);//since the org desc is normed to 1
						if (validID[ii] == 1)
							keyCount++;
					}
					numKeys = keyCount;

					sprintf(Fname, "%s/%d/%.4d.sift", Path, viewID, frameID);
					writeVisualSFMSiftGPU(Fname, fKpts, Desc, numKeys);

					/*for (int kk = 0; kk < numKeys; kk++)
					{
					keys[kk].x -= 0.5, keys[kk].y -= 0.5;
					int x = (int)keys.at(kk).x, y = (int)keys.at(kk).y;
					int id = x + y*cvImg.cols;
					Point3i rgb;
					rgb.z = cvImg.data[3 * id + 0];//b
					rgb.y = cvImg.data[3 * id + 1];//g
					rgb.x = cvImg.data[3 * id + 2];//r
					if (validID[ii] == 1)
					Vrgb.push_back(rgb);
					}
					//	sprintf(Fname, "%s/%d/%.4d.rgb", Path, viewID, frameID); WriteRGBBinarySIFT(Fname, Vrgb);
					if (Vrgb.size() > 0)*/
					printLOG("View (%d, %d): %d points ... Wrote to files. Take %.2fs\n", viewID, frameID, numKeys, omp_get_wtime() - start);
				}
				else
					printLOG("Cannot load %s", Fname);
			}
#ifdef EC2
			sprintf(Fname, "%s/SIFTExtraction_%d_%d_%.4d.txt", Path, viewID, startF, stopF); FILE *fp = fopen(Fname, "w"); fclose(fp);
#endif
		}
	}

	printLOG("Total time: %.2fs\n", omp_get_wtime() - start);
#else
	printLOG("SiftGPU is not supported \n");
#endif
	return;
}
void ExtractSiftCPU(char *Path, vector<int> &nviews, int startF, int stopF, int increF, int HistogramEqual, int ExtractionMethod, bool ROOTL1)
{
	//ExtractionMethod: 1: covdet, 2: vlsift, 3: opencv sift
	//SIFT DECTION: START
	CovFeature CovF; //detection type is default to harris laplace with no affine correction.
	SiftFeature SF;

	int descriptorSize = SIFTBINS;
	vector<uchar > descriptors; descriptors.reserve(MaxNFeatures * descriptorSize);
	vector<KeyPoint> keys; keys.reserve(MaxNFeatures);
	vector<Point3i> Vrgb; Vrgb.reserve(MaxNFeatures);

	Mat cvImg, equalizedImg;
	char Fname[512];
	int jpgmode = 1;
	double start = omp_get_wtime();
	if (nviews.size() == 0)
	{
		int MaxFeatures = 100000;
		float*           fKpts = new float[4 * MaxFeatures];
		uchar * Desc = new uchar[128 * MaxFeatures];

		double start = omp_get_wtime();
		for (int frameID = startF; frameID <= stopF; frameID += increF)
		{
			sprintf(Fname, "%s/Corpus/%.4d.sift", Path, frameID);
			if (IsFileExist(Fname) == 1)
				continue;

			double start = omp_get_wtime();
			Mat cvImg, equalizedImg;
			int threadID = omp_get_thread_num();

			char Fname[512];  sprintf(Fname, "%s/Corpus/%.4d.jpg", Path, frameID);
			if (IsFileExist(Fname) == 0)
				jpgmode = 0, sprintf(Fname, "%s/Corpus/%.4d.png", Path, frameID);

			if (IsFileExist(Fname) == 0)
			{
				printLOG("Cannot find %s\n", Fname);
				continue;
			}

			if (HistogramEqual == 1)
			{
				cvImg = imread(Fname, 0);
				equalizeHist(cvImg, equalizedImg);

				sprintf(Fname, "%s/Corpus/H_%.4d.jpg", Path, frameID);
				imwrite(Fname, equalizedImg);
			}

			int npts = 0;
			if (ExtractionMethod == 1)
			{
				if (VLCOVDET(Fname, CovF, npts, ROOTL1) == 1)
					continue;

				for (int ii = 0; ii < min(npts, 100000); ii++)
				{
					double maxis1 = pow(CovF.Kpts[6 * ii + 2], 2) + pow(CovF.Kpts[6 * ii + 3], 2);
					double maxis2 = pow(CovF.Kpts[6 * ii + 4], 2) + pow(CovF.Kpts[6 * ii + 5], 2);

					fKpts[4 * ii] = (float)CovF.Kpts[6 * ii] - 0.5;
					fKpts[4 * ii + 1] = (float)CovF.Kpts[6 * ii + 1] - 0.5;
					fKpts[4 * ii + 2] = (float)sqrt(max(maxis1, maxis2));
					fKpts[4 * ii + 3] = 1.0f;
				}

				sprintf(Fname, "%s/Corpus/%.4d.sift", Path, frameID);
				writeVisualSFMSiftGPU(Fname, fKpts, CovF.Desc, min(npts, 100000));
			}
			else if (ExtractionMethod == 2)
			{
				if (VLSIFT(Fname, SF, npts, 0, ROOTL1) == 1)
					continue;

				for (int ii = 0; ii < 4 * npts; ii++)
					fKpts[ii] = (float)SF.Kpts[ii];

				sprintf(Fname, "%s/Corpus/%.4d.sift", Path, frameID);
				writeVisualSFMSiftGPU(Fname, fKpts, SF.Desc, npts);
			}
			else
			{
				printLOG("OPENCV Sift is not supported\n");
				exit(0);
				/*int descriptorSize = 128;
				SiftFeatureDetector detector;
				SiftDescriptorExtractor extractor;
				SIFT sfeatures;
				Mat desc;

				Mat img1 = imread(Fname, 0);
				if (img1.empty())
				{
				printLOG("Can't read %s\n", Fname);
				continue;
				}
				detector.detect(img1, keys);
				extractor.compute(img1, keys, desc);

				for (int kk = 0; kk < npts; kk++)
				{
				fKpts[4 * kk] = keys[kk].pt.x - 0.5;
				fKpts[4 * kk + 1] = keys[kk].pt.y - 0.5;
				fKpts[4 * kk + 2] = keys[kk].size / 2;
				fKpts[4 * kk + 3] = keys[kk].angle;

				double norm = 0.0;
				for (int ll = 0; ll < descriptorSize; ll++)
				norm += pow(desc.at<float>(kk, ll), 2);
				for (int ll = 0; ll < descriptorSize; ll++)
				Desc[ll + kk * 128] = (unsigned char)(int)(floor)(255 * desc.at<float>(kk, ll) / norm);
				}

				sprintf(Fname, "%s/Corpus/%.4d.sift", Path, frameID);
				writeVisualSFMSiftGPU(Fname, fKpts, Desc, npts);*/
			}

			//Getting color info
			Vrgb.clear();
			if (jpgmode == 1)
				sprintf(Fname, "%s/Corpus/%.4d.jpg", Path, frameID);
			else
				sprintf(Fname, "%s/Corpus/%.4d.png", Path, frameID);
			if (IsFileExist(Fname) == 0)
			{
				printLOG("Cannot find %s\n", Fname);
				continue;
			}
			cvImg = imread(Fname, IMREAD_COLOR);
			for (int kk = 0; kk < npts; kk++)
			{
				int x = (int)fKpts[4 * kk], y = (int)fKpts[4 * kk + 1];
				int id = x + y * cvImg.cols;
				Point3i rgb;
				rgb.z = cvImg.data[3 * id + 0];//b
				rgb.y = cvImg.data[3 * id + 1];//g
				rgb.x = cvImg.data[3 * id + 2];//r
				Vrgb.push_back(rgb);
			}

			sprintf(Fname, "%s/Corpus/%.4d.rgb", Path, frameID); WriteRGBBinarySIFT(Fname, Vrgb);
			printLOG("Frame %d : %d points ... Wrote to files. Take %.2fs\n", frameID, npts, omp_get_wtime() - start);
		}
		printLOG("Total time: %.2fs\n", omp_get_wtime() - start);

		delete[]fKpts, delete[]Desc;
	}
	else
	{
		for (int ii = 0; ii < nviews.size(); ii++)
		{
			int viewID = nviews[ii];
			for (int frameID = startF; frameID <= stopF; frameID += increF)
			{
				keys.clear(), descriptors.clear();
				double start = omp_get_wtime();

				if (frameID < 0)
					continue;
				sprintf(Fname, "%s/%d/%.4d.kpts", Path, viewID, frameID);
				if (IsFileExist(Fname) == 1)
				{
					printLOG("Skip %s\n", Fname);
					continue;
				}

				sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, frameID);
				if (IsFileExist(Fname) == 0)
				{
					jpgmode = 0, sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, frameID);
					if (IsFileExist(Fname) == 0)
					{
						printLOG("Cannot find %s\n", Fname);
						continue;
					}
				}
				if (HistogramEqual == 1)
				{
					cvImg = imread(Fname, 0);
					equalizeHist(cvImg, equalizedImg);

					sprintf(Fname, "%s/%d/H_%.4d.jpg", Path, viewID, frameID);
					imwrite(Fname, equalizedImg);
				}

				int npts = 0;
				if (ExtractionMethod == 1)
				{
					if (VLCOVDET(Fname, CovF, npts, ROOTL1) == 1)
						return;

					for (int kk = 0; kk < npts; kk++)
					{
						double maxis1 = pow(CovF.Kpts[6 * kk + 2], 2) + pow(CovF.Kpts[6 * kk + 3], 2);
						double maxis2 = pow(CovF.Kpts[6 * kk + 4], 2) + pow(CovF.Kpts[6 * kk + 5], 2);

						keys.push_back(KeyPoint(CovF.Kpts[6 * kk], CovF.Kpts[6 * kk + 1], sqrt(max(maxis1, maxis2))));
						for (int ll = 0; ll < descriptorSize; ll++)
							descriptors.push_back(CovF.Desc[kk * 128 + ll]);
					}
				}
				else if (ExtractionMethod == 2)
				{
					if (VLSIFT(Fname, SF, npts, ROOTL1) == 1)
						return;

					KeyPoint keyi;
					for (int kk = 0; kk < npts; kk++)
					{
						keyi.pt = Point2f(SF.Kpts[4 * kk], SF.Kpts[4 * kk + 1]);
						keyi.size = SF.Kpts[4 * kk + 2], keyi.angle = SF.Kpts[4 * kk + 3];
						keys.push_back(keyi);

						for (int ll = 0; ll < descriptorSize; ll++)
							descriptors.push_back(SF.Desc[kk * 128 + ll]);
					}
				}
				else //OPENCV
				{
					printLOG("OPENCV Sift is not supported\n");
					exit(0);
				}


				/*//Getting color info
				Vrgb.clear();
				if (jpgmode == 1)
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, frameID);
				else
				sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, frameID);
				if (IsFileExist(Fname) == 0)
				{
				printLOG("Cannot find %s\n", Fname);
				continue;
				}
				cvImg = imread(Fname, IMREAD_COLOR);
				for (int kk = 0; kk < npts; kk++)
				{
				int x = (int)keys[kk].pt.x, y = (int)keys[kk].pt.y;
				int id = x + y*cvImg.cols;
				Point3i rgb;
				rgb.z = cvImg.data[3 * id + 0];//b
				rgb.y = cvImg.data[3 * id + 1];//g
				rgb.x = cvImg.data[3 * id + 2];//r
				Vrgb.push_back(rgb);
				}
				sprintf(Fname, "%s/%d/%.4d.rgb", Path, viewID, frameID); WriteRGBBinarySIFT(Fname, Vrgb);*/

				sprintf(Fname, "%s/%d/%.4d.sift", Path, viewID, frameID); writeVisualSFMSiftGPU(Fname, keys, SF.Desc);
				printLOG("View (%d, %d): %d points ... Wrote to files. Take %.2fs\n", viewID, frameID, npts, omp_get_wtime() - start);
			}
		}
	}
	printLOG("Total time: %.2fs\n", omp_get_wtime() - start);

	return;
}
void ExtractSiftGPU(char *Path, int camID, int frameID, Mat &Img, vector<Point2f> &Feat, SiftGPU* sift, bool ROOTL1)
{
	char Fname[512];

	Feat.clear();
	if (sift != 0)
	{
		sift->RunSIFT(Img.cols, Img.rows, Img.data, GL_LUMINANCE, GL_UNSIGNED_BYTE);
		int numKeys = min(sift->GetFeatureNum(), 50000);

		vector<SiftGPU::SiftKeypoint> keys; keys.resize(numKeys);
		vector<float > descriptors;  descriptors.resize(128 * numKeys);
		vector<uchar > descriptorsU;  descriptorsU.resize(128 * numKeys);

		sift->GetFeatureVector(&keys[0], &descriptors[0]);

		int dummy = numKeys - 1;
		//reverse the scale ordering for visualSfM
		float t;
		SiftKeypoint tempkey;
		for (int ii = 0; ii < numKeys / 2; ii++)
		{
			tempkey.x = keys[ii].x, tempkey.y = keys[ii].y, tempkey.s = keys[ii].s, tempkey.o = keys[ii].o;
			keys[ii].x = keys[dummy - ii].x, keys[ii].y = keys[dummy - ii].y, keys[ii].s = keys[dummy - ii].s, keys[ii].o = keys[dummy - ii].o;
			keys[dummy - ii].x = tempkey.x, keys[dummy - ii].y = tempkey.y, keys[dummy - ii].s = tempkey.s, keys[dummy - ii].o = tempkey.o;

			for (int jj = 0; jj < 128; jj++)
			{
				t = descriptors[ii * 128 + jj];
				descriptors[ii * 128 + jj] = descriptors[(dummy - ii) * 128 + jj] * 512;
				descriptors[(dummy - ii) * 128 + jj] = t * 512; //visualsfm requires it to be normalzie to 512
			}
		}

		if (ROOTL1)
			RootL1DescNorm(&descriptors[0], &descriptorsU[0], numKeys, 128);
		else
			RootL2DescNorm(&descriptors[0], &descriptorsU[0], numKeys, 128);

		//loading mask
		sprintf(Fname, "%s/MP/%d/%d.txt", Path, camID, frameID);
		if (IsFileExist(Fname) == 1)
		{
			Mat mask = Mat::zeros(Img.rows, Img.cols, CV_8U);

			const int nJoints = 18;
			float u, v, s, minU, maxU, minV, maxV;
			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
			{
				minU = (float)9e9, maxU = 0.f, minV = (float)9e9, maxV = 0.f;
				if (s > 0.1)
					minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
				for (int j = 1; j < nJoints; j++)
				{
					fscanf(fp, "%f %f %f ", &u, &v, &s);
					if (s > 0.1)
						minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
				}
				minU = max(minU - mask.cols / 50, 0.f), maxU = min(maxU + mask.cols / 50, 1.f*mask.cols - 1);
				minV = max(minV - mask.rows / 50, 0.f), maxV = min(maxV + mask.rows / 50, 1.f*mask.rows - 1);
				for (int i = minU; i < maxU; i++)
					for (int j = minV; j < maxV; j++)
						mask.data[i + j * mask.cols] = 255;
			}
			fclose(fp);

			int keyCount = 0;
			for (int ii = 0; ii < numKeys; ii++)
			{
				int x = keys[ii].x, y = keys[ii].y;
				if (mask.data[x + y * mask.cols] == (uchar)255)
					continue;

				keys[keyCount].x = keys[ii].x, keys[keyCount].y = keys[ii].y, keys[keyCount].s = keys[ii].s, keys[keyCount].o = keys[ii].o;
				for (int jj = 0; jj < 128; jj++)
					descriptorsU[keyCount * 128 + jj] = descriptorsU[ii * 128 + jj];

				keyCount++;
			}

			if (keyCount < numKeys)
			{
				printLOG("Clean %d/%d points for %s\n", numKeys - keyCount, numKeys, Fname);
				keys.resize(keyCount); numKeys = keyCount;
			}
		}

		sprintf(Fname, "%s/%d/%.4d.sift", Path, camID, frameID);
		writeVisualSFMSiftGPU(Fname, keys, &descriptorsU[0]);

		for (int ii = 0; ii < numKeys; ii++)
			Feat.push_back(Point2f(keys[ii].x - 0.5, keys[ii].y - 0.5)); //convert to keys from gpu coordinate to cpu

		return;
	}
	else
		ExtractSiftCPU(Path, camID, frameID, Img, Feat);

	return;
}
void ExtractSiftCPU(char *Path, int camID, int frameID, Mat &Img, vector<Point2f> &Feat, bool ROOTL1)
{
	int width = Img.cols, height = Img.rows;
	int descriptorSize = SIFTBINS;
	vector<float>keys; keys.reserve(MaxNFeatures);
	vector<unsigned char> descriptors; descriptors.reserve(MaxNFeatures*descriptorSize);

	SiftFeature SF; int npts;
	VLSIFT(Img, SF, npts);

	KeyPoint kpt;
	for (int kk = 0; kk < npts; kk++)
	{
		keys.push_back(SF.Kpts[4 * kk]);
		keys.push_back(SF.Kpts[4 * kk + 1]);
		keys.push_back(SF.Kpts[4 * kk + 2]);
		keys.push_back(SF.Kpts[4 * kk + 3]);

		for (int ll = 0; ll < descriptorSize; ll++)
			descriptors.push_back(SF.Desc[kk*descriptorSize + ll]);
	}

	//loading mask
	char Fname[512];
	sprintf(Fname, "%s/MP/%d/%d.txt", Path, camID, frameID);
	if (IsFileExist(Fname) == 1)
	{
		Mat mask = Mat::zeros(Img.rows, Img.cols, CV_8U);

		const int nJoints = 18;
		float u, v, s, minU, maxU, minV, maxV;
		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
		{
			minU = (float)9e9, maxU = 0.f, minV = (float)9e9, maxV = 0.f;
			if (s > 0.1)
				minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
			for (int j = 1; j < nJoints; j++)
			{
				fscanf(fp, "%f %f %f ", &u, &v, &s);
				if (s > 0.1)
					minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
			}
			minU = max(minU - mask.cols / 50, 0.f), maxU = min(maxU + mask.cols / 50, 1.f*mask.cols - 1);
			minV = max(minV - mask.rows / 50, 0.f), maxV = min(maxV + mask.rows / 50, 1.f*mask.rows - 1);
			for (int i = minU; i < maxU; i++)
				for (int j = minV; j < maxV; j++)
					mask.data[i + j * mask.cols] = 255;
		}
		fclose(fp);

		int keyCount = 0;
		for (int ii = 0; ii < npts; ii++)
		{
			int x = keys[4 * ii], y = keys[4 * ii + 1];
			if (mask.data[x + y * mask.cols] == (uchar)255)
				continue;
			keys[4 * keyCount] = keys[4 * ii], keys[4 * keyCount + 1] = keys[4 * ii + 1], keys[4 * keyCount + 2] = keys[4 * ii + 2], keys[4 * keyCount + 3] = keys[4 * ii + 3];
			for (int jj = 0; jj < 128; jj++)
				descriptors[keyCount * 128 + jj] = descriptors[ii * 128 + jj];
			keyCount++;
		}
		if (keyCount < npts)
			printLOG("Clean %d/%d points for %s\n", npts - keyCount, npts, Fname);
		npts = keyCount;
	}

	int *Id = new int[npts];
	float *S = new float[npts];
	for (int ii = 0; ii < npts; ii++)
	{
		Id[ii] = ii;
		S[ii] = -keys[4 * ii + 2];
	}
	Quick_Sort_Float(S, Id, 0, npts - 1);

	sprintf(Fname, "%s/%d/%.4d.sift", Path, camID, frameID);
	writeVisualSFMSiftGPU(Fname, &keys[0], &descriptors[0], Id, npts);

	for (int ii = 0; ii < npts; ii++)
	{
		int j = Id[ii];
		Feat.push_back(Point2f(keys[4 * j], keys[4 * j + 1]));
	}

	delete[]Id, delete[]S;

	return;
}
void ExtractSiftGPU(char *Path, int camID, int frameID, Mat &Img, vector<Point2f> &Feat, vector<float> &scale, SiftGPU* sift, bool ROOTL1)
{
	char Fname[512];

	Feat.clear();
	sift->RunSIFT(Img.cols, Img.rows, Img.data, GL_LUMINANCE, GL_UNSIGNED_BYTE);
	int numKeys = min(sift->GetFeatureNum(), 50000);

	vector<SiftGPU::SiftKeypoint> keys; keys.resize(numKeys);
	vector<float > descriptors;  descriptors.resize(128 * numKeys);
	vector<uchar > descriptorsU;  descriptorsU.resize(128 * numKeys);

	sift->GetFeatureVector(&keys[0], &descriptors[0]);

	int dummy = numKeys - 1;
	//reverse the scale ordering for visualSfM
	float t;
	SiftKeypoint tempkey;
	for (int ii = 0; ii < numKeys / 2; ii++)
	{
		tempkey.x = keys[ii].x, tempkey.y = keys[ii].y, tempkey.s = keys[ii].s, tempkey.o = keys[ii].o;
		keys[ii].x = keys[dummy - ii].x, keys[ii].y = keys[dummy - ii].y, keys[ii].s = keys[dummy - ii].s, keys[ii].o = keys[dummy - ii].o;
		keys[dummy - ii].x = tempkey.x, keys[dummy - ii].y = tempkey.y, keys[dummy - ii].s = tempkey.s, keys[dummy - ii].o = tempkey.o;

		for (int jj = 0; jj < 128; jj++)
		{
			t = descriptors[ii * 128 + jj];
			descriptors[ii * 128 + jj] = descriptors[(dummy - ii) * 128 + jj] * 512;
			descriptors[(dummy - ii) * 128 + jj] = t * 512; //visualsfm requires it to be normalzie to 512
		}
	}

	if (ROOTL1)
		RootL1DescNorm(&descriptors[0], &descriptorsU[0], numKeys, 128);
	else
		RootL2DescNorm(&descriptors[0], &descriptorsU[0], numKeys, 128);

	//loading mask
	sprintf(Fname, "%s/MP/%d/%d.txt", Path, camID, frameID);
	if (IsFileExist(Fname) == 1)
	{
		Mat mask = Mat::zeros(Img.rows, Img.cols, CV_8U);

		const int nJoints = 18;
		float u, v, s, minU, maxU, minV, maxV;
		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
		{
			minU = (float)9e9, maxU = 0.f, minV = (float)9e9, maxV = 0.f;
			if (s > 0.1)
				minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
			for (int j = 1; j < nJoints; j++)
			{
				fscanf(fp, "%f %f %f ", &u, &v, &s);
				if (s > 0.1)
					minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
			}
			minU = max(minU - mask.cols / 50, 0.f), maxU = min(maxU + mask.cols / 50, 1.f*mask.cols - 1);
			minV = max(minV - mask.rows / 50, 0.f), maxV = min(maxV + mask.rows / 50, 1.f*mask.rows - 1);
			for (int i = minU; i < maxU; i++)
				for (int j = minV; j < maxV; j++)
					mask.data[i + j * mask.cols] = 255;
		}
		fclose(fp);

		int keyCount = 0;
		for (int ii = 0; ii < numKeys; ii++)
		{
			int x = keys[ii].x, y = keys[ii].y;
			if (mask.data[x + y * mask.cols] == (uchar)255)
				continue;

			keys[keyCount].x = keys[ii].x, keys[keyCount].y = keys[ii].y, keys[keyCount].s = keys[ii].s, keys[keyCount].o = keys[ii].o;
			for (int jj = 0; jj < 128; jj++)
				descriptorsU[keyCount * 128 + jj] = descriptorsU[ii * 128 + jj];

			keyCount++;
		}

		if (keyCount < numKeys)
		{
			printLOG("Clean %d/%d points for %s\n", numKeys - keyCount, numKeys, Fname);
			keys.resize(keyCount); numKeys = keyCount;
		}
	}

	sprintf(Fname, "%s/%d/%.4d.sift", Path, camID, frameID);
	writeVisualSFMSiftGPU(Fname, keys, &descriptorsU[0]);

	Feat.clear(), scale.clear();
	for (int ii = 0; ii < numKeys; ii++)
		Feat.push_back(Point2f(keys[ii].x - 0.5, keys[ii].y - 0.5)), scale.push_back(keys[ii].s);//convert to keys from gpu coordinate to cpu

	return;
}
void ExtractSiftCPU(char *Path, int camID, int frameID, Mat &Img, vector<Point2f> &Feat, vector<float> &scale, bool ROOTL1)
{
	int width = Img.cols, height = Img.rows;
	int descriptorSize = SIFTBINS;
	vector<float>keys; keys.reserve(MaxNFeatures);
	vector<unsigned char> descriptors; descriptors.reserve(MaxNFeatures*descriptorSize);

	SiftFeature SF; int npts;
	VLSIFT(Img, SF, npts);

	KeyPoint kpt;
	for (int kk = 0; kk < npts; kk++)
	{
		keys.push_back(SF.Kpts[4 * kk]);
		keys.push_back(SF.Kpts[4 * kk + 1]);
		keys.push_back(SF.Kpts[4 * kk + 2]);
		keys.push_back(SF.Kpts[4 * kk + 3]);

		for (int ll = 0; ll < descriptorSize; ll++)
			descriptors.push_back(SF.Desc[kk*descriptorSize + ll]);
	}

	//loading mask
	char Fname[512];
	sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, camID, frameID);
	if (IsFileExist(Fname) == 1)
	{
		Mat mask = Mat::zeros(Img.rows, Img.cols, CV_8U);

		const int nJoints = 18;
		float u, v, s, minU, maxU, minV, maxV;
		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
		{
			minU = (float)9e9, maxU = 0.f, minV = (float)9e9, maxV = 0.f;
			if (s > 0.1)
				minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
			for (int j = 1; j < nJoints; j++)
			{
				fscanf(fp, "%f %f %f ", &u, &v, &s);
				if (s > 0.1)
					minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
			}
			minU = max(minU - mask.cols / 50, 0.f), maxU = min(maxU + mask.cols / 50, 1.f*mask.cols - 1);
			minV = max(minV - mask.rows / 50, 0.f), maxV = min(maxV + mask.rows / 50, 1.f*mask.rows - 1);

			for (int i = minU; i < maxU; i++)
				for (int j = minV; j < maxV; j++)
					mask.data[i + j * mask.cols] = 255;
		}
		fclose(fp);

		int keyCount = 0;
		for (int ii = 0; ii < npts; ii++)
		{
			int x = keys[4 * ii], y = keys[4 * ii + 1];
			if (mask.data[x + y * mask.cols] == (uchar)255)
				continue;
			keys[4 * keyCount] = keys[4 * ii], keys[4 * keyCount + 1] = keys[4 * ii + 1], keys[4 * keyCount + 2] = keys[4 * ii + 2], keys[4 * keyCount + 3] = keys[4 * ii + 3];
			for (int jj = 0; jj < 128; jj++)
				descriptors[keyCount * 128 + jj] = descriptors[ii * 128 + jj];
			keyCount++;
		}
		if (keyCount < npts)
			printLOG("Clean %d/%d points for %s\n", npts - keyCount, npts, Fname);
		npts = keyCount;
	}

	int *Id = new int[npts];
	float *S = new float[npts];
	for (int ii = 0; ii < npts; ii++)
	{
		Id[ii] = ii;
		S[ii] = -keys[4 * ii + 2];
	}
	Quick_Sort_Float(S, Id, 0, npts - 1);

	sprintf(Fname, "%s/%d/%.4d.sift", Path, camID, frameID);
	writeVisualSFMSiftGPU(Fname, &keys[0], &descriptors[0], Id, npts);

	for (int ii = 0; ii < npts; ii++)
	{
		int j = Id[ii];
		Feat.push_back(Point2f(keys[4 * j], keys[4 * j + 1])), scale.push_back(keys[4 * j + 2]);
	}

	delete[]Id, delete[]S;

	return;
}
void ExtractSiftGPU_Video(char *Path, vector<int> &nviews, int startF, int stopF, int increF, bool ROOTL1)
{
	// Allocation size to the largest width and largest height 1920x1080
	// Maximum working dimension. All the SIFT octaves that needs a larger texture size will be skipped. maxd = 2560 <-> 768MB of graphic memory.
	char * argv[] = { "-fo", "-1", "-v", "0", "-tc", "7680", "-p", "1920x1080", "-maxd", "4096", "-cuda" };
	char * argv2[] = { "-fo", "-1", "-v", "0", "-tc", "7680", "-nomc", "-p", "1920x1080", "-maxd", "4096", "-mo", "1", "-da" }; //one orienation and smaller expected # feats
																																//-fo -1    staring from -1 octave
																																//-v 1      only print out # feature and overall time
																																//-loweo    add a (.5, .5) offset
																																//-tc <num> set a soft limit to number of detected features
																																//-m,       up to 2 orientations for each feature (change to single orientation by using -m 1)
																																//-s        enable subpixel subscale (disable by using -s 0)
																																//"-cuda", "[device_id]"  : cuda implementation (fastest for smaller images). CUDA-implementation allows you to create multiple instances for multiple threads. Checkout src\TestWin\MultiThreadSIFT
																																// "-Display", "display_name" (for OPENGL) to select monitor/GPU (XLIB/GLUT) on windows the display name would be something like \\.\DISPLAY4
																																//Only the following parameters can be changed after initialization (by calling ParseParam):-dw, -ofix, -ofix-not, -fo, -unn, -maxd, -b
																																//to change other parameters at runtime, you need to first unload the dynamically loaded libaray reload the libarary, then create a new siftgpu instance

#ifdef USESIFTGPU
																																//Init SiftGPU: START
#ifdef _WINDOWS
#ifdef _DEBUG
	HMODULE  hsiftgpu = LoadLibrary("siftgpu_d.dll");
#else
	HMODULE  hsiftgpu = LoadLibrary("siftgpu.dll");
#endif
#else
	void * hsiftgpu = dlopen("libsiftgpu.so", RTLD_LAZY);
#endif

	if (hsiftgpu == NULL)
		return;

	SiftGPU* (*pCreateNewSiftGPU)(int) = NULL;
	pCreateNewSiftGPU = (SiftGPU* (*) (int)) GET_MYPROC(hsiftgpu, "CreateNewSiftGPU");
	SiftGPU* sift = pCreateNewSiftGPU(1);

#ifdef _WINDOWS
	int argc = sizeof(argv2) / sizeof(char*);
	sift->ParseParam(argc, argv2);
#else
	int argc = sizeof(argv) / sizeof(char*);
	sift->ParseParam(argc, argv);
#endif
	if (sift->CreateContextGL() != SiftGPU::SIFTGPU_FULL_SUPPORTED)
		return;
	//Init SiftGPU: END

	//SIFT DECTION: START
	int numKeys, descriptorSize = SIFTBINS;
	vector<float > descriptors; descriptors.reserve(MaxNFeatures * descriptorSize);
	vector<SiftGPU::SiftKeypoint> keys; keys.reserve(MaxNFeatures);
	vector<Point3i> Vrgb; Vrgb.reserve(MaxNFeatures);

	Mat cvImg, cvGray;
	char Fname[512];
	double start = omp_get_wtime();
	SiftKeypoint tempkey;
	float tempdesc[128];
	int jpgmode = 0;
	float *fKpts = new float[50000 * 4];
	unsigned char *Desc = new unsigned char[50000 * 128];

	vector<bool> validID;
	for (int ii = 0; ii < nviews.size(); ii++)
	{
		int viewID = nviews[ii];

		sprintf(Fname, "%s/%d/x.mp4", Path, viewID);
		cv::VideoCapture cap = VideoCapture(Fname);
		if (!cap.isOpened())
		{
			sprintf(Fname, "%s/%d/x.mov", Path, viewID);
			cap.open(Fname);
			if (!cap.isOpened())
			{
				printLOG("Cannot load %s\n", Fname);
				continue;
			}
		}
		int rotateImage = 0;
		sprintf(Fname, "%s/RotationInfo.txt", Path); FILE *fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int cid, code;
			while (fscanf(fp, "%d %d", &cid, &code) != EOF)
			{
				if (cid == viewID)
				{
					rotateImage = code;
					break;
				}
			}
			fclose(fp);
		}
		printLOG("Working on %d\n", viewID);

		int frameID = 0;
		while (true)
		{
			cap >> cvImg;
			if (cvImg.empty())
				break;
			if (frameID < startF || (frameID - startF) % increF != 0)
			{
				frameID++;
				continue;
			}
			if (frameID > stopF)
				break;

			if (rotateImage == 1) //flip updown
			{
				int width = cvImg.cols, height = cvImg.rows, nchannels = 3;
				for (int kk = 0; kk < nchannels; kk++)
				{
					for (int jj = 0; jj < height / 2; jj++)
						for (int ii = 0; ii < width; ii++)
						{
							char buf = cvImg.data[nchannels*ii + jj * nchannels*width + kk];
							cvImg.data[nchannels*ii + jj * nchannels*width + kk] = cvImg.data[nchannels*(width - 1 - ii) + (height - 1 - jj)*nchannels*width + kk];
							cvImg.data[nchannels*(width - 1 - ii) + (height - 1 - jj)*nchannels*width + kk] = buf;
						}
				}
			}
			keys.clear(), descriptors.clear();
			cvtColor(cvImg, cvGray, CV_BGR2GRAY);

			double startT = omp_get_wtime();
			if (sift->RunSIFT(cvGray.cols, cvGray.rows, cvGray.data, GL_LUMINANCE, GL_UNSIGNED_BYTE))  //You can have at most one OpenGL-based SiftGPU (per process)--> no omp can be used
			{
				numKeys = sift->GetFeatureNum();
				keys.resize(numKeys);    descriptors.resize(descriptorSize * numKeys);
				sift->GetFeatureVector(&keys[0], &descriptors[0]);

				validID.clear();
				sprintf(Fname, "%s/MP/%d/%d.txt", Path, viewID, frameID); FILE *fp = fopen(Fname, "r");
				if (fp != NULL)
				{
					//creating rect block mask
					const int nJoints = 18;
					float u, v, s, minU, maxU, minV, maxV;
					Mat mask = Mat::zeros(cvImg.rows, cvImg.cols, CV_8U);

					while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					{
						minU = (float)9e9, maxU = 0.f, minV = (float)9e9, maxV = 0.f;
						if (s > 0.1)
							minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
						for (int j = 1; j < nJoints; j++)
						{
							fscanf(fp, "%f %f %f ", &u, &v, &s);
							if (s > 0.1)
								minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
						}
						minU = max(minU - mask.cols / 50, 0.f), maxU = min(maxU + mask.cols / 50, 1.f*mask.cols - 1);
						minV = max(minV - mask.rows / 50, 0.f), maxV = min(maxV + mask.rows / 50, 1.f*mask.rows - 1);
						for (int i = minU; i < maxU; i++)
							for (int j = minV; j < maxV; j++)
								mask.data[i + j * mask.cols] = 255;
					}
					fclose(fp);

					for (int j = 0; j < numKeys; ++j)
					{
						int x = keys[j].x, y = keys[j].y;
						if ((int)mask.data[x + y * mask.cols] != 255)
							validID.push_back(1);
						else
							validID.push_back(0);
					}
				}
				else
					for (int i = 0; i < numKeys; i++)
						validID.push_back(1);

				//for visualsfm
				int keyCount = 0;
				for (int ii = 0; ii < numKeys; ii++)
				{
					fKpts[4 * keyCount] = keys[ii].x, fKpts[4 * keyCount + 1] = keys[ii].y, fKpts[4 * keyCount + 2] = keys[ii].s, fKpts[4 * keyCount + 3] = keys[ii].o;
					for (int jj = 0; jj < 128; jj++)
						Desc[keyCount * 128 + jj] = (unsigned char)(int)(floor)(descriptors[ii * 128 + jj] * 512);//since the org desc is normed to 1
					if (validID[ii] == 1)
						keyCount++;
				}

				sprintf(Fname, "%s/%d/%.4d.sift", Path, viewID, frameID);
				writeVisualSFMSiftGPU(Fname, fKpts, Desc, numKeys);

				printLOG("View (%d, %d): %d points ... Wrote to files. Take %.2fs\n", viewID, frameID, numKeys, omp_get_wtime() - startT);
			}
		}
#ifdef EC2
		sprintf(Fname, "%s/SIFTExtraction_%d_%d_%.4d.txt", Path, viewID, startF, stopF); fp = fopen(Fname, "w"); fclose(fp);
#endif
	}

	printLOG("Total time: %.2fs\n", omp_get_wtime() - start);
#else
	printLOG("SiftGPU is not supported\n");
#endif
	return;
}

int GeneratePointsCorrespondenceMatrix_SiftGPU(char *Path, int nviews, int timeID, int HistogramEqual, float nndrRatio, int *frameTimeStamp, bool ROOTL1, bool visualizeSift)
{
#ifdef USESIFTGPU
	// Allocation size to the largest width and largest height 1920x1080
	// Maximum working dimension. All the SIFT octaves that needs a larger texture size will be skipped. maxd = 2560 <-> 768MB of graphic memory.
	char * argv[] = { "-fo", "-1", "-v", "0", "-tc", "7680", "-p", "1920x1080", "-maxd", "4096", "-da" };
	//-fo -1    staring from -1 octave
	//-v 1      only print out # feature and overall time
	//-loweo    add a (.5, .5) offset
	//-tc <num> set a soft limit to number of detected features
	//-m,       up to 2 orientations for each feature (change to single orientation by using -m 1)
	//-s        enable subpixel subscale (disable by using -s 0)
	//"-cuda", "[device_id]"  : cuda implementation (fastest for smaller images). CUDA-implementation allows you to create multiple instances for multiple threads. Checkout src\TestWin\MultiThreadSIFT
	// "-Display", "display_name" (for OPENGL) to select monitor/GPU (XLIB/GLUT) on windows the display name would be something like \\.\DISPLAY4
	//Only the following parameters can be changed after initialization (by calling ParseParam):-dw, -ofix, -ofix-not, -fo, -unn, -maxd, -b
	//to change other parameters at runtime, you need to first unload the dynamically loaded libaray reload the libarary, then create a new siftgpu instance

	//Init SiftGPU: START
#ifdef _WINDOWS
#ifdef _DEBUG
	HMODULE  hsiftgpu = LoadLibrary("siftgpu_d.dll");
#else
	HMODULE  hsiftgpu = LoadLibrary("siftgpu.dll");
#endif
#else
	void * hsiftgpu = dlopen("libsiftgpu.so", RTLD_LAZY);
#endif

	if (hsiftgpu == NULL)
		return 0;

	SiftGPU* (*pCreateNewSiftGPU)(int) = NULL;
	SiftMatchGPU* (*pCreateNewSiftMatchGPU)(int) = NULL;
	pCreateNewSiftGPU = (SiftGPU* (*) (int)) GET_MYPROC(hsiftgpu, "CreateNewSiftGPU");
	pCreateNewSiftMatchGPU = (SiftMatchGPU* (*)(int)) GET_MYPROC(hsiftgpu, "CreateNewSiftMatchGPU");
	SiftGPU* sift = pCreateNewSiftGPU(1);

	int argc = sizeof(argv) / sizeof(char*);
	sift->ParseParam(argc, argv);
	if (sift->CreateContextGL() != SiftGPU::SIFTGPU_FULL_SUPPORTED)
		return 0;
	//Init SiftGPU: END

	//SIFT DECTION: START
	int numKeys, descriptorSize = SIFTBINS;
	vector<float > descriptors; descriptors.reserve(MaxNFeatures * descriptorSize);
	vector<uchar > descriptorsU; descriptorsU.reserve(MaxNFeatures * descriptorSize);
	vector<SiftGPU::SiftKeypoint> keys; keys.reserve(MaxNFeatures);

	vector<int>cumulativePts;
	vector<int>PtsPerView;

	int totalPts = 0;
	char Fname[512];
	Mat cvImg, cvGray, equalizedImg;
	vector<Point3i> Vrgb; Vrgb.reserve(30000);
	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));
	if (frameTimeStamp == NULL)
	{
		frameTimeStamp = new int[nviews];
		for (int ii = 0; ii < nviews; ii++)
			frameTimeStamp[ii] = 0;
	}

	int jpegmode = 1;
	float *fKpts = new float[50000 * 4];
	unsigned char *Desc = new unsigned char[50000 * 128];

	double start;
	vector<int> validID;
	for (int ii = 0; ii < nviews; ii++)
	{
		sprintf(Fname, "%s/%d", Path, ii), makeDir(Fname);
		keys.clear(), descriptors.clear();
		start = omp_get_wtime();

		//Try to read all sift points if available
		if (timeID < 0)
			sprintf(Fname, "%s/%.4d.sift", Path, ii);
		else
		{
			if (timeID - frameTimeStamp[ii] < 0)
			{
				numKeys = 0;
				cumulativePts.push_back(totalPts);
				totalPts += numKeys;
				PtsPerView.push_back(numKeys);
				continue;
			}
			sprintf(Fname, "%s/%d/%.4d.sift", Path, ii, timeID - frameTimeStamp[ii]);
		}

		ifstream fin;
		fin.open(Fname, ios::binary);
		if (fin.is_open())
		{
			int npts;
			fin.read(reinterpret_cast<char *>(&npts), sizeof(int));//SIFT
			fin.read(reinterpret_cast<char *>(&npts), sizeof(int));///V4.0
			fin.read(reinterpret_cast<char *>(&npts), sizeof(int));//npts
			fin.close();

			printLOG("Loaded %s with %d SIFTs\n", Fname, npts);
			cumulativePts.push_back(totalPts);
			totalPts += npts;
			PtsPerView.push_back(npts);
			continue; //Sift availble, move one
		}

		if (timeID < 0)
			sprintf(Fname, "%s/%.4d.jpg", Path, ii);
		else
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, ii, timeID - frameTimeStamp[ii]);

		//Check if image is available
		if (IsFileExist(Fname) == 0)
		{
			if (timeID < 0)
				sprintf(Fname, "%s/%.4d.png", Path, ii);
			else
				sprintf(Fname, "%s/%d/%.4d.png", Path, ii, timeID - frameTimeStamp[ii]);
			if (IsFileExist(Fname) == 0)
			{
				numKeys = 0;
				cumulativePts.push_back(totalPts);
				totalPts += numKeys;
				PtsPerView.push_back(numKeys);
				continue;
			}
			else
				jpegmode = 0;
		}
		/*ifstream testFin(Fname);
		if (testFin.is_open())
		testFin.close();
		else
		{
		numKeys = 0;
		cumulativePts.push_back(totalPts);
		totalPts += numKeys;
		PtsPerView.push_back(numKeys);
		continue;
		}*/

		cvImg = imread(Fname, IMREAD_COLOR);
		if (cvImg.empty())
		{
			numKeys = 0;
			cumulativePts.push_back(totalPts);
			totalPts += numKeys;
			PtsPerView.push_back(numKeys);
			continue;
		}

		if (HistogramEqual == 1)
		{
			cvtColor(cvImg, cvGray, CV_BGR2GRAY);
			equalizeHist(cvGray, equalizedImg);
		}
		else
			cvtColor(cvImg, equalizedImg, CV_BGR2GRAY);

		//if (sift->RunSIFT(Fname)) //You can have at most one OpenGL-based SiftGPU (per process)--> no omp can be used
		if (sift->RunSIFT(equalizedImg.cols, equalizedImg.rows, equalizedImg.data, GL_LUMINANCE, GL_UNSIGNED_BYTE))
		{
			//sprintf(Fname, "%s/%.4d.sift", Path, ii);sift->SaveSIFT(Fname);
			numKeys = sift->GetFeatureNum();
			keys.resize(numKeys); descriptors.resize(descriptorSize * numKeys);
			sift->GetFeatureVector(&keys[0], &descriptors[0]);

			validID.clear();
			if (timeID >= 0)
			{
				sprintf(Fname, "%s/MP/%d/%d.txt", Path, ii, timeID - frameTimeStamp[ii]);
				if (IsFileExist(Fname) == 1)
				{
					FILE *fp = fopen(Fname, "r");
					const int nJoints = 18;
					float u, v, s, minU, maxU, minV, maxV;
					Mat mask = Mat::zeros(cvImg.rows, cvImg.cols, CV_8U);

					while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					{
						minU = (float)9e9, maxU = 0.f, minV = (float)9e9, maxV = 0.f;
						if (s > 0.1)
							minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
						for (int j = 1; j < nJoints; j++)
						{
							fscanf(fp, "%f %f %f ", &u, &v, &s);
							if (s > 0.1)
								minU = min(minU, u), maxU = max(maxU, u), minV = min(minV, v), maxV = max(maxV, v);
						}
						minU = max(minU - cvImg.cols / 50, 0.f), maxU = min(maxU + cvImg.cols / 50, 1.f*cvImg.cols - 1);
						minV = max(minV - cvImg.rows / 50, 0.f), maxV = min(maxV + cvImg.rows / 50, 1.f*cvImg.rows - 1);
						rectangle(cvImg, Point2i(minU, minV), Point2i(maxU, maxV), colors[0], 3, 8, 0);
						for (int i = minU; i < maxU; i++)
							for (int j = minV; j < maxV; j++)
								mask.data[i + j * mask.cols] = 255;
					}
					fclose(fp);

					for (int j = 0; j < numKeys; ++j)
					{
						int x = keys[j].x, y = keys[j].y;
						if ((int)mask.data[x + y * mask.cols] == 255) //take human only
							validID.push_back(1);
						else
							validID.push_back(0);
					}
				}
				else
					for (int i = 0; i < numKeys; i++)
						validID.push_back(1);
			}
			else
				for (int i = 0; i < numKeys; i++)
					validID.push_back(1);

			//for visualsfm
			int keyCount = 0;
			for (int i = 0; i < numKeys; i++)
			{
				fKpts[4 * keyCount] = keys[i].x, fKpts[4 * keyCount + 1] = keys[i].y, fKpts[4 * keyCount + 2] = keys[i].s, fKpts[4 * keyCount + 3] = keys[i].o;
				for (int jj = 0; jj < 128; jj++)
					Desc[keyCount * 128 + jj] = (unsigned char)(int)(floor)(descriptors[i * 128 + jj] * 512);//since the org desc is normed to 1
				if (validID[i] == 1)
					keyCount++;
			}
			numKeys = keyCount;

			/*//Getting color info
			Vrgb.clear();
			for (int kk = 0; kk < numKeys; kk++)
			{
			keys[kk].x -= 0.5, keys[kk].y -= 0.5;
			int x = (int)keys.at(kk).x, y = (int)keys.at(kk).y;
			int id = x + y*cvImg.cols;
			Point3i rgb;
			rgb.z = cvImg.data[3 * id + 0];//b
			rgb.y = cvImg.data[3 * id + 1];//g
			rgb.x = cvImg.data[3 * id + 2];//r
			Vrgb.push_back(rgb);
			}

			if (ROOTL1)
			RootL1DescNorm(&descriptors[0], &descriptorsU[0], numKeys, 128);
			else
			RootL2DescNorm(&descriptors[0], &descriptorsU[0], numKeys, 128);*/

			if (visualizeSift)
			{
				for (int i = 0; i < numKeys; i++)
					cv::circle(cvImg, Point2i(fKpts[4 * i], fKpts[4 * i + 1]), 1, colors[i % 9], 2);

				namedWindow("Sift", CV_WINDOW_NORMAL);
				cv::Point2i text_origin = { cvImg.rows / 20, cvImg.cols / 20 };
				sprintf(Fname, "%d", ii), putText(cvImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*cvImg.cols / 640, colors[0], 3);
				cv::imshow("Sift", cvImg);
				cv::waitKey(1);
			}

			if (timeID < 0)
			{
				sprintf(Fname, "%s%.4d.sift", Path, ii); writeVisualSFMSiftGPU(Fname, fKpts, Desc, numKeys);//writeVisualSFMSiftGPU(Fname, keys, &descriptorsU[0]);
																											//sprintf(Fname, "%s/%.4d.rgb", Path, ii); WriteRGBBinarySIFT(Fname, Vrgb);
			}
			else
			{
				sprintf(Fname, "%s/%d/%.4d.sift", Path, ii, timeID - frameTimeStamp[ii]); writeVisualSFMSiftGPU(Fname, fKpts, Desc, numKeys); //writeVisualSFMSiftGPU(Fname, keys, &descriptorsU[0]);
																																			  //sprintf(Fname, "%s/%d/%.4d.rgb", Path, ii, timeID - frameTimeStamp[ii]); WriteRGBBinarySIFT(Fname, Vrgb);
			}

			printLOG("View %d_%d: %d points ... Wrote to files. Take %.2fs\n", ii, timeID - frameTimeStamp[ii], numKeys, omp_get_wtime() - start);
			cumulativePts.push_back(totalPts);
			totalPts += numKeys;
			PtsPerView.push_back(numKeys);
		}
		else
		{
			printLOG("Cannot load %s\n", Fname);
			numKeys = 0;
			cumulativePts.push_back(totalPts);
			totalPts += numKeys;
			PtsPerView.push_back(numKeys);
		}
	}
	cumulativePts.push_back(totalPts);


	if (timeID < 0)
		sprintf(Fname, "%s/CumlativePoints.txt", Path);
	else
	{
		sprintf(Fname, "%s/Dynamic", Path), makeDir(Fname);
		sprintf(Fname, "%s/Dynamic/%.4d/CumlativePoints.txt", Path, timeID);
	}
	FILE* fp = fopen(Fname, "w+");
	for (int ii = 0; ii < cumulativePts.size(); ii++)
		fprintf(fp, "%d\n", cumulativePts[ii]);
	fclose(fp);
	//SIFT DECTION: ENDS

	///SIFT MATCHING: START
	int nthreads = omp_get_max_threads();
	omp_set_num_threads(nthreads);

	vector<KeyPoint> Keys1, Keys2;
	vector<Point2i> *RawPairWiseMatchID = new vector<Point2i>[nthreads];
	for (int ii = 0; ii < nthreads; ii++)
		RawPairWiseMatchID[ii].reserve(10000);
	vector<Point2i> *SRawPairWiseMatchID = new vector<Point2i>[nthreads];
	for (int ii = 0; ii < nthreads; ii++)
		SRawPairWiseMatchID[ii].reserve(10000);

	const int ninlierThesh = 15;
	int *SortingVec = new int[50000 * nthreads]; //should be more than enough
	int *tId = new int[50000 * nthreads];

	bool BinaryDesc = false, useBFMatcher = true; // SET TO TRUE TO USE BRUTE FORCE MATCHER
	const int knn = 2, ntrees = 4, maxLeafCheck = 128;

	if (timeID < 0)
		sprintf(Fname, "%s/Matches", Path), makeDir(Fname);
	else
	{
		sprintf(Fname, "%s/Dynamic", Path), makeDir(Fname);
		sprintf(Fname, "%s/Dynamic/%.4d/", Path, timeID), makeDir(Fname);
	}

	start = omp_get_wtime();
	printLOG("Running feature matching...\n");
	Mat descriptors1;
	for (int jj = 0; jj < nviews - 1; jj++)
	{
		if (timeID < 0)
			sprintf(Fname, "%s%.4d.sift", Path, jj);
		else
			sprintf(Fname, "%s/%d/%.4d.sift", Path, jj, timeID - frameTimeStamp[jj]);

		vector<SiftKeypoint> kpts1;
		Mat descriptors1;
		readVisualSFMSiftGPU(Fname, kpts1, descriptors1);
		if (descriptors1.rows == 0)
			continue;

#pragma omp parallel for schedule(dynamic,1)
		for (int ii = jj + 1; ii < nviews; ii++)
		{
			if (timeID < 0)
				sprintf(Fname, "%s/Dynamic/M_%.2d_%.2d.txt", Path, jj, ii);
			else
				sprintf(Fname, "%s/Dynamic/%.4d/M_%.2d_%.2d.txt", Path, timeID, jj, ii);
			if (IsFileExist(Fname) == 0)
			{
				char Fname[512];
				if (timeID < 0)
					sprintf(Fname, "%s%.4d.sift", Path, ii);
				else
					sprintf(Fname, "%s/%d/%.4d.sift", Path, ii, timeID - frameTimeStamp[ii]);

				vector<SiftKeypoint> kpts2;
				Mat descriptors2;
				readVisualSFMSiftGPU(Fname, kpts2, descriptors2);
				if (descriptors2.rows == 0)
					continue;

				double start = omp_get_wtime();
				int threadID = omp_get_thread_num();
				RawPairWiseMatchID[threadID].clear(), SRawPairWiseMatchID[threadID].clear();

				//Finding nearest neighbor
				Mat indices, dists;
				vector<vector<DMatch> > matches;
				if (BinaryDesc)
				{
					//printLOG("Binary descriptors detected...\n");// ORB, Brief, BRISK, FREAK
					if (useBFMatcher)
					{
						cv::BFMatcher matcher(cv::NORM_HAMMING); // use cv::NORM_HAMMING2 for ORB descriptor with WTA_K == 3 or 4 (see ORB constructor)
						matcher.knnMatch(descriptors2, descriptors1, matches, knn);
					}
					else
					{
						// Create Flann LSH index
						cv::flann::Index flannIndex(descriptors1, cv::flann::LshIndexParams(12, 20, 2), cvflann::FLANN_DIST_HAMMING);
						flannIndex.knnSearch(descriptors2, indices, dists, knn, cv::flann::SearchParams());
					}
				}
				else
				{
					if (useBFMatcher)
					{
						cv::BFMatcher matcher(cv::NORM_L2);
						matcher.knnMatch(descriptors2, descriptors1, matches, knn);
					}
					else
					{
						// Create Flann KDTree index
						cv::flann::Index flannIndex(descriptors1, cv::flann::KDTreeIndexParams(ntrees));//, cvflann::FLANN_DIST_EUCLIDEAN);
						flannIndex.knnSearch(descriptors2, indices, dists, knn, cv::flann::SearchParams(maxLeafCheck));
					}
				}

				// Find correspondences by NNDR (Nearest Neighbor Distance Ratio)
				int count = ii - jj - 1;
				for (int i = 0; i <= jj - 1; i++)
					count += nviews - i - 1;

				if (useBFMatcher)
				{
					for (unsigned int i = 0; i < matches.size(); ++i)
						if (matches[i].size() == 2 && matches[i][0].distance <= nndrRatio * matches[i][1].distance)
							RawPairWiseMatchID[threadID].push_back(Point2i(matches[i][0].trainIdx, i));
				}
				else
				{
					for (int i = 0; i < descriptors2.rows; ++i)
					{
						int ind1 = indices.at<int>(i, 0);
						if (indices.at<int>(i, 0) >= 0 && indices.at<int>(i, 1) >= 0 && dists.at<float>(i, 0) <= nndrRatio * dists.at<float>(i, 1))
							RawPairWiseMatchID[threadID].push_back(Point2i(ind1, i));
					}
				}

				//To remove the nonsense case of every point matchces to 1 point-->IT HAPPENED
				if (RawPairWiseMatchID[threadID].size() > 0)
				{
					SRawPairWiseMatchID[threadID].push_back(RawPairWiseMatchID[threadID][0]);
					for (int i = 1; i < min((int)RawPairWiseMatchID[threadID].size(), 50000); i++)
					{
						if (RawPairWiseMatchID[threadID][i].x != RawPairWiseMatchID[threadID][i - 1].x)
							SRawPairWiseMatchID[threadID].push_back(RawPairWiseMatchID[threadID][i]);
					}
				}

				if (SRawPairWiseMatchID[threadID].size() < ninlierThesh)
				{
#pragma omp critical
					printLOG("(%d, %d) to (%d, %d)...%d matches (<%d)... %.2fs\n", jj, timeID - frameTimeStamp[jj], ii, timeID - frameTimeStamp[ii], SRawPairWiseMatchID[threadID].size(), ninlierThesh, omp_get_wtime() - start);
					if (timeID < 0)
						sprintf(Fname, "%s/Dynamic/M_%.2d_%.2d.txt", Path, jj, ii);
					else
						sprintf(Fname, "%s/Dynamic/%.4d/M_%.2d_%.2d.txt", Path, timeID, jj, ii);
					FILE *fp = fopen(Fname, "w+");
					fprintf(fp, "%d\n", 0);
					fclose(fp);
					continue;
				}

				//Start sorting
				for (int i = 0; i < min((int)SRawPairWiseMatchID[threadID].size(), 50000); i++)
					SortingVec[i + 50000 * threadID] = SRawPairWiseMatchID[threadID][i].x, tId[i + 50000 * threadID] = i;
				Quick_Sort_Int(SortingVec + 50000 * threadID, tId + 50000 * threadID, 0, min((int)SRawPairWiseMatchID[threadID].size(), 50000) - 1);

				//Store sorted vector
				RawPairWiseMatchID[threadID].push_back(SRawPairWiseMatchID[threadID].at(tId[0 + 50000 * threadID]));
				for (int i = 1; i < min((int)SRawPairWiseMatchID[threadID].size(), 50000); i++)
					if (SortingVec[i + 50000 * threadID] != SortingVec[i - 1 + 50000 * threadID])
						RawPairWiseMatchID[threadID].push_back(SRawPairWiseMatchID[threadID].at(tId[i + 50000 * threadID]));

#pragma omp critical
				printLOG("(%d, %d) to (%d, %d)...%d matches... %.2fs\n", jj, timeID - frameTimeStamp[jj], ii, timeID - frameTimeStamp[ii], SRawPairWiseMatchID[threadID].size(), omp_get_wtime() - start);

				if (timeID < 0)
					sprintf(Fname, "%s/Dynamic/M_%.2d_%.2d.txt", Path, jj, ii);
				else
					sprintf(Fname, "%s/Dynamic/%.4d/M_%.2d_%.2d.txt", Path, timeID, jj, ii);
				FILE *fp = fopen(Fname, "w+");
				fprintf(fp, "%d\n", SRawPairWiseMatchID[threadID].size());
				for (int i = 0; i < SRawPairWiseMatchID[threadID].size(); i++)
					fprintf(fp, "%d %d\n", SRawPairWiseMatchID[threadID][i].x, SRawPairWiseMatchID[threadID][i].y);
				fclose(fp);
			}
		}
	}
	printLOG("Finished matching feature points ... in %.2fs\n", omp_get_wtime() - start);

	delete[]SortingVec;
	delete[]tId;
	delete[]RawPairWiseMatchID, delete[]SRawPairWiseMatchID;
	delete sift;
	FREE_MYLIB(hsiftgpu);
	///SIFT MATCHING: ENDS
#else
	printLOG("SiftGPU is not supported\n");
#endif
	return 0;
}
int GeneratePointsCorrespondenceMatrix_CPU(char *Path, int nviews, int timeID, int HistogramEqual, float nndrRatio, int *frameTimeStamp, int extractionMethod, bool ROOTL1)
{
	if (frameTimeStamp == NULL)
	{
		frameTimeStamp = new int[nviews];
		for (int ii = 0; ii < nviews; ii++)
			frameTimeStamp[ii] = 0;
	}

	int nthreads = omp_get_max_threads();
	omp_set_num_threads(nthreads);

	//SIFT DECTION: START
	const int descriptorSize = SIFTBINS;
	vector<uchar > *descriptorsU = new vector<uchar >[nthreads];
	vector<KeyPoint> *keys = new vector<KeyPoint>[nthreads];
	vector<Point3i> *Vrgb = new vector<Point3i>[nthreads];
	for (int ii = 0; ii < nthreads; ii++)
		keys[ii].reserve(MaxNFeatures), Vrgb[ii].reserve(MaxNFeatures), descriptorsU[ii].reserve(MaxNFeatures * descriptorSize);

	SiftFeature *SF = new SiftFeature[nthreads];
	CovFeature *CovF = new CovFeature[nthreads];
	Mat *cvImg = new Mat[nthreads], *equalizedImg = new Mat[nthreads];

	int jpegmode = 1;
	double start = omp_get_wtime();
#pragma omp parallel for schedule(dynamic,1)
	for (int ii = 0; ii < nviews; ii++)
	{
		double start = omp_get_wtime();
		//Try to read all sift points if available
		char Fname[512];
		if (timeID < 0)
			sprintf(Fname, "%s/%.4d.kpts", Path, ii);
		else
		{
			if (timeID - frameTimeStamp[ii] < 0)
				continue;
			sprintf(Fname, "%s/%d/%.4d.kpts", Path, ii, timeID - frameTimeStamp[ii]);
		}
		if (IsFileExist(Fname) == 1)
		{
			printLOG("%s computed\n", Fname);
			continue;
		}

		if (timeID < 0)
			sprintf(Fname, "%s/%.4d.jpg", Path, ii);
		else
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, ii, timeID - frameTimeStamp[ii]);
		//Check if image is available
		if (IsFileExist(Fname) == 0)
		{
			if (timeID < 0)
				sprintf(Fname, "%s/%.4d.png", Path, ii);
			else
				sprintf(Fname, "%s/%d/%.4d.png", Path, ii, timeID - frameTimeStamp[ii]);
			if (IsFileExist(Fname) == 0)
				continue;
			else
				jpegmode = 0;
		}

		int threadID = omp_get_thread_num();
		keys[threadID].clear(), descriptorsU[threadID].clear(), Vrgb[threadID].clear();
		if (HistogramEqual == 1)
		{
			cvImg[threadID] = imread(Fname, 0);
			if (cvImg[threadID].empty())
				continue;

			equalizeHist(cvImg[threadID], equalizedImg[threadID]);

			if (timeID < 0)
				sprintf(Fname, "%s/_%.4d.jpg", Path, ii);
			else
				sprintf(Fname, "%s/%d/_%.4d.jpg", Path, ii, timeID - frameTimeStamp[ii]);
			imwrite(Fname, equalizedImg[threadID]);
		}

		int npts = 0;
		if (extractionMethod == 1)
		{
			if (VLCOVDET(Fname, CovF[threadID], npts, ROOTL1) == 1)
				continue;

			for (int kk = 0; kk < npts; kk++)
			{
				double maxis1 = pow(CovF[threadID].Kpts[6 * kk + 2], 2) + pow(CovF[threadID].Kpts[6 * kk + 3], 2);
				double maxis2 = pow(CovF[threadID].Kpts[6 * kk + 4], 2) + pow(CovF[threadID].Kpts[6 * kk + 5], 2);

				keys[threadID].push_back(KeyPoint(CovF[threadID].Kpts[6 * kk], CovF[threadID].Kpts[6 * kk + 1], sqrt(max(maxis1, maxis2))));
				for (int ll = 0; ll < descriptorSize; ll++)
					descriptorsU[threadID].push_back(CovF[threadID].Desc[kk * 128 + ll]);
			}
		}
		else if (extractionMethod == 2)
		{
			if (VLSIFT(Fname, SF[threadID], npts, ROOTL1) == 1)
				continue;

			for (int kk = 0; kk < npts; kk++)
			{
				keys[threadID].push_back(KeyPoint(SF[threadID].Kpts[4 * kk], SF[threadID].Kpts[4 * kk + 1], SF[threadID].Kpts[4 * kk + 2]));
				for (int ll = 0; ll < descriptorSize; ll++)
					descriptorsU[threadID].push_back(SF[threadID].Desc[kk * 128 + ll]);
			}
		}
		else
		{
			printLOG("OpenCV Sift not supported. Exit.");
			exit(0);
			/*int descriptorSize = 128;
			SiftFeatureDetector detector;
			SiftDescriptorExtractor extractor;
			SIFT sfeatures;
			Mat desc;

			Mat img1 = imread(Fname, 0);
			if (img1.empty())
			{
			printLOG("Can't read %s\n", Fname);
			continue;
			}
			detector.detect(img1, keys[threadID]);
			extractor.compute(img1, keys[threadID], desc);

			for (int kk = 0; kk < (int)keys[threadID].size(); kk++)
			{
			keys[threadID][kk].size *= 0.5; //OpenCV gives diamater instead of radius
			double norm = 0.0;
			for (int ll = 0; ll < descriptorSize; ll++)
			norm += pow(desc.at<float>(kk, ll), 2);
			norm = sqrt(norm);
			for (int ll = 0; ll < descriptorSize; ll++)
			descriptors[threadID].push_back(desc.at<float>(kk, ll) / norm);
			*/
		}

		//Getting color info
		if (jpegmode == 1)
		{
			if (timeID < 0)
				sprintf(Fname, "%s/%.4d.jpg", Path, ii);
			else
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, ii, timeID);
		}
		else
		{
			if (timeID < 0)
				sprintf(Fname, "%s/%.4d.png", Path, ii);
			else
				sprintf(Fname, "%s/%d/%.4d.png", Path, ii, timeID);
		}
		cvImg[threadID] = imread(Fname, IMREAD_COLOR);
		for (int kk = 0; kk < npts; kk++)
		{
			int x = (int)keys[threadID][kk].pt.x, y = (int)keys[threadID][kk].pt.y;
			if (x < 0 || y < 0 || x > cvImg[threadID].cols || y>cvImg[threadID].rows)
			{
				Vrgb[threadID].push_back(Point3d(0, 0, 0));
				continue;
			}
			int id = x + y * cvImg[threadID].cols;
			Point3i rgb;
			rgb.z = cvImg[threadID].data[3 * id + 0];//b
			rgb.y = cvImg[threadID].data[3 * id + 1];//g
			rgb.x = cvImg[threadID].data[3 * id + 2];//r
			Vrgb[threadID].push_back(rgb);
		}

		if (timeID < 0)
		{
			sprintf(Fname, "%s/%.4d.sift", Path, ii); writeVisualSFMSiftGPU(Fname, keys[threadID], &descriptorsU[threadID][0]);
			sprintf(Fname, "%s/%.4d.rgb", Path, ii); WriteRGBBinarySIFT(Fname, Vrgb[threadID]);
		}
		else
		{
			sprintf(Fname, "%s/%d", Path, ii), makeDir(Fname);
			sprintf(Fname, "%s/%d/%.4d.sift", Path, ii, timeID - frameTimeStamp[ii]); writeVisualSFMSiftGPU(Fname, keys[threadID], &descriptorsU[threadID][0]);
			sprintf(Fname, "%s/%d/%.4d.rgb", Path, ii, timeID - frameTimeStamp[ii]); WriteRGBBinarySIFT(Fname, Vrgb[threadID]);
		}

#pragma omp critical
		printLOG("View %d_%d: %d points ... Wrote to files. Take %.2fs\n", ii, timeID - frameTimeStamp[ii], npts, omp_get_wtime() - start);
	}
	printLOG("Feature detection: %.2fs\n", omp_get_wtime() - start);

	//Get cumulative info
	int totalPts = 0;
	vector<int>cumulativePts, PtsPerView;
	char Fname[512];
	for (int ii = 0; ii < nviews; ii++)
	{
		if (timeID < 0)
			sprintf(Fname, "%s/%.4d.kpts", Path, ii);
		else
			sprintf(Fname, "%s/%d/%.4d.kpts", Path, ii, timeID - frameTimeStamp[ii]);
		if (ReadKPointsBinarySIFT(Fname, keys[0]))
		{
			cumulativePts.push_back(totalPts);
			totalPts += (int)keys[0].size();
			PtsPerView.push_back((int)keys[0].size());
		}
		else
		{
			cumulativePts.push_back(totalPts);
			totalPts += 0;
			PtsPerView.push_back(0);
		}
	}
	cumulativePts.push_back(totalPts);

	if (timeID < 0)
		sprintf(Fname, "%s/CumlativePoints.txt", Path);
	else
	{
		sprintf(Fname, "%s/Dynamic", Path), makeDir(Fname);
		sprintf(Fname, "%s/Dynamic/%.4d/CumlativePoints.txt", Path, timeID);
	}
	FILE* fp = fopen(Fname, "w+");
	for (int ii = 0; ii < cumulativePts.size(); ii++)
		fprintf(fp, "%d\n", cumulativePts[ii]);
	fclose(fp);

	delete[]descriptorsU, delete[]keys, delete[]Vrgb;
	delete[]cvImg, delete[]equalizedImg;
	delete[]CovF, delete[]SF;
	//SIFT DECTION: ENDS

	///SIFT MATCHING: START
	vector<Point2i> *RawPairWiseMatchID = new vector<Point2i>[nthreads];
	for (int ii = 0; ii < nthreads; ii++)
		RawPairWiseMatchID[ii].reserve(10000);
	vector<Point2i> *SRawPairWiseMatchID = new vector<Point2i>[nthreads];
	for (int ii = 0; ii < nthreads; ii++)
		SRawPairWiseMatchID[ii].reserve(10000);

	const int ninlierThesh = 50;
	int *SortingVec = new int[MaxNFeatures * nthreads]; //should be more than enough
	int *tId = new int[MaxNFeatures * nthreads];

	bool BinaryDesc = false, useBFMatcher = false; // SET TO TRUE TO USE BRUTE FORCE MATCHER
	const int knn = 2, ntrees = 4, maxLeafCheck = 128;

	if (timeID > 0)
		sprintf(Fname, "%s/Dynamic", Path), makeDir(Fname);
	else
		sprintf(Fname, "%s/Matches", Path), makeDir(Fname);

	start = omp_get_wtime();
	printLOG("Running feature matching...\n");
	Mat descriptors1;
	for (int jj = 0; jj < nviews - 1; jj++)
	{
		if (timeID < 0)
			sprintf(Fname, "%s%.4d.sift", Path, jj);
		else
			sprintf(Fname, "%s/%d/%.4d.sift", Path, jj, timeID - frameTimeStamp[jj]);

		vector<SiftKeypoint> kpts;
		Mat descriptors1;
		readVisualSFMSiftGPU(Fname, kpts, descriptors1);

		//Mat descriptors1 = ReadDescriptorBinarySIFT(Fname);
		if (descriptors1.rows == 1)
			continue;

#pragma omp parallel for schedule(dynamic,1)
		for (int ii = jj + 1; ii < nviews; ii++)
		{
			char Fname[512];
			if (timeID < 0)
				sprintf(Fname, "%s/Dynamic/M_%.2d_%.2d.txt", Path, jj, ii);
			else
				sprintf(Fname, "%s/Dynamic/%.4d/M_%.2d_%.2d.txt", Path, timeID, jj, ii);
			if (IsFileExist(Fname) == 1)
			{
				printLOG("%s computed\n", Fname);
				continue;
			}

			if (timeID < 0)
				sprintf(Fname, "%s%.4d.sift", Path, ii);
			else
				sprintf(Fname, "%s/%d/%.4d.sift", Path, ii, timeID - frameTimeStamp[ii]);

			vector<SiftKeypoint> kpts2;
			Mat descriptors2;
			readVisualSFMSiftGPU(Fname, kpts2, descriptors2);

			//Mat descriptors2 = ReadDescriptorBinarySIFT(Fname);
			if (descriptors2.rows == 1)
				continue;

			double start = omp_get_wtime();
			int threadID = omp_get_thread_num();
			RawPairWiseMatchID[threadID].clear(), SRawPairWiseMatchID[threadID].clear();

			//Finding nearest neighbor
			Mat indices, dists;
			vector<vector<DMatch> > matches;
			if (BinaryDesc)
			{
				//printLOG("Binary descriptors detected...\n");// ORB, Brief, BRISK, FREAK
				if (useBFMatcher)
				{
					cv::BFMatcher matcher(cv::NORM_HAMMING); // use cv::NORM_HAMMING2 for ORB descriptor with WTA_K == 3 or 4 (see ORB constructor)
					matcher.knnMatch(descriptors2, descriptors1, matches, knn);
				}
				else
				{
					// Create Flann LSH index
					cv::flann::Index flannIndex(descriptors1, cv::flann::LshIndexParams(12, 20, 2), cvflann::FLANN_DIST_HAMMING);
					flannIndex.knnSearch(descriptors2, indices, dists, knn, cv::flann::SearchParams());
				}
			}
			else
			{
				if (useBFMatcher)
				{
					cv::BFMatcher matcher(cv::NORM_L2);
					matcher.knnMatch(descriptors2, descriptors1, matches, knn);
				}
				else
				{
					// Create Flann KDTree index
					cv::flann::Index flannIndex(descriptors1, cv::flann::KDTreeIndexParams(ntrees));//, cvflann::FLANN_DIST_EUCLIDEAN);
					flannIndex.knnSearch(descriptors2, indices, dists, knn, cv::flann::SearchParams(maxLeafCheck));
				}
			}

			// Find correspondences by NNDR (Nearest Neighbor Distance Ratio)
			int count = ii - jj - 1;
			for (int i = 0; i <= jj - 1; i++)
				count += nviews - i - 1;

			if (!useBFMatcher)
			{
				for (int i = 0; i < descriptors2.rows; ++i)
				{
					int ind1 = indices.at<int>(i, 0);
					if (indices.at<int>(i, 0) >= 0 && indices.at<int>(i, 1) >= 0 && dists.at<float>(i, 0) <= nndrRatio * dists.at<float>(i, 1))
						RawPairWiseMatchID[threadID].push_back(Point2i(ind1, i));
				}
			}
			else
			{
				for (unsigned int i = 0; i < matches.size(); ++i)
					if (matches.at(i).size() == 2 && matches.at(i).at(0).distance <= nndrRatio * matches.at(i).at(1).distance)
						RawPairWiseMatchID[threadID].push_back(Point2i(matches.at(i).at(0).trainIdx, i));
			}

			//To remove the nonsense case of every point matchces to 1 point-->IT HAPPENED
			SRawPairWiseMatchID[threadID].push_back(RawPairWiseMatchID[threadID][0]);
			for (int i = 1; i < min((int)RawPairWiseMatchID[threadID].size(), 50000); i++)
				if (RawPairWiseMatchID[threadID][i].x != RawPairWiseMatchID[threadID][i - 1].x)
					SRawPairWiseMatchID[threadID].push_back(RawPairWiseMatchID[threadID][i]);

			if (SRawPairWiseMatchID[threadID].size() < ninlierThesh)
				continue;

			//Start sorting
			for (int i = 0; i < min((int)SRawPairWiseMatchID[threadID].size(), 50000); i++)
			{
				SortingVec[i + 50000 * threadID] = SRawPairWiseMatchID[threadID].at(i).x;
				tId[i + 50000 * threadID] = i;
			}
			Quick_Sort_Int(SortingVec + 50000 * threadID, tId + 50000 * threadID, 0, min((int)SRawPairWiseMatchID[threadID].size(), 50000) - 1);

			//Store sorted vector
			RawPairWiseMatchID[threadID].push_back(SRawPairWiseMatchID[threadID].at(tId[0 + 50000 * threadID]));
			for (int i = 1; i < min((int)SRawPairWiseMatchID[threadID].size(), 50000); i++)
				if (SortingVec[i + 50000 * threadID] != SortingVec[i - 1 + 50000 * threadID])
					RawPairWiseMatchID[threadID].push_back(SRawPairWiseMatchID[threadID].at(tId[i + 50000 * threadID]));

#pragma omp critical
			{
				printLOG("(%d, %d) to (%d, %d)...%d matches... %.2fs\n", jj, timeID - frameTimeStamp[jj], ii, timeID - frameTimeStamp[ii], SRawPairWiseMatchID[threadID].size(), omp_get_wtime() - start);
				if (timeID < 0)
					sprintf(Fname, "%s/Dynamic/M_%.2d_%.2d.txt", Path, jj, ii);
				else
					sprintf(Fname, "%s/Dynamic/%.4d/M_%.2d_%.2d.txt", Path, timeID, jj, ii);
				FILE *fp = fopen(Fname, "w+");
				fprintf(fp, "%d\n", SRawPairWiseMatchID[threadID].size());
				for (int i = 0; i < SRawPairWiseMatchID[threadID].size(); i++)
					fprintf(fp, "%d %d\n", SRawPairWiseMatchID[threadID].at(i).x, SRawPairWiseMatchID[threadID].at(i).y);
				fclose(fp);
			}
		}
	}
	printLOG("Finished matching feature points ... in %.2fs\n", omp_get_wtime() - start);

	delete[]SortingVec;
	delete[]tId;
	delete[]RawPairWiseMatchID, delete[]SRawPairWiseMatchID;
	///SIFT MATCHING: ENDS

	return 0;
}

typedef struct {
	int id1, id2;
} matchID;

int GenerateUnduplicatedCorpusMatchesList(char *Path, int knnMax)
{
	char Fname[512];

	//image index must start from 0
	sprintf(Fname, "%s/Corpus/matches.txt", Path);	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}

	float s;
	int newid = -1, knnCount = 0, nimages = 0;

	matchID mid;
	vector<matchID > matches;  matches.reserve(1e6);
	while (fscanf(fp, "%d %d %f", &mid.id1, &mid.id2, &s) != EOF)
	{
		if (newid == -1 || newid != mid.id1)
			newid = mid.id1, knnCount = 0;
		if (knnCount < knnMax)
			matches.push_back(mid), knnCount++;
		nimages = max(nimages, mid.id1);
	}
	fclose(fp);
	nimages++;

	bool  *validMatches = new bool[nimages*nimages];
	for (int ii = 0; ii < nimages*nimages; ii++)
		validMatches[ii] = false;
	for (int ii = 0; ii < (int)matches.size(); ii++)
	{
		validMatches[matches[ii].id1 + nimages * matches[ii].id2] = true;
		validMatches[matches[ii].id2 + nimages * matches[ii].id1] = true;
	}

	///ccreate matching list
	/*sprintf(Fname, "%s/Corpus/vsfmPairs.txt", Path); fp = fopen(Fname, "w+");
	for (int ii = 0; ii < nimages; ii++)
	for (int jj = ii + 1; jj < nimages; jj++)
	if (validMatches[ii + jj*nimages])
	fprintf(fp, "%s/Corpus/%.4d.jpg %s/Corpus/%.4d.jpg\n", Path, ii, Path, jj);
	fclose(fp);*/

	sprintf(Fname, "%s/Corpus/ColMapPairs.txt", Path); fp = fopen(Fname, "w+");
	for (int ii = 0; ii < nimages; ii++)
		for (int jj = ii + 1; jj < nimages; jj++)
			if (validMatches[ii + jj * nimages])
				fprintf(fp, "%.4d.jpg %.4d.jpg\n", ii, jj);
	fclose(fp);

	delete[]validMatches;
	return 0;
}
int GenerateCameraIMatchList(char *Path, int CameraI, int startF, int stopF, int increF, int knnMax, int PnPMatchingForcedNearbyKeyFrameRange)
{
	char Fname[512];

	//make sure its PnPMatchingForcedNearbyKeyFrameRange nearest keyframes are in the list
	int cid, kfid, rfid, cfid, dummy;
	vector<int> vrfid, vcfid;
	sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, CameraI); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		exit(1);
	}
	while (fscanf(fp, "%d %d %d %d ", &cid, &kfid, &rfid, &dummy) != EOF)
		vrfid.push_back(rfid);
	fclose(fp);

	sprintf(Fname, "%s/Corpus/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		exit(1);
	}
	while (fscanf(fp, "%d %d ", &cfid, &cid) != EOF)
		if (cid == CameraI)
			vcfid.push_back(cfid);
	fclose(fp);

	sprintf(Fname, "%s/%d/VocabMatches.txt", Path, CameraI);	fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		float s;
		int newid = -1, knnCount = 0;

		matchID mid;
		vector<int> allQueryFrames; allQueryFrames.reserve(1e6);
		vector<matchID > matches;  matches.reserve(1e6);
		while (fscanf(fp, "%d %d %f", &mid.id1, &mid.id2, &s) != EOF)
		{
			if (newid == -1 || newid != mid.id1)
				newid = mid.id1, knnCount = 0;
			if (knnCount < knnMax)
				matches.push_back(mid), knnCount++;
			allQueryFrames.push_back(mid.id1);
		}
		fclose(fp);

		sort(allQueryFrames.begin(), allQueryFrames.end());
		std::vector<int>::iterator it = unique(allQueryFrames.begin(), allQueryFrames.end());
		allQueryFrames.resize(std::distance(allQueryFrames.begin(), it));

		vector<int> tID;
		int *T = new int[vrfid.size()], *TT = new int[vrfid.size()];

		sprintf(Fname, "%s/%d/ToMatch2.txt", Path, CameraI); fp = fopen(Fname, "w");
		for (auto fid : allQueryFrames)
		{
			tID.clear();
			for (int jj = 0; jj < (int)matches.size(); jj++)
			{
				if (matches[jj].id1<startF || matches[jj].id1>stopF)
					continue;
				if (matches[jj].id1 == fid) //matches id1 is the order of the file in the querry list
					tID.push_back(matches[jj].id2); // the order of the corpus image should be the same as its filename
			}

			if (vcfid.size() > 0) //only apply to all dedicated corpus
			{
				for (int jj = 0; jj < (int)vrfid.size(); jj++)
				{
					T[jj] = jj;
					TT[jj] = abs(fid - vrfid[jj]);
				}
				Quick_Sort_Int(TT, T, 0, vrfid.size() - 1);
				for (int jj = 0; jj < min(PnPMatchingForcedNearbyKeyFrameRange, (int)vrfid.size()); jj++)
					tID.push_back(vcfid[T[jj]]); //make sure its PnPMatchingForcedNearbyKeyFrameRange nearest keyframes are in the list
			}
			/*else //this will alter the order of the NN and better NNs may not be used in PnP
			{
			vector<int> bk = tID;
			for (int jj = 0; jj < tID.size(); jj++)
			{
			if (tID[jj] > 0 && tID[jj] < vcfid.size() - 1)
			bk.push_back(tID[jj] + 1), bk.push_back(tID[jj] - 1);
			}
			sort(bk.begin(), bk.end());
			std::vector<int>::iterator it = unique(bk.begin(), bk.end());
			bk.resize(std::distance(bk.begin(), it));
			tID = bk;
			}*/

			if (tID.size() > 0)
			{
				fprintf(fp, "%d %d ", fid, (int)tID.size());
				for (int jj = 0; jj < tID.size(); jj++)
					fprintf(fp, "%d ", tID[jj]);
				fprintf(fp, "\n");
			}
		}
		fclose(fp);
	}
	else
	{
		vector<int> tID;
		int *T = new int[vrfid.size()], *TT = new int[vrfid.size()];

		sprintf(Fname, "%s/%d/ToMatch2.txt", Path, CameraI); fp = fopen(Fname, "w");
		for (int fid = startF; fid <= stopF; fid += increF)
		{
			tID.clear();
			for (int jj = 0; jj < (int)vrfid.size(); jj++)
			{
				T[jj] = jj;
				TT[jj] = abs(fid - vrfid[jj]);
			}
			Quick_Sort_Int(TT, T, 0, vrfid.size() - 1);
			for (int jj = 0; jj < min(PnPMatchingForcedNearbyKeyFrameRange, (int)vrfid.size()); jj++)
				tID.push_back(vcfid[T[jj]]);

			if (tID.size() > 0)
			{
				fprintf(fp, "%d %d ", fid, (int)tID.size());
				for (int jj = 0; jj < tID.size(); jj++)
					fprintf(fp, "%d ", tID[jj]);
				fprintf(fp, "\n");
			}
		}
		fclose(fp);
	}

	return 0;
}

//Geometric filter
int USAC_FindFundamentalDriver(char *Path, int id1, int id2, int timeID)
{
	ConfigParamsFund cfg;
	bool USEPROSAC = false, USESPRT = true, USELOSAC = true;
	/// store common parameters
	cfg.common.confThreshold = 0.99;
	cfg.common.minSampleSize = 7;
	cfg.common.inlierThreshold = 1.5;
	cfg.common.maxHypotheses = 850000;
	cfg.common.maxSolutionsPerSample = 3;
	cfg.common.prevalidateSample = true;
	cfg.common.prevalidateModel = true;
	cfg.common.testDegeneracy = true;
	cfg.common.randomSamplingMethod = USACConfig::SAMP_UNIFORM;
	cfg.common.verifMethod = USACConfig::VERIF_SPRT;
	cfg.common.localOptMethod = USACConfig::LO_LOSAC;

	// read in PROSAC parameters if required
	if (USEPROSAC)
	{
		cfg.prosac.maxSamples;
		cfg.prosac.beta;
		cfg.prosac.nonRandConf;
		cfg.prosac.minStopLen;
	}

	// read in SPRT parameters if required
	if (USESPRT)
	{
		cfg.sprt.tM = 200.0;
		cfg.sprt.mS = 2.38;
		cfg.sprt.delta = 0.05;
		cfg.sprt.epsilon = 0.15;
	}

	// read in LO parameters if required
	if (USELOSAC)
	{
		cfg.losac.innerSampleSize = 15;
		cfg.losac.innerRansacRepetitions = 5;
		cfg.losac.thresholdMultiplier = 2.0;
		cfg.losac.numStepsIterative = 4;
	}
	cfg.fund.inputFilePath = Path;// "C:/temp/test1/orig_pts.txt";

								  // read data from from file
	char Fname[512];

	vector<KeyPoint> Keys1, Keys2;
	if (timeID < 0)
		sprintf(Fname, "%s/%.4d.kpts", Path, id1);
	else
		sprintf(Fname, "%s/%d/%.4d.kpts", Path, id1, timeID);
	if (!ReadKPointsBinarySIFT(Fname, Keys1, true))
		return 1;

	if (timeID < 0)
		sprintf(Fname, "%s/%.4d.kpts", Path, id2);
	else
		sprintf(Fname, "%s/%d/%.4d.kpts", Path, id2, timeID);
	if (!ReadKPointsBinarySIFT(Fname, Keys2, true))
		return 1;

	if (timeID < 0)
		sprintf(Fname, "%s/M_%.2d_%.2d.dat", Path, id1, id2);
	else
		sprintf(Fname, "%s/M_%.4d_%.2d_%.2d.dat", Path, timeID, id1, id2);

	int npts, pid1, pid2;
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot open %s\n", Fname);
		return 1;
	}
	fscanf(fp, "%d ", &npts);
	cfg.common.numDataPoints = npts;

	vector<Point2d>pts1, pts2;
	pts1.reserve(npts); pts2.reserve(npts);
	while (fscanf(fp, "%d %d ", &pid1, &pid2) != EOF)
	{
		pts1.push_back(Point2d(Keys1[pid1].pt.x, Keys1[pid1].pt.y));
		pts2.push_back(Point2d(Keys2[pid2].pt.x, Keys2[pid2].pt.y));
	}
	fclose(fp);

	std::vector<unsigned int> prosac_data;
	if (USEPROSAC)
	{
		prosac_data.resize(cfg.common.numDataPoints);
		if (!readPROSACDataFromFile(cfg.prosac.sortedPointsFile, cfg.common.numDataPoints, prosac_data))
			return 1;
		cfg.prosac.sortedPointIndices = &prosac_data[0];
	}
	else
		cfg.prosac.sortedPointIndices = NULL;

	int ninliers = 0;
	double Fmat[9];
	vector<int> InlierIndicator;
	USAC_FindFundamentalMatrix(cfg, pts1, pts2, Fmat, InlierIndicator, ninliers);

	/*sprintf(Fname, "%s/orig_pts.txt", Path); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", cfg.common.numDataPoints);
	for (int ii = 0; ii < cfg.common.numDataPoints; ii++)
	fprintf(fp, "%.2f %.2f %.2f %.2f\n", pts1[ii].x, pts1[ii].y, pts2[ii].x, pts2[ii].y);
	fclose(fp);*/

	// write out results
	sprintf(Fname, "%s/F.txt", Path); fp = fopen(Fname, "w+");
	for (int ii = 0; ii < 9; ii++)
		fprintf(fp, "%.8f ", Fmat[ii]);
	fclose(fp);

	sprintf(Fname, "%s/inliers.txt", Path); fp = fopen(Fname, "w+");
	for (unsigned int ii = 0; ii < cfg.common.numDataPoints; ii++)
		fprintf(fp, "%d\n", InlierIndicator[ii]);
	fclose(fp);

	return 0;
}
int USAC_FindHomographyDriver(char *Path, int id1, int id2, int timeID)
{
	bool USEPROSAC = false, USESPRT = true, USELOSAC = true;

	ConfigParamsHomog cfg;
	/// store common parameters
	cfg.common.confThreshold = 0.99;
	cfg.common.minSampleSize = 4;
	cfg.common.inlierThreshold = 2.0;
	cfg.common.maxHypotheses = 850000;
	cfg.common.maxSolutionsPerSample = 1;
	cfg.common.prevalidateSample = true;
	cfg.common.prevalidateModel = true;
	cfg.common.testDegeneracy = true;
	cfg.common.randomSamplingMethod = USACConfig::SAMP_UNIFORM;
	cfg.common.verifMethod = USACConfig::VERIF_SPRT;
	cfg.common.localOptMethod = USACConfig::LO_LOSAC;

	// read in PROSAC parameters if required
	if (USEPROSAC)
	{
		cfg.prosac.maxSamples;
		cfg.prosac.beta;
		cfg.prosac.nonRandConf;
		cfg.prosac.minStopLen;
	}

	// read in SPRT parameters if required
	if (USESPRT)
	{
		cfg.sprt.tM = 100.0;
		cfg.sprt.mS = 1.0;
		cfg.sprt.delta = 0.01;
		cfg.sprt.epsilon = 0.2;
	}

	// read in LO parameters if required
	if (USELOSAC)
	{
		cfg.losac.innerSampleSize = 12;
		cfg.losac.innerRansacRepetitions = 3;
		cfg.losac.thresholdMultiplier = 2.0;
		cfg.losac.numStepsIterative = 4;
	}
	cfg.homog.inputFilePath = Path;// "C:/temp/test1/orig_pts.txt";

								   // read data from from file
	char Fname[512];

	vector<KeyPoint> Keys1, Keys2;
	if (timeID < 0)
		sprintf(Fname, "%s/%.4d.kpts", Path, id1);
	else
		sprintf(Fname, "%s/%d/%.4d.kpts", Path, id1, timeID);
	if (!ReadKPointsBinarySIFT(Fname, Keys1))
		return 1;

	if (timeID < 0)
		sprintf(Fname, "%s/%.4d.kpts", Path, id2);
	else
		sprintf(Fname, "%s/%d/%.4d.kpts", Path, id2, timeID);
	if (!ReadKPointsBinarySIFT(Fname, Keys2))
		return 1;

	if (timeID < 0)
		sprintf(Fname, "%s/M_%.2d_%.2d.dat", Path, id1, id2);
	else
		sprintf(Fname, "%s/M_%.4d_%.2d_%.2d.dat", Path, timeID, id1, id2);

	int npts, pid1, pid2;
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot open %s\n", Fname);
		return 1;
	}
	fscanf(fp, "%d ", &npts);
	cfg.common.numDataPoints = npts;

	vector<Point2d>pts1, pts2;
	pts1.reserve(npts); pts2.reserve(npts);
	while (fscanf(fp, "%d %d ", &pid1, &pid2) != EOF)
	{
		pts1.push_back(Point2d(Keys1[pid1].pt.x, Keys1[pid1].pt.y));
		pts2.push_back(Point2d(Keys2[pid2].pt.x, Keys2[pid2].pt.y));
	}
	fclose(fp);

	std::vector<unsigned int> prosac_data;
	if (USEPROSAC)
	{
		prosac_data.resize(cfg.common.numDataPoints);
		if (!readPROSACDataFromFile(cfg.prosac.sortedPointsFile, cfg.common.numDataPoints, prosac_data))
			return 1;
		cfg.prosac.sortedPointIndices = &prosac_data[0];
	}
	else
		cfg.prosac.sortedPointIndices = NULL;

	int ninliers = 0;
	double Hmat[9];
	vector<int> InlierIndicator;
	USAC_FindHomography(cfg, pts1, pts2, Hmat, InlierIndicator, ninliers);

	/*sprintf(Fname, "%s/orig_pts.txt", Path); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", cfg.common.numDataPoints);
	for (int ii = 0; ii < cfg.common.numDataPoints; ii++)
	fprintf(fp, "%.2f %.2f %.2f %.2f\n", pts1[ii].x, pts1[ii].y, pts2[ii].x, pts2[ii].y);
	fclose(fp);*/

	// write out results
	sprintf(Fname, "%s/H.txt", Path); fp = fopen(Fname, "w+");
	for (int ii = 0; ii < 9; ii++)
		fprintf(fp, "%.8f ", Hmat[ii]);
	fclose(fp);

	sprintf(Fname, "%s/inliers.txt", Path); fp = fopen(Fname, "w+");
	for (unsigned int ii = 0; ii < cfg.common.numDataPoints; ii++)
		fprintf(fp, "%d\n", InlierIndicator[ii]);
	fclose(fp);

	return 0;
}

//Lens correction
int LensCorrectionVideoDriver(char *Path, char *VideoName, double *K, double *distortion, int LensType, int nimages, double Imgscale, double Contscale, int interpAlgo)
{
	char Fname[512];
	double iK[9];

	mat_invert(K, iK, 3);
	double omega, DistCtr[2];
	if (LensType == 1)
		omega = distortion[0], DistCtr[0] = distortion[1], DistCtr[1] = distortion[2];
	else if (LensType == 2)
		omega = distortion[0];

	Mat cvImg;
	unsigned char *Img = 0;
	double *Para = 0;

	VideoCapture  capture(VideoName);
	if (!capture.isOpened())  // if not success, exit program
	{
		printLOG("Cannot open %s\n", Fname);
		return -1;
	}

	for (int Id = 0; Id < nimages; Id++)
	{
		if (!capture.read(cvImg))
			break;

		int width = cvImg.cols, height = cvImg.rows, nchannels = cvImg.channels();
		int Mwidth = Imgscale * width, Mheight = Imgscale * height, Mlength = Mwidth * Mheight;
		if (Id == 0)
		{
			Img = new unsigned char[Mlength*nchannels];
			Para = new double[Mlength*nchannels];
		}

		for (int kk = 0; kk < nchannels; kk++)
		{
			for (int jj = 0; jj < height; jj++)
				for (int ii = 0; ii < width; ii++)
					Img[ii + jj * width + kk * width*height] = cvImg.data[ii*nchannels + jj * width*nchannels + kk];
			if (Para != NULL)
				Generate_Para_Spline(Img + kk * width*height, Para + kk * width*height, width, height, interpAlgo);
		}

		if (LensType == 0)
			LensUndistortion(Img, width, height, nchannels, K, distortion, interpAlgo, Imgscale, Contscale, Para);
		else if (LensType == 1)
			FishEyeCorrection(Img, cvImg.cols, cvImg.rows, 3, omega, DistCtr[0], DistCtr[1], interpAlgo, Imgscale, Contscale, Para);
		else if (LensType == 2)
			FishEyeCorrection(Img, cvImg.cols, cvImg.rows, 3, K, iK, omega, interpAlgo, Imgscale, Contscale, Para);
		else
			return 1;

		Mat nImg(Mheight, Mwidth, CV_8UC3);
		for (int kk = 0; kk < nchannels; kk++)
			for (int jj = 0; jj < Mheight; jj++)
				for (int ii = 0; ii < Mwidth; ii++)
					nImg.data[ii*nchannels + jj * Mwidth*nchannels + kk] = Img[ii + jj * Mwidth + kk * Mlength];

		sprintf(Fname, "%s/%.4d.png", Path, Id + 1);
		imwrite(Fname, nImg);
	}

	delete[]Img;

	return 0;
}
int LensCorrectionImageSequenceDriver(char *Path, double *K, double *distortion, int LensType, int startF, int stopF, double Imgscale, double Contscale, int interpAlgo)
{
	char Fname[512];
	double iK[9];

	mat_invert(K, iK, 3);
	double omega, DistCtr[2];
	if (LensType == FISHEYE)
		omega = distortion[0], DistCtr[0] = distortion[1], DistCtr[1] = distortion[2];
	else if (LensType == RADIAL_TANGENTIAL_PRISM)
		omega = distortion[0];

	Mat cvImg;
	unsigned char *Img = 0;
	double *Para = 0;

	int percent = 10, increment = 10;
	for (int Id = startF; Id <= stopF; Id++)
	{
		sprintf(Fname, "%s/%.4d.png", Path, Id);	cvImg = imread(Fname, 1);
		if (cvImg.empty())
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}

		int per = 100 * (Id - startF) / (stopF - startF + 1);
		if (per >= percent)
		{
			percent += increment;
			printLOG("\rWorking on %s: %d%% ...", Path, per);
		}
		int width = cvImg.cols, height = cvImg.rows, nchannels = cvImg.channels();
		int Mwidth = Imgscale * width, Mheight = Imgscale * height, Mlength = Mwidth * Mheight;
		if (Id == startF)
		{
			Img = new unsigned char[Mlength*nchannels];
			Para = new double[Mlength*nchannels];
		}

		for (int kk = 0; kk < nchannels; kk++)
		{
			for (int jj = 0; jj < height; jj++)
				for (int ii = 0; ii < width; ii++)
					Img[ii + jj * width + kk * width*height] = cvImg.data[ii*nchannels + jj * width*nchannels + kk];
			if (Para != NULL)
				Generate_Para_Spline(Img + kk * width*height, Para + kk * width*height, width, height, interpAlgo);
		}

		if (LensType == RADIAL_TANGENTIAL_PRISM)
			LensUndistortion(Img, width, height, nchannels, K, distortion, interpAlgo, Imgscale, Contscale, Para);
		else if (LensType == FISHEYE)
			FishEyeCorrection(Img, width, height, nchannels, K, distortion[0], interpAlgo, Imgscale, Contscale, Para);

		Mat nImg(Mheight, Mwidth, CV_8UC3);
		for (int kk = 0; kk < nchannels; kk++)
			for (int jj = 0; jj < Mheight; jj++)
				for (int ii = 0; ii < Mwidth; ii++)
					nImg.data[ii*nchannels + jj * Mwidth*nchannels + kk] = Img[ii + jj * Mwidth + kk * Mlength];

		sprintf(Fname, "%s/__%.4d.jpg", Path, Id);
		imwrite(Fname, nImg);
	}
	printLOG("\rWorking on %s: 100%%\n", Fname);

	delete[]Img;

	return 0;
}
void LensCorrectionImageSequenceDriver2(vector<std::string> &vNameIn, vector<std::string> &vNameOut, double *Intrinsic, double *distortion, int startF, int stopF, int nchannels, int LensType, int interpAlgo)
{
	vector<int> compression_params;
	compression_params.push_back(CV_IMWRITE_JPEG_QUALITY);
	compression_params.push_back(100);

	char Fname[512];
	Mat cvImg = imread(vNameIn[0], nchannels == 1 ? 0 : 1);
	if (cvImg.empty())
	{
		printLOG("Cannot load %s\n", vNameIn[0].c_str());
		return;
	}
	int width = cvImg.cols, height = cvImg.rows, length = width * height;

	//Generate mapping data
	Point2d *MapXY = new Point2d[width*height];

	double K[9] = { Intrinsic[0], Intrinsic[2], Intrinsic[3], 0, Intrinsic[1], Intrinsic[4] };
	for (int jj = 0; jj < height; jj++)
		for (int ii = 0; ii < width; ii++)
			MapXY[ii + jj * width] = Point2d(ii, jj);

	if (LensType == RADIAL_TANGENTIAL_PRISM)
		LensDistortionPoint(MapXY, K, distortion, width*height);
	else
		FishEyeDistortionPoint(MapXY, K, distortion[0], width*height);

	//undistort
	double *Para = new double[length*nchannels];
	unsigned char *Img = new unsigned char[length*nchannels];

	for (int fid = 0; fid < vNameIn.size(); fid++)
	{

		std::size_t pos1;
		string fidName = vNameOut[fid];
		while (true)
		{
			pos1 = fidName.find("/");
			if (pos1 == string::npos)
				break;
			fidName = fidName.substr(pos1 + 1);
		}
		pos1 = fidName.find(".");
		fidName = fidName.substr(0, pos1);
		printLOG("%d..", atoi(fidName.c_str()));

		if (fid != startF)
			cvImg = imread(vNameIn[fid], nchannels == 1 ? 0 : 1);
		if (cvImg.empty())
			continue;

		for (int kk = 0; kk < nchannels; kk++)
		{
			for (int jj = 0; jj < height; jj++)
				for (int ii = 0; ii < width; ii++)
					Img[ii + jj * width + kk * width*height] = cvImg.data[ii*nchannels + jj * width*nchannels + kk];
			Generate_Para_Spline(Img + kk * width*height, Para + kk * width*height, width, height, interpAlgo);
		}

		double S[3];
		for (int jj = 0; jj < height; jj++)
		{
			for (int ii = 0; ii < width; ii++)
			{
				Point2d ImgPt = MapXY[ii + jj * width];
				if (ImgPt.x < 0 || ImgPt.x > width - 1 || ImgPt.y<0.0 || ImgPt.y > height - 1)
					for (int kk = 0; kk < nchannels; kk++)
						cvImg.data[ii*nchannels + jj * width*nchannels + kk] = (unsigned char)0;
				else
				{
					for (int kk = 0; kk < nchannels; kk++)
					{
						Get_Value_Spline(Para + kk * length, width, height, ImgPt.x, ImgPt.y, S, -1, interpAlgo);
						S[0] = min(max(S[0], 0.0), 255.0);
						cvImg.data[ii*nchannels + jj * width*nchannels + kk] = (unsigned char)(S[0] + 0.5);
					}
				}
			}
		}

		std::size_t pos = vNameOut[fid].find(".jpg");
		if (pos != string::npos)
			imwrite(vNameOut[fid], cvImg, compression_params);
		else
			imwrite(vNameOut[fid], cvImg);
	}
	printLOG("\n");

	delete[]Para, delete[]Img, delete[]MapXY;
	return;
}
void LensCorrectionImageSequenceDriver3(vector<std::string> &vNameIn, vector<std::string> &vNameOut, VideoData &VideoI, int startF, int stopF, int nchannels, int LensType, int rotated, int interpAlgo)
{
	vector<int> compression_params;
	compression_params.push_back(CV_IMWRITE_JPEG_QUALITY);
	compression_params.push_back(100);

	Mat cvImg = imread(vNameIn[vNameIn.size() / 2], nchannels == 1 ? 0 : 1);
	if (cvImg.empty())
	{
		printLOG("Cannot load %s\n", vNameIn[0].c_str());
		return;
	}
	int width = cvImg.cols, height = cvImg.rows, length = width * height;

	//undistort
	double *Para = new double[length*nchannels];
	unsigned char *Img = new unsigned char[length*nchannels];

	for (int fid = startF; fid <= stopF; fid++)
	{
		printLOG("%d..", fid);
		if (IsFileExist(vNameOut[fid - startF].c_str()))
			continue;

		if (fid != startF)
			cvImg = imread(vNameIn[fid - startF], nchannels == 1 ? 0 : 1);
		if (cvImg.empty())
			continue;

		if (rotated == 1)
		{
			int width = cvImg.cols, height = cvImg.rows, nchannels = 3;
			for (int kk = 0; kk < nchannels; kk++)
			{
				for (int jj = 0; jj < height / 2; jj++)
					for (int ii = 0; ii < width; ii++)
					{
						char buf = cvImg.data[nchannels*ii + jj * nchannels*width + kk];
						cvImg.data[nchannels*ii + jj * nchannels*width + kk] = cvImg.data[nchannels*(width - 1 - ii) + (height - 1 - jj)*nchannels*width + kk];
						cvImg.data[nchannels*(width - 1 - ii) + (height - 1 - jj)*nchannels*width + kk] = buf;
					}
			}
		}

		for (int kk = 0; kk < nchannels; kk++)
		{
			for (int jj = 0; jj < height; jj++)
				for (int ii = 0; ii < width; ii++)
					Img[ii + jj * width + kk * width*height] = cvImg.data[ii*nchannels + jj * width*nchannels + kk];
			Generate_Para_Spline(Img + kk * width*height, Para + kk * width*height, width, height, interpAlgo);
		}

		double S[3];
		for (int jj = 0; jj < height; jj++)
		{
			for (int ii = 0; ii < width; ii++)
			{
				Point2d ImgPt(ii, jj);
				if (LensType == RADIAL_TANGENTIAL_PRISM)
					LensDistortionPoint(&ImgPt, VideoI.VideoInfo[fid].K, VideoI.VideoInfo[fid].distortion);
				else
					FishEyeDistortionPoint(&ImgPt, VideoI.VideoInfo[fid].K, VideoI.VideoInfo[fid].distortion[0]);

				if (ImgPt.x < 0 || ImgPt.x > width - 1 || ImgPt.y<0.0 || ImgPt.y > height - 1)
					for (int kk = 0; kk < nchannels; kk++)
						cvImg.data[ii*nchannels + jj * width*nchannels + kk] = (unsigned char)0;
				else
				{
					for (int kk = 0; kk < nchannels; kk++)
					{
						Get_Value_Spline(Para + kk * length, width, height, ImgPt.x, ImgPt.y, S, -1, interpAlgo);
						S[0] = min(max(S[0], 0.0), 255.0);
						cvImg.data[ii*nchannels + jj * width*nchannels + kk] = (unsigned char)(S[0] + 0.5);
					}
				}
			}
		}

		std::size_t pos = vNameOut[fid - startF].find(".jpg");
		if (pos != string::npos)
			imwrite(vNameOut[fid - startF], cvImg, compression_params);
		else
			imwrite(vNameOut[fid - startF], cvImg);
	}
	printLOG("\n");

	delete[]Para, delete[]Img;
	return;
}

int PickStaticImagesFromVideo(char *Path, char *VideoName, int SaveFrameDif, int redetectInterval, double percentile, double MovingThresh2, int &nNonBlurImages, bool visCamual)
{
	Mat colorImg, gray, prevGray, tImg, backGround, bestFrameInWind;
	vector<Point2f> points[2];
	vector<double>flowMag2;
	vector<uchar> status;
	vector<float> err;

	char Fname[512];
	sprintf(Fname, "%s/%s", Path, VideoName);
	VideoCapture  capture(Fname);
	if (!capture.isOpened())  // if not success, exit program
	{
		printLOG("Cannot open %s\n", Fname);
		return -1;
	}

	namedWindow("Static Image detection with LK", WINDOW_NORMAL);

	bool needToInit = true;
	int MAX_COUNT = 5000, frameID = 0, lastSaveframe = -SaveFrameDif - 1;

	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, 0.03);
	Size subPixWinSize(21, 21), winSize(31, 31);

	nNonBlurImages = 0;
	int bestframeID;
	vector<double> distance; distance.reserve(500);
	double Movement, smallestMovement = 1000.0;
	while (true)
	{
		if (!capture.read(colorImg))
			break;
		cvtColor(colorImg, gray, CV_BGR2GRAY);

		if (visCamual) //Create background
			cvtColor(gray, backGround, CV_GRAY2BGR);

		if (frameID == 0) // automatic initialization
		{
			goodFeaturesToTrack(gray, points[1], MAX_COUNT, 0.01, 10, Mat(), 3, false, 0.04);
			cornerSubPix(gray, points[1], subPixWinSize, Size(-1, -1), termcrit);
			if (visCamual)
				for (int jj = 0; jj < points[1].size() && visCamual; jj++)
					circle(backGround, points[1][jj], 5, Scalar(83, 185, 255), -1, 8);
		}

		if (!points[0].empty())
		{
			status.clear(); err.clear();
			if (prevGray.empty())
				gray.copyTo(prevGray);
			calcOpticalFlowPyrLK(prevGray, gray, points[0], points[1], status, err, winSize, 1, termcrit, 0, 0.001);

			size_t i, k;
			flowMag2.clear();
			for (i = k = 0; i < points[1].size(); i++)
			{
				if (!status[i])
					continue;

				flowMag2.push_back((points[1][i].x - points[0][i].x)*(points[1][i].x - points[0][i].x) + (points[1][i].y - points[0][i].y)*(points[1][i].y - points[0][i].y));

				points[1][k++] = points[1][i];
				if (visCamual)
					circle(backGround, points[1][i], 5, Scalar(83, 185, 255), -1, 8);
			}
			points[1].resize(k);

			sort(flowMag2.begin(), flowMag2.end());
			if (flowMag2.size() > 0)
				distance.push_back(flowMag2.at((int)(percentile*flowMag2.size())));
			else
				distance.push_back(-1);
			printLOG("@frame %d: %.3f\n", frameID, distance.at(frameID - 1));


			if (flowMag2.size() > 0)
			{
				Movement = flowMag2.at((int)(percentile*flowMag2.size()));
				if (smallestMovement > Movement)
				{
					bestFrameInWind = colorImg;
					smallestMovement = Movement;
					bestframeID = frameID;
				}

				if (0.3*Movement > smallestMovement && smallestMovement < MovingThresh2 && frameID - lastSaveframe > SaveFrameDif)
				{
					printLOG("Saving frame %d\n", bestframeID);
					sprintf(Fname, "%s/%.4d.png", Path, nNonBlurImages);
					imwrite(Fname, bestFrameInWind);
					lastSaveframe = frameID;
					smallestMovement = 1000.0;
					nNonBlurImages++;
				}

				if (flowMag2.size() < 50 || frameID % redetectInterval == 0)
				{
					goodFeaturesToTrack(gray, points[1], MAX_COUNT, 0.01, 10, Mat(), 3, false, 0.04);
					cornerSubPix(gray, points[1], subPixWinSize, Size(-1, -1), termcrit);
				}
			}
			else
			{
				goodFeaturesToTrack(gray, points[1], MAX_COUNT, 0.01, 10, Mat(), 3, false, 0.04);
				cornerSubPix(gray, points[1], subPixWinSize, Size(-1, -1), termcrit);
			}
		}

		needToInit = false;
		if (visCamual)
		{
			imshow("Static Image detection with LK", backGround);
			char c = (char)waitKey(10);
			if (c == 27)
				break;
		}

		std::swap(points[1], points[0]);
		swap(prevGray, gray);
		frameID++;
	}
	return 0;
}
int PickStaticImagesFromImages(char *Path, int SaveFrameDif, int redetectInterval, double percentile, double MovingThresh2, bool visCamual)
{
	Mat colorImg, gray, prevGray, tImg, backGround, bestFrameInWind;
	vector<Point2f> points[2];
	vector<double>flowMag2;
	vector<uchar> status;
	vector<float> err;

	char Fname[512];

	namedWindow("Static Image detection with LK", WINDOW_NORMAL);

	bool needToInit = true;
	int MAX_COUNT = 5000, frameID = 0, lastSaveframe = -SaveFrameDif - 1;

	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, 0.03);
	Size subPixWinSize(21, 21), winSize(31, 31);

	vector<double> distance; distance.reserve(500);
	int bestframeID = 0;
	double Movement, smallestMovement = 1000.0;
	while (true)
	{
		sprintf(Fname, "%s/%.4d.png", Path, frameID + 1);
		colorImg = imread(Fname, 1);
		if (colorImg.empty())
			break;

		cvtColor(colorImg, gray, CV_BGR2GRAY);

		if (visCamual) //Create background
			cvtColor(gray, backGround, CV_GRAY2BGR);

		if (frameID == 0) // automatic initialization
		{
			goodFeaturesToTrack(gray, points[1], MAX_COUNT, 0.01, 10, Mat(), 3, false, 0.04);
			cornerSubPix(gray, points[1], subPixWinSize, Size(-1, -1), termcrit);
			if (visCamual)
				for (int jj = 0; jj < points[1].size() && visCamual; jj++)
					circle(backGround, points[1][jj], 5, Scalar(83, 185, 255), -1, 8);
		}

		if (!points[0].empty())
		{
			status.clear(); err.clear();
			if (prevGray.empty())
				gray.copyTo(prevGray);
			calcOpticalFlowPyrLK(prevGray, gray, points[0], points[1], status, err, winSize, 1, termcrit, 0, 0.001);

			size_t i, k;
			flowMag2.clear();
			for (i = k = 0; i < points[1].size(); i++)
			{
				if (!status[i])
					continue;

				flowMag2.push_back((points[1][i].x - points[0][i].x)*(points[1][i].x - points[0][i].x) + (points[1][i].y - points[0][i].y)*(points[1][i].y - points[0][i].y));

				points[1][k++] = points[1][i];
				if (visCamual)
					circle(backGround, points[1][i], 5, Scalar(83, 185, 255), -1, 8);
			}
			points[1].resize(k);

			sort(flowMag2.begin(), flowMag2.end());
			if (flowMag2.size() > 0)
				distance.push_back(flowMag2.at((int)(percentile*flowMag2.size())));
			else
				distance.push_back(-1);
			printLOG("@frame %d: %.3f\n", frameID, distance.at(frameID - 1));

			if (flowMag2.size() > 0)
			{
				Movement = flowMag2.at((int)(percentile*flowMag2.size()));
				if (smallestMovement > Movement)
				{
					bestFrameInWind = colorImg;
					smallestMovement = Movement;
					bestframeID = frameID;
				}

				if (0.3*Movement > smallestMovement && smallestMovement < MovingThresh2 && frameID - lastSaveframe > SaveFrameDif)
				{
					printLOG("Saving frame %d\n", bestframeID);
					sprintf(Fname, "%s/_%.4d.png", Path, bestframeID);
					imwrite(Fname, bestFrameInWind);
					lastSaveframe = frameID;
					smallestMovement = 1000.0;
				}

				if (flowMag2.size() < 50 || frameID % redetectInterval == 0)
				{
					goodFeaturesToTrack(gray, points[1], MAX_COUNT, 0.01, 10, Mat(), 3, false, 0.04);
					cornerSubPix(gray, points[1], subPixWinSize, Size(-1, -1), termcrit);
				}
			}
			else
			{
				printLOG("Redected @ frame %d due to low # of features", frameID);
				goodFeaturesToTrack(gray, points[1], MAX_COUNT, 0.01, 10, Mat(), 3, false, 0.04);
				cornerSubPix(gray, points[1], subPixWinSize, Size(-1, -1), termcrit);
			}
		}

		needToInit = false;
		if (visCamual)
		{
			imshow("Static Image detection with LK", backGround);
			char c = (char)waitKey(10);
			if (c == 27)
				break;
		}

		std::swap(points[1], points[0]);
		swap(prevGray, gray);
		frameID++;
	}

	FILE *fp = fopen("C:/temp/distance.txt", "w+");
	for (int ii = 0; ii < distance.size(); ii++)
		fprintf(fp, "%.3f\n", distance[ii]);
	fclose(fp);

	return 0;
}

//Matching
static int readWarp(string iFilename, Mat& warp, int motionType) {

	// it reads from file a specific number of raw values:
	// 9 values for homography, 6 otherwise
	CV_Assert(warp.type() == CV_32FC1);
	int numOfElements;
	if (motionType == MOTION_HOMOGRAPHY)
		numOfElements = 9;
	else
		numOfElements = 6;

	int i;
	int ret_value;

	ifstream myfile(iFilename.c_str());
	if (myfile.is_open()) {
		float* matPtr = warp.ptr<float>(0);
		for (i = 0; i < numOfElements; i++) {
			myfile >> matPtr[i];
		}
		ret_value = 1;
	}
	else {
		cout << "Unable to open file " << iFilename.c_str() << endl;
		ret_value = 0;
	}
	return ret_value;
}
static int saveWarp(string fileName, const Mat& warp, int motionType)
{
	// it saves the raw matrix elements in a file
	CV_Assert(warp.type() == CV_32FC1);

	const float* matPtr = warp.ptr<float>(0);
	int ret_value;

	ofstream outfile(fileName.c_str());
	if (!outfile) {
		cerr << "error in saving "
			<< "Couldn't open file '" << fileName.c_str() << "'!" << endl;
		ret_value = 0;
	}
	else {//save the warp's elements
		outfile << matPtr[0] << " " << matPtr[1] << " " << matPtr[2] << endl;
		outfile << matPtr[3] << " " << matPtr[4] << " " << matPtr[5] << endl;
		if (motionType == MOTION_HOMOGRAPHY) {
			outfile << matPtr[6] << " " << matPtr[7] << " " << matPtr[8] << endl;
		}
		ret_value = 1;
	}
	return ret_value;

}
static void draw_warped_roi(Mat& image, const int width, const int height, Mat& W)
{
	Point2f top_left, top_right, bottom_left, bottom_right;

	Mat  H = Mat(3, 1, CV_32F);
	Mat  U = Mat(3, 1, CV_32F);

	Mat warp_mat = Mat::eye(3, 3, CV_32F);

	for (int y = 0; y < W.rows; y++)
		for (int x = 0; x < W.cols; x++)
			warp_mat.at<float>(y, x) = W.at<float>(y, x);

	//warp the corners of rectangle

	// top-left
	HOMO_VECTOR(H, 1, 1);
	gemm(warp_mat, H, 1, 0, 0, U);
	GET_HOMO_VALUES(U, top_left.x, top_left.y);

	// top-right
	HOMO_VECTOR(H, width, 1);
	gemm(warp_mat, H, 1, 0, 0, U);
	GET_HOMO_VALUES(U, top_right.x, top_right.y);

	// bottom-left
	HOMO_VECTOR(H, 1, height);
	gemm(warp_mat, H, 1, 0, 0, U);
	GET_HOMO_VALUES(U, bottom_left.x, bottom_left.y);

	// bottom-right
	HOMO_VECTOR(H, width, height);
	gemm(warp_mat, H, 1, 0, 0, U);
	GET_HOMO_VALUES(U, bottom_right.x, bottom_right.y);

	// draw the warped perimeter
	line(image, top_left, top_right, Scalar(255, 0, 255));
	line(image, top_right, bottom_right, Scalar(255, 0, 255));
	line(image, bottom_right, bottom_left, Scalar(255, 0, 255));
	line(image, bottom_left, top_left, Scalar(255, 0, 255));
}

int RecomputeNMatches(char *Path, vector<int> TrackInst, int nCams)
{
	char Fname[512];
	int npts, pid, fid;
	float u, v, s;

	for (int inst = 0; inst < (int)TrackInst.size(); inst++)
	{
		int startF = TrackInst[inst], maxNpts = 0;
		for (int cid = 0; cid < nCams; cid++)
		{
			sprintf(Fname, "%s/Dynamic/K2_%d_%.4d.txt", Path, cid, startF);
			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d %f %f %f", &pid, &fid, &u, &v, &s) != EOF)
				maxNpts = max(maxNpts, pid);
			fclose(fp);
		}

		sprintf(Fname, "%s/Dynamic/nMatches_%.4d.txt", Path, startF); 	FILE *fp = fopen(Fname, "w+");
		fprintf(fp, "%d %d\n", startF, maxNpts); fclose(fp);
	}

	vector<int> VstartF, Vnpts;
	for (int inst = 0; inst < (int)TrackInst.size(); inst++)
	{
		int startF = TrackInst[inst];
		sprintf(Fname, "%s/Dynamic/nMatches_%.4d.txt", Path, startF); 	FILE *fp = fopen(Fname, "r");
		fscanf(fp, "%d %d\n", &startF, &npts); fclose(fp);

		VstartF.push_back(startF), Vnpts.push_back(npts);
	}
	sprintf(Fname, "%s/Dynamic/nMatches.txt", Path); 	FILE *fp = fopen(Fname, "w+");
	for (int ii = 0; ii < (int)VstartF.size(); ii++)
		fprintf(fp, "%d %d\n", VstartF[ii], Vnpts[ii]);
	fclose(fp);

	return 0;
}
int RefineInitialDynamicPointsAppearance(char *Path, int StartInstFid, int nCams, int NViewPlus, double imgScale)
{
	char Fname[512];
	for (int cid = 0; cid < nCams; cid++)
	{
		sprintf(Fname, "%s/Dynamic/K2_%d_%.4d.txt", Path, cid, StartInstFid);
		if (IsFileExist(Fname) == 1)
			return 0;
	}

	LKParameters LKArg;
	LKArg.DIC_Algo = 8, LKArg.InterpAlgo = 1, LKArg.ZNCCThreshold = 0.8; LKArg.hsubset = 40;// to be set depending of sift scale
	LKArg.Incomplete_Subset_Handling = 0, LKArg.Convergence_Criteria = 0, LKArg.Analysis_Speed = 0, LKArg.IterMax = 10; //usually, camera are well orientied to see the same point-->many iteration can falsely rotate the patch to match with other wrong points

	vector<int>PvalidCamID;
	Mat *Img = new Mat[nCams];
	vector<double *> ImgPara(nCams);

	int fid, npts, maxNpts = 0;
	sprintf(Fname, "%s/Dynamic/nMatches.txt", Path); FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d", &fid, &npts) != EOF)
		maxNpts = max(npts, maxNpts);
	fclose(fp);

	int *startFPerCam = new int[nCams];
	vector<int>*PViewIdAll3D = new vector<int>[maxNpts];
	vector<Point2f>*uvAll3D = new vector<Point2f>[maxNpts];
	vector<float>*sAll3D = new vector<float>[maxNpts];
	vector<float>*aAll3D = new vector<float>[maxNpts];

	vector<int>*fViewIdAll3D = new vector<int>[maxNpts];
	vector<Point2f>*fuvAll3D = new vector<Point2f>[maxNpts];
	vector<float>*fsAll3D = new vector<float>[maxNpts];
	vector<float>*faAll3D = new vector<float>[maxNpts];

	double *zncc = new double[9 * nCams*nCams];
	Point2d *bestMatches = new Point2d[9 * nCams*nCams];
	double *Timg = new double[(2 * LKArg.hsubset + 1)*(2 * LKArg.hsubset + 1)];
	double *CorrelBuf = new double[6 * (2 * LKArg.hsubset + 1)*(2 * LKArg.hsubset + 1)];

	for (int ii = 0; ii < maxNpts; ii++)
		PViewIdAll3D[ii].clear(), fuvAll3D[ii].clear(), fsAll3D[ii].clear(), faAll3D[ii].clear();

	//Read key points
	for (int cid = 0; cid < nCams; cid++)
	{
		int pid, startF; float u, v, s, a;
		startFPerCam[cid] = -1;

		sprintf(Fname, "%s/Dynamic/K_%d_%.4d.txt", Path, cid, StartInstFid);
		if (IsFileExist(Fname) == 0)
			continue;
		fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %f %f %f %f", &pid, &startF, &u, &v, &s, &a) != EOF)
		{
			startFPerCam[cid] = startF;
			PViewIdAll3D[pid].push_back(cid);
			uvAll3D[pid].push_back(Point2f(u, v));
			sAll3D[pid].push_back(s);
			aAll3D[pid].push_back(a);
		}
		fclose(fp);
	}

	//Read images
	for (int cid = 0; cid < nCams; cid++)
	{
		if (startFPerCam[cid] == -1)
			continue;

		sprintf(Fname, "%s/%d/%.4d.png", Path, cid, startFPerCam[cid]);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, startFPerCam[cid]);
			if (IsFileExist(Fname) == 0)
				continue;
		}
		Img[cid] = imread(Fname, 0);
		if (Img[cid].empty() == 1)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		if (ImgPara[cid] == NULL)
			ImgPara[cid] = new double[Img[cid].cols* Img[cid].rows];
		imgScale = 1.0*Img[cid].cols / 1920.0;
		Generate_Para_Spline(Img[cid].data, ImgPara[cid], Img[cid].cols, Img[cid].rows, 1);
	}

	int goodNptsCount = 0;

	double starttime = omp_get_wtime();
	int increPer = 10, Per = increPer;
	for (int pid = 0; pid < maxNpts; pid++)
	{
#pragma omp critical
		if (100.0*pid / maxNpts >= Per)
		{
			// printLOG("%d: @%d%% ...%.2fs\n", StartInstFid, Per, omp_get_wtime() - starttime);
			Per += increPer;
		}

		//Load images to do zncc
		int nvis = (int)PViewIdAll3D[pid].size();
		if (nvis < NViewPlus)
			continue;

		double maxFscale = 0.0;
		for (int ii = 0; ii < nvis; ii++)
			maxFscale = maxFscale > sAll3D[pid][ii] ? maxFscale : sAll3D[pid][ii];
		LKArg.hsubset = (int)(min(max(3.0*maxFscale, 8.0*imgScale), 20 * imgScale) + 0.5);

		double iWp[4], scale[4], rot[4], adif;
		for (int jj = 0; jj < nvis; jj++)
		{
			for (int ii = 0; ii < nvis; ii++)
			{
				if (ii == jj)
					continue;

				int cid1 = PViewIdAll3D[pid][jj], cid2 = PViewIdAll3D[pid][ii];
				Point2d pt1 = uvAll3D[pid][jj], pt2 = uvAll3D[pid][ii];

				scale[0] = sAll3D[pid][jj] / sAll3D[pid][ii] - 1.0, scale[1] = 0, scale[2] = 0, scale[3] = scale[0]; //prescale the features

				adif = aAll3D[pid][ii] - aAll3D[pid][jj];
				rot[0] = cos(adif), rot[1] = -sin(adif), rot[2] = sin(adif), rot[3] = cos(adif); //pre-rotate the features

				mat_mul(scale, rot, iWp, 2, 2, 2);

				zncc[ii + jj * nvis] = 1.0 - TemplateMatching(ImgPara[cid1], ImgPara[cid2], Img[cid1].cols, Img[cid1].rows, Img[cid2].cols, Img[cid2].rows, 1, pt1, pt2, LKArg, false, Timg, CorrelBuf, iWp);
				bestMatches[ii + jj * nvis] = pt2;
			}
		}

		//Take the one with the largest set of small cost as ref
		int RefCid = 0;
		double OverallCost, BestOverallCost = 9e9;
		for (int jj = 0; jj < nvis; jj++)
		{
			OverallCost = 0.0;
			for (int ii = 0; ii < nvis; ii++)
			{
				if (ii != jj)
					OverallCost += zncc[ii + jj * nvis];
			}
			if (OverallCost < BestOverallCost)
				BestOverallCost = OverallCost, RefCid = jj;
		}

		int nadded = 1;
		for (int ii = 0; ii < nvis; ii++)
		{
			if (ii == RefCid)
				continue;
			if (zncc[ii + RefCid * nvis] > 1.0 - LKArg.ZNCCThreshold)  //remove the bad one according to the selected ref
				continue;
			nadded++;
		}
		if (nadded >= NViewPlus)
		{
			fViewIdAll3D[goodNptsCount].push_back(PViewIdAll3D[pid][RefCid]);
			fuvAll3D[goodNptsCount].push_back(uvAll3D[pid][RefCid]);
			fsAll3D[goodNptsCount].push_back(sAll3D[pid][RefCid]);
			faAll3D[goodNptsCount].push_back(aAll3D[pid][RefCid]);

			for (int ii = 0; ii < nvis; ii++)
			{
				if (ii == RefCid)
					continue;
				if (zncc[ii + RefCid * nvis] > 1.0 - LKArg.ZNCCThreshold)  //remove the bad one according to the selected ref
					continue;

				fViewIdAll3D[goodNptsCount].push_back(PViewIdAll3D[pid][ii]);
				fuvAll3D[goodNptsCount].push_back(bestMatches[ii + RefCid * nvis]);
				fsAll3D[goodNptsCount].push_back(sAll3D[pid][ii]);
				faAll3D[goodNptsCount].push_back(aAll3D[pid][ii]);
			}
			goodNptsCount++;

		}
	}

	for (int cid = 0; cid < nCams; cid++)
	{
		sprintf(Fname, "%s/Dynamic/K2_%d_%.4d.txt", Path, cid, StartInstFid); fp = fopen(Fname, "w+");
		for (int ii = 0; ii < goodNptsCount; ii++)
			for (int jj = 0; jj < (int)fuvAll3D[ii].size(); jj++)
				if (cid == fViewIdAll3D[ii][jj])
					fprintf(fp, "%d %d %.4f %.4f %.3f %.4f\n", ii, startFPerCam[cid], fuvAll3D[ii][jj].x, fuvAll3D[ii][jj].y, fsAll3D[ii][jj], faAll3D[ii][jj]);
		fclose(fp);
	}

	sprintf(Fname, "%s/Dynamic/nMatches_%.4d.txt", Path, StartInstFid); 	fp = fopen(Fname, "w+");
	fprintf(fp, "%d %d\n", StartInstFid, goodNptsCount + 1);
	fclose(fp);

#pragma omp critical
	printLOG("%d: Done ...%.2fs\n", StartInstFid, omp_get_wtime() - starttime);

	delete[]PViewIdAll3D, delete[]uvAll3D, delete[]sAll3D, delete[]aAll3D, delete[] fViewIdAll3D, delete[]fuvAll3D, delete[]fsAll3D, delete[]faAll3D;
	delete[]zncc, delete[]Timg, delete[]CorrelBuf, delete[]bestMatches, delete[]Img;
	for (int ii = 0; ii < (int)ImgPara.size(); ii++)
		delete[]ImgPara[ii];
	return 0;
}
int CheckPairWiseZNCC(char *Path, vector<int> &validCamID, int nCams, int nframes, int npts, int pid, int f_instance, int nViewsPlus, LKParameters LKArg, int *CamID, int *RealframeID, Point2f *FrameSyncedPointsDistorted, float *FrameSyncedS, Mat *Img, vector<double *> &ImgPara)
{
	char Fname[512];

	vector<int> PvalidCamID;
	for (int ii = 0; ii < nCams; ii++)
	{
		if (CamID[ii*nframes*npts + pid * nframes + f_instance] > -1)
			PvalidCamID.push_back(ii);
	}
	int nvis = (int)PvalidCamID.size();
	if (nvis < nViewsPlus)
		return 0;

	//Load images incase need to do zncc
	double imgScale;
	for (int ii = 0; ii < (int)PvalidCamID.size(); ii++)
	{
		int cid = PvalidCamID[ii];
		sprintf(Fname, "%s/%d/%.4d.png", Path, cid, RealframeID[cid*nframes*npts + pid * nframes + f_instance]);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, RealframeID[cid*nframes*npts + pid * nframes + f_instance]);
			if (IsFileExist(Fname) == 0)
				return 0;
		}
		Img[cid] = imread(Fname, 0);
		imgScale = 1.0*Img[cid].cols / 1920;
		if (ImgPara[cid] == NULL)
			ImgPara[cid] = new double[Img[cid].cols* Img[cid].rows];
		Generate_Para_Spline(Img[cid].data, ImgPara[cid], Img[cid].cols, Img[cid].rows, 1);
	}
	double maxFscale = 0.0;
	for (int ii = 0; ii < nvis; ii++)
	{
		int cid = PvalidCamID[ii];
		if (maxFscale < FrameSyncedS[cid*nframes*npts + pid * nframes + f_instance])
			maxFscale = FrameSyncedS[cid*nframes*npts + pid * nframes + f_instance];
	}
	LKArg.hsubset = (int)(min(max(3.0*maxFscale, 8.0*imgScale), 20 * imgScale) + 0.5);

	double *zncc = new double[nCams*nCams];
	double *Timg = new double[(2 * LKArg.hsubset + 1)*(2 * LKArg.hsubset + 1)];
	double *CorrelBuf = new double[6 * (2 * LKArg.hsubset + 1)*(2 * LKArg.hsubset + 1)];

	double iWp[4];
	for (int jj = 0; jj < nvis - 1; jj++)
	{
		for (int ii = jj + 1; ii < nvis; ii++)
		{
			int cid1 = PvalidCamID[jj], cid2 = PvalidCamID[ii];
			Point2d pt1 = FrameSyncedPointsDistorted[cid1*nframes*npts + pid * nframes + f_instance], pt2 = FrameSyncedPointsDistorted[cid2*nframes*npts + pid * nframes + f_instance];
			//zncc[ii - 1] = ComputeZNCCImagePatch(Img[cid1], Img[cid2], pt1, pt2, 8, 1, CorrelBuf);

			iWp[0] = FrameSyncedS[cid1*nframes*npts + pid * nframes + f_instance] / FrameSyncedS[cid2*nframes*npts + pid * nframes + f_instance] - 1.0, iWp[1] = 0, iWp[2] = 0, iWp[3] = iWp[0]; //prescale the features
			zncc[ii + jj * nvis] = 1.0 - TemplateMatching(ImgPara[cid1], ImgPara[cid2], Img[cid1].cols, Img[cid1].rows, Img[cid2].cols, Img[cid2].rows, 1, pt1, pt2, LKArg, false, Timg, CorrelBuf, iWp);
			zncc[jj + ii * nvis] = zncc[ii + jj * nvis];
		}
	}

	//Take the one with the largest set of small cost as ref
	int RefCam = 0;
	double OverallCost, BestOverallCost = 9e9;
	for (int jj = 0; jj < nvis; jj++)
	{
		OverallCost = 0.0;
		for (int ii = 0; ii < nvis; ii++)
		{
			if (ii != jj)
				OverallCost += zncc[ii + jj * nvis];
		}
		if (OverallCost < BestOverallCost)
			BestOverallCost = OverallCost, RefCam = jj;
	}

	int availCount = 0;
	vector<int> cameraID, rframeID, availID;
	for (int ii = 0; ii < nvis; ii++)
	{
		if (ii == RefCam)
			;
		else if (zncc[ii + RefCam * nvis] > 1.0 - LKArg.ZNCCThreshold)  //remove the bad one according to the selected ref
			continue;

		int cid = PvalidCamID[ii];
		validCamID.push_back(cid);
		availCount++;
	}

	delete[]zncc, delete[]Timg, delete[]CorrelBuf;
	if (availCount < nViewsPlus)
		return 0;
	else
		return 1;
}

//Tracking
int WarpImageFlowDriver(char *Fin, char *Fout, char *FnameX, char *FnameY, int nchannels, int Gsigma, int InterpAlgo, bool removeStatic)
{
	int ii, jj, kk;

	Mat view = imread(Fin, nchannels == 1 ? 0 : 1);
	if (view.data == NULL)
	{
		cout << "Cannot load: " << Fin << endl;
		return 1;
	}
	int width = view.cols, height = view.rows, length = width * height;

	float *Flow = new float[2 * length];
	if (!ReadFlowBinary(FnameX, FnameY, Flow, Flow + length, width, height))
		return 2;

	if (Gsigma > 0.5)
	{
		double *Image = new double[length*nchannels];
		double *wImageD = new double[length*nchannels];
		for (kk = 0; kk < nchannels; kk++)
		{
			for (jj = 0; jj < height; jj++)
				for (ii = 0; ii < width; ii++)
					Image[ii + jj * width + length * kk] = (double)(int)view.data[nchannels*ii + kk + jj * nchannels*width];
			Gaussian_smooth(Image + kk * length, Image + kk * length, height, width, 255.0, Gsigma);
		}

		WarpImageFlowDouble(Flow, wImageD, Image, width, height, nchannels, InterpAlgo, removeStatic);
		SaveDataToImage(Fout, wImageD, width, height, nchannels);

		delete[]Image;
		delete[]wImageD;
	}
	else
	{
		unsigned char *Image = new unsigned char[length*nchannels];
		unsigned char *wImage = new unsigned char[length*nchannels];
		for (kk = 0; kk < nchannels; kk++)
			for (jj = 0; jj < height; jj++)
				for (ii = 0; ii < width; ii++)
					Image[ii + jj * width + kk * length] = (unsigned char)view.data[nchannels*ii + jj * nchannels*width + kk];

		WarpImageFlow(Flow, wImage, Image, width, height, nchannels, InterpAlgo, removeStatic);
		SaveDataToImage(Fout, wImage, width, height, nchannels);

		delete[]Image;
		delete[]wImage;
	}

	delete[]Flow;

	return 0;
}
int TVL1OpticalFlowDriver(char *Path, int selectedCam, int startF, int stopF, int increF, TVL1Parameters argGF, int forward, int backward, int SaveWarpedImage)
{
	char Fname1[200], Fname2[512], Fname3[200], Fname4[200];
	sprintf(Fname1, "%s/%d/Flow", Path, selectedCam); makeDir(Fname1);

	Mat frame0, frame1;
	float *fx = 0, *fy = 0;

	Mat_<Point2f> flowF;
	Mat_<Point2f> flowR;
	Ptr<DualTVL1OpticalFlow> tvl1;
	tvl1->setTau(argGF.tau);
	tvl1->setLambda(argGF.lamda);
	tvl1->setTheta(argGF.theta);
	tvl1->setEpsilon(argGF.epsilon);
	tvl1->setInnerIterations(argGF.iterations);
	tvl1->setScalesNumber(argGF.nscales);
	tvl1->setWarpingsNumber(argGF.warps);
	tvl1->setInnerIterations(false);

	if (SaveWarpedImage == 1)
	{
		sprintf(Fname1, "%s/%d/Warped", Path, selectedCam);
		makeDir(Fname1);
	}

	double start = omp_get_wtime();
	for (int frameID = startF; frameID <= stopF - increF; frameID += increF)
	{
		sprintf(Fname1, "%s/%d/%.4d.png", Path, selectedCam, frameID);
		sprintf(Fname2, "%s/%d/%.4d.png", Path, selectedCam, frameID + increF);
		frame0 = imread(Fname1, IMREAD_GRAYSCALE); //only accept grayscale image
		frame1 = imread(Fname2, IMREAD_GRAYSCALE); //only accept grayscale image

		if (!frame0.data || !frame1.data)
		{
			printLOG("Cannot load frame %d or %d\n", frameID, frameID + increF);
			delete[]fx;
			delete[]fy;
			return 1;
		}

		int width = frame0.cols, height = frame0.rows;
		if (fx == NULL || fy == NULL)
		{
			fx = new float[width*height];
			fy = new float[width*height];
		}

		//Foward flow
		if (forward)
		{
			tvl1->calc(frame0, frame1, flowF);

			sprintf(Fname1, "%s/%d/Flow/X_%d_%.4d.dat", Path, selectedCam, frameID, frameID + increF);
			sprintf(Fname2, "%s/%d/Flow/Y_%d_%.4d.dat", Path, selectedCam, frameID, frameID + increF);
			cvFlowtoFloat(flowF, fx, fy);

			if (!WriteFlowBinary(Fname1, Fname2, fx, fy, width, height))
			{
				printLOG("Cannot write flow for frame %d or %d\n", frameID, frameID + increF);
				continue;
			}

			if (SaveWarpedImage == 1)
			{
				sprintf(Fname3, "%s/%d/%.4d.png", Path, selectedCam, frameID + increF);
				sprintf(Fname4, "%s/%d/Warped/F_%.4d.png", Path, selectedCam, frameID);
				WarpImageFlowDriver(Fname3, Fname4, Fname1, Fname2, 3, 0.0, 1, true);
			}
		}

		if (backward)
		{
			//Backward flow
			tvl1->calc(frame1, frame0, flowR);

			sprintf(Fname1, "%s/%d/Flow/X_%d_%.4d.dat", Path, selectedCam, frameID + increF, frameID);
			sprintf(Fname2, "%s/%d/Flow/Y_%d_%.4d.dat", Path, selectedCam, frameID + increF, frameID);
			cvFlowtoFloat(flowR, fx, fy);
			if (!WriteFlowBinary(Fname1, Fname2, fx, fy, width, height))
			{
				printLOG("Cannot write flow for frame %d or %d\n", frameID, frameID + increF);
				continue;
			}
			if (SaveWarpedImage == 1)
			{
				sprintf(Fname3, "%s/%d/%.4d.png", Path, selectedCam, frameID);
				sprintf(Fname4, "%s/%d/Warped/B_%.4d.png", Path, selectedCam, frameID + increF);
				WarpImageFlowDriver(Fname3, Fname4, Fname1, Fname2, 3, 0.0, 1, true);
			}
		}

		printLOG("%d .. ", frameID);
	}
	printLOG("\nTotal time: %.2fs\n", omp_get_wtime() - start);

	delete[]fx, delete[]fy;

	return 0;
}
int TrackOpenCVLK(char *Path, int startF, int stopF, int HarrisCornerPatch, int PatchSize, int npryLevels, int nonMaxRadius, int minFeatures, int maxFeatures, double successTrackingRatio)
{
	Mat colorImg, gray, prevGray, tImg, backGround, bestFrameInWind;
	vector<Point2f> points[2];
	vector<uchar> status;
	vector<float> err;

	char Fname[512];
	namedWindow("OpenCV LK", WINDOW_NORMAL);


	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, 0.03);
	Size winSize(PatchSize, PatchSize);

	for (int frameID = startF; frameID <= stopF; frameID++)
	{
		sprintf(Fname, "%s/%.4d.png", Path, frameID); colorImg = imread(Fname, 1);
		if (colorImg.empty())
		{
			printLOG("Cannot read %s\n", Fname);
			break;
		}

		cvtColor(colorImg, gray, CV_BGR2GRAY);
		cvtColor(gray, backGround, CV_GRAY2BGR);

		if (points[0].size() == 0)
		{
			points[0].clear(), points[1].clear();
			goodFeaturesToTrack(gray, points[1], maxFeatures, 0.01, nonMaxRadius, Mat(), HarrisCornerPatch, false, 0.04);
			if (points[1].size() < (int)minFeatures)
				points[1].clear();
			for (int i = 0; i < points[1].size(); i++)
				circle(backGround, points[1][i], 1, Scalar(0, 0, 255), 2);
		}

		if (!points[0].empty())
		{
			status.clear(); err.clear();
			if (prevGray.empty())
				gray.copyTo(prevGray);
			calcOpticalFlowPyrLK(prevGray, gray, points[0], points[1], status, err, winSize, npryLevels, termcrit, 0, 0.001);

			int i, k;
			for (i = k = 0; i < (int)points[1].size(); i++)
			{
				if (!status[i])
					continue;
				points[1][k++] = points[1][i];
			}

			if (k < successTrackingRatio*(int)points[1].size() || (int)points[1].size() < minFeatures)
			{
				goodFeaturesToTrack(gray, points[1], maxFeatures, 0.01, nonMaxRadius, Mat(), HarrisCornerPatch, false, 0.04);
				if (points[1].size() < (int)minFeatures)
					points[1].clear();
			}
			else
				points[1].resize(k);

			for (i = 0; i < (int)points[1].size(); i++)
				circle(backGround, points[1][i], 1, Scalar(0, 0, 255), 2);
		}

		imshow("OpenCV LK", backGround);
		sprintf(Fname, "%s/t_%.4d.png", Path, frameID); imwrite(Fname, backGround);
		if (waitKey(2) == 27)
			points[1].clear();

		std::swap(points[1], points[0]);
		swap(prevGray, gray);
	}

	return 0;
}

int TrackAllPointsWithRefTemplateDriver(char *Path, int viewID, int startF, int increF, int fps, int trackingTime, int nWins, int WinStep, int cvPyrLevel, double MeanSSGThresh, int interpAlgo)
{
	char Fname[512];
	int TrackRange = fps * trackingTime;

	printLOG("***Working on (cid, fid):  (%d, %d)***\n", viewID, startF);

	float s, a;
	Point2f uv;
	int trueStartF, pid;
	vector<int> truePid; truePid.reserve(5000);
	vector<Point2f> uvRef; uvRef.reserve(5000);
	vector<float> sRef; sRef.reserve(5000);
	vector<float> aRef; aRef.reserve(5000);

	sprintf(Fname, "%s/Dynamic/K2_%d_%.4d.txt", Path, viewID, startF);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/Dynamic/K_%d_%.4d.txt", Path, viewID, startF);
		if (IsFileExist(Fname) == 0)
		{
			printLOG("Cannot load %s\n", Fname);
			return -1;
		}
	}
	FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d %f %f %f %f ", &pid, &trueStartF, &uv.x, &uv.y, &s, &a) != EOF)
		truePid.push_back(pid), uvRef.push_back(uv), sRef.push_back(s), aRef.push_back(a);
	fclose(fp);
	if (truePid.size() == 0)
		return -1;

	//Compute Mean sum square gradient score
	sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, trueStartF);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, trueStartF);
	Mat Img = imread(Fname, 0);
	if (Img.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return -1;
	}
	double *ImgPara = new double[Img.rows*Img.cols];
	unsigned char *ImgPtr = (unsigned char*)(Img.data);
	Generate_Para_Spline(ImgPtr, ImgPara, Img.cols, Img.rows, interpAlgo);

	vector<float> tsRef; tsRef = sRef;
	std::sort(tsRef.begin(), tsRef.end());
	//float ratio = 1.0*Img.cols / 1920;
	//float scaleMin = min(1.5f*ratio, tsRef[(int)(0.2*(int)tsRef.size())]), scaleMax = min(max(3.5f*ratio, tsRef[(int)(0.8f*(int)tsRef.size())]), 7.f * ratio); //scale is the radius of the blob
	//int maxWinSize = (int)(scaleMax + 0.5) * 6 + 1 + 30 * ratio; //each subwindown ranges from 13-> 43)+20 incase scale blows up

	float ratio = 1.0;
	float scaleMin = min(1.5f*ratio, tsRef[(int)(0.2*(int)tsRef.size())]), scaleMax = min(max(3.5f*ratio, tsRef[(int)(0.8f*(int)tsRef.size())]), 10.f * ratio); //scale is the radius of the blob
	int maxWinSize = (int)(scaleMax + 0.5) * 6 + 1 + 30 * ratio; //each subwindown ranges from 13-> 43)+20 incase scale blows up

	vector<double> ssg(uvRef.size());
#pragma omp parallel for schedule(dynamic,1)
	for (int ii = 0; ii < (int)uvRef.size(); ii++)
	{
		if (sRef[ii]<scaleMin || sRef[ii] > scaleMax)
		{
			ssg[ii] = 0.0;
			continue;
		}
		if (uvRef[ii].x > maxWinSize && uvRef[ii].x < Img.cols - maxWinSize && uvRef[ii].y > maxWinSize && uvRef[ii].y < Img.rows - maxWinSize)
			ssg[ii] = ComputeSSIG(ImgPara, uvRef[ii].x, uvRef[ii].y, (int)(sRef[ii] * 3 + 0.5), Img.cols, Img.rows, 1, 1);
		else
			ssg[ii] = 0.0;
	}
	delete[]ImgPara;

	//Filter bad points based on Mean sum square gradient score
	vector<float> GoodsRef; GoodsRef.reserve(5000);
	vector<Point2f> GooduvRef; GooduvRef.reserve(5000);
	vector<int> GoodtruePid; GoodtruePid.reserve(5000);
	for (int ii = 0; ii < (int)uvRef.size(); ii++)
		if (ssg[ii] > MeanSSGThresh)
			GooduvRef.push_back(uvRef[ii]), GoodsRef.push_back(sRef[ii]), GoodtruePid.push_back(truePid[ii]);

	uvRef.clear(), sRef.clear(), truePid.clear();
	uvRef = GooduvRef, sRef = GoodsRef, truePid = GoodtruePid;

	printLOG("Building image pyramid: Fore-Track images ...");
	vector<Mat> *ForePyr = new vector<Mat>[TrackRange], *BackPyr = new vector<Mat>[TrackRange];

	int ForeTrackRange = fps * trackingTime, BackTrackRange = fps * trackingTime;
	for (int ii = 0; ii < ForeTrackRange; ii++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, ii*increF + trueStartF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, ii*increF + trueStartF);
		Img = imread(Fname, 0);
		if (Img.empty())
		{
			ForeTrackRange = ii;
			break;
		}
		buildOpticalFlowPyramid(Img, ForePyr[ii], Size(maxWinSize, maxWinSize), cvPyrLevel, false);
	}
	printLOG("Back-Track images ...");
	for (int ii = 0; ii < BackTrackRange; ii++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, -ii * increF + trueStartF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, -ii * increF + trueStartF);
		Img = imread(Fname, 0);
		if (Img.empty())
		{
			BackTrackRange = ii;
			break;
		}
		buildOpticalFlowPyramid(Img, BackPyr[ii], Size(maxWinSize, maxWinSize), cvPyrLevel, false);
	}
	printLOG("Done\n");


	int npts = (int)uvRef.size();
	vector<Point2f> *ForeTrackUV = new vector<Point2f>[npts], *BackTrackUV = new vector<Point2f>[npts];
	vector<float> *ForeScale = new vector<float>[npts], *BackScale = new vector<float >[npts];
	vector<AffinePara> *cForeWarp = new vector<AffinePara>[npts], *cBackWarp = new vector<AffinePara >[npts];
	vector<FeatureDesc> *ForeDesc = new vector<FeatureDesc>[npts], *BackDesc = new vector<FeatureDesc>[npts];

	printLOG("Start tracking %d points\n", npts);
	double start = omp_get_wtime();
	TrackAllPointsWithRefTemplate(Path, viewID, trueStartF, uvRef, sRef, ForeTrackUV, BackTrackUV, ForeScale, BackScale, cForeWarp, cBackWarp, ForeDesc, BackDesc, ForePyr, BackPyr, maxWinSize, nWins, WinStep, cvPyrLevel, fps, ForeTrackRange, BackTrackRange, interpAlgo);
	printLOG("\nTotal time: %.2fs\n", omp_get_wtime() - start);

	//Write data
	sprintf(Fname, "%s/Track2D", Path); makeDir(Fname);
	sprintf(Fname, "%s/Track2D/FT_%d_%.4d.txt", Path, viewID, startF); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", npts);
	for (int pid = 0; pid < npts; pid++)
	{
		if ((int)ForeTrackUV[pid].size() < fps / 3)
			continue;
		else
		{
			fprintf(fp, "%d %d ", truePid[pid], (int)ForeTrackUV[pid].size());
			for (int fid = 0; fid < (int)ForeTrackUV[pid].size(); fid++)
				fprintf(fp, "%d %.4f %.4f %.3f %.4f %.8f %.8f %.8f %.8f ", trueStartF + fid, ForeTrackUV[pid][fid].x, ForeTrackUV[pid][fid].y, ForeScale[pid][fid], aRef[pid], cForeWarp[pid][fid].warp[0], cForeWarp[pid][fid].warp[1], cForeWarp[pid][fid].warp[2], cForeWarp[pid][fid].warp[3]);
			fprintf(fp, "\n");
		}
	}
	fclose(fp);

	sprintf(Fname, "%s/Track2D/BT_%d_%.4d.txt", Path, viewID, startF); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", npts);
	for (int pid = 0; pid < npts; pid++)
	{
		if ((int)BackTrackUV[pid].size() < fps / 3)
			continue;
		else
		{
			fprintf(fp, "%d %d ", truePid[pid], (int)BackTrackUV[pid].size());
			for (int fid = 0; fid < (int)BackTrackUV[pid].size(); fid++)
				fprintf(fp, "%d %.4f %.4f %.3f %.4f %.8f %.8f %.8f %.8f ", trueStartF - fid, BackTrackUV[pid][fid].x, BackTrackUV[pid][fid].y, BackScale[pid][fid], aRef[pid], cBackWarp[pid][fid].warp[0], cBackWarp[pid][fid].warp[1], cBackWarp[pid][fid].warp[2], cBackWarp[pid][fid].warp[3]);
			fprintf(fp, "\n");
		}
	}
	fclose(fp);


	sprintf(Fname, "%s/Track2D/%d_%.4d.txt", Path, viewID, startF); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", npts);
	for (int pid = 0; pid < npts; pid++)
	{
		if ((int)BackTrackUV[pid].size() + (int)ForeTrackUV[pid].size() < fps / 3)
			continue;
		else
		{
			fprintf(fp, "%d %d ", truePid[pid], (int)BackTrackUV[pid].size() + ForeTrackUV[pid].size() - 1);
			for (int fid = 0; fid < (int)ForeTrackUV[pid].size(); fid++)
				fprintf(fp, "%d %.4f %.4f %.3f %.4f %.8f %.8f %.8f %.8f  ", trueStartF + fid, ForeTrackUV[pid][fid].x, ForeTrackUV[pid][fid].y, ForeScale[pid][fid], aRef[pid], cForeWarp[pid][fid].warp[0], cForeWarp[pid][fid].warp[1], cForeWarp[pid][fid].warp[2], cForeWarp[pid][fid].warp[3]);
			for (int fid = 1; fid < (int)BackTrackUV[pid].size(); fid++)
				fprintf(fp, "%d %.4f %.4f %.3f %.4f %.8f %.8f %.8f %.8f  ", trueStartF - fid, BackTrackUV[pid][fid].x, BackTrackUV[pid][fid].y, BackScale[pid][fid], aRef[pid], cBackWarp[pid][fid].warp[0], cBackWarp[pid][fid].warp[1], cBackWarp[pid][fid].warp[2], cBackWarp[pid][fid].warp[3]);
			fprintf(fp, "\n");
		}
	}
	fclose(fp);
	printLOG("***Done with (cid, fid):  (%d, %d)***\n", viewID, startF);

	delete[]cForeWarp, delete[]cBackWarp;
	delete[]ForePyr, delete[]BackPyr;
	delete[]ForeTrackUV, delete[]BackTrackUV;
	delete[]ForeScale, delete[]BackScale;
	delete[]ForeDesc, delete[]BackDesc;

	return npts;
}
int TrackAllPointsWithRefTemplate_DenseFlowDriven_Driver(char *Path, int viewID, int startF, int increF, double fps, double trackingTime, int nWins, int WinStep, double MeanSSGThresh, int noTemplateUpdate, int interpAlgo)
{
	char Fname[512];
	int TrackRange = (int)(fps * trackingTime);

	printLOG("***Working on (cid, fid):  (%d, %d)***\n", viewID, startF);

	float s, a;
	Point2f uv;
	int trueStartF, pid;
	vector<int> truePid; truePid.reserve(5000);
	vector<Point2f> uvRef; uvRef.reserve(5000);
	vector<float> sRef; sRef.reserve(5000);
	vector<float> aRef; aRef.reserve(5000);
	//sprintf(Fname, "%s/Dynamic/K2_%d_%.4d.txt", Path, viewID, startF);
	sprintf(Fname, "%s/Dynamic/%d_%.4d.txt", Path, viewID, startF);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/Dynamic/K_%d_%.4d.txt", Path, viewID, startF);
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return -1;
	}
	while (fscanf(fp, "%d %d %f %f %f %f", &pid, &trueStartF, &uv.x, &uv.y, &s, &a) != EOF)
		truePid.push_back(pid), uvRef.push_back(uv), sRef.push_back(s), aRef.push_back(a);
	fclose(fp);

	if (truePid.size() == 0)
		return 0;

	//Compute Mean sum square gradient score
	sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, trueStartF);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, trueStartF);
	Mat Img = imread(Fname, 0);
	if (Img.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return -1;
	}
	double *ImgPara = new double[Img.rows*Img.cols];
	unsigned char *ImgPtr = (unsigned char*)(Img.data);
	Generate_Para_Spline(ImgPtr, ImgPara, Img.cols, Img.rows, interpAlgo);

	vector<float> tsRef; tsRef = sRef;
	std::sort(tsRef.begin(), tsRef.end());
	float ratio = 1.0*Img.cols / 1920;
	float scaleMin = min(1.5f*ratio, tsRef[(int)(0.2*(int)tsRef.size())]), scaleMax = min(max(3.5f*ratio, tsRef[(int)(0.8f*(int)tsRef.size())]), 7.f * ratio); //scale is the radius of the blob
	int maxWinSize = (int)(scaleMax + 0.5) * 6 + 1 + 30 * ratio; //each subwindown ranges from 13-> 43)+20 incase scale blows up

	vector<double> ssg(uvRef.size());
#pragma omp parallel for schedule(dynamic,1)
	for (int ii = 0; ii < (int)uvRef.size(); ii++)
	{
		if (sRef[ii]<scaleMin || sRef[ii] > scaleMax)
		{
			ssg[ii] = 0.0;
			continue;
		}
		if (uvRef[ii].x > maxWinSize && uvRef[ii].x < Img.cols - maxWinSize && uvRef[ii].y > maxWinSize && uvRef[ii].y < Img.rows - maxWinSize)
			ssg[ii] = ComputeSSIG(ImgPara, uvRef[ii].x, uvRef[ii].y, (int)(sRef[ii] * 3 + 0.5), Img.cols, Img.rows, 1, 1);
		else
			ssg[ii] = 0.0;
	}
	delete[]ImgPara;

	//Filter bad points based on Mean sum square gradient score
	vector<float> GoodsRef; GoodsRef.reserve(5000);
	vector<Point2f> GooduvRef; GooduvRef.reserve(5000);
	vector<int> GoodtruePid; GoodtruePid.reserve(5000);
	for (int ii = 0; ii < (int)uvRef.size(); ii++)
		if (ssg[ii] > MeanSSGThresh)
			GooduvRef.push_back(uvRef[ii]), GoodsRef.push_back(sRef[ii]), GoodtruePid.push_back(truePid[ii]);

	uvRef.clear(), sRef.clear(), truePid.clear();
	uvRef = GooduvRef, sRef = GoodsRef, truePid = GoodtruePid;


	printLOG("Building image pyramid: Fore-Track images ...");
	vector<Mat> *ForePyr = new vector<Mat>[TrackRange + 1], *BackPyr = new vector<Mat>[TrackRange + 1];

	int ForeTrackRange = (int)fps*trackingTime, BackTrackRange = (int)fps*trackingTime;
	for (int ii = 0; ii < ForeTrackRange; ii++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, ii*increF + trueStartF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, ii*increF + trueStartF);
		Img = imread(Fname, 0);
		if (Img.empty())
		{
			ForeTrackRange = ii;
			break;
		}
		buildOpticalFlowPyramid(Img, ForePyr[ii], Size(maxWinSize, maxWinSize), 1, false);
	}
	printLOG("Back-Track images ...");
	for (int ii = 0; ii < BackTrackRange; ii++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, -ii * increF + trueStartF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, -ii * increF + trueStartF);
		Img = imread(Fname, 0);
		if (Img.empty())
		{
			BackTrackRange = ii;
			break;
		}
		buildOpticalFlowPyramid(Img, BackPyr[ii], Size(maxWinSize, maxWinSize), 1, false);
	}
	printLOG("Done\n");

	printLOG("Read dense forward flow ...");
	vector<float*> DFx, DFy;
	DFx.reserve(ForeTrackRange), DFy.reserve(ForeTrackRange);
	for (int ii = 0; ii < ForeTrackRange; ii++)
	{
		int width = ForePyr[0][0].cols, height = ForePyr[0][0].rows;
		float *fx = new float[width*height], *fy = new float[width*height];

		char Fname1[200]; sprintf(Fname1, "%s/%d/Flow/X_%d_%.4d.dat", Path, viewID, ii*increF + trueStartF, (ii + 1)*increF + trueStartF);
		char Fname2[512]; sprintf(Fname2, "%s/%d/Flow/Y_%d_%.4d.dat", Path, viewID, ii*increF + trueStartF, (ii + 1)*increF + trueStartF);
		if (!ReadFlowBinary(Fname1, Fname2, fx, fy, width, height))
		{
			printLOG("Cannot find %s or %s. Please compute it!\n", Fname1, Fname2);
			ForeTrackRange = ii + 1;
			break;
		}
		DFx.push_back(fx), DFy.push_back(fy);
	}

	printLOG("\nRead dense backward flow ...");
	vector<float*> DBx, DBy;
	DBx.reserve(BackTrackRange), DBy.reserve(BackTrackRange);
	for (int ii = 0; ii < BackTrackRange + 1; ii++)
	{
		int width = BackPyr[0][0].cols, height = BackPyr[0][0].rows;
		float *fx = new float[width*height], *fy = new float[width*height];

		char Fname1[200]; sprintf(Fname1, "%s/%d/Flow/X_%d_%.4d.dat", Path, viewID, -ii * increF + trueStartF, -(ii + 1)*increF + trueStartF);
		char Fname2[512]; sprintf(Fname2, "%s/%d/Flow/Y_%d_%.4d.dat", Path, viewID, -ii * increF + trueStartF, -(ii + 1)*increF + trueStartF);
		if (!ReadFlowBinary(Fname1, Fname2, fx, fy, width, height))
		{
			printLOG("Cannot find %s or %s. Please compute it!\n", Fname1, Fname2);
			BackTrackRange = ii + 1;
			break;
		}
		DBx.push_back(fx), DBy.push_back(fy);
	}
	printLOG("Done\n");

	int npts = (int)uvRef.size();
	vector<Point2f> *ForeTrackUV = new vector<Point2f>[npts], *BackTrackUV = new vector<Point2f>[npts];
	vector<float> *ForeScale = new vector<float>[npts], *BackScale = new vector<float >[npts];
	vector<FeatureDesc> *ForeDesc = new vector<FeatureDesc>[npts], *BackDesc = new vector<FeatureDesc>[npts];
	vector<AffinePara> *cForeWarp = new vector<AffinePara>[npts], *cBackWarp = new vector<AffinePara >[npts];

	printLOG("Start tracking %d points\n", npts);
	double start = omp_get_wtime();
	TrackAllPointsWithRefTemplate_DenseFlowDriven(Path, viewID, trueStartF, uvRef, sRef, ForeTrackUV, BackTrackUV, ForeScale, BackScale, cForeWarp, cBackWarp, ForeDesc, BackDesc, ForePyr, BackPyr,
		DFx, DFy, DBx, DBy, maxWinSize, nWins, WinStep, fps, ForeTrackRange, BackTrackRange, noTemplateUpdate, interpAlgo);
	printLOG("\nTotal time: %.2fs\n", omp_get_wtime() - start);

	//lets get points tracked well in both directions
	for (int pid = 0; pid < npts; pid++)
		if ((int)ForeTrackUV[pid].size() < min(0.7*ForeTrackRange, fps / 10) || (int)BackTrackUV[pid].size() < min(0.7*BackTrackRange, fps / 10))
			ForeTrackUV[pid].clear(), BackTrackUV[pid].clear();

	//Write data
	sprintf(Fname, "%s/Track2D", Path); makeDir(Fname);
	sprintf(Fname, "%s/Track2D/FT_%d_%.4d.txt", Path, viewID, startF); fp = fopen(Fname, "w+");

	int nvalidpts = 0;
	for (int pid = 0; pid < npts; pid++)
		if ((int)ForeTrackUV[pid].size() > min(0.7*ForeTrackRange, fps / 10))
			nvalidpts++;

	fprintf(fp, "%d\n", nvalidpts);
	int count = 0;
	for (int pid = 0; pid < npts; pid++)
	{
		if ((int)ForeTrackUV[pid].size() > min(0.7*ForeTrackRange, fps / 10))
		{
			fprintf(fp, "%d %d ", count, (int)ForeTrackUV[pid].size());
			for (int fid = 0; fid < (int)ForeTrackUV[pid].size(); fid++)
				fprintf(fp, "%d %.4f %.4f %.3f ", trueStartF + fid, ForeTrackUV[pid][fid].x, ForeTrackUV[pid][fid].y, ForeScale[pid][fid]);
			fprintf(fp, "\n");
			count++;
		}
	}
	fclose(fp);

	sprintf(Fname, "%s/Track2D/BT_%d_%.4d.txt", Path, viewID, startF); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", nvalidpts);
	count = 0;
	for (int pid = 0; pid < npts; pid++)
	{
		if ((int)BackTrackUV[pid].size() > min(0.7*BackTrackRange, fps / 10))
		{
			fprintf(fp, "%d %d ", count, (int)BackTrackUV[pid].size());
			for (int fid = 0; fid < (int)BackTrackUV[pid].size(); fid++)
				fprintf(fp, "%d %.4f %.4f %.3f ", trueStartF - fid, BackTrackUV[pid][fid].x, BackTrackUV[pid][fid].y, BackScale[pid][fid]);
			fprintf(fp, "\n");
			count++;
		}
	}
	fclose(fp);

	sprintf(Fname, "%s/Track2D/D%d_%.4d.txt", Path, viewID, startF); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", npts);
	for (int pid = 0; pid < npts; pid++)
	{
		if ((int)BackTrackUV[pid].size() + (int)ForeTrackUV[pid].size() < min(0.7*ForeTrackRange, fps / 10) + min(0.7*BackTrackRange, fps / 10))
			continue;
		else
		{
			fprintf(fp, "%d %d ", truePid[pid], (int)BackTrackUV[pid].size() + ForeTrackUV[pid].size() - 1);
			for (int fid = 0; fid < (int)ForeTrackUV[pid].size(); fid++)
				fprintf(fp, "%d %.4f %.4f %.3f %.4f %.8f %.8f %.8f %.8f ", trueStartF + fid, ForeTrackUV[pid][fid].x, ForeTrackUV[pid][fid].y, ForeScale[pid][fid], aRef[pid], cForeWarp[pid][fid].warp[0], cForeWarp[pid][fid].warp[1], cForeWarp[pid][fid].warp[2], cForeWarp[pid][fid].warp[3]);
			for (int fid = 1; fid < (int)BackTrackUV[pid].size(); fid++)
				fprintf(fp, "%d %.4f %.4f %.3f %.4f %.8f %.8f %.8f %.8f  ", trueStartF - fid, BackTrackUV[pid][fid].x, BackTrackUV[pid][fid].y, BackScale[pid][fid], aRef[pid], cBackWarp[pid][fid].warp[0], cBackWarp[pid][fid].warp[1], cBackWarp[pid][fid].warp[2], cBackWarp[pid][fid].warp[3]);
			fprintf(fp, "\n");
		}
	}
	fclose(fp);

	printLOG("***Done with (cid, fid):  (%d, %d)***\n", viewID, startF);

	for (int ii = 0; ii < (int)DFx.size(); ii++)
		delete[]DFx[ii], delete[]DFy[ii];
	for (int ii = 0; ii < (int)DBx.size(); ii++)
		delete[]DBx[ii], delete[]DBy[ii];
	delete[]cForeWarp, delete[]cBackWarp;
	delete[]ForePyr, delete[]BackPyr;
	delete[]ForeTrackUV, delete[]BackTrackUV;
	delete[]ForeScale, delete[]BackScale;
	delete[]ForeDesc, delete[]BackDesc;

	return npts;
}
int TrackAllCorpusPointsWithRefTemplateDriver(char *Path, int viewID, int startF, int increF, int TrackRange, int nWins, int WinStep, int cvPyrLevel, double MeanSSGThresh, int CameraNotCalibrated, int distortionCorrected, int interpAlgo)
{
	char Fname[512];
	int fps = 30;

	int pid;
	float s;
	Point2f uv; Point3d xyz;
	vector<int> truePid; truePid.reserve(5000);
	vector<Point3d> Vxyz; Vxyz.reserve(5000);
	vector<Point2f> VuvRef; VuvRef.reserve(5000);
	vector<float> Vscale; Vscale.reserve(5000);
	vector<float> tVscale; tVscale.reserve(5000);
	sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return -1;
	}
	while (fscanf(fp, "%d %lf %lf %lf %f %f %f", &pid, &xyz.x, &xyz.y, &xyz.z, &uv.x, &uv.y, &s) != EOF)
	{
		truePid.push_back(pid);
		VuvRef.push_back(uv);
		Vscale.push_back(s);
		tVscale.push_back(s);
	}
	fclose(fp);

	CameraData Cam;
	if (distortionCorrected == 0 && CameraNotCalibrated == 0)//unless cameraParas.notCalibrated == true, the Inliers.txt is corrected
	{
		MineIntrinsicInfo(Path, Cam, viewID, startF);
		if (Cam.LensModel == 0)
			LensDistortionPoint(VuvRef, Cam.K, Cam.distortion);
		else
			FishEyeDistortionPoint(VuvRef, Cam.distortion[0], Cam.distortion[1], Cam.distortion[2]);
	}

	//Compute Mean sum square gradient score
	sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, startF);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, startF);
	Mat Img = imread(Fname, 0);
	if (Img.empty())
	{
		printLOG("Cannot load %s\n", Fname);
		return -1;
	}
	double *ImgPara = new double[Img.rows*Img.cols];
	unsigned char *ImgPtr = (unsigned char*)(Img.data);
	Generate_Para_Spline(ImgPtr, ImgPara, Img.cols, Img.rows, interpAlgo);

	std::sort(tVscale.begin(), tVscale.end());
	float ratio = 1.0*Img.cols / 1920;
	float scaleMin = min(1.5f*ratio, tVscale[(int)(0.1*(int)tVscale.size())]), scaleMax = min(max(3.5f*ratio, tVscale[(int)(0.9*(int)tVscale.size())]), 9.f * ratio); //scale is the radius of the blob
	int maxWinSize = (int)(scaleMax + 0.5) * 6 + 1 + 30 * ratio; //each subwindown ranges from 13-> 43)+20 incase scale blows up

	vector<double> ssg(VuvRef.size());
#pragma omp parallel for schedule(dynamic,8)
	for (int ii = 0; ii < (int)VuvRef.size(); ii++)
	{
		if (Vscale[ii]<scaleMin || Vscale[ii] > scaleMax)
		{
			ssg[ii] = 0.0;
			continue;
		}
		if (VuvRef[ii].x > maxWinSize && VuvRef[ii].x < Img.cols - maxWinSize && VuvRef[ii].y > maxWinSize && VuvRef[ii].y < Img.rows - maxWinSize)
			ssg[ii] = ComputeSSIG(ImgPara, VuvRef[ii].x, VuvRef[ii].y, (int)(Vscale[ii] * 3 + 0.5), Img.cols, Img.rows, 1, 1);
		else
			ssg[ii] = 0.0;
	}
	delete[]ImgPara;

	//Filter bad points based on Mean sum square gradient score
	vector<float> GoodsRef;
	vector<Point2f> GooduvRef;
	vector<int> GoodtruePid, GoodPid;
	for (int ii = 0; ii < (int)VuvRef.size(); ii++)
	{
		if (ssg[ii] > MeanSSGThresh)
		{
			GoodsRef.push_back(Vscale[ii]);
			GooduvRef.push_back(VuvRef[ii]), GoodtruePid.push_back(truePid[ii]), GoodPid.push_back(ii);
		}
	}

	VuvRef.clear(), Vscale.clear(), truePid.clear();
	VuvRef = GooduvRef, Vscale = GoodsRef, truePid = GoodtruePid;

	int npts = (int)VuvRef.size();
	vector<Point2f> *ForeTrackUV = new vector<Point2f>[npts], *BackTrackUV = new vector<Point2f>[npts];
	vector<float> *ForeScale = new vector<float>[npts], *BackScale = new vector<float >[npts];
	vector<AffinePara> *cForeWarp = new vector<AffinePara>[npts], *cBackWarp = new vector<AffinePara >[npts];
	vector<FeatureDesc> *ForeDesc = new vector<FeatureDesc>[npts], *BackDesc = new vector<FeatureDesc>[npts];

	printLOG("Building image pyramid for %d: Fore-Track images ...", viewID);
	int ForeTrackRange = TrackRange, BackTrackRange = TrackRange;
	vector<Mat> *ForePyr = new vector<Mat>[TrackRange + 1], *BackPyr = new vector<Mat>[TrackRange + 1];
	for (int ii = 0; ii < ForeTrackRange; ii++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, ii*increF + startF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, ii*increF + startF);
		Img = imread(Fname, 0);
		if (Img.empty())
		{
			ForeTrackRange = ii;
			break;
		}
		buildOpticalFlowPyramid(Img, ForePyr[ii], Size(maxWinSize, maxWinSize), cvPyrLevel, false);
	}
	printLOG("Back-Track images ...");
	for (int ii = 0; ii < BackTrackRange; ii++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, -ii * increF + startF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, -ii * increF + startF);
		Img = imread(Fname, 0);
		if (Img.empty())
		{
			BackTrackRange = ii;
			break;
		}
		buildOpticalFlowPyramid(Img, BackPyr[ii], Size(maxWinSize, maxWinSize), cvPyrLevel, false);
	}
	printLOG("Done\n");

	printLOG("Start tracking %d points\n", npts);
	double start = omp_get_wtime();
	TrackAllPointsWithRefTemplate(Path, viewID, startF, VuvRef, Vscale, ForeTrackUV, BackTrackUV, ForeScale, BackScale, cForeWarp, cBackWarp, ForeDesc, BackDesc, ForePyr, BackPyr, maxWinSize, nWins, WinStep, cvPyrLevel, fps, ForeTrackRange, BackTrackRange, interpAlgo);
	printLOG("\nTotal time: %.2fs\n", omp_get_wtime() - start);

	delete[]cForeWarp, delete[]cBackWarp;
#ifdef _WINDOWS
	sprintf(Fname, "%s/cTrack2D", Path); makeDir(Fname);
	sprintf(Fname, "%s/Track2D/FT_%d_%.4d.txt", Path, viewID, startF); fp = fopen(Fname, "w+");
	for (int pid = 0; pid < npts; pid++)
	{
		fprintf(fp, "%d %d ", truePid[pid], (int)ForeTrackUV[pid].size());
		for (int fid = 0; fid < (int)ForeTrackUV[pid].size(); fid++)
			fprintf(fp, "%d %.4f %.4f %.3f ", startF + fid * increF, ForeTrackUV[pid][fid].x, ForeTrackUV[pid][fid].y, ForeScale[pid][fid]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/Track2D/BT_%d_%.4d.txt", Path, viewID, startF);; fp = fopen(Fname, "w+");
	for (int pid = 0; pid < npts; pid++)
	{
		fprintf(fp, "%d %d ", truePid[pid], (int)BackTrackUV[pid].size());
		for (int fid = 0; fid < (int)BackTrackUV[pid].size(); fid++)
			fprintf(fp, "%d %.4f %.4f %.3f ", startF - fid * increF, BackTrackUV[pid][fid].x, BackTrackUV[pid][fid].y, BackScale[pid][fid]);
		fprintf(fp, "\n");
	}
	fclose(fp);
#endif

	//Write data
	sprintf(Fname, "%s/%d/cTrack2D", Path, viewID); makeDir(Fname);
	for (int fid = 1; fid <= TrackRange; fid++)
	{
		int count = 0;
		for (int pid = 0; pid < npts; pid++)
			if (ForeTrackUV[pid].size() > fid)
				count++;

		if (count > 0)
		{
			sprintf(Fname, "%s/%d/cTrack2D/%.4d_%.4d.txt", Path, viewID, startF, startF + fid * increF); fp = fopen(Fname, "w+");
			for (int pid = 0; pid < npts; pid++)
				if (ForeTrackUV[pid].size() > fid)
				{
					if (distortionCorrected == 0 && CameraNotCalibrated == 0)
					{
						if (Cam.LensModel == 0)
							LensCorrectionPoint(&ForeTrackUV[pid][fid], Cam.K, Cam.distortion);
						else
							FishEyeCorrectionPoint(&ForeTrackUV[pid][fid], Cam.K, Cam.distortion[0]);
					}
					fprintf(fp, "%d %.4f %.4f %.2f\n", GoodtruePid[pid], ForeTrackUV[pid][fid].x, ForeTrackUV[pid][fid].y, ForeScale[pid][fid]);
				}
			fclose(fp);
		}
	}

	for (int fid = 1; fid <= TrackRange; fid++)
	{
		int count = 0;
		for (int pid = 0; pid < npts; pid++)
			if (BackTrackUV[pid].size() > fid)
				count++;

		if (count > 0)
		{
			sprintf(Fname, "%s/%d/cTrack2D/%.4d_%.4d.txt", Path, viewID, startF, startF - fid * increF); fp = fopen(Fname, "w+");
			for (int pid = 0; pid < npts; pid++)
				if (BackTrackUV[pid].size() > fid)
				{
					if (distortionCorrected == 1 && CameraNotCalibrated == 0)
					{
						if (Cam.LensModel == 0)
							LensCorrectionPoint(&BackTrackUV[pid][fid], Cam.K, Cam.distortion);
						else
							FishEyeCorrectionPoint(&BackTrackUV[pid][fid], Cam.K, Cam.distortion[0]);
					}
					fprintf(fp, "%d %.4f %.4f %.2f\n", GoodtruePid[pid], BackTrackUV[pid][fid].x, BackTrackUV[pid][fid].y, BackScale[pid][fid]);
				}
			fclose(fp);
		}
	}

	delete[]ForePyr, delete[]BackPyr;
	delete[]ForeTrackUV, delete[]BackTrackUV;
	delete[]ForeScale, delete[]BackScale;
	delete[]ForeDesc, delete[]BackDesc;

	return npts;
}
int TrackCorpusFeatureToNonKeyFrames(char *Path, int viewID, int keyFrameID, int startF, int TrackRange, int winDim, int npryLevels, double bidir_Thresh, double successConsecutiveTrackingRatio, double successRefTrackingRatio, double avgflowMagThresh, int interpAlgo, bool highQualityTracker, int nThreads, int display)
{
	int nWindows = 3, WinStep = 3, MaxWinSize = 77, MinWinSize = 11;
	double dispThresh2 = bidir_Thresh * bidir_Thresh;

	char Fname[512];
	sprintf(Fname, "%s/cTrack2D", Path), makeDir(Fname);
	sprintf(Fname, "%s/%d/PnPmTc", Path, viewID), makeDir(Fname);
	sprintf(Fname, "%s/%d/PnPTc", Path, viewID); makeDir(Fname);

	int threeDID, twoDID, pid, nf, n;
	float s;
	Point2f uv;
	vector<Point2f> Vuv; Vuv.reserve(5000);
	vector<int> VthreeDID; VthreeDID.reserve(5000);
	vector<int> VtwoDID; VtwoDID.reserve(5000);
	vector<float> Vscale; Vscale.reserve(5000);
	sprintf(Fname, "%s/Corpus/CorpusK_%.4d.txt", Path, keyFrameID); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return -1;
	}
	while (fscanf(fp, "%d %f %f %f %d", &threeDID, &uv.x, &uv.y, &s, &twoDID) != EOF)
	{
		VthreeDID.push_back(threeDID);
		Vscale.push_back(s);
		VtwoDID.push_back(twoDID);
	}
	fclose(fp);

	if (VthreeDID.size() == 0)
		return 0;

	//Forward is from raw sift. Backward is from auto feature distortion correction --> lets read from raw sift so that everything is unified
	vector<KeyPoint> kpts;
	sprintf(Fname, "%s/Corpus/%.4d.sift", Path, keyFrameID);
	if (readVisualSFMSiftGPU(Fname, kpts) == 1)
		return -1;
	for (auto id : VtwoDID)
		Vuv.push_back(kpts[id].pt);

	Mat gray, prevGray, backGround;
	vector<Mat> pPyr, cPyr, rPyr;
	vector<Point2f> points[3];
	vector<uchar> status;
	vector<float> err;
	bool *ToDel = new bool[Vuv.size()];
	vector<vector<Point2f> > tracklets;


	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));
	if (display > 0)
		sprintf(Fname, "Tracking of Camera %d", viewID), namedWindow(Fname, WINDOW_NORMAL);

	vector<float>allDistance; allDistance.reserve(10000);
	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, 0.03);
	Size winSize(winDim, winDim);
	int width, height, WinLength = (MaxWinSize + 2)*(MaxWinSize + 2) * 2;
	double *ImgIParaC = NULL, *ImgIParaP = NULL, *ImgIParaR = NULL;
	double *T1 = new double[WinLength*nThreads], *T2 = new double[6 * WinLength*nThreads];

	vector<float> *ForeScale = new vector<float>[Vuv.size()], *BackScale = new vector<float>[Vuv.size()];
	vector<AffinePara> *ForeWarp = new vector<AffinePara>[Vuv.size()], *ForeiWarp = new vector<AffinePara>[Vuv.size()], *BackWarp = new vector<AffinePara>[Vuv.size()], *BackiWarp = new vector<AffinePara>[Vuv.size()];
	for (size_t ii = 0; ii < Vuv.size(); ii++)
	{
		AffinePara w1, w2, w3, w4;
		ForeScale[ii].reserve(TrackRange), ForeScale[ii].push_back(Vscale[ii]);
		BackScale[ii].reserve(TrackRange), BackScale[ii].push_back(Vscale[ii]);
		ForeWarp[ii].reserve(TrackRange), ForeWarp[ii].push_back(w1);
		BackWarp[ii].reserve(TrackRange), BackWarp[ii].push_back(w2);
		ForeiWarp[ii].reserve(TrackRange), ForeiWarp[ii].push_back(w3);
		BackiWarp[ii].reserve(TrackRange), BackiWarp[ii].push_back(w4);
	}

	if (nThreads > 1)
		omp_set_num_threads(nThreads);

	bool binary = true;

	//Forward track: computed during keyframe gen. Retrieved its info to write out to PnP
	bool hasCache = false;
	sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.dat", Path, viewID, startF);
	if (IsFileExist(Fname) == 1)
		hasCache = true;
	else
	{
		sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.txt", Path, viewID, startF);
		if (IsFileExist(Fname) == 1)
			hasCache = true;
	}

	if (hasCache)
	{
#pragma omp critical
		printLOG("Found cache for #%d\n", keyFrameID);
		int localPid = 0, maxnf = 0;
		vector<int> VthreeDID2;
		vector<float> Vscale2;
		vector<Point2f> *ForeTrackUV = new vector<Point2f>[VtwoDID.size()];
		if (binary)
		{
			ifstream fin;
			fin.open(Fname, ios::binary);
			fin.read(reinterpret_cast<char *>(&n), sizeof(int));
			for (int jj = 0; jj < n; jj++)
			{
				fin.read(reinterpret_cast<char *>(&pid), sizeof(int));
				fin.read(reinterpret_cast<char *>(&nf), sizeof(int));

				maxnf = max(maxnf, nf);
				vector<Point2f> Tracklet(nf);
				ForeTrackUV[localPid].clear();
				for (int ii = 0; ii < nf; ii++)
				{
					fin.read(reinterpret_cast<char *>(&uv.x), sizeof(float));
					fin.read(reinterpret_cast<char *>(&uv.y), sizeof(float));
					fin.read(reinterpret_cast<char *>(&s), sizeof(float));
					ForeTrackUV[localPid].push_back(uv);
				}

				int foundID = -1; //consists of all sift points but only some of them pass the sfm selection
				for (size_t ii = 0; ii < VtwoDID.size() && foundID == -1; ii++)
					if (pid == VtwoDID[ii])
						foundID = ii;

				if (foundID != -1)
				{
					VthreeDID2.push_back(VthreeDID[foundID]);
					Vscale2.push_back(Vscale[foundID]);
					localPid++;
				}
			}
			fin.close();
		}
		else
		{
			fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d ", &pid, &nf) != EOF)
			{
				if (pid < 0 || nf < 0)
					break;
				maxnf = max(maxnf, nf);
				ForeTrackUV[localPid].clear();
				for (int ii = 0; ii < nf; ii++)
				{
					fscanf(fp, "%f %f ", &uv.x, &uv.y);
					ForeTrackUV[localPid].push_back(uv);
				}

				int foundID = -1; //consists of all sift points but only some of them pass the sfm selection
				for (size_t ii = 0; ii < VtwoDID.size() && foundID == -1; ii++)
					if (pid == VtwoDID[ii])
						foundID = ii;

				if (foundID != -1)
				{
					VthreeDID2.push_back(VthreeDID[foundID]);
					Vscale2.push_back(Vscale[foundID]);
					localPid++;
				}
			}
			fclose(fp);
		}

		//write PnP
		vector<pair<int, Point3f> > *PnPPoints = new vector<pair<int, Point3f>>[maxnf];
		for (int ii = 0; ii < localPid; ii++)
			for (int jj = 0; jj < (int)ForeTrackUV[ii].size(); jj++)
				PnPPoints[jj].push_back(std::make_pair(VthreeDID2[ii], Point3f(ForeTrackUV[ii][jj].x, ForeTrackUV[ii][jj].y, Vscale2[ii])));

		for (int fidi = startF; fidi <= startF + maxnf - 1; fidi++)
		{
			sprintf(Fname, "%s/%d/PnPTc/Inliers_%d_%.4d.txt", Path, viewID, startF, fidi); fp = fopen(Fname, "w");
			fprintf(fp, "%d\n", PnPPoints[fidi - startF].size());
			for (int ii = 0; ii < (int)PnPPoints[fidi - startF].size(); ii++)
				fprintf(fp, "%d %.3f %.3f %.3f\n", PnPPoints[fidi - startF][ii].first, PnPPoints[fidi - startF][ii].second.x, PnPPoints[fidi - startF][ii].second.y, PnPPoints[fidi - startF][ii].second.z);
			fclose(fp);
		}

		delete[]PnPPoints, delete[]ForeTrackUV;
	}
	else //lets compute it
	{
		int fid, localfid = 0;
		for (fid = startF; fid <= startF + TrackRange; fid++)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, fid);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n", Fname);
					break;
				}
			}
			gray = imread(Fname, 0);
			buildOpticalFlowPyramid(gray, cPyr, winSize, npryLevels, true);

			width = gray.cols, height = gray.rows;
			if (ImgIParaC == NULL)
				ImgIParaC = new double[height*width], ImgIParaR = new double[height*width];
			double ratio = 1.0*gray.cols / 1920;

			if (fid == startF)
			{
				winSize.width = winDim * gray.cols / 1920;
				winSize.height = winDim * gray.cols / 1920;
				points[0] = Vuv;
				for (size_t ii = 0; ii < Vuv.size(); ii++)
				{
					vector<Point2f> track; track.push_back(Vuv[ii]);
					tracklets.push_back(track);
					ToDel[ii] = false;
				}
				buildOpticalFlowPyramid(gray, rPyr, winSize, npryLevels, true);
				Generate_Para_Spline(gray.data, ImgIParaR, width, height, interpAlgo);

				//std::swap(ImgIParaC, ImgIParaP);
				std::swap(pPyr, cPyr);
				std::swap(prevGray, gray);
				continue;
			}
			localfid++;

			if (display > 0)
			{
				cvtColor(prevGray, backGround, CV_GRAY2BGR);
				for (int pid = 0; pid < points[0].size(); pid++)
				{
					if (!ToDel[pid])
					{
						circle(backGround, points[0][pid], 1, colors[pid % 8], 2);
						if (display == 2)
							circle(backGround, points[0][pid], max(1, max(min((int)(ForeScale[pid][localfid - 1] * 3 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5))), colors[pid % 8], 2);
					}
				}

				CvPoint text_origin = { backGround.cols / 30, backGround.cols / 30 };
				sprintf(Fname, "@%d->%d", startF, fid);
				putText(backGround, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * backGround.cols / 640, CV_RGB(0, 255, 0), 2);
				if (display == 1)
					sprintf(Fname, "Tracking of Camera %d", viewID), imshow(Fname, backGround), waitKey(2);
			}

			Generate_Para_Spline(gray.data, ImgIParaC, width, height, interpAlgo);

			allDistance.clear();
			int pNpts = 0, tNpts = 0;
			double iavgmagFlow, avgmagFlow, curTrackingRatio, RefTrackingRatio;

			status.clear(), err.clear(), points[1].clear();
			points[2] = points[0];
			calcOpticalFlowPyrLK(pPyr, cPyr, points[0], points[1], status, err, winSize, npryLevels, termcrit); //forward
			calcOpticalFlowPyrLK(cPyr, pPyr, points[1], points[2], status, err, winSize, npryLevels, termcrit); //backward

			for (size_t pid = 0; pid < points[0].size(); pid++)
			{
				if (points[0][pid].x > 0 && points[0][pid].y > 0)
					pNpts++;
				if (status[pid] == 0 || ToDel[pid] == 1 || points[0][pid].x < 0)
					points[1][pid] = Point2f(-1, -1);
				else
				{
					double BiDirDist = norm(points[2][pid] - points[0][pid]);
					if (BiDirDist < bidir_Thresh*gray.cols / 1920)
						allDistance.push_back(norm(points[1][pid] - points[0][pid])),
						tNpts++;
					else
						points[1][pid] = Point2f(-1, -1), ToDel[pid] = 1;
				}
			}
			sort(allDistance.begin(), allDistance.end());

			if (tNpts < points[0].size() / 10)
				iavgmagFlow = 9e9;
			else
				iavgmagFlow = allDistance[tNpts / 5]; //take 20% percentile as the reference
			curTrackingRatio = 1.0* tNpts / pNpts;

			if (tNpts > (int)points[0].size() / 10)
			{
				tNpts = 0;
				allDistance.clear();

				if (!highQualityTracker)
				{
					points[2] = Vuv;
					calcOpticalFlowPyrLK(rPyr, cPyr, Vuv, points[1], status, err, winSize, max(0, npryLevels - 1), termcrit); //from refF to current frame with init
					calcOpticalFlowPyrLK(cPyr, rPyr, points[1], points[2], status, err, winSize, max(0, npryLevels - 1), termcrit); //from current to ref frame with init

					for (int ii = 0; ii < (int)Vuv.size(); ii++)
					{
						if (status[ii] == 0 || ToDel[ii] == 1 || points[1][ii].x < 0)
							points[1][ii] = Point2f(-1, -1), ToDel[ii] = 1;
						else
						{
							double BiDirDist = norm(points[2][ii] - Vuv[ii]);
							if (BiDirDist < bidir_Thresh*gray.cols / 1920)
								allDistance.push_back(norm(points[1][ii] - points[0][ii])), tracklets[ii].push_back(points[1][ii]), tNpts++;
							else
								points[1][ii] = Point2f(-1, -1), ToDel[ii] = 1;
						}
					}
				}
				else
				{
#pragma omp parallel for schedule(dynamic, 1)
					for (int pid = 0; pid < (int)Vuv.size(); pid++)
					{
						int threadID = omp_get_thread_num();
						if (ToDel[pid] == 1)
							continue;

						LKParameters LKArg; //LKArg.hsubset to be changed according to the point scale
						LKArg.DisplacementThresh = bidir_Thresh, LKArg.DIC_Algo = 3, LKArg.InterpAlgo = interpAlgo, LKArg.EpipEnforce = 0;
						LKArg.Incomplete_Subset_Handling = 0, LKArg.Convergence_Criteria = 0, LKArg.Analysis_Speed = 0, LKArg.IterMax = 15;
						LKArg.PSSDab_thresh = 0.1, LKArg.ZNCCThreshold = 0.7;
						double bestcwarp[4], besticwarp[4], cwarp[4], icwarp[4];

						Point2d bestNpt;
						double dist, minDist = 9e9;
						vector<double> vdist;
						int winsize = max(min((int)(ForeScale[pid][localfid - 1] * 6 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5)), orghsubset = winsize / 2 + 1;

						for (int trial = 0; trial < nWindows; trial++)  //Look for the best window size with minimum drift and consistent flow wrst the ref template:
						{
							LKArg.hsubset = orghsubset - trial * WinStep / 2;
							Point2d refpt = Vuv[pid], npt = points[1][pid], brefpt = Vuv[pid];

							for (int ii = 0; ii < 4; ii++)
								cwarp[ii] = ForeWarp[pid][localfid - 1].warp[ii];
							double score1 = TemplateMatching(ImgIParaR, ImgIParaC, width, height, width, height, 1, refpt, npt, LKArg, false, T1 + WinLength * threadID, T2 + 6 * WinLength*threadID, cwarp);
							if (score1 < LKArg.ZNCCThreshold || npt.x <winsize || npt.y < winsize || npt.x >width - winsize || npt.y >height - winsize)
								continue;

							for (int ii = 0; ii < 4; ii++)
								icwarp[ii] = ForeiWarp[pid][localfid - 1].warp[ii];
							double score2 = TemplateMatching(ImgIParaC, ImgIParaR, width, height, width, height, 1, npt, brefpt, LKArg, false, T1 + WinLength * threadID, T2 + 6 * WinLength*threadID, icwarp);
							if (score2 < LKArg.ZNCCThreshold || brefpt.x <winsize || brefpt.y < winsize || brefpt.x >width - winsize || brefpt.y >height - winsize)
								continue;

							dist = pow(brefpt.x - refpt.x, 2) + pow(brefpt.y - refpt.y, 2);
							vdist.push_back(sqrt(dist));
							if (dist < minDist && dist < dispThresh2)
							{
								minDist = dist, bestNpt = npt;
								for (int ii = 0; ii < 4; ii++)
									bestcwarp[ii] = cwarp[ii], besticwarp[ii] = icwarp[ii];
							}
						}

						ToDel[pid] = true;
						if (minDist < dispThresh2)
						{
							points[1][pid] = bestNpt;

							ForeWarp[pid].push_back(AffinePara(bestcwarp));
							ForeiWarp[pid].push_back(AffinePara(besticwarp));

							ToDel[pid] = false;
							double ns = ForeScale[pid][0] * max(ForeWarp[pid][localfid].warp[0] + 1.0 + ForeWarp[pid][localfid].warp[1], ForeWarp[pid][localfid].warp[2] + ForeWarp[pid][localfid].warp[3] + 1.0);
							ForeScale[pid].push_back(ns);

#pragma omp critical
							allDistance.push_back(norm(points[1][pid] - Vuv[pid])), tracklets[pid].push_back(points[1][pid]), tNpts++;
						}
					}
				}

				if (tNpts > Vuv.size() / 10)
				{
					sort(allDistance.begin(), allDistance.end());
					avgmagFlow = allDistance[tNpts / 5]; //take 20% percentile as the reference
					RefTrackingRatio = 1.0* tNpts / Vuv.size();
				}
				else
					RefTrackingRatio = 0, curTrackingRatio = 0, avgmagFlow = 9e9; //force to updae

			}
			else
				RefTrackingRatio = 0, curTrackingRatio = 0, avgmagFlow = 9e9; //force to update

			if (display > 0)
				printLOG("%d/%d : #Points: %.4d. Ref flow strength: %.2f. Intermediate flow strength: %.2f. RefTracking: %.2f CurTracking: %.2f...\n", fid, viewID, allDistance.size(), avgmagFlow, iavgmagFlow, RefTrackingRatio, curTrackingRatio);
			bool flag1 = RefTrackingRatio < successRefTrackingRatio;
			bool flag2 = curTrackingRatio < successConsecutiveTrackingRatio;
			bool flag3 = iavgmagFlow > avgflowMagThresh / 1920 * rPyr[0].cols;
			if (flag1 || flag2 || flag3)
				break;

			//std::swap(ImgIParaC, ImgIParaP);
			std::swap(pPyr, cPyr);
			std::swap(prevGray, gray);
			std::swap(points[0], points[1]);
		}

		//write out tracklet
		if (binary)
		{
			sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.dat", Path, viewID, startF);
			ofstream fout; fout.open(Fname, ios::binary);
			int n = (int)tracklets.size();
			fout.write(reinterpret_cast<char *>(&n), sizeof(int));
			for (int ii = 0; ii < (int)tracklets.size(); ii++)
			{
				int id = VtwoDID[ii], len = (int)tracklets[ii].size();
				fout.write(reinterpret_cast<char *>(&id), sizeof(int));
				fout.write(reinterpret_cast<char *>(&len), sizeof(int));
				for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
				{
					float u = (float)tracklets[ii][jj].x, v = (float)tracklets[ii][jj].y, s = (float)ForeScale[ii][jj];
					fout.write(reinterpret_cast<char *>(&u), sizeof(float));
					fout.write(reinterpret_cast<char *>(&v), sizeof(float));
					fout.write(reinterpret_cast<char *>(&s), sizeof(float));
				}
			}
			fout.close();
		}
		else
		{
			sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.txt", Path, viewID, startF); fp = fopen(Fname, "w+");
			for (int ii = 0; ii < (int)tracklets.size(); ii++)
			{
				fprintf(fp, "%d %d ", VtwoDID[ii], (int)tracklets[ii].size());
				for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
					fprintf(fp, "%.3f %.3f %.3f ", tracklets[ii][jj].x, tracklets[ii][jj].y, ForeScale[ii][jj]);
				fprintf(fp, "\n");
			}
			fclose(fp);
		}

		//write PnP
		vector<pair<int, Point3f> > *PnPPoints = new vector<pair<int, Point3f>>[fid - startF + 1];
		for (int ii = 0; ii < (int)tracklets.size(); ii++)
			for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
				PnPPoints[jj].push_back(std::make_pair(VthreeDID[ii], Point3f(tracklets[ii][jj].x, tracklets[ii][jj].y, ForeScale[ii][jj])));

		for (int fidi = startF; fidi <= fid; fidi++)
		{
			sprintf(Fname, "%s/%d/PnPTc/Inliers_%d_%.4d.txt", Path, viewID, startF, fidi); fp = fopen(Fname, "w");
			fprintf(fp, "%d\n", PnPPoints[fidi - startF].size());
			for (int ii = 0; ii < (int)PnPPoints[fidi - startF].size(); ii++)
				fprintf(fp, "%d %.3f %.3f %.3f\n", PnPPoints[fidi - startF][ii].first, PnPPoints[fidi - startF][ii].second.x, PnPPoints[fidi - startF][ii].second.y, PnPPoints[fidi - startF][ii].second.z);
			fclose(fp);
		}

		delete[]PnPPoints;
		rPyr.clear(), tracklets.clear(), points[0].clear(), points[1].clear();
	}

	//Work on backward track
	hasCache = false;
	sprintf(Fname, "%s/cTrack2D/LBT_%d_%.4d.dat", Path, viewID, startF);
	if (IsFileExist(Fname) == 1)
		hasCache = true;
	else
	{
		sprintf(Fname, "%s/cTrack2D/LBT_%d_%.4d.txt", Path, viewID, startF);
		if (IsFileExist(Fname) == 1)
			hasCache = true;
	}

	if (hasCache)
	{
#pragma omp critical
		printLOG("Found cache for #%d\n", keyFrameID);
		int localPid = 0, maxnf = 0;
		vector<int> VthreeDID2;
		vector<float> Vscale2;
		vector<Point2f> *BackTrackUV = new vector<Point2f>[VtwoDID.size()];
		if (binary)
		{
			ifstream fin;
			fin.open(Fname, ios::binary);
			fin.read(reinterpret_cast<char *>(&n), sizeof(int));
			for (int jj = 0; jj < n; jj++)
			{
				fin.read(reinterpret_cast<char *>(&pid), sizeof(int));
				fin.read(reinterpret_cast<char *>(&nf), sizeof(int));

				maxnf = max(maxnf, nf);
				vector<Point2f> Tracklet(nf);
				BackTrackUV[localPid].clear();
				for (int ii = 0; ii < nf; ii++)
				{
					fin.read(reinterpret_cast<char *>(&uv.x), sizeof(float));
					fin.read(reinterpret_cast<char *>(&uv.y), sizeof(float));
					fin.read(reinterpret_cast<char *>(&s), sizeof(float));
					BackTrackUV[localPid].push_back(uv);
				}

				int foundID = -1; //consists of all sift points but only some of them pass the sfm selection
				for (size_t ii = 0; ii < VtwoDID.size() && foundID == -1; ii++)
					if (pid == VtwoDID[ii])
						foundID = ii;

				if (foundID != -1)
				{
					VthreeDID2.push_back(VthreeDID[foundID]);
					Vscale2.push_back(Vscale[foundID]);
					localPid++;
				}
			}
			fin.close();
		}
		else
		{
			fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d ", &pid, &nf) != EOF)
			{
				if (pid < 0 || nf < 0)
					break;
				maxnf = max(maxnf, nf);
				BackTrackUV[localPid].clear();
				for (int ii = 0; ii < nf; ii++)
				{
					fscanf(fp, "%f %f ", &uv.x, &uv.y);
					BackTrackUV[localPid].push_back(uv);
				}

				int foundID = -1; //consists of all sift points but only some of them pass the sfm selection
				for (size_t ii = 0; ii < VtwoDID.size() && foundID == -1; ii++)
					if (pid == VtwoDID[ii])
						foundID = ii;

				if (foundID != -1)
				{
					VthreeDID2.push_back(VthreeDID[foundID]);
					Vscale2.push_back(Vscale[foundID]);
					localPid++;
				}
			}
			fclose(fp);
		}

		//write PnP
		vector<pair<int, Point3f> > *PnPPoints = new vector<pair<int, Point3f>>[maxnf];
		for (int ii = 0; ii < localPid; ii++)
			for (int jj = 0; jj < (int)BackTrackUV[ii].size(); jj++)
				PnPPoints[jj].push_back(std::make_pair(VthreeDID2[ii], Point3f(BackTrackUV[ii][jj].x, BackTrackUV[ii][jj].y, Vscale2[ii])));

		for (int fidi = 0; fidi < maxnf; fidi++)
		{
			sprintf(Fname, "%s/%d/PnPTc/Inliers_%d_%.4d.txt", Path, viewID, startF, startF - fidi); fp = fopen(Fname, "w");
			fprintf(fp, "%d\n", PnPPoints[fidi].size());
			for (int ii = 0; ii < (int)PnPPoints[fidi].size(); ii++)
				fprintf(fp, "%d %.3f %.3f %.3f\n", PnPPoints[fidi][ii].first, PnPPoints[fidi][ii].second.x, PnPPoints[fidi][ii].second.y, PnPPoints[fidi][ii].second.z);
			fclose(fp);
		}

		delete[]PnPPoints, delete[]BackTrackUV;
	}
	else //lets compute it
	{
		int fid, localfid = 0;
		for (fid = startF; fid >= startF - TrackRange; fid--)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, fid);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n", Fname);
					break;
				}
			}
			gray = imread(Fname, 0);
			buildOpticalFlowPyramid(gray, cPyr, winSize, npryLevels, true);

			width = gray.cols, height = gray.rows;
			if (ImgIParaC == NULL)
				ImgIParaC = new double[height*width], ImgIParaR = new double[height*width];
			Generate_Para_Spline(gray.data, ImgIParaC, width, height, interpAlgo);
			double ratio = 1.0*gray.cols / 1920;

			if (fid == startF)
			{
				winSize.width = winDim * gray.cols / 1920;
				winSize.height = winDim * gray.cols / 1920;
				points[0] = Vuv;
				for (size_t pid = 0; pid < Vuv.size(); pid++)
				{
					vector<Point2f> track; track.push_back(Vuv[pid]);
					tracklets.push_back(track);
					ToDel[pid] = false;
				}
				buildOpticalFlowPyramid(gray, rPyr, winSize, npryLevels, true);
				Generate_Para_Spline(gray.data, ImgIParaR, width, height, interpAlgo);

				swap(pPyr, cPyr);
				swap(prevGray, gray);
				continue;
			}
			localfid++;

			if (display > 0)
			{
				cvtColor(prevGray, backGround, CV_GRAY2BGR);
				for (int pid = 0; pid < points[0].size(); pid++)
				{
					if (!ToDel[pid])
					{
						circle(backGround, points[0][pid], 1, colors[pid % 8], 2);
						if (display == 2)
							circle(backGround, points[0][pid], max(1, max(min((int)(BackScale[pid][localfid - 1] * 3 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5))), colors[pid % 8], 2);
					}
				}

				CvPoint text_origin = { backGround.cols / 30, backGround.cols / 30 };
				sprintf(Fname, "@%d->%d", startF, fid);
				putText(backGround, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * backGround.cols / 640, CV_RGB(0, 255, 0), 2);
				if (display == 1)
					sprintf(Fname, "Tracking of Camera %d", viewID), imshow(Fname, backGround), waitKey(2);
			}

			int pNpts = 0, tNpts = 0;
			double iavgmagFlow, avgmagFlow, curTrackingRatio, RefTrackingRatio;

			status.clear(), err.clear(), points[1].clear();
			points[2] = points[0];
			calcOpticalFlowPyrLK(pPyr, cPyr, points[0], points[1], status, err, winSize, npryLevels, termcrit); //forward
			calcOpticalFlowPyrLK(cPyr, pPyr, points[1], points[2], status, err, winSize, npryLevels, termcrit); //backward

			allDistance.clear();
			for (size_t pid = 0; pid < points[0].size(); pid++)
			{
				if (points[0][pid].x > 0 && points[0][pid].y > 0)
					pNpts++;
				if (status[pid] == 0 || ToDel[pid] == 1 || points[0][pid].x < 0)
					points[1][pid] = Point2f(-1, -1);
				else
				{
					double BiDirDist = norm(points[2][pid] - points[0][pid]);
					if (BiDirDist < bidir_Thresh*gray.cols / 1920)
						allDistance.push_back(norm(points[1][pid] - points[0][pid])),
						tNpts++;
					else
						points[1][pid] = Point2f(-1, -1), ToDel[pid] = 1;
				}
			}
			sort(allDistance.begin(), allDistance.end());

			if (tNpts < points[0].size() / 10)
				iavgmagFlow = 9e9;
			else
				iavgmagFlow = allDistance[tNpts / 5]; //take 20% percentile as the reference
			curTrackingRatio = 1.0* tNpts / pNpts;

			if (tNpts > points[0].size() / 10)
			{
				tNpts = 0;
				allDistance.clear();
				if (!highQualityTracker)
				{
					points[2] = Vuv;
					calcOpticalFlowPyrLK(rPyr, cPyr, Vuv, points[1], status, err, winSize, max(0, npryLevels - 1), termcrit); //from refF to current frame with init
					calcOpticalFlowPyrLK(cPyr, rPyr, points[1], points[2], status, err, winSize, max(0, npryLevels - 1), termcrit); //from current to ref frame with init

					for (int ii = 0; ii < (int)Vuv.size(); ii++)
					{
						if (status[ii] == 0 || ToDel[ii] == 1 || points[1][ii].x < 0)
							points[1][ii] = Point2f(-1, -1), ToDel[ii] = true;
						else
						{
							double BiDirDist = norm(points[2][ii] - Vuv[ii]);
							if (BiDirDist < bidir_Thresh*gray.cols / 1920)
								allDistance.push_back(norm(points[1][ii] - points[0][ii])), tracklets[ii].push_back(points[1][ii]), tNpts++;
							else
								points[1][ii] = Point2f(-1, -1), ToDel[ii] = true;
						}
					}
				}
				else
				{
#pragma omp parallel for schedule(dynamic, 1)
					for (int pid = 0; pid < (int)Vuv.size(); pid++)
					{
						int threadID = omp_get_thread_num();
						if (ToDel[pid])
							continue;

						LKParameters LKArg; //LKArg.hsubset to be changed according to the point scale
						LKArg.DisplacementThresh = bidir_Thresh, LKArg.DIC_Algo = 3, LKArg.InterpAlgo = interpAlgo, LKArg.EpipEnforce = 0;
						LKArg.Incomplete_Subset_Handling = 0, LKArg.Convergence_Criteria = 0, LKArg.Analysis_Speed = 0, LKArg.IterMax = 15;
						LKArg.PSSDab_thresh = 0.1, LKArg.ZNCCThreshold = 0.7;
						double bestcwarp[4], besticwarp[4], cwarp[4], icwarp[4];

						Point2d bestNpt;
						double minDist = 9e9;
						int winsize = max(min((int)(BackScale[pid][localfid - 1] * 6 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5)), orghsubset = winsize / 2 + 1;

						for (int trial = 0; trial < nWindows; trial++)  //Look for the best window size with minimum drift and consistent flow wrst the ref template:
						{
							LKArg.hsubset = orghsubset - trial * WinStep / 2;
							Point2d refpt = Vuv[pid], npt = points[1][pid], brefpt = Vuv[pid];

							for (int ii = 0; ii < 4; ii++)
								cwarp[ii] = BackWarp[pid][localfid - 1].warp[ii];
							double score1 = TemplateMatching(ImgIParaR, ImgIParaC, width, height, width, height, 1, refpt, npt, LKArg, false, T1 + WinLength * threadID, T2 + 6 * WinLength*threadID, cwarp);
							if (score1 < LKArg.ZNCCThreshold || npt.x <winsize || npt.y < winsize || npt.x >width - winsize || npt.y >height - winsize)
								continue;

							for (int ii = 0; ii < 4; ii++)
								icwarp[ii] = BackiWarp[pid][localfid - 1].warp[ii];
							double score2 = TemplateMatching(ImgIParaC, ImgIParaR, width, height, width, height, 1, npt, brefpt, LKArg, false, T1 + WinLength * threadID, T2 + 6 * WinLength*threadID, icwarp);
							if (score2 < LKArg.ZNCCThreshold || brefpt.x <winsize || brefpt.y < winsize || brefpt.x >width - winsize || brefpt.y >height - winsize)
								continue;

							double dist = pow(brefpt.x - refpt.x, 2) + pow(brefpt.y - refpt.y, 2);
							if (dist < minDist && dist < dispThresh2)
							{
								minDist = dist, bestNpt = npt;
								for (int ii = 0; ii < 4; ii++)
									bestcwarp[ii] = cwarp[ii], besticwarp[ii] = icwarp[ii];
							}
						}

						ToDel[pid] = true;
						if (minDist < dispThresh2)
						{
							points[1][pid] = bestNpt;

							BackWarp[pid].push_back(AffinePara(bestcwarp));
							BackiWarp[pid].push_back(AffinePara(besticwarp));

							ToDel[pid] = false;
							double ns = BackScale[pid][0] * max(BackWarp[pid][localfid].warp[0] + 1.0 + BackWarp[pid][localfid].warp[1], BackWarp[pid][localfid].warp[2] + BackWarp[pid][localfid].warp[3] + 1.0);
							BackScale[pid].push_back(ns);

#pragma omp critical
							allDistance.push_back(norm(points[1][pid] - Vuv[pid])), tracklets[pid].push_back(points[1][pid]), tNpts++;
						}
					}
				}

				if (tNpts > Vuv.size() / 10)
				{
					sort(allDistance.begin(), allDistance.end());
					avgmagFlow = allDistance[tNpts / 5]; //take 20% percentile as the reference
					RefTrackingRatio = 1.0* tNpts / Vuv.size();
				}
				else
					RefTrackingRatio = 0, curTrackingRatio = 0, avgmagFlow = 9e9; //force to updae
			}
			else
				RefTrackingRatio = 0, curTrackingRatio = 0, avgmagFlow = 9e9; //force to update

			if (display > 0)
				printLOG("%d/%d : #Points: %.4d. Ref flow strength: %.2f. Intermediate flow strength: %.2f. RefTracking: %.2f CurTracking: %.2f...\n", fid, viewID, allDistance.size(), avgmagFlow, iavgmagFlow, RefTrackingRatio, curTrackingRatio);
			bool flag1 = RefTrackingRatio < successRefTrackingRatio;
			bool flag2 = curTrackingRatio < successConsecutiveTrackingRatio;
			bool flag3 = iavgmagFlow > avgflowMagThresh / 1920 * rPyr[0].cols;
			if (flag1 || flag2 || flag3)
				break;

			swap(pPyr, cPyr);
			swap(prevGray, gray);
			swap(points[0], points[1]);
		}

		//write out tracklet
		if (binary)
		{
			sprintf(Fname, "%s/cTrack2D/LBT_%d_%.4d.dat", Path, viewID, startF);
			ofstream fout; fout.open(Fname, ios::binary);
			int n = (int)tracklets.size(); fout.write(reinterpret_cast<char *>(&n), sizeof(int));
			for (int ii = 0; ii < n; ii++)
			{
				int id = VtwoDID[ii], len = (int)tracklets[ii].size();
				fout.write(reinterpret_cast<char *>(&id), sizeof(int));
				fout.write(reinterpret_cast<char *>(&len), sizeof(int));
				for (int jj = 0; jj < len; jj++)
				{
					float u = (float)tracklets[ii][jj].x, v = (float)tracklets[ii][jj].y, s = (float)BackScale[ii][jj];
					fout.write(reinterpret_cast<char *>(&u), sizeof(float));
					fout.write(reinterpret_cast<char *>(&v), sizeof(float));
					fout.write(reinterpret_cast<char *>(&s), sizeof(float));
				}
			}
			fout.close();
		}
		else
		{
			sprintf(Fname, "%s/cTrack2D/LBT_%d_%.4d.txt", Path, viewID, startF); fp = fopen(Fname, "w+");
			for (int ii = 0; ii < (int)tracklets.size(); ii++)
			{
				fprintf(fp, "%d %d ", VtwoDID[ii], (int)tracklets[ii].size());
				for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
					fprintf(fp, "%.3f %.3f %.3f ", tracklets[ii][jj].x, tracklets[ii][jj].y, BackScale[ii][jj]);
				fprintf(fp, "\n");
			}
			fclose(fp);
		}

		//write PnP
		vector<pair<int, Point3f> > *PnPPoints = new vector<pair<int, Point3f>>[startF - fid + 1];
		for (int ii = 0; ii < (int)tracklets.size(); ii++)
			for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
				PnPPoints[jj].push_back(std::make_pair(VthreeDID[ii], Point3f(tracklets[ii][jj].x, tracklets[ii][jj].y, Vscale[ii])));

		for (int fidi = startF; fidi >= fid; fidi--)
		{
			sprintf(Fname, "%s/%d/PnPTc/Inliers_%d_%.4d.txt", Path, viewID, startF, fidi); fp = fopen(Fname, "w");
			fprintf(fp, "%d\n", PnPPoints[startF - fidi].size());
			for (int ii = 0; ii < (int)PnPPoints[startF - fidi].size(); ii++)
				fprintf(fp, "%d %.3f %.3f %.3f\n", PnPPoints[startF - fidi][ii].first, PnPPoints[startF - fidi][ii].second.x, PnPPoints[startF - fidi][ii].second.y, PnPPoints[startF - fidi][ii].second.z);
			fclose(fp);
		}

		delete[]PnPPoints;
		cPyr.clear(), tracklets.clear(), points[0].clear(), points[1].clear();
	}

	if (display > 01)
		cvDestroyAllWindows();

	delete[]ToDel, delete[]ImgIParaC, delete[]ImgIParaR, delete[]T1, delete[]T2;
	delete[]ForeScale, delete[]BackScale, delete[]ForeWarp, delete[]ForeiWarp, delete[]BackWarp, delete[]BackiWarp;

	return 0;
}
int TrackGlocalLocalCorpusFeatureToNonKeyFrames(char *Path, int viewID, int keyFrameID, int startF, int TrackRange, int winDim, int npryLevels, double bidir_Thresh, double successConsecutiveTrackingRatio, double successRefTrackingRatio, double avgflowMagThresh, int interpAlgo, bool highQualityTracker, int nThreads, int display)
{
	int nWindows = 3, WinStep = 3, MaxWinSize = 77, MinWinSize = 11;
	double dispThresh2 = bidir_Thresh * bidir_Thresh;

	char Fname[512];
	sprintf(Fname, "%s/cTrack2D", Path), makeDir(Fname);
	sprintf(Fname, "%s/%d/PnPTc", Path, viewID); makeDir(Fname);
	sprintf(Fname, "%s/%d/PnPmTc", Path, viewID), makeDir(Fname);

	int Global3DId, Local3DId, twoDID, pid, nf, n;
	float x, y, z, s;
	Point2f uv;
	vector<Point2f> Vuv, _Vuv; Vuv.reserve(5000), _Vuv.reserve(5000);
	vector<int> VGlobal3DId, VLocal3DId; VGlobal3DId.reserve(5000), VLocal3DId.reserve(5000);
	vector<int> VtwoDID; VtwoDID.reserve(5000);
	vector<float> Vscale; Vscale.reserve(5000);

	sprintf(Fname, "%s/%d/PnP/KF_Inliers_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return -1;
	}
	while (fscanf(fp, "%d %d %f %f %f %d %f %f %f ", &Global3DId, &Local3DId, &x, &y, &z, &twoDID, &uv.x, &uv.y, &s) != EOF)
	{
		bool found = false;
		for (int ii = 0; ii < VtwoDID.size() && !found; ii++)
			if (VtwoDID[ii] == twoDID)
				found = true;

		if (!found)
		{
			VGlobal3DId.push_back(Global3DId);
			VLocal3DId.push_back(Local3DId);
			VtwoDID.push_back(twoDID);
			_Vuv.push_back(uv);
			Vscale.push_back(s);
		}
	}
	fclose(fp);

	if (VtwoDID.size() == 0)
		return 0;

	vector<KeyPoint> kpts;
	sprintf(Fname, "%s/%d/%.4d.sift", Path, viewID, startF); //the sift file in Corpus folder is a replicate of this file
	if (readVisualSFMSiftGPU(Fname, kpts) == 1)
		return -1;
	for (size_t ii = 0; ii < VtwoDID.size(); ii++)
	{
		double dist = sqrt(pow(_Vuv[ii].x - kpts[VtwoDID[ii]].pt.x, 2) + pow(_Vuv[ii].y - kpts[VtwoDID[ii]].pt.y, 2));
		if (dist > 200)
		{
			printLOG("**************\n\n\n\nDif between sift and PnP %d_%.4d**************\n\n\n\n", viewID, startF);
			return -1;
		}
		Vuv.push_back(kpts[VtwoDID[ii]].pt);
	}

	Mat gray, prevGray, backGround;
	vector<Mat> pPyr, cPyr, rPyr;
	vector<Point2f> points[3];
	vector<uchar> status;
	vector<float> err;
	bool *ToDel = new bool[Vuv.size()];
	vector<vector<Point2f> > tracklets;

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255)), colors.push_back(Scalar(0, 128, 255)), colors.push_back(Scalar(0, 255, 255)), colors.push_back(Scalar(0, 255, 0)), colors.push_back(Scalar(255, 128, 0)), colors.push_back(Scalar(255, 255, 0)), colors.push_back(Scalar(255, 0, 0)), colors.push_back(Scalar(255, 0, 255)), colors.push_back(Scalar(255, 255, 255));
	if (display > 0)
		sprintf(Fname, "Tracking of Camera %d", viewID), namedWindow(Fname, WINDOW_NORMAL);

	vector<float>allDistance; allDistance.reserve(10000);
	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, 0.03);
	Size winSize(winDim, winDim);
	int width, height, WinLength = (MaxWinSize + 2)*(MaxWinSize + 2) * 2;
	double *ImgIParaC = NULL, *ImgIParaP = NULL, *ImgIParaR = NULL;
	double *T1 = new double[WinLength*nThreads], *T2 = new double[6 * WinLength*nThreads];

	vector<float> *ForeScale = new vector<float>[Vuv.size()], *BackScale = new vector<float>[Vuv.size()];
	vector<AffinePara> *ForeWarp = new vector<AffinePara>[Vuv.size()], *ForeiWarp = new vector<AffinePara>[Vuv.size()], *BackWarp = new vector<AffinePara>[Vuv.size()], *BackiWarp = new vector<AffinePara>[Vuv.size()];
	for (size_t ii = 0; ii < Vuv.size(); ii++)
	{
		AffinePara w1, w2, w3, w4;
		ForeScale[ii].reserve(TrackRange), ForeScale[ii].push_back(Vscale[ii]);
		BackScale[ii].reserve(TrackRange), BackScale[ii].push_back(Vscale[ii]);
		ForeWarp[ii].reserve(TrackRange), ForeWarp[ii].push_back(w1);
		BackWarp[ii].reserve(TrackRange), BackWarp[ii].push_back(w2);
		ForeiWarp[ii].reserve(TrackRange), ForeiWarp[ii].push_back(w3);
		BackiWarp[ii].reserve(TrackRange), BackiWarp[ii].push_back(w4);
	}

	if (nThreads > 1)
		omp_set_num_threads(nThreads);

	bool binary = true;

	//Forward track: computed during keyframe gen. Retrieved its info to write out to PnP
	bool hasCache = false;
	sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.dat", Path, viewID, startF);
	if (IsFileExist(Fname) == 1)
		hasCache = true;
	else
	{
		sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.txt", Path, viewID, startF);
		if (IsFileExist(Fname) == 1)
			hasCache = true;
	}
	if (hasCache)
	{
		printLOG("Found FT cache for #%d\n", keyFrameID);
		int localPid = 0, maxnf = 0;
		vector<int> VGlobal3DID2, VLocal3DID2;
		vector<bool>trackingIndeedFulfill(VtwoDID.size());
		for (size_t ii = 0; ii < VtwoDID.size(); ii++)
			trackingIndeedFulfill[ii] = false;

		Point3f uvs;
		vector<Point3f> *ForeTrackUVS = new vector<Point3f>[VtwoDID.size()];
		if (binary)
		{
			ifstream fin;
			fin.open(Fname, ios::binary);
			fin.read(reinterpret_cast<char *>(&n), sizeof(int));
			for (int jj = 0; jj < n && hasCache; jj++)
			{
				fin.read(reinterpret_cast<char *>(&pid), sizeof(int));
				fin.read(reinterpret_cast<char *>(&nf), sizeof(int));

				maxnf = max(maxnf, nf);
				vector<Point2f> Tracklet(nf);
				ForeTrackUVS[localPid].clear();
				for (int ii = 0; ii < nf; ii++)
				{
					fin.read(reinterpret_cast<char *>(&uvs.x), sizeof(float));
					fin.read(reinterpret_cast<char *>(&uvs.y), sizeof(float));
					fin.read(reinterpret_cast<char *>(&uvs.z), sizeof(float));
					ForeTrackUVS[localPid].push_back(uvs);
				}

				int foundID = -1; //consists of all sift points but only some of them pass the sfm selection
				for (size_t ii = 0; ii < VtwoDID.size() && foundID == -1 && hasCache; ii++)
				{
					if (pid == VtwoDID[ii])
					{
						double dist = sqrt(pow(ForeTrackUVS[localPid][0].x - kpts[pid].pt.x, 2) + pow(ForeTrackUVS[localPid][0].y - kpts[pid].pt.y, 2));
						if (dist < 1)
							foundID = ii;
						else
							hasCache = false;
					}
				}

				if (foundID != -1)
				{
					trackingIndeedFulfill[foundID] = true;
					VGlobal3DID2.push_back(VGlobal3DId[foundID]);
					VLocal3DID2.push_back(VLocal3DId[foundID]);
					localPid++;
				}
				if (localPid >= VtwoDID.size())
					break;
			}
			fin.close();
		}
		else
		{
			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d ", &pid, &nf) != EOF)
			{
				if (pid < 0 || nf < 0 || !hasCache)
					break;
				maxnf = max(maxnf, nf);
				ForeTrackUVS[localPid].clear();
				for (int ii = 0; ii < nf; ii++)
				{
					fscanf(fp, "%f %f %f ", &uvs.x, &uvs.y, &uvs.z);
					ForeTrackUVS[localPid].push_back(uvs);
				}

				int foundID = -1; //consists of all sift points but only some of them pass the sfm selection
				for (size_t ii = 0; ii < VtwoDID.size() && foundID == -1 && hasCache; ii++)
				{
					if (pid == VtwoDID[ii])
					{
						double dist = sqrt(pow(ForeTrackUVS[localPid][0].x - kpts[pid].pt.x, 2) + pow(ForeTrackUVS[localPid][0].y - kpts[pid].pt.y, 2));
						if (dist < 1)
							foundID = ii;
						else
							hasCache = false;
					}
				}

				if (foundID != -1)
				{
					trackingIndeedFulfill[foundID] = true;
					VGlobal3DID2.push_back(VGlobal3DId[foundID]);
					VLocal3DID2.push_back(VLocal3DId[foundID]);
					for (size_t jj = 0; jj < ForeTrackUVS[localPid].size(); jj++)
						ForeTrackUVS[localPid][jj].z = Vscale[foundID];
					localPid++;
				}
				if (localPid >= VtwoDID.size())
					break;
			}
			fclose(fp);
		}

		for (size_t ii = 0; ii < VtwoDID.size(); ii++)
		{
			if (!trackingIndeedFulfill[ii])
			{
				hasCache = false;
				printLOG("Reading from %s but not all PnP are fulfilled\n", Fname);
				break;
			}
		}

		if (hasCache)
		{
			/*//write PnP
			vector<pair<Point2i, Point3f> > *PnPPoints = new vector<pair<Point2i, Point3f>>[maxnf];
			for (int ii = 0; ii < localPid; ii++)
			for (int jj = 0; jj < (int)ForeTrackUVS[ii].size(); jj++)
			PnPPoints[jj].push_back(std::make_pair(Point2i(VGlobal3DID2[ii], VLocal3DID2[ii]), Point3f(ForeTrackUVS[ii][jj].x, ForeTrackUVS[ii][jj].y, ForeTrackUVS[ii][jj].z)));

			for (int fidi = startF; fidi <= startF + maxnf - 1; fidi++)
			{
			sprintf(Fname, "%s/%d/PnPTc/Inliers_%d_%.4d.txt", Path, viewID, startF, fidi); FILE *fp = fopen(Fname, "w");
			fprintf(fp, "%d\n", PnPPoints[fidi - startF].size());
			for (int ii = 0; ii < (int)PnPPoints[fidi - startF].size(); ii++)
			fprintf(fp, "%d %d %.3f %.3f %.3f\n", PnPPoints[fidi - startF][ii].first.x, PnPPoints[fidi - startF][ii].first.y, PnPPoints[fidi - startF][ii].second.x, PnPPoints[fidi - startF][ii].second.y, PnPPoints[fidi - startF][ii].second.z);
			fclose(fp);
			}
			deletet []PnPPoints;	*/

			sprintf(Fname, "%s/%d/PnPTc/InliersF_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "w");
			for (int ii = 0; ii < localPid; ii++)
			{
				fprintf(fp, "%d %d %d\n", VGlobal3DID2[ii], VLocal3DID2[ii], ForeTrackUVS[ii].size());
				for (int jj = 0; jj < (int)ForeTrackUVS[ii].size(); jj++)
					fprintf(fp, "%.3f %.3f %.3f ", ForeTrackUVS[ii][jj].x, ForeTrackUVS[ii][jj].y, ForeTrackUVS[ii][jj].z);
				fprintf(fp, "\n");
			}
			fclose(fp);
		}

		delete[]ForeTrackUVS;
	}
	if (!hasCache) //lets compute it
	{
		int fid, localfid = 0;
		for (fid = startF; fid <= startF + TrackRange; fid++)
		{
			printLOG("%d..", fid);
			sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, fid);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n", Fname);
					break;
				}
			}
			gray = imread(Fname, 0);
			if (gray.empty())
				break;

			buildOpticalFlowPyramid(gray, cPyr, winSize, npryLevels, true);

			width = gray.cols, height = gray.rows;
			if (ImgIParaC == NULL)
				ImgIParaC = new double[height*width], ImgIParaR = new double[height*width];
			double ratio = 1.0*gray.cols / 1920;

			if (fid == startF)
			{
				winSize.width = winDim * gray.cols / 1920;
				winSize.height = winDim * gray.cols / 1920;
				points[0] = Vuv;
				for (size_t ii = 0; ii < Vuv.size(); ii++)
				{
					vector<Point2f> track; track.push_back(Vuv[ii]);
					tracklets.push_back(track);
					ToDel[ii] = false;
				}
				buildOpticalFlowPyramid(gray, rPyr, winSize, npryLevels, true);
				Generate_Para_Spline(gray.data, ImgIParaR, width, height, interpAlgo);

				//std::swap(ImgIParaC, ImgIParaP);
				std::swap(pPyr, cPyr);
				std::swap(prevGray, gray);
				continue;
			}
			localfid++;

			if (display > 0)
			{
				cvtColor(prevGray, backGround, CV_GRAY2BGR);
				int cnpts = 0;
				for (int pid = 0; pid < points[0].size(); pid++)
				{
					if (!ToDel[pid])
					{
						cnpts++;
						circle(backGround, points[0][pid], 1, colors[pid % 8], 2);
						if (display == 2)
							circle(backGround, points[0][pid], max(1, max(min((int)(ForeScale[pid][localfid - 1] * 3 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5))), colors[pid % 8], 2);
					}
				}

				CvPoint text_origin = { backGround.cols / 30, backGround.cols / 30 };
				sprintf(Fname, "@%d->%d: %d npts", startF, fid, cnpts);
				putText(backGround, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * backGround.cols / 640, CV_RGB(0, 255, 0), 2);
				if (display == 1)
					sprintf(Fname, "Tracking of Camera %d", viewID), imshow(Fname, backGround), waitKey(2);
			}

			Generate_Para_Spline(gray.data, ImgIParaC, width, height, interpAlgo);

			allDistance.clear();
			int pNpts = 0, tNpts = 0;
			double iavgmagFlow, avgmagFlow, curTrackingRatio, RefTrackingRatio;

			status.clear(), err.clear(), points[1].clear();
			points[2] = points[0];
			calcOpticalFlowPyrLK(pPyr, cPyr, points[0], points[1], status, err, winSize, npryLevels, termcrit); //forward
			calcOpticalFlowPyrLK(cPyr, pPyr, points[1], points[2], status, err, winSize, npryLevels, termcrit); //backward

			for (size_t pid = 0; pid < points[0].size(); pid++)
			{
				if (points[0][pid].x > 0 && points[0][pid].y > 0)
					pNpts++;
				if (status[pid] == 0 || ToDel[pid] == 1 || points[0][pid].x < 0)
					points[1][pid] = Point2f(-1, -1);
				else
				{
					double BiDirDist = norm(points[2][pid] - points[0][pid]);
					if (BiDirDist < bidir_Thresh*gray.cols / 1920)
						allDistance.push_back(norm(points[1][pid] - points[0][pid])),
						tNpts++;
					else
						points[1][pid] = Point2f(-1, -1), ToDel[pid] = 1;
				}
			}
			sort(allDistance.begin(), allDistance.end());

			if (tNpts < points[0].size() / 10)
				iavgmagFlow = 9e9;
			else
				iavgmagFlow = allDistance[tNpts / 5]; //take 20% percentile as the reference
			curTrackingRatio = 1.0* tNpts / pNpts;

			if (tNpts > (int)points[0].size() / 10)
			{
				tNpts = 0;
				allDistance.clear();

				if (!highQualityTracker)
				{
					points[2] = Vuv;
					calcOpticalFlowPyrLK(rPyr, cPyr, Vuv, points[1], status, err, winSize, max(0, npryLevels - 1), termcrit); //from refF to current frame with init
					calcOpticalFlowPyrLK(cPyr, rPyr, points[1], points[2], status, err, winSize, max(0, npryLevels - 1), termcrit); //from current to ref frame with init

					for (int ii = 0; ii < (int)Vuv.size(); ii++)
					{
						if (status[ii] == 0 || ToDel[ii] == 1 || points[1][ii].x < 0)
							points[1][ii] = Point2f(-1, -1), ToDel[ii] = 1;
						else
						{
							double BiDirDist = norm(points[2][ii] - Vuv[ii]);
							if (BiDirDist < bidir_Thresh*gray.cols / 1920)
								allDistance.push_back(norm(points[1][ii] - points[0][ii])), tracklets[ii].push_back(points[1][ii]), tNpts++;
							else
								points[1][ii] = Point2f(-1, -1), ToDel[ii] = 1;
						}
					}
				}
				else
				{
#pragma omp parallel for schedule(dynamic, 2)
					for (int pid = 0; pid < (int)Vuv.size(); pid++)
					{
						int threadID = omp_get_thread_num();
						if (ToDel[pid] == 1)
							continue;

						LKParameters LKArg; //LKArg.hsubset to be changed according to the point scale
						LKArg.DisplacementThresh = bidir_Thresh, LKArg.DIC_Algo = 3, LKArg.InterpAlgo = interpAlgo, LKArg.EpipEnforce = 0;
						LKArg.Incomplete_Subset_Handling = 0, LKArg.Convergence_Criteria = 0, LKArg.Analysis_Speed = 0, LKArg.IterMax = 15;
						LKArg.PSSDab_thresh = 0.1, LKArg.ZNCCThreshold = 0.7;
						double bestcwarp[4], besticwarp[4], cwarp[4], icwarp[4];

						Point2d bestNpt;
						double dist, minDist = 9e9;
						vector<double> vdist;
						int winsize = max(min((int)(ForeScale[pid][localfid - 1] * 6 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5)), orghsubset = winsize / 2 + 1;

						for (int trial = 0; trial < nWindows; trial++)  //Look for the best window size with minimum drift and consistent flow wrst the ref template:
						{
							LKArg.hsubset = orghsubset - trial * WinStep / 2;
							Point2d refpt = Vuv[pid], npt = points[1][pid], brefpt = Vuv[pid];

							for (int ii = 0; ii < 4; ii++)
								cwarp[ii] = ForeWarp[pid][localfid - 1].warp[ii];
							double score1 = TemplateMatching(ImgIParaR, ImgIParaC, width, height, width, height, 1, refpt, npt, LKArg, false, T1 + WinLength * threadID, T2 + 6 * WinLength*threadID, cwarp);
							if (score1 < LKArg.ZNCCThreshold || npt.x <winsize || npt.y < winsize || npt.x >width - winsize || npt.y >height - winsize)
								continue;

							for (int ii = 0; ii < 4; ii++)
								icwarp[ii] = ForeiWarp[pid][localfid - 1].warp[ii];
							double score2 = TemplateMatching(ImgIParaC, ImgIParaR, width, height, width, height, 1, npt, brefpt, LKArg, false, T1 + WinLength * threadID, T2 + 6 * WinLength*threadID, icwarp);
							if (score2 < LKArg.ZNCCThreshold || brefpt.x <winsize || brefpt.y < winsize || brefpt.x >width - winsize || brefpt.y >height - winsize)
								continue;

							dist = pow(brefpt.x - refpt.x, 2) + pow(brefpt.y - refpt.y, 2);
							vdist.push_back(sqrt(dist));
							if (dist < minDist && dist < dispThresh2)
							{
								minDist = dist, bestNpt = npt;
								for (int ii = 0; ii < 4; ii++)
									bestcwarp[ii] = cwarp[ii], besticwarp[ii] = icwarp[ii];
							}
						}

						ToDel[pid] = true;
						if (minDist < dispThresh2)
						{
							points[1][pid] = bestNpt;

							ForeWarp[pid].push_back(AffinePara(bestcwarp));
							ForeiWarp[pid].push_back(AffinePara(besticwarp));

							ToDel[pid] = false;
							double ns = ForeScale[pid][0] * max(ForeWarp[pid][localfid].warp[0] + 1.0 + ForeWarp[pid][localfid].warp[1], ForeWarp[pid][localfid].warp[2] + ForeWarp[pid][localfid].warp[3] + 1.0);
							ForeScale[pid].push_back(ns);

#pragma omp critical
							allDistance.push_back(norm(points[1][pid] - Vuv[pid])), tracklets[pid].push_back(points[1][pid]), tNpts++;
						}
					}
				}

				if (tNpts > Vuv.size() / 10)
				{
					sort(allDistance.begin(), allDistance.end());
					avgmagFlow = allDistance[tNpts / 5]; //take 20% percentile as the reference
					RefTrackingRatio = 1.0* tNpts / Vuv.size();
				}
				else
					RefTrackingRatio = 0, curTrackingRatio = 0, avgmagFlow = 9e9; //force to updae
			}
			else
				RefTrackingRatio = 0, curTrackingRatio = 0, avgmagFlow = 9e9; //force to update

			if (display > 0)
				printLOG("%d/%d : #Points: %.4d. Ref flow strength: %.2f. Intermediate flow strength: %.2f. RefTracking: %.2f CurTracking: %.2f...\n", fid, viewID, allDistance.size(), avgmagFlow, iavgmagFlow, RefTrackingRatio, curTrackingRatio);
			bool flag1 = RefTrackingRatio < successRefTrackingRatio;
			bool flag2 = curTrackingRatio < successConsecutiveTrackingRatio;
			bool flag3 = iavgmagFlow > avgflowMagThresh / 1920 * rPyr[0].cols;
			if (flag1 || flag2 || flag3)
				break;

			//std::swap(ImgIParaC, ImgIParaP);
			std::swap(pPyr, cPyr);
			std::swap(prevGray, gray);
			std::swap(points[0], points[1]);
		}
		printLOG("Done\n");

		//write out tracklet
		if (binary)
		{
			sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.dat", Path, viewID, startF);
			ofstream fout; fout.open(Fname, ios::binary);
			int n = (int)tracklets.size();
			fout.write(reinterpret_cast<char *>(&n), sizeof(int));
			for (int ii = 0; ii < (int)tracklets.size(); ii++)
			{
				int id = VtwoDID[ii], len = (int)tracklets[ii].size();
				fout.write(reinterpret_cast<char *>(&id), sizeof(int));
				fout.write(reinterpret_cast<char *>(&len), sizeof(int));
				for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
				{
					float u = (float)tracklets[ii][jj].x, v = (float)tracklets[ii][jj].y, s = (float)ForeScale[ii][jj];
					fout.write(reinterpret_cast<char *>(&u), sizeof(float));
					fout.write(reinterpret_cast<char *>(&v), sizeof(float));
					fout.write(reinterpret_cast<char *>(&s), sizeof(float));
				}
			}
			fout.close();
		}
		else
		{
			sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "w+");
			for (int ii = 0; ii < (int)tracklets.size(); ii++)
			{
				fprintf(fp, "%d %d ", VtwoDID[ii], (int)tracklets[ii].size());
				for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
					fprintf(fp, "%.3f %.3f %.3f ", tracklets[ii][jj].x, tracklets[ii][jj].y, ForeScale[ii][jj]);
				fprintf(fp, "\n");
			}
			fclose(fp);
		}

		/*//write PnP
		vector<pair<Point2i, Point3f> > *PnPPoints = new vector<pair<Point2i, Point3f>>[fid - startF + 1];
		for (int ii = 0; ii < (int)tracklets.size(); ii++)
		for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
		PnPPoints[jj].push_back(std::make_pair(Point2i(VGlobal3DId[ii], VLocal3DId[ii]), Point3f(tracklets[ii][jj].x, tracklets[ii][jj].y, ForeScale[ii][jj])));

		for (int fidi = startF; fidi <= fid; fidi++)
		{
		sprintf(Fname, "%s/%d/PnPTc/Inliers_%d_%.4d.txt", Path, viewID, startF, fidi); FILE *fp = fopen(Fname, "w");
		fprintf(fp, "%d\n", PnPPoints[fidi - startF].size());
		for (int ii = 0; ii < (int)PnPPoints[fidi - startF].size(); ii++)
		fprintf(fp, "%d %d %.3f %.3f %.3f\n", PnPPoints[fidi - startF][ii].first.x, PnPPoints[fidi - startF][ii].first.y, PnPPoints[fidi - startF][ii].second.x, PnPPoints[fidi - startF][ii].second.y, PnPPoints[fidi - startF][ii].second.z);
		fclose(fp);
		}
		delete[]PnPPoints;*/

		sprintf(Fname, "%s/%d/PnPTc/InliersF_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "w");
		for (size_t ii = 0; ii < tracklets.size(); ii++)
		{
			fprintf(fp, "%d %d %d\n", VGlobal3DId[ii], VLocal3DId[ii], tracklets[ii].size());
			for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
				fprintf(fp, "%.3f %.3f %.3f ", tracklets[ii][jj].x, tracklets[ii][jj].y, ForeScale[ii][jj]);
			fprintf(fp, "\n");
		}
		fclose(fp);

		rPyr.clear(), tracklets.clear(), points[0].clear(), points[1].clear();
	}

	//Work on backward track
	hasCache = false;
	sprintf(Fname, "%s/cTrack2D/LBT_%d_%.4d.dat", Path, viewID, startF);
	if (IsFileExist(Fname) == 1)
		hasCache = true;
	else
	{
		sprintf(Fname, "%s/cTrack2D/LBT_%d_%.4d.txt", Path, viewID, startF);
		if (IsFileExist(Fname) == 1)
			hasCache = true;
	}
	if (hasCache)
	{
		printLOG("Found BT cache for #%d\n", keyFrameID);
		int localPid = 0, maxnf = 0;
		vector<int> VGlobal3DID2, VLocal3DID2;
		vector<Point3f> *BackTrackUVS = new vector<Point3f>[VtwoDID.size()];
		vector<bool>trackingIndeedFulfill(VtwoDID.size());
		for (size_t ii = 0; ii < VtwoDID.size(); ii++)
			trackingIndeedFulfill[ii] = false;

		Point3f uvs;
		if (binary)
		{
			ifstream fin;
			fin.open(Fname, ios::binary);
			fin.read(reinterpret_cast<char *>(&n), sizeof(int));
			for (int jj = 0; jj < n; jj++)
			{
				fin.read(reinterpret_cast<char *>(&pid), sizeof(int));
				fin.read(reinterpret_cast<char *>(&nf), sizeof(int));

				maxnf = max(maxnf, nf);
				vector<Point2f> Tracklet(nf);
				BackTrackUVS[localPid].clear();
				for (int ii = 0; ii < nf; ii++)
				{
					fin.read(reinterpret_cast<char *>(&uvs.x), sizeof(float));
					fin.read(reinterpret_cast<char *>(&uvs.y), sizeof(float));
					fin.read(reinterpret_cast<char *>(&uvs.z), sizeof(float));
					BackTrackUVS[localPid].push_back(uvs);
				}

				int foundID = -1; //consists of all sift points but only some of them pass the sfm selection
				for (size_t ii = 0; ii < VtwoDID.size() && foundID == -1 && hasCache; ii++)
				{
					if (pid == VtwoDID[ii])
					{
						double dist = sqrt(pow(BackTrackUVS[localPid][0].x - kpts[pid].pt.x, 2) + pow(BackTrackUVS[localPid][0].y - kpts[pid].pt.y, 2));
						if (dist < 1)
							foundID = ii;
						else
							hasCache = false;
					}
				}

				if (foundID != -1)
				{
					trackingIndeedFulfill[foundID] = true;
					VGlobal3DID2.push_back(VGlobal3DId[foundID]);
					VLocal3DID2.push_back(VLocal3DId[foundID]);
					localPid++;
				}
				if (localPid >= VtwoDID.size())
					break;
			}
			fin.close();
		}
		else
		{
			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d ", &pid, &nf) != EOF)
			{
				if (pid < 0 || nf < 0)
					break;
				maxnf = max(maxnf, nf);
				BackTrackUVS[localPid].clear();
				for (int ii = 0; ii < nf; ii++)
				{
					fscanf(fp, "%f %f ", &uv.x, &uv.y);
					BackTrackUVS[localPid].push_back(uvs);
				}

				int foundID = -1; //consists of all sift points but only some of them pass the sfm selection
				for (size_t ii = 0; ii < VtwoDID.size() && foundID == -1 && hasCache; ii++)
				{
					if (pid == VtwoDID[ii])
					{
						double dist = sqrt(pow(BackTrackUVS[localPid][0].x - kpts[pid].pt.x, 2) + pow(BackTrackUVS[localPid][0].y - kpts[pid].pt.y, 2));
						if (dist < 1)
							foundID = ii;
						else
							hasCache = false;
					}
				}

				if (foundID != -1)
				{
					trackingIndeedFulfill[foundID] = true;
					VGlobal3DID2.push_back(VGlobal3DId[foundID]);
					VLocal3DID2.push_back(VLocal3DId[foundID]);
					for (size_t jj = 0; jj < BackTrackUVS[localPid].size(); jj++)
						BackTrackUVS[localPid][jj].z = Vscale[foundID];
					localPid++;
				}
				if (localPid >= VtwoDID.size())
					break;
			}
			fclose(fp);
		}

		for (size_t ii = 0; ii < VtwoDID.size(); ii++)
		{
			if (!trackingIndeedFulfill[ii])
			{
				printLOG("Reading from %s but not all PnP points were fulfilled\n", Fname);
				hasCache = false;
				break;
			}
		}

		if (hasCache)
		{/*//write PnP
		 vector<pair<Point2i, Point3f> > *PnPPoints = new vector<pair<Point2i, Point3f>>[maxnf];
		 for (int ii = 0; ii < localPid; ii++)
		 for (int jj = 0; jj < (int)BackTrackUV[ii].size(); jj++)
		 PnPPoints[jj].push_back(std::make_pair(Point2i(VGlobal3DID2[ii], VLocal3DID2[ii]), Point3f(BackTrackUV[ii][jj].x, BackTrackUV[ii][jj].y, Vscale2[ii])));

		 for (int fidi = 0; fidi < maxnf; fidi++)
		 {
		 sprintf(Fname, "%s/%d/PnPTc/Inliers_%d_%.4d.txt", Path, viewID, startF, startF - fidi); FILE* fp = fopen(Fname, "w");
		 fprintf(fp, "%d\n", PnPPoints[fidi].size());
		 for (int ii = 0; ii < (int)PnPPoints[fidi].size(); ii++)
		 fprintf(fp, "%d %d %.3f %.3f %.3f\n", PnPPoints[fidi][ii].first, PnPPoints[fidi][ii].first.y, PnPPoints[fidi][ii].second.x, PnPPoints[fidi][ii].second.y, PnPPoints[fidi][ii].second.z);
		 fclose(fp);
		 }
		 delete[]PnPPoints;*/

			sprintf(Fname, "%s/%d/PnPTc/InliersB_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "w");
			for (int ii = 0; ii < localPid; ii++)
			{
				fprintf(fp, "%d %d %d\n", VGlobal3DID2[ii], VLocal3DID2[ii], BackTrackUVS[ii].size());
				for (int jj = 0; jj < (int)BackTrackUVS[ii].size(); jj++)
					fprintf(fp, "%.3f %.3f %.3f ", BackTrackUVS[ii][jj].x, BackTrackUVS[ii][jj].y, BackTrackUVS[ii][jj].z);
				fprintf(fp, "\n");
			}
			fclose(fp);
		}

		delete[]BackTrackUVS;
	}
	if (!hasCache) //lets compute it
	{
		int fid, localfid = 0;
		for (fid = startF; fid >= startF - TrackRange; fid--)
		{
			printLOG("%d..", fid);
			sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, fid);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n", Fname);
					break;
				}
			}
			gray = imread(Fname, 0);
			buildOpticalFlowPyramid(gray, cPyr, winSize, npryLevels, true);

			width = gray.cols, height = gray.rows;
			if (ImgIParaC == NULL)
				ImgIParaC = new double[height*width], ImgIParaR = new double[height*width];
			Generate_Para_Spline(gray.data, ImgIParaC, width, height, interpAlgo);
			double ratio = 1.0*gray.cols / 1920;

			if (fid == startF)
			{
				winSize.width = winDim * gray.cols / 1920;
				winSize.height = winDim * gray.cols / 1920;
				points[0] = Vuv;
				for (size_t pid = 0; pid < Vuv.size(); pid++)
				{
					vector<Point2f> track; track.push_back(Vuv[pid]);
					tracklets.push_back(track);
					ToDel[pid] = false;
				}
				buildOpticalFlowPyramid(gray, rPyr, winSize, npryLevels, true);
				Generate_Para_Spline(gray.data, ImgIParaR, width, height, interpAlgo);

				swap(pPyr, cPyr);
				swap(prevGray, gray);
				continue;
			}
			localfid++;

			if (display > 0)
			{
				cvtColor(prevGray, backGround, CV_GRAY2BGR);
				int cnpts = 0;
				for (int pid = 0; pid < points[0].size(); pid++)
				{
					if (!ToDel[pid])
					{
						cnpts++;
						circle(backGround, points[0][pid], 1, colors[pid % 8], 2);
						if (display == 2)
							circle(backGround, points[0][pid], max(1, max(min((int)(BackScale[pid][localfid - 1] * 3 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5))), colors[pid % 8], 2);
					}
				}

				CvPoint text_origin = { backGround.cols / 30, backGround.cols / 30 };
				sprintf(Fname, "@%d->%d: %d npts", startF, fid, cnpts);
				putText(backGround, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * backGround.cols / 640, CV_RGB(0, 255, 0), 2);
				if (display == 1)
					sprintf(Fname, "Tracking of Camera %d", viewID), imshow(Fname, backGround), waitKey(2);
			}

			int pNpts = 0, tNpts = 0;
			double iavgmagFlow, avgmagFlow, curTrackingRatio, RefTrackingRatio;

			status.clear(), err.clear(), points[1].clear();
			points[2] = points[0];
			calcOpticalFlowPyrLK(pPyr, cPyr, points[0], points[1], status, err, winSize, npryLevels, termcrit); //forward
			calcOpticalFlowPyrLK(cPyr, pPyr, points[1], points[2], status, err, winSize, npryLevels, termcrit); //backward

			allDistance.clear();
			for (size_t pid = 0; pid < points[0].size(); pid++)
			{
				if (points[0][pid].x > 0 && points[0][pid].y > 0)
					pNpts++;
				if (status[pid] == 0 || ToDel[pid] == 1 || points[0][pid].x < 0)
					points[1][pid] = Point2f(-1, -1);
				else
				{
					double BiDirDist = norm(points[2][pid] - points[0][pid]);
					if (BiDirDist < bidir_Thresh*gray.cols / 1920)
						allDistance.push_back(norm(points[1][pid] - points[0][pid])),
						tNpts++;
					else
						points[1][pid] = Point2f(-1, -1), ToDel[pid] = 1;
				}
			}
			sort(allDistance.begin(), allDistance.end());

			if (tNpts < points[0].size() / 10)
				iavgmagFlow = 9e9;
			else
				iavgmagFlow = allDistance[tNpts / 5]; //take 20% percentile as the reference
			curTrackingRatio = 1.0* tNpts / pNpts;

			if (tNpts > points[0].size() / 10)
			{
				tNpts = 0;
				allDistance.clear();
				if (!highQualityTracker)
				{
					points[2] = Vuv;
					calcOpticalFlowPyrLK(rPyr, cPyr, Vuv, points[1], status, err, winSize, max(0, npryLevels - 1), termcrit); //from refF to current frame with init
					calcOpticalFlowPyrLK(cPyr, rPyr, points[1], points[2], status, err, winSize, max(0, npryLevels - 1), termcrit); //from current to ref frame with init

					for (int ii = 0; ii < (int)Vuv.size(); ii++)
					{
						if (status[ii] == 0 || ToDel[ii] == 1 || points[1][ii].x < 0)
							points[1][ii] = Point2f(-1, -1), ToDel[ii] = true;
						else
						{
							double BiDirDist = norm(points[2][ii] - Vuv[ii]);
							if (BiDirDist < bidir_Thresh*gray.cols / 1920)
								allDistance.push_back(norm(points[1][ii] - points[0][ii])), tracklets[ii].push_back(points[1][ii]), tNpts++;
							else
								points[1][ii] = Point2f(-1, -1), ToDel[ii] = true;
						}
					}
				}
				else
				{
#pragma omp parallel for schedule(dynamic, 2)
					for (int pid = 0; pid < (int)Vuv.size(); pid++)
					{
						int threadID = omp_get_thread_num();
						if (ToDel[pid])
							continue;

						LKParameters LKArg; //LKArg.hsubset to be changed according to the point scale
						LKArg.DisplacementThresh = bidir_Thresh, LKArg.DIC_Algo = 3, LKArg.InterpAlgo = interpAlgo, LKArg.EpipEnforce = 0;
						LKArg.Incomplete_Subset_Handling = 0, LKArg.Convergence_Criteria = 0, LKArg.Analysis_Speed = 0, LKArg.IterMax = 15;
						LKArg.PSSDab_thresh = 0.1, LKArg.ZNCCThreshold = 0.7;
						double bestcwarp[4], besticwarp[4], cwarp[4], icwarp[4];

						Point2d bestNpt;
						double minDist = 9e9;
						int winsize = max(min((int)(BackScale[pid][localfid - 1] * 6 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5)), orghsubset = winsize / 2 + 1;

						for (int trial = 0; trial < nWindows; trial++)  //Look for the best window size with minimum drift and consistent flow wrst the ref template:
						{
							LKArg.hsubset = orghsubset - trial * WinStep / 2;
							Point2d refpt = Vuv[pid], npt = points[1][pid], brefpt = Vuv[pid];

							for (int ii = 0; ii < 4; ii++)
								cwarp[ii] = BackWarp[pid][localfid - 1].warp[ii];
							double score1 = TemplateMatching(ImgIParaR, ImgIParaC, width, height, width, height, 1, refpt, npt, LKArg, false, T1 + WinLength * threadID, T2 + 6 * WinLength*threadID, cwarp);
							if (score1 < LKArg.ZNCCThreshold || npt.x <winsize || npt.y < winsize || npt.x >width - winsize || npt.y >height - winsize)
								continue;

							for (int ii = 0; ii < 4; ii++)
								icwarp[ii] = BackiWarp[pid][localfid - 1].warp[ii];
							double score2 = TemplateMatching(ImgIParaC, ImgIParaR, width, height, width, height, 1, npt, brefpt, LKArg, false, T1 + WinLength * threadID, T2 + 6 * WinLength*threadID, icwarp);
							if (score2 < LKArg.ZNCCThreshold || brefpt.x <winsize || brefpt.y < winsize || brefpt.x >width - winsize || brefpt.y >height - winsize)
								continue;

							double dist = pow(brefpt.x - refpt.x, 2) + pow(brefpt.y - refpt.y, 2);
							if (dist < minDist && dist < dispThresh2)
							{
								minDist = dist, bestNpt = npt;
								for (int ii = 0; ii < 4; ii++)
									bestcwarp[ii] = cwarp[ii], besticwarp[ii] = icwarp[ii];
							}
						}

						ToDel[pid] = true;
						if (minDist < dispThresh2)
						{
							points[1][pid] = bestNpt;

							BackWarp[pid].push_back(AffinePara(bestcwarp));
							BackiWarp[pid].push_back(AffinePara(besticwarp));

							ToDel[pid] = false;
							double ns = BackScale[pid][0] * max(BackWarp[pid][localfid].warp[0] + 1.0 + BackWarp[pid][localfid].warp[1], BackWarp[pid][localfid].warp[2] + BackWarp[pid][localfid].warp[3] + 1.0);
							BackScale[pid].push_back(ns);

#pragma omp critical
							allDistance.push_back(norm(points[1][pid] - Vuv[pid])), tracklets[pid].push_back(points[1][pid]), tNpts++;
						}
					}
				}

				if (tNpts > Vuv.size() / 10)
				{
					sort(allDistance.begin(), allDistance.end());
					avgmagFlow = allDistance[tNpts / 5]; //take 20% percentile as the reference
					RefTrackingRatio = 1.0* tNpts / Vuv.size();
				}
				else
					RefTrackingRatio = 0, curTrackingRatio = 0, avgmagFlow = 9e9; //force to updae
			}
			else
				RefTrackingRatio = 0, curTrackingRatio = 0, avgmagFlow = 9e9; //force to update

			if (display > 0)
				printLOG("%d/%d : #Points: %.4d. Ref flow strength: %.2f. Intermediate flow strength: %.2f. RefTracking: %.2f CurTracking: %.2f...\n", fid, viewID, allDistance.size(), avgmagFlow, iavgmagFlow, RefTrackingRatio, curTrackingRatio);
			bool flag1 = RefTrackingRatio < successRefTrackingRatio;
			bool flag2 = curTrackingRatio < successConsecutiveTrackingRatio;
			bool flag3 = iavgmagFlow > avgflowMagThresh / 1920 * rPyr[0].cols;
			if (flag1 || flag2 || flag3)
				break;

			swap(pPyr, cPyr);
			swap(prevGray, gray);
			swap(points[0], points[1]);
		}
		printLOG("Done\n");

		//write out tracklet
		if (binary)
		{
			sprintf(Fname, "%s/cTrack2D/LBT_%d_%.4d.dat", Path, viewID, startF);
			ofstream fout; fout.open(Fname, ios::binary);
			int n = (int)tracklets.size(); fout.write(reinterpret_cast<char *>(&n), sizeof(int));
			for (int ii = 0; ii < n; ii++)
			{
				int id = VtwoDID[ii], len = (int)tracklets[ii].size();
				fout.write(reinterpret_cast<char *>(&id), sizeof(int));
				fout.write(reinterpret_cast<char *>(&len), sizeof(int));
				for (int jj = 0; jj < len; jj++)
				{
					float u = (float)tracklets[ii][jj].x, v = (float)tracklets[ii][jj].y, s = (float)BackScale[ii][jj];
					fout.write(reinterpret_cast<char *>(&u), sizeof(float));
					fout.write(reinterpret_cast<char *>(&v), sizeof(float));
					fout.write(reinterpret_cast<char *>(&s), sizeof(float));
				}
			}
			fout.close();
		}
		else
		{
			sprintf(Fname, "%s/cTrack2D/LBT_%d_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "w+");
			for (int ii = 0; ii < (int)tracklets.size(); ii++)
			{
				fprintf(fp, "%d %d ", VtwoDID[ii], (int)tracklets[ii].size());
				for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
					fprintf(fp, "%.3f %.3f %.3f ", tracklets[ii][jj].x, tracklets[ii][jj].y, BackScale[ii][jj]);
				fprintf(fp, "\n");
			}
			fclose(fp);
		}

		/*//write PnP
		vector<pair<Point2i, Point3f> > *PnPPoints = new vector<pair<Point2i, Point3f>>[startF - fid + 1];
		for (int ii = 0; ii < (int)tracklets.size(); ii++)
		for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
		PnPPoints[jj].push_back(std::make_pair(Point2i(VGlobal3DId[ii], VLocal3DId[ii]), Point3f(tracklets[ii][jj].x, tracklets[ii][jj].y, Vscale[ii])));

		for (int fidi = startF; fidi >= fid; fidi--)
		{
		sprintf(Fname, "%s/%d/PnPTc/Inliers_%d_%.4d.txt", Path, viewID, startF, fidi); FILE *fp = fopen(Fname, "w");
		fprintf(fp, "%d\n", PnPPoints[startF - fidi].size());
		for (int ii = 0; ii < (int)PnPPoints[startF - fidi].size(); ii++)
		fprintf(fp, "%d %d %.3f %.3f %.3f\n", PnPPoints[startF - fidi][ii].first.x, PnPPoints[startF - fidi][ii].first.y, PnPPoints[startF - fidi][ii].second.x, PnPPoints[startF - fidi][ii].second.y, PnPPoints[startF - fidi][ii].second.z);
		fclose(fp);
		}
		delete[]PnPPoints;*/

		sprintf(Fname, "%s/%d/PnPTc/InliersB_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "w");
		for (size_t ii = 0; ii < tracklets.size(); ii++)
		{
			fprintf(fp, "%d %d %d\n", VGlobal3DId[ii], VLocal3DId[ii], tracklets[ii].size());
			for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
				fprintf(fp, "%.3f %.3f %.3f ", tracklets[ii][jj].x, tracklets[ii][jj].y, BackScale[ii][jj]);
			fprintf(fp, "\n");
		}
		fclose(fp);

		cPyr.clear(), tracklets.clear(), points[0].clear(), points[1].clear();
	}

	if (display > 1)
		cvDestroyAllWindows();

	delete[]ToDel, delete[]ImgIParaC, delete[]ImgIParaR, delete[]T1, delete[]T2;
	delete[]ForeScale, delete[]BackScale, delete[]ForeWarp, delete[]ForeiWarp, delete[]BackWarp, delete[]BackiWarp;

	return 0;
}
int TrackHarrisPointsWithRefTemplateDriver(char *Path, int selectedCamID, int startF, int TrackRange, int increF, int HarrisminDistance, int WinSize, int cvPyrLevel, int nHarrisPartitions, int maxFeatures, int interpAlgo, int debug)
{
	printLOG("***Working on (cid, fid):  (%d, %d)***\n", selectedCamID, startF);

	int fps = 30;
	char Fname[512];
	sprintf(Fname, "%s/%d/Harris/", Path, selectedCamID); makeDir(Fname);
	sprintf(Fname, "%s/Harris//FT_%d_%.4d.txt", Path, selectedCamID, startF);
	if (IsFileExist(Fname) == 1)
		return 0;

	/*char Fname1[512];  sprintf(Fname1, "%s/%d/Harris/%d_%.4d.txt", Path, selectedCamID, startF, startF + increF);
	char Fname2[512];  sprintf(Fname2, "%s/%d/Harris/%d_%.4d.txt", Path, selectedCamID, startF, startF - increF);
	if (IsFileExist(Fname1) && IsFileExist(Fname2))
	{
	printLOG("(%d,%d) computed\n");
	return 0;
	}*/

	sprintf(Fname, "%s/%d/%.4d.png", Path, selectedCamID, startF); //reference image
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, selectedCamID, startF); //reference image
	Mat cvImg = imread(Fname, 0);
	if (cvImg.empty() == 1)
		return 0;

	int width = cvImg.cols, height = cvImg.rows;
	unsigned char *Img = new unsigned char[width*height];

	int nWinSize = 1, WinStep = 0;
	WinSize = WinSize * width / 1920;
	double ratio = 1.0*width / 1920;
	LKParameters LKArg; //LKArg.hsubset to be changed according to the point scale
	LKArg.DisplacementThresh = 0.5, LKArg.DIC_Algo = 3, LKArg.InterpAlgo = interpAlgo, LKArg.EpipEnforce = 0;
	LKArg.Incomplete_Subset_Handling = 0, LKArg.Convergence_Criteria = 0, LKArg.Analysis_Speed = 0, LKArg.IterMax = 15;
	LKArg.PSSDab_thresh = 0.1, LKArg.ZNCCThreshold = 0.7;

	Size winSize(WinSize, WinSize);
	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 30, 0.01);

	vector<Point2f> uvRef; uvRef.reserve(maxFeatures);
	BucketGoodFeaturesToTrack(cvImg, uvRef, nHarrisPartitions, maxFeatures, 0.01, HarrisminDistance* width / 1920, 7 * width / 1920, 0, 0.04);
	int npts = (int)uvRef.size();

	int c, f, opencv2ffmpeg = 0;
	sprintf(Fname, "%s/opencv2ffmpeg.txt", Path);
	if (IsFileExist(Fname) == 1)
	{
		printLOG("Loaded %s\n", Fname);
		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d ", &c, &f) != EOF)
			if (c == selectedCamID)
				opencv2ffmpeg = f;
		fclose(fp);
	}

	sprintf(Fname, "%s/DynamicClassColor.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		vector<Point3i> DynamicClassColor;
		Point3i Color;
		while (fscanf(fp, "%d %d %d ", &Color.x, &Color.y, &Color.z) != EOF)
			DynamicClassColor.push_back(Color);
		fclose(fp);

		sprintf(Fname, "%s/Seg/%d/%.4d.png", Path, selectedCamID, startF); Mat segImg = imread(Fname);
		RemoveMatchesOfDifferentClass(uvRef, segImg, DynamicClassColor, true);
	}
	npts = (int)uvRef.size();

	Point2f tl, br;
	vector<Point2f> vtl, vbr;
	bool hasBB = false;
	sprintf(Fname, "%s/%d/boundingbox/%.4d.png.txt", Path, selectedCamID, startF - opencv2ffmpeg);
	if (IsFileExist(Fname) == 1)
		hasBB = true;
	else
	{
		sprintf(Fname, "%s/%d/boundingbox/%.4d.jpg.txt", Path, selectedCamID, startF - opencv2ffmpeg);
		if (IsFileExist(Fname) == 1)
			hasBB = true;
	}
	if (hasBB)
	{
		fp = fopen(Fname, "r");
		while (fscanf(fp, "%f %f %f %f %s", &tl.y, &tl.x, &br.y, &br.x, Fname) != EOF)
			//while (fscanf(fp, "%f %f %f %f %s", &tl.x, &tl.y, &br.x, &br.y, Fname) != EOF)
			if (strcmp(Fname, "car") == 0 || strcmp(Fname, "bus") == 0 || strcmp(Fname, "truck") == 0 || strcmp(Fname, "van") == 0 || strcmp(Fname, "suv") == 0 || strcmp(Fname, "person") == 0)
				vtl.push_back(tl), vbr.push_back(br);
		fclose(fp);

		vector<int> ToKeep;
		for (size_t ll = 0; ll < uvRef.size(); ll++)
		{
			for (size_t ii = 0; ii < vbr.size(); ii++)
			{
				if (uvRef[ll].x > vtl[ii].x && uvRef[ll].x < vbr[ii].x && uvRef[ll].y > vtl[ii].y && uvRef[ll].y < vbr[ii].y)
				{
					ToKeep.push_back(ll);
					break;
				}
			}
		}

		vector<Point2f> nuv; nuv.reserve(ToKeep.size());
		for (size_t ii = 0; ii < ToKeep.size(); ii++)
			nuv.push_back(uvRef[ToKeep[ii]]);
		uvRef = nuv;
		npts = (int)uvRef.size();
	}

	printLOG("Start tracking %d points\n", npts);
	if (npts == 0)
		return 0;

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));
	Mat bg;
	if (debug)
	{
		namedWindow("HarrisR", WINDOW_NORMAL);
		cvtColor(cvImg, bg, CV_GRAY2BGR);
		for (int ii = 0; ii < uvRef.size(); ii++)
			circle(bg, uvRef[ii], 3, colors[ii % 8], 2);
		imshow("HarrisR", bg); waitKey(1);
	}

	//Filter bad points based on Mean sum square gradient score
	vector<float> sRef; sRef.reserve(npts);
	vector<int> GoodtruePid; GoodtruePid.reserve(npts);
	for (int ii = 0; ii < npts; ii++)
		sRef.push_back(1.f*WinSize / 6), GoodtruePid.push_back(ii);

	int maxthreads = omp_get_max_threads();
	int Tlength = (WinSize + 2)*(WinSize + 2) * 2;
	vector<AffinePara> *ForeWarp = new vector<AffinePara>[npts], *ForeiWarp = new vector<AffinePara>[npts], *BackWarp = new vector<AffinePara>[npts], *BackiWarp = new vector<AffinePara>[npts];
	int *AllrefFid = new int[npts], *FramesTrackedCount = new int[npts], *JustUpdate = new int[npts], *PermTrackFail = new int[npts], *TempTrackFail = new int[npts];
	double *T1 = new double[Tlength * maxthreads], *T2 = new double[6 * Tlength * maxthreads];


	vector<double *>ForeImgIPara, BackImgIPara;
	vector<Mat> *ForePyr = new vector<Mat>[TrackRange], *BackPyr = new vector<Mat>[TrackRange];
	vector<Point2f> *ForeTrackUV = new vector<Point2f>[npts], *BackTrackUV = new vector<Point2f>[npts];
	vector<float> *ForeScale = new vector<float>[npts], *BackScale = new vector<float >[npts];
	vector<AffinePara> *cForeWarp = new vector<AffinePara>[npts], *cBackWarp = new vector<AffinePara >[npts];
	vector<FeatureDesc> *ForeDesc = new vector<FeatureDesc>[npts], *BackDesc = new vector<FeatureDesc>[npts];

	AffinePara w1, w2, w3, w4;
	if (LKArg.DIC_Algo == -2)
		w1.warp[0] = 1, w2.warp[0] = 1, w3.warp[0] = 1, w4.warp[0] = 1;//set scale to be 1 for sim-trans

	omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic,8)
	for (int ii = 0; ii < npts; ii++)
	{
		ForeTrackUV[ii].reserve(TrackRange), ForeTrackUV[ii].push_back(uvRef[ii]);
		BackTrackUV[ii].reserve(TrackRange), BackTrackUV[ii].push_back(uvRef[ii]);
		ForeScale[ii].reserve(TrackRange), ForeScale[ii].push_back(sRef[ii]);
		BackScale[ii].reserve(TrackRange), BackScale[ii].push_back(sRef[ii]);
		ForeWarp[ii].reserve(TrackRange), ForeWarp[ii].push_back(w1);
		BackWarp[ii].reserve(TrackRange), BackWarp[ii].push_back(w2);
		ForeiWarp[ii].reserve(TrackRange), ForeiWarp[ii].push_back(w3);
		BackiWarp[ii].reserve(TrackRange), BackiWarp[ii].push_back(w4);
	}

	double start = omp_get_wtime();
	printLOG("Foretrack  @(%d/%d):", startF, selectedCamID);

	AffinePara  baseWarp;
	baseWarp.warp[0] = 1.0, baseWarp.warp[1] = 0.0, baseWarp.warp[2] = 0.0, baseWarp.warp[3] = 1.0;
	for (int ii = 0; ii < npts; ii++)
		cForeWarp[ii].push_back(baseWarp), AllrefFid[ii] = 0, FramesTrackedCount[ii] = 0, JustUpdate[ii] = 0, PermTrackFail[ii] = 0, TempTrackFail[ii] = 0;

	sprintf(Fname, "%s/%d/%.4d.png", Path, selectedCamID, startF);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, selectedCamID, startF);
		if (IsFileExist(Fname) == 0)
			return 1;
	}
	cvImg = imread(Fname, 0);
	buildOpticalFlowPyramid(cvImg, ForePyr[0], Size(WinSize, WinSize), cvPyrLevel, false);

	for (int ii = 0; ii < height*width; ii++)
		Img[ii] = cvImg.data[ii];
	double *ImgIParai = new double[height*width];
	Generate_Para_Spline(Img, ImgIParai, width, height, LKArg.InterpAlgo);
	ForeImgIPara.push_back(ImgIParai);

	for (int fid = 1; fid < TrackRange; fid++)
	{
		int nvalidPoints = 0;
		for (int pid = 0; pid < npts; pid++)
			if (PermTrackFail[pid] == 0)
				nvalidPoints++;
		if (nvalidPoints > 0)
			printLOG("@f %d ... ", fid *increF + startF);

		sprintf(Fname, "%s/%d/%.4d.png", Path, selectedCamID, fid*increF + startF);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, selectedCamID, fid*increF + startF);
			if (IsFileExist(Fname) == 0)
			{
				printLOG("Cannot load %s\n", Fname);
				break;
			}
		}
		cvImg = imread(Fname, 0);
		buildOpticalFlowPyramid(cvImg, ForePyr[fid], Size(WinSize, WinSize), cvPyrLevel, false);

		for (int ii = 0; ii < height*width; ii++)
			Img[ii] = cvImg.data[ii];
		double *ImgIParai = new double[height*width];
		Generate_Para_Spline(Img, ImgIParai, width, height, LKArg.InterpAlgo);
		ForeImgIPara.push_back(ImgIParai);

#pragma omp parallel for schedule(dynamic,1)
		for (int pid = 0; pid < npts; pid++)
		{
			if (PermTrackFail[pid] == 1)
				continue;

			if (fid - AllrefFid[pid] > fps) //force update the template every 1s
				AllrefFid[pid] = (int)ForeTrackUV[pid].size() - 1, FramesTrackedCount[pid] = 0;

			//Look for the best window size with minimum drift
			TempTrackFail[pid] = 0;
			int refFid = AllrefFid[pid];
			int winsize = max(min((int)(ForeScale[pid][fid - 1] * 6 + 0.5), WinSize), (int)(ratio * 11 + 0.5) / 2 * 2 + 1);
			int threadID = omp_get_thread_num();
			if (Track_1P_1F_WithRefTemplate(ForeTrackUV[pid], ForeWarp[pid], ForeiWarp[pid], ForePyr, ForeImgIPara[refFid], ForeImgIPara[fid], refFid, fid, pid, winsize, nWinSize, WinStep, cvPyrLevel, LKArg, T1 + Tlength * threadID, T2 + 6 * Tlength*threadID))
			{
				FramesTrackedCount[pid]++;
				double ns = LKArg.DIC_Algo != -2 ? ForeScale[pid][refFid] * max(ForeWarp[pid][fid].warp[0] + 1.0 + ForeWarp[pid][fid].warp[1], ForeWarp[pid][fid].warp[2] + ForeWarp[pid][fid].warp[3] + 1.0) : ForeScale[pid][refFid] * ForeWarp[pid][fid].warp[0];
				ForeScale[pid].push_back(ns);

				//update base template 
				AffinePara currentWarp, cumWarp, baseWarp;
				baseWarp.warp[0] = cForeWarp[pid][refFid].warp[0], baseWarp.warp[1] = cForeWarp[pid][refFid].warp[1], baseWarp.warp[2] = cForeWarp[pid][refFid].warp[2], baseWarp.warp[3] = cForeWarp[pid][refFid].warp[3];

				//compute warping wrst 1st template
				if (LKArg.DIC_Algo != -2)
					currentWarp.warp[0] = ForeWarp[pid][fid].warp[0] + 1.0, currentWarp.warp[1] = ForeWarp[pid][fid].warp[1], currentWarp.warp[2] = ForeWarp[pid][fid].warp[2], currentWarp.warp[3] = ForeWarp[pid][fid].warp[3] + 1.0;
				else
				{
					double w_s = ForeWarp[pid][fid].warp[0], w_a = ForeWarp[pid][fid].warp[1];
					currentWarp.warp[0] = w_s * cos(w_a), currentWarp.warp[1] = -w_s * sin(w_a), currentWarp.warp[2] = w_s * sin(w_a), currentWarp.warp[3] = w_s * cos(w_a);
				}
				mat_mul(baseWarp.warp, currentWarp.warp, cumWarp.warp, 2, 2, 2);
				cForeWarp[pid].push_back(cumWarp);
			}
			else
				TempTrackFail[pid] = 1;
		}


#pragma omp parallel for schedule(dynamic,1)
		for (int pid = 0; pid < npts; pid++) //Analyze the tracking results
		{
			if (PermTrackFail[pid] == 1)
				continue;

			if (TempTrackFail[pid] == 1)//tracking fails
			{
				if (FramesTrackedCount[pid] < 4) //just update the ref template but tracking last only a few frames --> SHOULD STOP THE TRACK (occluded points?)
				{
					ForeTrackUV[pid].erase(ForeTrackUV[pid].end() - FramesTrackedCount[pid], ForeTrackUV[pid].end());
					ForeScale[pid].erase(ForeScale[pid].end() - FramesTrackedCount[pid], ForeScale[pid].end());
					PermTrackFail[pid] = 1;
					//printLOG("(%d: %d) ... ", pid, ForeTrackUV[pid].size());
				}
				else //Lets update the template and re-run the track so that the point is up to the other points' progress
				{
					//if (debug)
					//printLOG("***(%d,%d)*** ", pid, fid + startF);
					AllrefFid[pid] = (int)ForeTrackUV[pid].size() - 1, FramesTrackedCount[pid] = 0, JustUpdate[pid] = 1;

					TempTrackFail[pid] = 0;
					int refFid = AllrefFid[pid];
					int winsize = max(min((int)(ForeScale[pid][fid - 1] * 6 + 0.5), WinSize), (int)(ratio * 11 + 0.5) / 2 * 2 + 1);
					int threadID = omp_get_thread_num();
					if (Track_1P_1F_WithRefTemplate(ForeTrackUV[pid], ForeWarp[pid], ForeiWarp[pid], ForePyr, ForeImgIPara[refFid], ForeImgIPara[fid], refFid, fid, pid, winsize, nWinSize, WinStep, cvPyrLevel, LKArg, T1 + Tlength * threadID, T2 + Tlength * 6 * threadID))
					{
						FramesTrackedCount[pid]++;
						if (LKArg.DIC_Algo != -2)
						{
							double ns = ForeScale[pid][refFid] * max(ForeWarp[pid][fid].warp[0] + 1.0 + ForeWarp[pid][fid].warp[1], ForeWarp[pid][fid].warp[2] + ForeWarp[pid][fid].warp[3] + 1.0);
							ForeScale[pid].push_back(ns);
						}
						else
						{
							double ns = ForeScale[pid][refFid] * ForeWarp[pid][fid].warp[0];
							ForeScale[pid].push_back(ns);
						}

						//update base template
						AffinePara currentWarp, cumWarp, baseWarp;
						baseWarp.warp[0] = cForeWarp[pid][refFid].warp[0], baseWarp.warp[1] = cForeWarp[pid][refFid].warp[1], baseWarp.warp[2] = cForeWarp[pid][refFid].warp[2], baseWarp.warp[3] = cForeWarp[pid][refFid].warp[3];

						//compute warping wrst 1st template
						if (LKArg.DIC_Algo != -2)
							currentWarp.warp[0] = ForeWarp[pid][fid].warp[0] + 1.0, currentWarp.warp[1] = ForeWarp[pid][fid].warp[1],
							currentWarp.warp[2] = ForeWarp[pid][fid].warp[2], currentWarp.warp[3] = ForeWarp[pid][fid].warp[3] + 1.0;
						else
						{
							double w_s = ForeWarp[pid][fid].warp[0];
							double w_a = ForeWarp[pid][fid].warp[1];
							currentWarp.warp[0] = w_s * cos(w_a), currentWarp.warp[1] = -w_s * sin(w_a), currentWarp.warp[2] = w_s * sin(w_a), currentWarp.warp[3] = w_s * cos(w_a);
						}
						mat_mul(baseWarp.warp, currentWarp.warp, cumWarp.warp, 2, 2, 2);

						cForeWarp[pid].push_back(cumWarp);
					}
					else //permanent failure
						PermTrackFail[pid] = 1;
				}
			}
		}

		if (debug)
		{
			cvtColor(cvImg, bg, CV_GRAY2BGR);
			for (int pid = 0; pid < uvRef.size(); pid++)
				if (PermTrackFail[pid] == 0)
					circle(bg, ForeTrackUV[pid].back(), 3, colors[pid % 8], 2);
			imshow("HarrisR", bg); waitKey(1);
		}
	}

	start = omp_get_wtime();
	printLOG("\nBacktrack @(%d, %d):", startF, selectedCamID);

	//reset para
	baseWarp.warp[0] = 1.0, baseWarp.warp[1] = 0.0, baseWarp.warp[2] = 0.0, baseWarp.warp[3] = 1.0;
	for (int ii = 0; ii < npts; ii++)
		cBackWarp[ii].push_back(baseWarp), AllrefFid[ii] = 0, FramesTrackedCount[ii] = 0, JustUpdate[ii] = 0, PermTrackFail[ii] = 0, TempTrackFail[ii] = 0;

	sprintf(Fname, "%s/%d/%.4d.png", Path, selectedCamID, startF);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, selectedCamID, startF);
		if (IsFileExist(Fname) == 0)
			return 1;
	}
	cvImg = imread(Fname, 0);
	buildOpticalFlowPyramid(cvImg, BackPyr[0], Size(WinSize, WinSize), cvPyrLevel, false);

	for (int ii = 0; ii < height*width; ii++)
		Img[ii] = cvImg.data[ii];
	Generate_Para_Spline(Img, ImgIParai, width, height, LKArg.InterpAlgo);
	BackImgIPara.push_back(ImgIParai);

	for (int fid = 1; fid < TrackRange; fid++)
	{
		int nvalidPoints = 0;
		for (int pid = 0; pid < npts; pid++)
			if (PermTrackFail[pid] == 0)
				nvalidPoints++;
		if (nvalidPoints > 0)
			printLOG("@f %d ... ", -fid * increF + startF);

		sprintf(Fname, "%s/%d/%.4d.png", Path, selectedCamID, -fid * increF + startF);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, selectedCamID, -fid * increF + startF);
			if (IsFileExist(Fname) == 0)
			{
				printLOG("Cannot load %s\n", Fname);
				break;
			}
		}
		cvImg = imread(Fname, 0);
		buildOpticalFlowPyramid(cvImg, BackPyr[fid], Size(WinSize, WinSize), cvPyrLevel, false);

		for (int ii = 0; ii < height*width; ii++)
			Img[ii] = cvImg.data[ii];
		double *ImgIParai = new double[height*width];
		Generate_Para_Spline(Img, ImgIParai, width, height, LKArg.InterpAlgo);
		BackImgIPara.push_back(ImgIParai);

#pragma omp parallel for schedule(dynamic,1)
		for (int pid = 0; pid < npts; pid++)
		{
			if (PermTrackFail[pid] == 1)
				continue;

			if (fid - AllrefFid[pid] > fps) //force update the template every 1s
				AllrefFid[pid] = (int)BackTrackUV[pid].size() - 1, FramesTrackedCount[pid] = 0;

			//Look for the best window size  with minimum drift
			TempTrackFail[pid] = 0;
			int refFid = AllrefFid[pid];
			int winsize = max(min((int)(BackScale[pid][fid - 1] * 6 + 0.5), WinSize), (int)(ratio * 11 + 0.5) / 2 * 2 + 1);
			int threadID = omp_get_thread_num();
			if (Track_1P_1F_WithRefTemplate(BackTrackUV[pid], BackWarp[pid], BackiWarp[pid], BackPyr, BackImgIPara[refFid], BackImgIPara[fid], refFid, fid, pid, winsize, nWinSize, WinStep, cvPyrLevel, LKArg, T1 + Tlength * threadID, T2 + Tlength * 6 * threadID))
			{
				FramesTrackedCount[pid]++;
				if (LKArg.DIC_Algo != -2)
				{
					double ns = BackScale[pid][refFid] * max(BackWarp[pid][fid].warp[0] + 1.0 + BackWarp[pid][fid].warp[1], BackWarp[pid][fid].warp[2] + BackWarp[pid][fid].warp[3] + 1.0);
					BackScale[pid].push_back(ns);
				}
				else
				{
					double ns = BackScale[pid][refFid] * BackWarp[pid][fid].warp[0];
					BackScale[pid].push_back(ns);
				}

				//update base template
				AffinePara currentWarp, cumWarp, baseWarp;
				baseWarp.warp[0] = cBackWarp[pid][refFid].warp[0], baseWarp.warp[1] = cBackWarp[pid][refFid].warp[1], baseWarp.warp[2] = cBackWarp[pid][refFid].warp[2], baseWarp.warp[3] = cBackWarp[pid][refFid].warp[3];

				//compute warping wrst 1st template
				if (LKArg.DIC_Algo != -2)
					currentWarp.warp[0] = BackWarp[pid][fid].warp[0] + 1.0, currentWarp.warp[1] = BackWarp[pid][fid].warp[1],
					currentWarp.warp[2] = BackWarp[pid][fid].warp[2], currentWarp.warp[3] = BackWarp[pid][fid].warp[3] + 1.0;
				else
				{
					double w_s = BackWarp[pid][fid].warp[0];
					double w_a = BackWarp[pid][fid].warp[1];
					currentWarp.warp[0] = w_s * cos(w_a), currentWarp.warp[1] = -w_s * sin(w_a), currentWarp.warp[2] = w_s * sin(w_a), currentWarp.warp[3] = w_s * cos(w_a);
				}
				mat_mul(baseWarp.warp, currentWarp.warp, cumWarp.warp, 2, 2, 2);

				cBackWarp[pid].push_back(cumWarp);
			}
			else
				TempTrackFail[pid] = 1;
		}

#pragma omp parallel for schedule(dynamic,1)
		for (int pid = 0; pid < npts; pid++) //Analyze the tracking results
		{
			if (PermTrackFail[pid] == 1)
				continue;

			if (TempTrackFail[pid] == 1)//tracking fails
			{
				if (FramesTrackedCount[pid] < 4) //just update the ref template but tracking last only a few frames --> SHOULD STOP THE TRACK (occluded points?)
				{
					BackTrackUV[pid].erase(BackTrackUV[pid].end() - FramesTrackedCount[pid], BackTrackUV[pid].end());
					BackScale[pid].erase(BackScale[pid].end() - FramesTrackedCount[pid], BackScale[pid].end());
					PermTrackFail[pid] = 1;
					//printLOG("(%d: %d) ... ", pid, BackTrackUV[pid].size());
				}
				else //Lets update the template and re-run the track so that the point is up to the other points' progress
				{
					AllrefFid[pid] = (int)BackTrackUV[pid].size() - 1, FramesTrackedCount[pid] = 0, JustUpdate[pid] = 1;

					TempTrackFail[pid] = 0;
					int refFid = AllrefFid[pid];
					int winsize = max(min((int)(BackScale[pid][fid - 1] * 6 + 0.5), WinSize), (int)(ratio * 11 + 0.5) / 2 * 2 + 1);
					int threadID = omp_get_thread_num();
					if (Track_1P_1F_WithRefTemplate(BackTrackUV[pid], BackWarp[pid], BackiWarp[pid], BackPyr, BackImgIPara[refFid], BackImgIPara[fid], refFid, fid, pid, winsize, nWinSize, WinStep, cvPyrLevel, LKArg, T1 + Tlength * threadID, T2 + Tlength * 6 * threadID))
					{
						FramesTrackedCount[pid]++;
						if (LKArg.DIC_Algo != -2)
						{
							double ns = BackScale[pid][refFid] * max(BackWarp[pid][fid].warp[0] + 1.0 + BackWarp[pid][fid].warp[1], BackWarp[pid][fid].warp[2] + BackWarp[pid][fid].warp[3] + 1.0);
							BackScale[pid].push_back(ns);
						}
						else
						{
							double ns = BackScale[pid][refFid] * BackWarp[pid][fid].warp[0];
							BackScale[pid].push_back(ns);
						}

						//update base template
						AffinePara currentWarp, cumWarp, baseWarp;
						baseWarp.warp[0] = cBackWarp[pid][refFid].warp[0], baseWarp.warp[1] = cBackWarp[pid][refFid].warp[1], baseWarp.warp[2] = cBackWarp[pid][refFid].warp[2], baseWarp.warp[3] = cBackWarp[pid][refFid].warp[3];

						//compute warping wrst 1st template
						if (LKArg.DIC_Algo != -2)
							currentWarp.warp[0] = BackWarp[pid][fid].warp[0] + 1.0, currentWarp.warp[1] = BackWarp[pid][fid].warp[1],
							currentWarp.warp[2] = BackWarp[pid][fid].warp[2], currentWarp.warp[3] = BackWarp[pid][fid].warp[3] + 1.0;
						else
						{
							double w_s = BackWarp[pid][fid].warp[0];
							double w_a = BackWarp[pid][fid].warp[1];
							currentWarp.warp[0] = w_s * cos(w_a), currentWarp.warp[1] = -w_s * sin(w_a), currentWarp.warp[2] = w_s * sin(w_a), currentWarp.warp[3] = w_s * cos(w_a);
						}
						mat_mul(baseWarp.warp, currentWarp.warp, cumWarp.warp, 2, 2, 2);

						cBackWarp[pid].push_back(cumWarp);
					}
					else //permanent failure
						PermTrackFail[pid] = 1;
				}
			}
		}

		if (debug)
		{
			cvtColor(cvImg, bg, CV_GRAY2BGR);
			for (int pid = 0; pid < uvRef.size(); pid++)
				if (PermTrackFail[pid] == 0)
					circle(bg, BackTrackUV[pid].back(), 3, colors[pid % 8], 2);
			imshow("HarrisR", bg); waitKey(1);
		}
	}

	printLOG("\nTotal time: %.2fs\n", omp_get_wtime() - start);

	//Write data to visualize
	sprintf(Fname, "%s/Harris/", Path); makeDir(Fname);
	sprintf(Fname, "%s/Harris//FT_%d_%.4d.txt", Path, selectedCamID, startF); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", npts);
	for (int pid = 0; pid < npts; pid++)
	{
		fprintf(fp, "%d %d ", pid, (int)ForeTrackUV[pid].size());
		for (int fid = 0; fid < (int)ForeTrackUV[pid].size(); fid++)
			fprintf(fp, "%d %.4f %.4f %.3f ", startF + fid * increF, ForeTrackUV[pid][fid].x, ForeTrackUV[pid][fid].y, ForeScale[pid][fid]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/Harris//BT_%d_%.4d.txt", Path, selectedCamID, startF); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", npts);
	for (int pid = 0; pid < npts; pid++)
	{
		fprintf(fp, "%d %d ", pid, (int)BackTrackUV[pid].size());
		for (int fid = 0; fid < (int)BackTrackUV[pid].size(); fid++)
			fprintf(fp, "%d %.4f %.4f %.3f ", startF - fid * increF, BackTrackUV[pid][fid].x, BackTrackUV[pid][fid].y, BackScale[pid][fid]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	/*//Write data: too many files
	for (int fid = 1; fid <= TrackRange; fid++)
	{
	int count = 0;
	for (int pid = 0; pid < npts; pid++)
	if (ForeTrackUV[pid].size() > fid)
	count++;

	if (count > 0)
	{
	sprintf(Fname, "%s/%d/Harris/%d_%.4d.txt", Path, selectedCamID, startF, startF + fid*increF); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", count);
	for (int pid = 0; pid < npts; pid++)
	if (ForeTrackUV[pid].size() > fid)
	fprintf(fp, "%d %.4f %.4f %.2f\n", GoodtruePid[pid], ForeTrackUV[pid][fid].x, ForeTrackUV[pid][fid].y, ForeScale[pid][fid]);
	fclose(fp);
	}
	}
	for (int fid = 1; fid <= TrackRange; fid++)
	{
	int count = 0;
	for (int pid = 0; pid < npts; pid++)
	if (BackTrackUV[pid].size() > fid)
	count++;

	if (count > 0)
	{
	sprintf(Fname, "%s/%d/Harris/%d_%.4d.txt", Path, selectedCamID, startF, startF - fid*increF); fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", count);
	for (int pid = 0; pid < npts; pid++)
	if (BackTrackUV[pid].size() > fid)
	fprintf(fp, "%d %.4f %.4f %.2f\n", GoodtruePid[pid], BackTrackUV[pid][fid].x, BackTrackUV[pid][fid].y, BackScale[pid][fid]);
	fclose(fp);
	}
	}*/

	printLOG("***Done with (cid, fid):  (%d, %d)***\n", selectedCamID, startF);

	if (debug)
		cv::destroyWindow("HarrisR");

	for (int ii = 0; ii < (int)ForeImgIPara.size(); ii++)
		delete[]ForeImgIPara[ii];
	delete[]ForeWarp, delete[]ForeiWarp;
	for (int ii = 1; ii < (int)BackImgIPara.size(); ii++) //first one is shared with ForeImgIPara
		delete[]BackImgIPara[ii];
	delete[]BackWarp, delete[]BackiWarp;

	delete[]Img, delete[]T1, delete[]T2;
	delete[]AllrefFid, delete[]FramesTrackedCount, delete[]JustUpdate, delete[]PermTrackFail, delete[]TempTrackFail;
	delete[]cForeWarp, delete[]cBackWarp;
	delete[]ForePyr, delete[]BackPyr;
	delete[]ForeTrackUV, delete[]BackTrackUV;
	delete[]ForeScale, delete[]BackScale;
	delete[]ForeDesc, delete[]BackDesc;

	return npts;
}

int MergeTrackedCorpusFeaturetoNonKeyframe(char *Path, vector<int> &sCams, int startF, int stopF, int increF)
{
	char Fname[512];

	Corpus CorpusInfo;
	int dummy, nPoints, useColor;
	sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	fscanf(fp, "%d %d %d", &dummy, &nPoints, &useColor);
	CorpusInfo.n3dPoints = nPoints;
	Point3d xyz;
	Point3i rgb;
	CorpusInfo.xyz.reserve(nPoints);
	if (useColor)
	{
		CorpusInfo.rgb.reserve(nPoints);
		for (int jj = 0; jj < nPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
			CorpusInfo.xyz.push_back(xyz);
			CorpusInfo.rgb.push_back(rgb);
		}
	}
	else
	{
		CorpusInfo.rgb.reserve(nPoints);
		for (int jj = 0; jj < nPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
			CorpusInfo.xyz.push_back(xyz);
		}
	}
	fclose(fp);

	printLOG("Merging tracked corpus features: ");
	omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic, 1)
	for (int cid = 0; cid < sCams.size(); cid++)
	{
		int camID = sCams[cid];

		char Fname[512];
		int id, npts; Point2d uv; double s;
		vector<int> Vp3did, cSeedDistance;
		vector<double> Vs;
		vector<Point2d>Vuv;

		CameraData CamInfoI;
		CamInfoI.notCalibrated = false;
		if (!ReadIntrinsicResultI(Path, camID, CamInfoI))
		{
			CamInfoI.notCalibrated = true;
			for (int jj = 0; jj < 7; jj++)
				CamInfoI.distortion[jj] = 0.0;
		}

		int per = 5;
		for (int propF = startF; propF <= stopF; propF += increF)
		{
			double cper = (100.0*(propF - startF) / increF) / ((stopF - startF) / increF + 1);
			if (cper >= per)
			{
#pragma omp critical
				printLOG("(%d,%d)..", camID, per);
				per += 5;
			}
			sprintf(Fname, "%s/%d/PnPmTc/Inliers_%.4d.txt", Path, camID, propF);
			if (IsFileExist(Fname) == 0)
			{
				Vp3did.clear(), Vuv.clear(), cSeedDistance.clear();
				for (int seedF = startF; seedF <= stopF; seedF += increF)
				{
					sprintf(Fname, "%s/%d/PnPTc/Inliers_%d_%.4d.txt", Path, camID, seedF, propF);
					if (IsFileExist(Fname) == 0)
						continue;
					FILE *fp = fopen(Fname, "r");
					fscanf(fp, "%d ", &npts);
					while (fscanf(fp, "%d %lf %lf %lf", &id, &uv.x, &uv.y, &s) != EOF)
					{
						bool duplicatedPid = false;
						for (int ii = 0; ii < (int)Vp3did.size(); ii++)
						{
							if (id == Vp3did[ii]) //if the current point is seen from multiple propagation seed
							{
								if (cSeedDistance[ii] > abs(seedF - propF)) // pick the closest seed
								{
									cSeedDistance[ii] = abs(seedF - propF);
									Vp3did[ii] = id, Vuv[ii] = uv, Vs[ii] = s;
								}
								duplicatedPid = true;
								break;
							}
						}
						if (!duplicatedPid)
						{
							cSeedDistance.push_back(abs(seedF - propF));
							Vp3did.push_back(id), Vuv.push_back(uv), Vs.push_back(s);
						}
					}
					fclose(fp);
				}
				if (Vp3did.size() == 0)
					continue;

				if (!CamInfoI.notCalibrated)
				{
					if (CamInfoI.LensModel == 0)
						LensCorrectionPoint(Vuv, CamInfoI.K, CamInfoI.distortion);
					else
						// FishEyeCorrectionPoint(Vuv, CamInfoI.distortion[0], CamInfoI.distortion[1], CamInfoI.distortion[2]);
						FishEyeCorrectionPoint(Vuv, CamInfoI.K, CamInfoI.distortion[0]);
				}

				sprintf(Fname, "%s/%d/PnPmTc/Inliers_%.4d.txt", Path, camID, propF); FILE *fp = fopen(Fname, "w+");
				for (int ii = 0; ii < (int)Vp3did.size(); ii++)
				{
					int threeDid = Vp3did[ii];
					fprintf(fp, "%d %f %f %f %.6f %.6f %.2f\n", Vp3did[ii], CorpusInfo.xyz[threeDid].x, CorpusInfo.xyz[threeDid].y, CorpusInfo.xyz[threeDid].z, Vuv[ii].x, Vuv[ii].y, Vs[ii]);
				}
				fclose(fp);
			}
		}
	}
	printLOG("\n");

	return 0;
}
int MergeTrackedCorpusFeaturetoNonKeyframe2(char *Path, int camID, vector<int> &KeyFrameID2LocalFrameID, int startF, int stopF, int increF)
{
	printLOG("Merging tracked corpus features for Cam %d: ", camID);

	char Fname[512];
	int nf, lpid, gpid, dummy;
	Point3d xyz; Point3f  uvs;
	Point3i rgb, glc;

	Corpus GlobalCorpusInfo, LocalCorpusInfo;
	sprintf(Fname, "%s/%d/Video3DCorpus.xyz", Path, camID); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		while (fscanf(fp, "%d %d %lf %lf %lf ", &lpid, &gpid, &xyz.x, &xyz.y, &xyz.z) != EOF)
		{
			if (lpid > LocalCorpusInfo.xyz.size())
			{
				dummy = LocalCorpusInfo.xyz.size();
				for (int ii = dummy; ii < lpid; ii++)
					LocalCorpusInfo.xyz.push_back(Point3d(0, 0, 0));
			}

			LocalCorpusInfo.xyz.push_back(xyz);
		}
		fclose(fp);
	}
	else
	{
		int dummy, nPoints, useColor;
		sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		fscanf(fp, "%d %d %d", &dummy, &nPoints, &useColor);
		GlobalCorpusInfo.n3dPoints = nPoints;
		GlobalCorpusInfo.xyz.reserve(nPoints);
		if (useColor)
		{
			GlobalCorpusInfo.rgb.reserve(nPoints);
			for (int jj = 0; jj < nPoints; jj++)
			{
				fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
				GlobalCorpusInfo.xyz.push_back(xyz);
				GlobalCorpusInfo.rgb.push_back(rgb);
			}
		}
		else
		{
			GlobalCorpusInfo.rgb.reserve(nPoints);
			for (int jj = 0; jj < nPoints; jj++)
			{
				fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
				GlobalCorpusInfo.xyz.push_back(xyz);
			}
		}
		fclose(fp);
	}

	vector<Point3i> *allGLF = new vector<Point3i>[stopF + 1];
	vector<Point3f> *allUVS = new vector<Point3f>[stopF + 1];

	for (auto propF : KeyFrameID2LocalFrameID)
	{
		printLOG("%d..", propF);
		sprintf(Fname, "%s/%d/PnPTc/InliersF_%.4d.txt", Path, camID, propF);
		if (IsFileExist(Fname) == 1)
		{
			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d %d ", &glc.x, &glc.y, &nf) != EOF)
			{
				for (int f = 0; f < nf; f++)
				{
					fscanf(fp, "%f %f %f ", &uvs.x, &uvs.y, &uvs.z);
					if (propF + f > stopF)
						continue;
					bool duplicatedPid = false;
					for (int ii = 0; ii < (int)allGLF[propF + f].size(); ii++)
					{
						if (glc.x == allGLF[propF + f][ii].x && glc.y == allGLF[propF + f][ii].y) //if the current point is seen from multiple propagation seed
						{
							if (allGLF[propF + f][ii].z > f)
							{
								allGLF[propF + f][ii].z = f;
								allGLF[propF + f][ii].x = glc.x;
								allGLF[propF + f][ii].y = glc.y;
								allUVS[propF + f][ii] = uvs;
							}
							duplicatedPid = true;
							break;
						}
					}

					if (!duplicatedPid)
					{
						glc.z = f;
						allGLF[propF + f].push_back(glc);
						allUVS[propF + f].push_back(uvs);
					}
				}
			}
			fclose(fp);
		}
		sprintf(Fname, "%s/%d/PnPTc/InliersB_%.4d.txt", Path, camID, propF);
		if (IsFileExist(Fname) == 1)
		{
			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d %d ", &glc.x, &glc.y, &nf) != EOF)
			{
				for (int f = 0; f < nf; f++)
				{
					fscanf(fp, "%f %f %f ", &uvs.x, &uvs.y, &uvs.z);
					if (propF - f < startF)
						continue;

					bool duplicatedPid = false;
					for (int ii = 0; ii < (int)allGLF[propF - f].size(); ii++)
					{
						if (glc.x == allGLF[propF - f][ii].x && glc.y == allGLF[propF - f][ii].y) //if the current point is seen from multiple propagation seed
						{
							if (allGLF[propF - f][ii].z > f)
							{
								allGLF[propF - f][ii].z = f;
								allGLF[propF - f][ii].x = glc.x;
								allGLF[propF - f][ii].y = glc.y;
								allUVS[propF - f][ii] = uvs;
							}
							duplicatedPid = true;
							break;
						}
					}

					if (!duplicatedPid)
					{
						glc.z = f;
						allGLF[propF - f].push_back(glc);
						allUVS[propF - f].push_back(uvs);
					}
				}
			}
			fclose(fp);
		}
	}

	printLOG("writing PnPmTc data [%d-->%d]...", camID, startF, stopF);
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		sprintf(Fname, "%s/%d/PnPmTc/Inliers_%.4d.txt", Path, camID, fid); fp = fopen(Fname, "w+");
		if (LocalCorpusInfo.xyz.size() > 0)
		{
			for (size_t ii = 0; ii < allGLF[fid].size(); ii++)
			{
				lpid = allGLF[fid][ii].y;
				fprintf(fp, "%d %d %f %f %f %.3f %.3f %.3f\n", allGLF[fid][ii].x, lpid, LocalCorpusInfo.xyz[lpid].x, LocalCorpusInfo.xyz[lpid].y, LocalCorpusInfo.xyz[lpid].z, allUVS[fid][ii].x, allUVS[fid][ii].y, allUVS[fid][ii].z);
			}
		}
		else
		{
			for (size_t ii = 0; ii < allGLF[fid].size(); ii++)
			{
				gpid = allGLF[fid][ii].x;
				fprintf(fp, "%d %d %f %f %f %.3f %.3f %.3f\n", gpid, allGLF[fid][ii].y, GlobalCorpusInfo.xyz[gpid].x, GlobalCorpusInfo.xyz[gpid].y, GlobalCorpusInfo.xyz[gpid].z, allUVS[fid][ii].x, allUVS[fid][ii].y, allUVS[fid][ii].z);
			}
		}
		fclose(fp);
	}
	printLOG("Done\n");

	delete[]allGLF, delete[]allUVS;

	return 0;
}
int MergeTrackedCorpusPoints(char *Path, int camID, int startF, int stopF, int increF)
{
	char Fname[512];

	Corpus CorpusInfo;
	int dummy, nPoints, useColor;
	sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	fscanf(fp, "%d %d %d", &dummy, &nPoints, &useColor);
	CorpusInfo.n3dPoints = nPoints;
	Point3d xyz;	Point3i rgb;
	CorpusInfo.xyz.reserve(nPoints);
	if (useColor)
	{
		CorpusInfo.rgb.reserve(nPoints);
		for (int jj = 0; jj < nPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
			CorpusInfo.xyz.push_back(xyz);
			CorpusInfo.rgb.push_back(rgb);
		}
	}
	else
	{
		CorpusInfo.rgb.reserve(nPoints);
		for (int jj = 0; jj < nPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
			CorpusInfo.xyz.push_back(xyz);
		}
	}
	fclose(fp);

	int id; Point2d uv; double s;
	vector<int> Vp3did, Vp3did2, cSeedDistance;
	vector<double> Vs, Vs2;
	vector<Point2d>Vuv, Vuv2;
	vector<Point3d> Vxyz2;

	printLOG("Cam %d: ", camID);
	for (int selectedF = startF; selectedF <= stopF; selectedF += increF)
	{
		Vp3did.clear(), Vuv.clear(), cSeedDistance.clear();
		for (int fid = startF; fid <= stopF; fid += increF)
		{
			sprintf(Fname, "%s/%d/Track2D/%.4d_%.4d.txt", Path, camID, fid, selectedF); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%d %lf %lf %lf", &id, &uv.x, &uv.y, &s) != EOF)
			{
				bool duplicatedPid = false;
				for (int ii = 0; ii < (int)Vp3did.size(); ii++)
				{
					if (id == Vp3did[ii]) //if the current point is seen from multiple propagation seed
					{
						if (cSeedDistance[ii] > abs(selectedF - fid)) // pick the closest seed
						{
							cSeedDistance[ii] = abs(selectedF - fid);
							Vp3did[ii] = id, Vuv[ii] = uv, Vs[ii] = s;
						}
						duplicatedPid = true;
						break;
					}
				}
				if (!duplicatedPid)
				{
					cSeedDistance.push_back(abs(selectedF - fid));
					Vp3did.push_back(id), Vuv.push_back(uv), Vs.push_back(s);
				}
			}
			fclose(fp);
		}
		if (Vp3did.size() == 0)
			continue;

		Vp3did2.clear(), Vxyz2.clear(), Vuv2.clear(), Vs2.clear();
		sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, camID, selectedF); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			while (fscanf(fp, "%d %lf %lf %lf %lf %lf %lf", &id, &xyz.x, &xyz.y, &xyz.z, &uv.x, &uv.y, &s) != EOF)
			{
				Vp3did2.push_back(id), Vxyz2.push_back(xyz), Vuv2.push_back(uv);
				Vs2.push_back(s);
			}
			fclose(fp);
		}

		//find tracked points not in Inliers_3D2D
		int count = 0;
		for (int ii = 0; ii < (int)Vp3did.size(); ii++)
		{
			bool found = false;
			for (int jj = 0; jj < (int)Vp3did2.size(); jj++)
			{
				if (Vp3did[ii] == Vp3did2[jj])
				{
					found = true;
					break;
				}
			}

			if (!found) //let's add the tracked point to Inliers_3D2D
			{
				count++;
				Vp3did2.push_back(Vp3did[ii]);
				Vuv2.push_back(Vuv[ii]);
				Vxyz2.push_back(CorpusInfo.xyz[Vp3did[ii]]);
				Vs2.push_back(Vs[ii]);
			}
		}
		printLOG("@%d: %d+ ...", selectedF, count);

		sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, camID, selectedF); fp = fopen(Fname, "w+");
		for (int ii = 0; ii < (int)Vp3did2.size(); ii++)
			fprintf(fp, "%d %f %f %f %.6f %.6f %.2f\n", Vp3did2[ii], Vxyz2[ii].x, Vxyz2[ii].y, Vxyz2[ii].z, Vuv2[ii].x, Vuv2[ii].y, Vs2[ii]);
		fclose(fp);
	}
	printLOG("\n");

	return 0;
}

int VideoBasedBlurDetection(char *Path, int SelectedCameraID, int startF, int stopF, vector<int> &goodFid)
{
	double startTime = omp_get_wtime();
	char Fname[512];
	sprintf(Fname, "%s/%d/x.mp4", Path, SelectedCameraID); VideoCapture cap(Fname);
	if (!cap.isOpened())
	{
		sprintf(Fname, "%s/%d/x.mov", Path, SelectedCameraID); cap.open(Fname);
		if (!cap.isOpened())
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
	}

	//int fid = startF;
	int orgStop = stopF;
	stopF = min(stopF, (int)cap.get(CV_CAP_PROP_FRAME_COUNT));
	//cap.set(CV_CAP_PROP_POS_FRAMES, fid);

	Mat cvImg, Gx, Gy;
	vector<double>iSqG; iSqG.reserve(stopF - startF + 1);

	printLOG("Computing blurryness score for camera %d...\n", SelectedCameraID);
	int fid = 0, per = 10, increPer = 10;
	while (true)
	{
		bool bSuccess = cap.read(cvImg);
		if (fid < startF)
		{
			fid++;
			continue;
		}
		if (!bSuccess)
		{
			sprintf(Fname, "%s/Logs/realStopFrame.txt", Path);
			FILE *fp = fopen(Fname, "w");
			fprintf(fp, "%d\n", fid);
			fclose(fp);

			stopF = fid;
		}
		if (!bSuccess || fid > stopF)
			break;

		Sobel(cvImg, Gx, CV_32F, 1, 0);
		Sobel(cvImg, Gy, CV_32F, 0, 1);
		double normGx = norm(Gx), normGy = norm(Gy);
		double isumSqG = 1.0 / (normGx * normGx + normGy * normGy + 1e-16);
		iSqG.push_back(isumSqG);

		if (100 * (fid - startF) / (stopF - startF + 1) >= per)
			printLOG("%d%%..", per), per += increPer;
		//printLOG("(%d: %.3e)..", fid, isumSqG);
		fid++;
	}
	printLOG("100%%\n");

	printLOG("Detect blurry frames...");
	//apply smothing and dif filters to detect changes in intensity grad
	double *smoothed_iSqG = new double[iSqG.size()],
		*dif_iSqG = new double[iSqG.size()],
		*absdif_iSqG = new double[iSqG.size()];

	double kernel[5] = { 0.2, 0.2, 0.2, 0.2, 0.2 };
	filter1D_row_Double(kernel, 5, &iSqG[0], smoothed_iSqG, (int)iSqG.size(), 1);

	kernel[0] = 0.5, kernel[1] = -0.5;
	filter1D_row_Double(kernel, 2, smoothed_iSqG, dif_iSqG, (int)iSqG.size(), 1);

	//trying to find sensible gradient threshold
	int *id = new int[iSqG.size()];
	for (int ii = 0; ii < (int)iSqG.size(); ii++)
		absdif_iSqG[ii] = abs(dif_iSqG[ii]), id[ii] = ii;

	Quick_Sort_Double(absdif_iSqG, id, 0, (int)iSqG.size() - 1);

	double avg = 0.0;
	for (int ii = 0; ii < 90 * iSqG.size() / 100; ii++)
		avg += dif_iSqG[id[ii]];
	avg = avg / (90 * iSqG.size() / 100);

	double var = 0.0;
	for (int ii = 0; ii < 90 * iSqG.size() / 100; ii++)
		var += pow(dif_iSqG[id[ii]] - avg, 2);
	var = sqrt(var / ((90 * iSqG.size() / 100) - 1));

	//find good frames
	for (int ii = 0; ii < (int)iSqG.size(); ii++)
		if (abs(dif_iSqG[ii] - avg) < var)
			goodFid.push_back(ii);

	delete[]smoothed_iSqG, delete[]absdif_iSqG, delete[]dif_iSqG, delete[] id;
	printLOG("Done... %.2fs\n", omp_get_wtime() - startTime);

	sprintf(Fname, "%s/%d/goodFrames_%d_%d.txt", Path, SelectedCameraID, startF, orgStop); FILE *fp = fopen(Fname, "w");
	for (int jj = 0; jj < (int)goodFid.size(); jj++)
		fprintf(fp, "%d\n", goodFid[jj]);
	fclose(fp);

	return 0;
}
int VideoBasedBlurDetection2(char *Path, int SelectedCameraID, int startF, int stopF, vector<int> &goodFid)
{
	double startTime = omp_get_wtime();
	char Fname[512];

	Mat cvImg, Gx, Gy;
	vector<double>iSqG; iSqG.reserve(stopF - startF + 1);

	printLOG("Computing blurryness score for camera %d: ", SelectedCameraID);
	int fid = 0, per = 10, increPer = 10;
	for (int fid = startF; fid <= stopF; fid++)
	{
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, SelectedCameraID, fid);
		//sprintf(Fname, "%s/img_%.10d.jpg", Path, fid);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, SelectedCameraID, fid);
			if (IsFileExist(Fname) == 0)
			{
				printLOG("Cannot load %s\n", Fname);

				sprintf(Fname, "%s/Logs/realStopFrame.txt", Path);
				FILE *fp = fopen(Fname, "w");
				fprintf(fp, "%d\n", fid);
				fclose(fp);

				stopF = fid;
				break;
			}
		}
		cvImg = imread(Fname);

		Sobel(cvImg, Gx, CV_32F, 1, 0);
		Sobel(cvImg, Gy, CV_32F, 0, 1);
		double normGx = norm(Gx), normGy = norm(Gy);
		double isumSqG = 1.0 / (normGx * normGx + normGy * normGy + 1e-16);
		iSqG.push_back(isumSqG);

		if (100 * (fid - startF) / (stopF - startF + 1) >= per)
			printLOG("%d%%..", per), per += increPer;
		//printLOG("(%d: %.3e)..", fid, isumSqG);
	}
	printLOG("100%%\n");

	printLOG("Detect blurry frames...");
	//apply smothing and dif filters to detect changes in intensity grad
	double *smoothed_iSqG = new double[iSqG.size()],
		*dif_iSqG = new double[iSqG.size()],
		*absdif_iSqG = new double[iSqG.size()];

	double kernel[5] = { 0.2, 0.2, 0.2, 0.2, 0.2 };
	filter1D_row_Double(kernel, 5, &iSqG[0], smoothed_iSqG, (int)iSqG.size(), 1);

	kernel[0] = 0.5, kernel[1] = -0.5;
	filter1D_row_Double(kernel, 2, smoothed_iSqG, dif_iSqG, (int)iSqG.size(), 1);

	//trying to find sensible gradient threshold
	int *id = new int[iSqG.size()];
	for (int ii = 0; ii < (int)iSqG.size(); ii++)
		absdif_iSqG[ii] = abs(dif_iSqG[ii]), id[ii] = ii;

	Quick_Sort_Double(absdif_iSqG, id, 0, (int)iSqG.size() - 1);

	double avg = 0.0;
	for (int ii = 0; ii < 90 * iSqG.size() / 100; ii++)
		avg += dif_iSqG[id[ii]];
	avg = avg / (90 * iSqG.size() / 100);

	double var = 0.0;
	for (int ii = 0; ii < 90 * iSqG.size() / 100; ii++)
		var += pow(dif_iSqG[id[ii]] - avg, 2);
	var = sqrt(var / ((90 * iSqG.size() / 100) - 1));

	//find good frames
	for (int ii = 0; ii < (int)iSqG.size(); ii++)
		if (abs(dif_iSqG[ii] - avg) < var)
			goodFid.push_back(ii + startF);

	delete[]smoothed_iSqG, delete[]absdif_iSqG, delete[]dif_iSqG, delete[] id;
	printLOG("Done... %.2fs\n", omp_get_wtime() - startTime);

	sprintf(Fname, "%s/%d/goodFrames_%d_%d.txt", Path, SelectedCameraID, startF, stopF); FILE *fp = fopen(Fname, "w");
	for (int jj = 0; jj < (int)goodFid.size(); jj++)
		fprintf(fp, "%d\n", goodFid[jj]);
	fclose(fp);

	return 0;
}
int KeyFramesViaOpticalFlow(char *Path, int SelectedCamera, vector<int> &nonBlurFrames, double successTrackingRatio, double avgflowMagThresh, int minFeatures, int maxKFInternal, int startF, int stopF, int rotateImage, double scale, int display)
{
	char Fname[512];
	sprintf(Fname, "%s/Corpus", Path); makeDir(Fname);

	Mat colorImg, preColorImg, gray, prevGray, tImg, backGround, nearestNonBlur, resizeImg;
	vector<Point2f> points[3];
	vector<uchar> status;
	vector<float> err;

	int maxFeatures = 50000, npryLevels = 3;
	float *allDistance = new float[maxFeatures];
	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, 0.03);
	Size winSize(31, 31);

	bool *TakenNonBlurFrames = new bool[nonBlurFrames.size()];
	for (int ii = 0; ii < (int)nonBlurFrames.size(); ii++)
		TakenNonBlurFrames[ii] = false;

	sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, SelectedCamera); FILE *fp = fopen(Fname, "w+");

	sprintf(Fname, "%s/%d/x.mp4", Path, SelectedCamera); VideoCapture cap(Fname);
	if (!cap.isOpened())
	{
		sprintf(Fname, "%s/%d/x.mov", Path, SelectedCamera); cap.open(Fname);
		if (!cap.isOpened())
		{
			printLOG("Cannot load %s\n", Fname);
			return 0;
		}
	}
	stopF = min(stopF, (int)cap.get(CV_CAP_PROP_FRAME_COUNT));
	//cap.set(CV_CAP_PROP_POS_FRAMES, startF);

	if (display == 1)
		sprintf(Fname, "KF of Camera %d", SelectedCamera), namedWindow(Fname, WINDOW_NORMAL);
	int fid = 0, nkf = 0, latestNonBlurred = 0, lkf, npts_lkf;
	int mytest = 0;
	while (true)
	{
		if (!cap.read(colorImg)) //if not success, break loop
			break;
		if (fid < startF)
		{
			fid++;
			continue;
		}
		if (stopF > 0 && fid > stopF)
			break;

		if (rotateImage == 1) //flip updown
		{
			int width = colorImg.cols, height = colorImg.rows, nchannels = 3;
			for (int kk = 0; kk < nchannels; kk++)
			{
				for (int jj = 0; jj < height / 2; jj++)
					for (int ii = 0; ii < width; ii++)
					{
						uchar buf = colorImg.data[nchannels*ii + jj * nchannels*width + kk];
						colorImg.data[nchannels*ii + jj * nchannels*width + kk] = colorImg.data[nchannels*(width - 1 - ii) + (height - 1 - jj)*nchannels*width + kk];
						colorImg.data[nchannels*(width - 1 - ii) + (height - 1 - jj)*nchannels*width + kk] = buf;
					}
			}
		}
		//cache the frame if it is not blured
		for (auto ii : nonBlurFrames)
		{
			if (ii == fid)
			{
				mytest = fid;
				nearestNonBlur = colorImg;
				break;
			}
		}

		cvtColor(colorImg, gray, CV_BGR2GRAY);
		if (display == 1)
			cvtColor(gray, backGround, CV_GRAY2BGR);

		if (points[0].size() == 0)
		{
			points[0].clear(), points[1].clear();
			goodFeaturesToTrack(gray, points[1], maxFeatures, 0.001, 15 * max(1, gray.cols / 1920), Mat(), 7 * max(1, gray.cols / 1920), false, 0.04);
			//BucketGoodFeaturesToTrack(gray, points[1], 5, maxFeatures, 0.001, 15, 7, 0, 0.04);
			if (points[1].size() > (int)(1.5*minFeatures)) //starting frame should contain many features
			{
				sprintf(Fname, "%s/Corpus/%d_%.4d.png", Path, SelectedCamera, nkf);
				if (scale == 1.0)
					imwrite(Fname, colorImg); //keyframe
				else
				{
					cv::resize(colorImg, resizeImg, Size(), scale, scale, CV_INTER_CUBIC);
					imwrite(Fname, resizeImg);
				}
				npts_lkf = (int)points[1].size(), lkf = fid, nkf++;

				fprintf(fp, "%d %d %d 1\n", SelectedCamera, nkf - 1, fid);
				printLOG("Set KeyF %.4d. RealF: %.4d. #points: %d\n", nkf - 1, fid, npts_lkf);
			}
			else
				points[1].clear();

			if (display == 1)
				for (int jj = 0; jj < points[1].size(); jj++)
					circle(backGround, points[1][jj], 3, Scalar(0, 0, 255), 2);
		}
		else
		{
			status.clear(); err.clear();
			if (prevGray.empty())
				gray.copyTo(prevGray);
			calcOpticalFlowPyrLK(prevGray, gray, points[0], points[1], status, err, winSize, npryLevels, termcrit);
			//calcOpticalFlowPyrLK(gray, prevGray, points[1], points[2], status, err, winSize, npryLevels, termcrit); //forward-back constistency check

			int i, k;
			double avgmagFlow = 0.0;
			for (i = k = 0; i < (int)points[1].size(); i++)
			{
				if (!status[i])
					continue;
				//if (norm(points[0][i] - points[2][i]) > 1) //forward-back constistency check
				//	continue;
				allDistance[k] = norm(points[1][i] - points[0][i]);
				points[1][k++] = points[1][i];
			}
			sort(allDistance, allDistance + k);
			avgmagFlow = allDistance[k / 5]; //take 20% percentile as the reference

											 /*for (i = k = 0; i < (int)points[1].size(); i++)
											 {
											 if (!status[i])
											 continue;
											 avgmagFlow += norm(points[1][i] - points[0][i]);
											 points[1][k++] = points[1][i];
											 }
											 avgmagFlow /= k;*/

											 //printLOG("RealF: %.4d. Flow strength: %.2f. Tracking ratio: %.2f.\n", fid, avgmagFlow, 1.0*k / (int)points[1].size());
			if (k < successTrackingRatio*(int)points[1].size() || avgmagFlow >avgflowMagThresh / 1920 * backGround.cols || fid - lkf > maxKFInternal || (int)points[1].size() < minFeatures)
			{
				printLOG("Cam #%d: Attempt for keyFrame @RealF %d : #Points: %.4d. Flow strength: %.2f. Tracking ratio: %.2f...", SelectedCamera, fid, points[1].size(), avgmagFlow, 1.0*k / (int)points[1].size());
				int nPtsOld = (int)points[1].size();
				double oldTrackingRatio = 1.0*k / (int)points[1].size();

				goodFeaturesToTrack(gray, points[1], maxFeatures, 0.001, 15 * max(1, gray.cols / 1920), Mat(), 7 * max(1, gray.cols / 1920), false, 0.04);
				//BucketGoodFeaturesToTrack(gray, points[1], 5, maxFeatures, 0.001, 15, 7, 0, 0.04); //attempting keyframe
				if (points[1].size() > (int)(1.5*minFeatures)) //starting frame should contain many features
				{
					//try to find the nearest non-blurred frames
					int nnDist = 9e9, bestFid = -1, bestId = 0;
					for (int ii = 0; ii < (int)nonBlurFrames.size(); ii++)
					{
						if (fid < nonBlurFrames[ii]) //only look back in time
							break;
						int Dist = fid - nonBlurFrames[ii];
						if (nnDist > Dist)
							nnDist = Dist, bestFid = nonBlurFrames[ii], bestId = ii;
					}

					if (bestFid == -1 || TakenNonBlurFrames[bestId])//if it is taken....Better having nothing
					{
						;/*cap.set(CV_CAP_PROP_POS_FRAMES, fid - maxKFInternal / 10);  //better take the latest good image instead of the current one (blur, shake...)
						 if (cap.read(colorImg))
						 imwrite(Fname, colorImg);
						 fprintf(fp, "%d %d %d\n", SelectedCamera, nkf, fid - maxKFInternal / 10);
						 printLOG("KeyF %d, realF: %d: #points: %.4d. Flow strength: %.2f. Tracking ratio: %.2f.\n", nkf, fid - maxKFInternal / 10, nPtsOld, avgmagFlow, 1.0*k / (int)points[1].size());*/
					}
					else
					{
						TakenNonBlurFrames[bestId] = true;
						if (mytest != bestFid)
							printLOG("Problem with keyFrame\n");

						//cap.set(CV_CAP_PROP_POS_FRAMES, bestFid);  //better take the latest good image instead of the current one (blury, shaky...)
						sprintf(Fname, "%s/Corpus/%d_%.4d.png", Path, SelectedCamera, nkf);
						if (scale == 1.0)
							imwrite(Fname, nearestNonBlur);
						else
						{
							cv::resize(nearestNonBlur, resizeImg, Size(), scale, scale, CV_INTER_CUBIC);
							imwrite(Fname, resizeImg);
						}

						npts_lkf = (int)points[1].size(), lkf = bestFid, nkf++;
						fprintf(fp, "%d %d %d 1\n", SelectedCamera, nkf - 1, bestFid);
						printLOG("Set KeyF %.4d. RealF: %.4d. #Points: %d", nkf - 1, bestFid, npts_lkf);

						//cap.set(CV_CAP_PROP_POS_FRAMES, fid + 1);
					}
				}
				else
					points[1].clear();
				printLOG("\n");
			}
			else
				points[1].resize(k);

			if (display == 1)
				for (i = 0; i < (int)points[1].size(); i++)
					circle(backGround, points[1][i], 3, Scalar(0, 0, 255), 2);
		}

		if (display == 1)
		{
			CvPoint text_origin = { backGround.cols / 30, backGround.cols / 30 };
			sprintf(Fname, "@%d: %d nkfs", fid - startF, nkf);
			putText(backGround, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * backGround.cols / 640, CV_RGB(0, 0, 255), 2);
			sprintf(Fname, "KF of Camera %d", SelectedCamera);	imshow(Fname, backGround);
			waitKey(2);
		}

		std::swap(points[1], points[0]);
		swap(prevGray, gray);
		fid++;
	}

	fclose(fp);
	cvDestroyAllWindows();
	delete[]TakenNonBlurFrames;

	return nkf;
}
int KeyFramesViaOpticalFlow_HQ(char *Path, int SelectedCamera, int startF, int stopF, int extractedImages, int rotateImage, vector<int> &nonBlurFrames, double successConsecutiveTrackingRatio, double successRefTrackingRatio, double avgflowMagThresh, int minnFeatures, int minKFInternal, int maxKFInternal, double bidir_Thresh, int interpAlgo, bool HighQualityTracking, int nThreads, int display, bool binary, bool dedicatedCorpus)
{
	int maxFeatures = 50000, npryLevels = 4, nWindows = 3, WinStep = 3, MaxWinSize = 77, MinWinSize = 11, TrackRange = min(300, stopF - startF);

	vector<int> compression_params;
	compression_params.push_back(CV_IMWRITE_JPEG_QUALITY);
	compression_params.push_back(100);

	char Fname[512];
	sprintf(Fname, "%s/Corpus", Path); makeDir(Fname);
	sprintf(Fname, "%s/cTrack2D", Path); makeDir(Fname);

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));

	vector<Mat> pPyr, cPyr, rPyr;
	Mat colorImg, preColorImg, gray, prevGray, tImg, backGround, nearestNonBlur, refFrame, resizeImg, intermediateColor, intermediateGray;
	vector<Point2f> points[4], lastRefPts;
	vector<uchar> status;
	vector<float> err, vscale;
	vector<bool> ToDel;
	vector<vector<Point2f> > tracklets;

	omp_set_num_threads(min(nThreads, omp_get_max_threads()));

	vector<float>allDistance; allDistance.reserve(maxFeatures);
	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, 0.03);
	Size winSize(MaxWinSize, MaxWinSize);
	int width, height, WinLength = (MaxWinSize + 2)*(MaxWinSize + 2) * 2;
	double *ImgIParaC = NULL, *ImgIParaP = NULL, *ImgIParaR = NULL;
	double *T1 = new double[WinLength*nThreads], *T2 = new double[6 * WinLength*nThreads];
	double dispThresh2 = bidir_Thresh * bidir_Thresh;

	int localfid;
	AffinePara warp;
	vector<float> *ForeScale = new vector<float>[maxFeatures], *BackScale = new vector<float>[maxFeatures];
	vector<AffinePara> *ForeWarp = new vector<AffinePara>[maxFeatures], *ForeiWarp = new vector<AffinePara>[maxFeatures];

	bool *TakenNonBlurFrames = new bool[nonBlurFrames.size()];
	for (int ii = 0; ii < (int)nonBlurFrames.size(); ii++)
		TakenNonBlurFrames[ii] = false;

	sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, SelectedCamera); FILE *fp = fopen(Fname, "w+");

	VideoWriter writer;
	bool firstTime = false;
	if (display == 1)
		sprintf(Fname, "KF of Camera %d", SelectedCamera), namedWindow(Fname, WINDOW_NORMAL);

	VideoCapture cap;
	vector<std::pair<Mat, int> > vImg_fid, vImg_fid2;

	if (extractedImages == 0)
	{
		sprintf(Fname, "%s/%d/x.mp4", Path, SelectedCamera); cap.open(Fname);
		if (!cap.isOpened())
		{
			sprintf(Fname, "%s/%d/x.mov", Path, SelectedCamera); cap.open(Fname);
			if (!cap.isOpened())
			{
				printLOG("Cannot load %s\n", Fname);
				return 0;
			}
		}
		stopF = min(stopF, (int)cap.get(CV_CAP_PROP_FRAME_COUNT));
		for (int fid = 0; fid < startF; fid++)
			if (!cap.read(colorImg)) //if not success, break loop
				return 1;
	}

	double startTime = omp_get_wtime();

	int fid = 0, nkf = 0, lastKFid, lkf, npts_lkf, firstKey = 0, skipFrame = 0;
	for (int fid = startF; fid <= stopF; fid++)
	{
		if (skipFrame == 1)
		{
			if (fid - lkf <= minKFInternal / 10)
			{
				if (extractedImages == 0)
				{
					if (vImg_fid2.size() == 0) //no buffer (no rolling back)
					{
						if (!cap.read(colorImg)) //if not success, break loop
							break;
						if (rotateImage == 1) //flip updown
						{
							int width = colorImg.cols, height = colorImg.rows, nchannels = 3;
							for (int kk = 0; kk < nchannels; kk++)
							{
								for (int jj = 0; jj < height / 2; jj++)
									for (int ii = 0; ii < width; ii++)
									{
										uchar buf = colorImg.data[nchannels*ii + jj * nchannels*width + kk];
										colorImg.data[nchannels*ii + jj * nchannels*width + kk] = colorImg.data[nchannels*(width - 1 - ii) + (height - 1 - jj)*nchannels*width + kk];
										colorImg.data[nchannels*(width - 1 - ii) + (height - 1 - jj)*nchannels*width + kk] = buf;
									}
							}
						}
					}
					else
					{
						colorImg = vImg_fid2.back().first;
						vImg_fid2.pop_back();
					}
					vImg_fid.push_back(make_pair(colorImg.clone(), fid));
				}
				continue;
			}
			else
				skipFrame = 0;
		}

		if (extractedImages == 1)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, SelectedCamera, fid);
			//sprintf(Fname, "%s/img_%.10d.jpg", Path, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, SelectedCamera, fid);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n", Fname);
					break;
				}
			}
			colorImg = imread(Fname);
		}
		else
		{
			if (vImg_fid2.size() == 0) //no buffer (no rolling back)
			{
				if (!cap.read(colorImg)) //if not success, break loop
					break;
				if (rotateImage == 1) //flip updown
				{
					int width = colorImg.cols, height = colorImg.rows, nchannels = 3;
					for (int kk = 0; kk < nchannels; kk++)
					{
						for (int jj = 0; jj < height / 2; jj++)
							for (int ii = 0; ii < width; ii++)
							{
								uchar buf = colorImg.data[nchannels*ii + jj * nchannels*width + kk];
								colorImg.data[nchannels*ii + jj * nchannels*width + kk] = colorImg.data[nchannels*(width - 1 - ii) + (height - 1 - jj)*nchannels*width + kk];
								colorImg.data[nchannels*(width - 1 - ii) + (height - 1 - jj)*nchannels*width + kk] = buf;
							}
					}
				}
			}
			else
			{
				colorImg = vImg_fid2.back().first;
				vImg_fid2.pop_back();
			}
			vImg_fid.push_back(make_pair(colorImg.clone(), fid));
		}
		cvtColor(colorImg, gray, CV_BGR2GRAY);
		buildOpticalFlowPyramid(gray, cPyr, winSize, npryLevels, true);

		width = gray.cols, height = gray.rows;
		if (ImgIParaC == NULL && HighQualityTracking == 1)
			ImgIParaC = new double[height*width], ImgIParaR = new double[height*width];
		double ratio = 1.0*gray.cols / 1920;

		if (display == 1)
			cvtColor(gray, backGround, CV_GRAY2BGR);

		double startTime = omp_get_wtime();
		if (points[0].size() == 0)
		{
			points[0].clear(), points[1].clear();
			ExtractSiftCPU(Path, SelectedCamera, fid, gray, points[1], vscale, true);

			if (points[1].size() > (int)(1.5*minnFeatures)) //starting frame should contain many features
			{
				firstKey = 1;
				sprintf(Fname, "%s/%d/%.4d_%d.jpg", Path, SelectedCamera, fid, nkf);
				imwrite(Fname, colorImg, compression_params);

				refFrame = gray.clone();
				buildOpticalFlowPyramid(refFrame, rPyr, winSize, npryLevels, true);

				if (extractedImages == 0) //new kf starts
					vImg_fid.clear();
				lastKFid = fid, localfid = 1;
				lastRefPts = points[1];
				npts_lkf = (int)points[1].size(), lkf = fid;

				tracklets.clear(), ToDel.clear(), points[0].clear();
				if (HighQualityTracking == 1)
				{
					Generate_Para_Spline(refFrame.data, ImgIParaR, width, height, interpAlgo);
					if (npts_lkf > maxFeatures)
					{
						delete[]ForeScale, delete[]BackScale, delete[]ForeWarp, delete[]ForeiWarp;
						ForeScale = new vector<float>[npts_lkf], ForeWarp = new vector<AffinePara>[npts_lkf], ForeiWarp = new vector<AffinePara>[npts_lkf];
					}
					for (int ii = 0; ii < npts_lkf; ii++)
					{
						ForeScale[ii].reserve(TrackRange), ForeScale[ii].push_back(vscale[ii]);
						ForeWarp[ii].reserve(TrackRange), ForeWarp[ii].push_back(warp);
						ForeiWarp[ii].reserve(TrackRange), ForeiWarp[ii].push_back(warp);
					}
				}
				for (int ii = 0; ii < npts_lkf; ii++)
				{
					ToDel.push_back(0);
					vector<Point2f> track; track.push_back(lastRefPts[ii]), tracklets.push_back(track);
				}

				fprintf(fp, "%d %d %d 1\n", SelectedCamera, nkf, lkf);
				printLOG("Set KeyF %.4d. RealF: %.4d. #points: %d\n", nkf, fid, npts_lkf);
				nkf++;

				if (display == 1)
					for (int pid = 0; pid < points[1].size(); pid++)
						if (!ToDel[pid])
							circle(backGround, points[1][pid], max(1, max(min((int)(ForeScale[pid][localfid - 1] * 3 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5))), colors[pid % 8], 2), circle(backGround, points[1][pid], 1, colors[pid % 8], 2);
			}
			else
			{
				sprintf(Fname, "%s/%d/%.4d.sift", Path, SelectedCamera, fid); remove(Fname);
				points[0].clear(), points[1].clear(), vscale.clear();
				//if (extractedImages == 0) // will be clear in new kf extraction anyway
				//	vImg_fid.clear();
			}
		}
		else
		{
			if (HighQualityTracking == 1)
				Generate_Para_Spline(gray.data, ImgIParaC, width, height, interpAlgo);

			int pNpts = 0, tNpts = 0;
			double avgmagFlow, RefAvgmagFlow, curTrackingRatio, RefTrackingRatio;

			status.clear(), err.clear(), points[1].clear();
			points[2] = points[0];
			calcOpticalFlowPyrLK(pPyr, cPyr, points[0], points[1], status, err, winSize, npryLevels, termcrit);
			calcOpticalFlowPyrLK(cPyr, pPyr, points[1], points[2], status, err, winSize, npryLevels, termcrit);

			allDistance.clear();
			for (int ii = 0; ii < (int)points[0].size(); ii++)
			{
				if (points[0][ii].x > 0 && points[0][ii].y > 0)
					pNpts++;
				if (status[ii] == 0 || ToDel[ii] == 1 || points[0][ii].x < 0)
					points[1][ii] = Point2f(-1, -1), ToDel[ii] = 1;
				else
				{
					double BiDirDist = norm(points[2][ii] - points[0][ii]);
					if (BiDirDist < bidir_Thresh*gray.cols / 1920)
						allDistance.push_back(norm(points[1][ii] - points[0][ii])), tNpts++;
					else
						points[1][ii] = Point2f(-1, -1), ToDel[ii] = 1;
				}
			}
			sort(allDistance.begin(), allDistance.end());

			curTrackingRatio = 1.0* tNpts / pNpts;
			if (tNpts < minnFeatures / 5)
				RefTrackingRatio = 0, curTrackingRatio = 0, avgmagFlow = 9e9; //force to upate
			else
			{
				avgmagFlow = allDistance[tNpts / 5]; //take 20% percentile as the reference

				tNpts = 0;
				allDistance.clear();

				if (HighQualityTracking == 1)
				{
#pragma omp parallel for schedule(dynamic, 1)
					for (int pid = 0; pid < npts_lkf; pid++)
					{
						int threadID = omp_get_thread_num();
						if (ToDel[pid] == 1)
							continue;

						LKParameters LKArg; //LKArg.hsubset to be changed according to the point scale
						LKArg.DisplacementThresh = bidir_Thresh, LKArg.DIC_Algo = 3, LKArg.InterpAlgo = interpAlgo, LKArg.EpipEnforce = 0;
						LKArg.Incomplete_Subset_Handling = 0, LKArg.Convergence_Criteria = 0, LKArg.Analysis_Speed = 0, LKArg.IterMax = 15;
						LKArg.PSSDab_thresh = 0.1, LKArg.ZNCCThreshold = 0.7;
						double bestcwarp[4], besticwarp[4], cwarp[4], icwarp[4];

						Point2d bestNpt;
						double dist, minDist = 9e9;
						vector<double> vdist;
						int winsize = max(min((int)(ForeScale[pid][localfid - 1] * 6 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5)), orghsubset = winsize / 2 + 1;

						for (int trial = 0; trial < nWindows; trial++)  //Look for the best window size with minimum drift and consistent flow wrst the ref template:
						{
							LKArg.hsubset = orghsubset - trial * WinStep / 2;
							Point2d refpt = lastRefPts[pid], npt = points[1][pid], brefpt = lastRefPts[pid];

							for (int ii = 0; ii < 4; ii++)
								cwarp[ii] = ForeWarp[pid][localfid - 1].warp[ii];
							double score1 = TemplateMatching(ImgIParaR, ImgIParaC, width, height, width, height, 1, refpt, npt, LKArg, false, T1 + WinLength * threadID, T2 + 6 * WinLength*threadID, cwarp);
							if (score1 < LKArg.ZNCCThreshold || npt.x <winsize || npt.y < winsize || npt.x >width - winsize || npt.y >height - winsize)
								continue;

							for (int ii = 0; ii < 4; ii++)
								icwarp[ii] = ForeiWarp[pid][localfid - 1].warp[ii];
							double score2 = TemplateMatching(ImgIParaC, ImgIParaR, width, height, width, height, 1, npt, brefpt, LKArg, false, T1 + WinLength * threadID, T2 + 6 * WinLength*threadID, icwarp);
							if (score2 < LKArg.ZNCCThreshold || brefpt.x <winsize || brefpt.y < winsize || brefpt.x >width - winsize || brefpt.y >height - winsize)
								continue;

							dist = pow(brefpt.x - refpt.x, 2) + pow(brefpt.y - refpt.y, 2);
							vdist.push_back(sqrt(dist));
							if (dist < minDist && dist < dispThresh2)
							{
								minDist = dist, bestNpt = npt;
								for (int ii = 0; ii < 4; ii++)
									bestcwarp[ii] = cwarp[ii], besticwarp[ii] = icwarp[ii];
							}
						}

						ToDel[pid] = true;
						if (minDist < dispThresh2)
						{
							points[1][pid] = bestNpt;

							ForeWarp[pid].push_back(AffinePara(bestcwarp));
							ForeiWarp[pid].push_back(AffinePara(besticwarp));

							ToDel[pid] = false;
							double ns = ForeScale[pid][0] * max(ForeWarp[pid][localfid].warp[0] + 1.0 + ForeWarp[pid][localfid].warp[1], ForeWarp[pid][localfid].warp[2] + ForeWarp[pid][localfid].warp[3] + 1.0);
							ForeScale[pid].push_back(ns);

#pragma omp critical
							allDistance.push_back(norm(points[1][pid] - lastRefPts[pid])), tracklets[pid].push_back(points[1][pid]), tNpts++;
						}
					}
				}
				else
				{
					status.clear(), err.clear();
					points[2] = lastRefPts;
					calcOpticalFlowPyrLK(pPyr, cPyr, lastRefPts, points[1], status, err, winSize, npryLevels, termcrit);
					calcOpticalFlowPyrLK(cPyr, pPyr, points[1], points[2], status, err, winSize, npryLevels, termcrit);

					for (int pid = 0; pid < npts_lkf; pid++)
					{
						if (status[pid] == 0 || ToDel[pid] == 1 || points[1][pid].x < 0)
							points[1][pid] = Point2f(-1, -1), ToDel[pid] = 1;
						else
						{
							double BiDirDist = norm(points[2][pid] - lastRefPts[pid]);
							if (BiDirDist < bidir_Thresh*gray.cols / 1920)
								allDistance.push_back(norm(points[1][pid] - points[0][pid])), tracklets[pid].push_back(points[1][pid]), tNpts++;
							else
								points[1][pid] = Point2f(-1, -1), ToDel[pid] = 1;
						}
					}
				}
				localfid++;

				if (tNpts > minnFeatures / 5)
				{
					sort(allDistance.begin(), allDistance.end());
					RefAvgmagFlow = allDistance[tNpts / 5]; //take 20% percentile as the reference
					RefTrackingRatio = 1.0* tNpts / npts_lkf;
				}
				else
					RefTrackingRatio = 0, curTrackingRatio = 0; //force to updae
			}

			printLOG("%d/%d : #Points: %.4d. Flow strength: %.2f. RefvFlow strength: %.2f. CurTrackingr: %.2f. RefTrackingR: %.2f...%.2fs ", fid, SelectedCamera, allDistance.size(), avgmagFlow, RefAvgmagFlow, curTrackingRatio, RefTrackingRatio, omp_get_wtime() - startTime);
			bool flag1 = RefTrackingRatio < successRefTrackingRatio;
			bool flag2 = curTrackingRatio < successConsecutiveTrackingRatio;
			bool flag3 = avgmagFlow > avgflowMagThresh *ratio;
			bool flag4 = allDistance.size() < min(0.3*lastRefPts.size(), 1.0*minnFeatures);
			bool flag5 = fid - lkf > maxKFInternal;
			if (flag1 || flag2 || flag3 || flag4 || flag5)
			{
				if (!binary)
				{
					sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.txt", Path, SelectedCamera, lkf); FILE *fp2 = fopen(Fname, "w+");
					for (int ii = 0; ii < (int)tracklets.size(); ii++)
					{
						fprintf(fp2, "%d %d ", ii, (int)tracklets[ii].size());
						for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
							fprintf(fp2, "%.2f %.2f %.3f", tracklets[ii][jj].x, tracklets[ii][jj].y, ForeScale[ii][jj]);
						fprintf(fp2, "\n");
					}
					fclose(fp2);
				}
				else
				{
					sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.dat", Path, SelectedCamera, lkf);
					ofstream fout; fout.open(Fname, ios::binary);
					int n = (int)tracklets.size();
					fout.write(reinterpret_cast<char *>(&n), sizeof(int));
					for (int ii = 0; ii < (int)tracklets.size(); ii++)
					{
						int len = (int)tracklets[ii].size();
						fout.write(reinterpret_cast<char *>(&ii), sizeof(int));
						fout.write(reinterpret_cast<char *>(&len), sizeof(int));
						for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
						{
							float u = (float)tracklets[ii][jj].x, v = (float)tracklets[ii][jj].y, s = (float)ForeScale[ii][jj];
							fout.write(reinterpret_cast<char *>(&u), sizeof(float));
							fout.write(reinterpret_cast<char *>(&v), sizeof(float));
							fout.write(reinterpret_cast<char *>(&s), sizeof(float));
						}
					}
					fout.close();
				}

				if (fid - lkf <= minKFInternal / 10) //stop tracking the previous kf and prepare to set the new kf
					skipFrame = 1;
				else
					skipFrame = 0;

				if (fid - lkf <= minKFInternal) //stop tracking the previous kf and prepare to set the new kf
				{
					tracklets.clear(), ToDel.clear(), points[0].clear(), points[1].clear(), vscale.clear();
					for (int ii = 0; ii < npts_lkf; ii++)
						ForeScale[ii].clear(), ForeWarp[ii].clear(), ForeiWarp[ii].clear();

					//if (extractedImages == 0) // will be clear in new kf extraction anyway
					//	vImg_fid.clear();
				}
				else
				{
					tracklets.clear(), ToDel.clear(), points[0].clear(), points[1].clear(), vscale.clear();
					for (int ii = 0; ii < npts_lkf; ii++)
						ForeScale[ii].clear(), ForeWarp[ii].clear(), ForeiWarp[ii].clear();

					//try to find the nearest non-blurred frames
					int nnDist = 9e9, bestId = 0, bestFid = -1;
					for (int ii = 0; ii < (int)nonBlurFrames.size(); ii++)
					{
						if (fid < nonBlurFrames[ii]) //only look back in time
							break;
						int Dist = fid - nonBlurFrames[ii];
						if (nnDist > Dist)
							nnDist = Dist, bestFid = nonBlurFrames[ii], bestId = ii;
					}
					if (bestFid == -1 || TakenNonBlurFrames[bestId] || bestFid <= lastKFid)//fine, move on
					{
						points[1].clear(), vscale.clear();
						//if (extractedImages == 0) // will be clear in new kf extraction anyway
						//	vImg_fid.clear();
					}
					else
					{
						if (extractedImages == 1)
						{
							fid = bestFid; //roll back
							sprintf(Fname, "%s/%d/%.4d.jpg", Path, SelectedCamera, fid);
							//sprintf(Fname, "%s/img_%.10d.jpg", Path, fid);
							if (IsFileExist(Fname) == 0)
							{
								sprintf(Fname, "%s/%d/%.4d.png", Path, SelectedCamera, fid);
								if (IsFileExist(Fname) == 0)
								{
									printLOG("Cannot load %s\n", Fname);
									break;
								}
							}
							colorImg = imread(Fname);
						}
						else
						{
							int rollback = fid - bestFid, stackLength = (int)vImg_fid.size();
							for (int ii = 0; ii < rollback; ii++)
								vImg_fid2.push_back(vImg_fid[stackLength - ii - 1]);
							fid = bestFid; //roll back

							bool found = false;
							for (size_t ii = 0; ii < vImg_fid.size() && !found; ii++)
							{
								if (vImg_fid[ii].second == fid)
									colorImg = vImg_fid[ii].first, found = true;
							}
						}
						cvtColor(colorImg, gray, CV_BGR2GRAY);

						//check if the frame can be the key frame
						ExtractSiftCPU(Path, SelectedCamera, fid, gray, points[1], vscale, true);

						if (points[1].size() > (int)(1.5*minnFeatures)) //starting frame should contain many features
						{
							//set intermediate frame as well
							int intermediateFid = lastKFid + (bestFid - lastKFid) / 2;
							if (intermediateFid > lastKFid + 1)
							{
								if (extractedImages == 1)
								{
									sprintf(Fname, "%s/%d/%.4d.jpg", Path, SelectedCamera, intermediateFid);
									//sprintf(Fname, "%s/img_%.10d.jpg", Path, intermediateFid);
									if (IsFileExist(Fname) == 0)
										sprintf(Fname, "%s/%d/%.4d.png", Path, SelectedCamera, intermediateFid);
									intermediateColor = imread(Fname);
								}
								else
								{
									bool found = false;
									for (size_t ii = 0; ii < vImg_fid.size() && !found; ii++)
									{
										if (vImg_fid[ii].second == intermediateFid)
											intermediateColor = vImg_fid[ii].first, found = true;
									}
								}

								sprintf(Fname, "%s/%d/%.4d_%d.jpg", Path, SelectedCamera, intermediateFid, nkf);
								imwrite(Fname, intermediateColor, compression_params);
								cvtColor(intermediateColor, intermediateGray, CV_BGR2GRAY);

								//extract sift for intermediate frame
								points[3].clear();
								ExtractSiftCPU(Path, SelectedCamera, intermediateFid, intermediateGray, points[3], true);
								printLOG("\nSet i-KeyF %.4d. RealF: %.4d. #Points: %d\n", nkf, intermediateFid, points[3].size());
								fprintf(fp, "%d %d %d 2\n", SelectedCamera, nkf, intermediateFid);
								nkf++;
							}
							TakenNonBlurFrames[bestId] = true;

							sprintf(Fname, "%s/%d/%.4d_%d.jpg", Path, SelectedCamera, bestFid, nkf);
							imwrite(Fname, gray, compression_params);

							refFrame = gray.clone();
							buildOpticalFlowPyramid(refFrame, rPyr, winSize, npryLevels, true);
							//buildOpticalFlowPyramid(gray, cPyr, winSize, npryLevels, true);
							cPyr = rPyr;

							if (display == 1)
								cvtColor(gray, backGround, CV_GRAY2BGR);

							if (extractedImages == 0) //start new key frame
								vImg_fid.clear();
							lastKFid = bestFid, localfid = 1;
							lastRefPts = points[1];
							npts_lkf = (int)points[1].size(), lkf = bestFid;

							fprintf(fp, "%d %d %d 3\n", SelectedCamera, nkf, bestFid);
							printLOG("Set KeyF %.4d. RealF: %.4d. #Points: %d", nkf, bestFid, npts_lkf);
							nkf++;

							if (HighQualityTracking == 1)
							{
								Generate_Para_Spline(refFrame.data, ImgIParaR, width, height, interpAlgo);
								if (npts_lkf > maxFeatures)
								{
									delete[]ForeScale, delete[]BackScale, delete[]ForeWarp, delete[]ForeiWarp;
									ForeScale = new vector<float>[npts_lkf], ForeWarp = new vector<AffinePara>[npts_lkf], ForeiWarp = new vector<AffinePara>[npts_lkf];
								}
								for (int ii = 0; ii < npts_lkf; ii++)
								{
									ForeScale[ii].reserve(TrackRange), ForeScale[ii].push_back(vscale[ii]);
									ForeWarp[ii].reserve(TrackRange), ForeWarp[ii].push_back(warp);
									ForeiWarp[ii].reserve(TrackRange), ForeiWarp[ii].push_back(warp);
								}
							}

							for (int ii = 0; ii < npts_lkf; ii++)
							{
								ToDel.push_back(0);
								vector<Point2f> track; track.push_back(lastRefPts[ii]), tracklets.push_back(track);
							}
						}
						else //fine, move on
						{
							sprintf(Fname, "%s/%d/%.4d.sift", Path, SelectedCamera, fid);
							remove(Fname);
							points[0].clear(), points[1].clear(), vscale.clear();
							//if (extractedImages == 0) // will be clear in new kf extraction anyway
							//	vImg_fid.clear();
						}
					}
				}
				printLOG("\n");
			}
			else
				printLOG("\n");

			if (display == 1)
				for (int pid = 0; pid < (int)points[1].size(); pid++)
					if (!ToDel[pid])
						circle(backGround, points[1][pid], max(1, max(min((int)(ForeScale[pid][localfid - 1] * 3 + 0.5), (int)(ratio*MaxWinSize + 0.5)), (int)(ratio * MinWinSize + 0.5))), colors[pid % 8], 2), circle(backGround, points[1][pid], 1, colors[pid % 8], 2);
		}

		if (display > 0)
		{
			CvPoint text_origin = { backGround.cols / 30, backGround.cols / 30 };
			sprintf(Fname, "@%d: %d nkfs", fid, nkf);
			putText(backGround, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * backGround.cols / 640, CV_RGB(0, 255, 0), 2);
			if (display == 1)
			{
				sprintf(Fname, "KF of Camera %d", SelectedCamera);
				imshow(Fname, backGround); waitKey(2);
			}
			else
			{
				if (!firstTime)
				{
					firstTime = true;
					sprintf(Fname, "%s/Vis/CorpusTrackingVis_%d.avi", Path, SelectedCamera);
					writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, cvSize(backGround.cols, backGround.rows));
				}

				CvPoint text_origin = { backGround.cols / 30, backGround.cols / 30 };
				sprintf(Fname, "Frame %d/%d", SelectedCamera, fid);
				putText(backGround, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * backGround.cols / 640, CV_RGB(255, 0, 0), 3);
				writer << backGround;
				writer.release();
			}
			//sprintf(Fname, "%s/Vis/%d.png", Path, fid);  imwrite(Fname, backGround);
		}

		swap(pPyr, cPyr);
		swap(prevGray, gray);
		swap(points[0], points[1]);
	}
	fclose(fp);

	//write out tracklet
	if (!binary)
	{
		sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.txt", Path, SelectedCamera, lkf); FILE *fp2 = fopen(Fname, "w+");
		for (int ii = 0; ii < (int)tracklets.size(); ii++)
		{
			fprintf(fp2, "%d %d ", ii, (int)tracklets[ii].size());
			for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
				fprintf(fp2, "%.2f %.2f ", tracklets[ii][jj].x, tracklets[ii][jj].y, ForeScale[ii][jj]);
			fprintf(fp2, "\n");
		}
		fclose(fp2);
	}
	else
	{
		sprintf(Fname, "%s/cTrack2D/LFT_%d_%.4d.dat", Path, SelectedCamera, lkf);
		ofstream fout; fout.open(Fname, ios::binary);
		int n = (int)tracklets.size();
		fout.write(reinterpret_cast<char *>(&n), sizeof(int));
		for (int ii = 0; ii < (int)tracklets.size(); ii++)
		{
			int len = (int)tracklets[ii].size();
			fout.write(reinterpret_cast<char *>(&ii), sizeof(int));
			fout.write(reinterpret_cast<char *>(&len), sizeof(int));
			for (int jj = 0; jj < (int)tracklets[ii].size(); jj++)
			{
				float u = (float)tracklets[ii][jj].x, v = (float)tracklets[ii][jj].y, s = (float)ForeScale[ii][jj];
				fout.write(reinterpret_cast<char *>(&u), sizeof(float));
				fout.write(reinterpret_cast<char *>(&v), sizeof(float));
				fout.write(reinterpret_cast<char *>(&s), sizeof(float));
			}
		}
		fout.close();
	}


	tracklets.clear(), ToDel.clear(), points[0].clear(), points[1].clear(), vscale.clear();
	for (int ii = 0; ii < npts_lkf; ii++)
		ForeScale[ii].clear(), ForeWarp[ii].clear(), ForeiWarp[ii].clear();
	delete[]ForeScale, delete[]BackScale, delete[]ForeWarp, delete[]ForeiWarp;

	printLOG("Takes: %.2fs\n", omp_get_wtime() - startTime);

	if (display == 1)
		cvDestroyAllWindows();
	delete[]TakenNonBlurFrames;

	return nkf;
}

int ExtractSiftGPUFromImageListDriver(char *Path, vector<Point2i> &vCidFid)
{
	char Fname[512];

	int kfid, rfid, cfid, dummy;
	vector<int> vcfid;
	Mat colorImg, grayImg;

	//unable to apply to video seq because ffmpeg does not allow precise frame seeking
	char * argv[] = { "-fo", "-1", "-v", "0", "-tc", "7680", "-nomc", "-p", "1920x1080", "-maxd", "1920", "-mo", "1", "-da" }; //one orienation and smaller expected # feats
#ifdef _WINDOWS
#ifdef _DEBUG
	HMODULE  hsiftgpu = LoadLibrary("siftgpu_d.dll");
#else
	HMODULE  hsiftgpu = LoadLibrary("siftgpu.dll");
#endif
#else
	void * hsiftgpu = dlopen("libsiftgpu.so", RTLD_LAZY);
#endif

	if (hsiftgpu == NULL)
		return 0;

	SiftGPU* (*pCreateNewSiftGPU)(int) = NULL;
	pCreateNewSiftGPU = (SiftGPU* (*) (int)) GET_MYPROC(hsiftgpu, "CreateNewSiftGPU");
	SiftGPU* sift = pCreateNewSiftGPU(1);

	int argc = sizeof(argv) / sizeof(char*);
	sift->ParseParam(argc, argv);
	if (sift->CreateContextGL() != SiftGPU::SIFTGPU_FULL_SUPPORTED)
		return 1;

	vector<Point2f> Feat;
	for (int ii = 0; ii < vCidFid.size(); ii++)
	{
		if (ii % 100 == 0)
			printLOG("%d/%d...", ii, vCidFid.size());
		sprintf(Fname, "%s/%d/%.4d.sift", Path, vCidFid[ii].x, vCidFid[ii].y);
		if (IsFileExist(Fname) == 1)
			continue;

		Feat.clear();
		sprintf(Fname, "%s/%d/%.4d.png", Path, vCidFid[ii].x, vCidFid[ii].y);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, vCidFid[ii].x, vCidFid[ii].y);
		colorImg = imread(Fname);

		cvtColor(colorImg, grayImg, CV_BGR2GRAY);
		ExtractSiftGPU(Path, vCidFid[ii].x, vCidFid[ii].y, grayImg, Feat, sift, true);
	}
	printLOG("\n");

	return 0;
}
int ExtractSiftCPUFromImageListDriver(char *Path, vector<Point2i> &vCidFid)
{
	int nthreads = omp_get_max_threads();
	Mat *colorImg = new Mat[nthreads], *grayImg = new Mat[nthreads];
	vector<Point2f> *Feat = new vector<Point2f>[nthreads];

	omp_set_num_threads(nthreads);
#pragma omp parallel for schedule(dynamic,1)
	for (int ii = 0; ii < vCidFid.size(); ii++)
	{
		char Fname[512];
		if (ii % 100 == 0)
			printLOG("%d/%d...", ii, vCidFid.size());
		//sprintf(Fname, "%s/%d/%.4d.sift", Path, vCidFid[ii].x, vCidFid[ii].y);
		//if (IsFileExist(Fname) == 1)
		//	continue;

		int threadId = omp_get_thread_num();
		Feat[threadId].clear();
		sprintf(Fname, "%s/%d/%.4d.png", Path, vCidFid[ii].x, vCidFid[ii].y);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, vCidFid[ii].x, vCidFid[ii].y);
			if (IsFileExist(Fname) == 0)
			{
				printLOG("Cannot load %s\n", Fname);
				continue;
			}
		}
		colorImg[threadId] = imread(Fname);

		cvtColor(colorImg[threadId], grayImg[threadId], CV_BGR2GRAY);
		ExtractSiftCPU(Path, vCidFid[ii].x, vCidFid[ii].y, grayImg[threadId], Feat[threadId], true);
	}
	printLOG("\n");
}

int DistributeCorpusCalibToAllCamKeyFrames(char *Path, int nCams, int distortionCorrected)
{
	char Fname[512];

	int count = 0;
	vector<Point3i> gfid_cid_lfid;
	sprintf(Fname, "%s/Corpus/CameraToBuildCorpus3.txt", Path);
	if (IsFileExist(Fname) == 1)
	{
		int gfid, cid, lfid;
		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %d ", &gfid, &cid, &lfid) != EOF)
			gfid_cid_lfid.push_back(Point3i(gfid, cid, lfid));
		fclose(fp);
	}
	else
	{
		for (int cid = 0; cid < nCams; cid++)
		{
			int kfid, rfid, cfid, dummy;
			sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, cid); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
			{
				printLOG("Cannot load %s\n", Fname);
				return 1;
			}
			while (fscanf(fp, "%d %d %d %d ", &cid, &kfid, &rfid, &dummy) != EOF)
				gfid_cid_lfid.push_back(Point3i(count, cid, rfid)), count++;
			fclose(fp);
		}
	}

	Corpus CorpusInfo;
	sprintf(Fname, "%s/Corpus", Path);
	ReadCorpusInfo(Fname, CorpusInfo, false, true);

	vector<FILE*> vfp;
	for (int cid = 0; cid < nCams; cid++)
	{
		sprintf(Fname, "%s/Intrinsic_%.4d.txt", Path, cid);
		FILE *fp1 = fopen(Fname, "w");
		vfp.push_back(fp1);

		sprintf(Fname, "%s/CamPose_%.4d.txt", Path, cid);
		FILE *fp2 = fopen(Fname, "w");
		vfp.push_back(fp2);
	}

	for (size_t ii = 0; ii < gfid_cid_lfid.size(); ii++)
	{
		if (ii >= CorpusInfo.nCameras)
			continue;
		if (gfid_cid_lfid[ii].z > 9000 && gfid_cid_lfid[ii].z < 12000)
			int a = 0;
		if (CorpusInfo.camera[ii].valid)
		{
			int cid = gfid_cid_lfid[ii].y, lfid = gfid_cid_lfid[ii].z;

			//intrinsic
			fprintf(vfp[2 * cid], "%d %d %d %d %d ", lfid, CorpusInfo.camera[ii].LensModel, CorpusInfo.camera[ii].ShutterModel, CorpusInfo.camera[ii].width, CorpusInfo.camera[ii].height);
			for (int jj = 0; jj < 5; jj++)
				fprintf(vfp[2 * cid], "%f ", CorpusInfo.camera[ii].intrinsic[jj]);
			if (CorpusInfo.camera[ii].LensModel == RADIAL_TANGENTIAL_PRISM)
				for (int jj = 0; jj < 7; jj++)
					fprintf(vfp[2 * cid], "%f ", CorpusInfo.camera[ii].distortion[jj]);
			else
				for (int jj = 0; jj < 3; jj++)
					fprintf(vfp[2 * cid], "%f ", CorpusInfo.camera[ii].distortion[jj]);
			fprintf(vfp[2 * cid], "\n");

			//extrinsic
			fprintf(vfp[2 * cid + 1], "%d  ", lfid);
			for (int jj = 0; jj < 6; jj++)
				fprintf(vfp[2 * cid + 1], "%.16f ", CorpusInfo.camera[ii].rt[jj]);
			if (CorpusInfo.camera[ii].ShutterModel == ROLLING_SHUTTER)
				for (int jj = 0; jj < 6; jj++)
					fprintf(vfp[2 * cid + 1], "%.16f ", CorpusInfo.camera[ii].wt[jj]);
			fprintf(vfp[2 * cid + 1], "\n");
		}
	}

	for (int cid = 0; cid < nCams; cid++)
		fclose(vfp[2 * cid]), fclose(vfp[2 * cid + 1]);

	for (int cid = 0; cid < nCams; cid++)
		sprintf(Fname, "%s/%d/PnP", Path, cid), makeDir(Fname);

	for (size_t ii = 0; ii < gfid_cid_lfid.size(); ii++)
	{
		if (ii >= CorpusInfo.nCameras)
			continue;

		int cid = gfid_cid_lfid[ii].y, lfid = gfid_cid_lfid[ii].z;
		sprintf(Fname, "%s/%d/PnP/KF_Inliers_%.4d.txt", Path, cid, lfid); FILE *fp = fopen(Fname, "w+");
		int npts = (int)CorpusInfo.uvAllViews[ii].size();
		for (int jj = 0; jj < npts; jj++)
		{
			int globalCorpusP3Did = CorpusInfo.threeDIdAllViews[ii][jj], p2DId = -1;
			for (int kk = 0; kk < CorpusInfo.pointIdAll3D[globalCorpusP3Did].size() && p2DId == -1; kk++)
			{
				if (CorpusInfo.viewIdAll3D[globalCorpusP3Did][kk] == ii)
					p2DId = CorpusInfo.pointIdAll3D[globalCorpusP3Did][kk];
			}

			if (p2DId == -1)
			{
				printf("Problem with gfid %d &gpid %d\n", ii, globalCorpusP3Did);
				continue;
			}
			Point3d xyz = CorpusInfo.xyz[globalCorpusP3Did];
			Point2d uv = CorpusInfo.uvAllViews[ii][jj];

			if (distortionCorrected == 0) //CorpusInfo has been corrected after re-BA
			{
				if (CorpusInfo.camera[ii].LensModel == FISHEYE)
					FishEyeDistortionPoint(&uv, CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].distortion[0]);
				else
					LensDistortionPoint(&uv, CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].distortion);
			}

			fprintf(fp, "%d %d %.6f %.6f %.6f %d %.4f %.4f %.2f\n", globalCorpusP3Did, globalCorpusP3Did, xyz.x, xyz.y, xyz.z, p2DId, uv.x, uv.y, CorpusInfo.scaleAllViews[ii][jj]);
		}
		fclose(fp);
	}

	return 0;
}
int GenKeyFramesFromCorpusImgs(char *Path, vector<int> &SelectedCams)
{
	char Fname[512], Fname2[512];;
	FILE *fp1 = NULL, *fp3 = NULL, *fp2 = NULL, *fp4 = NULL;

	int lensType, cumnkf = 0;
	double focal = 1000;
	Mat img;

	vector<int> compression_params;
	compression_params.push_back(CV_IMWRITE_JPEG_QUALITY);
	compression_params.push_back(100);

	for (auto cid : SelectedCams)
	{
		printLOG("%d..", cid);

		int kfid, rfid, cfid, dummy;
		vector<int> vrfid, vcfid;
		sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, cid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			exit(1);
		}
		while (fscanf(fp, "%d %d %d %d ", &cid, &kfid, &rfid, &dummy) != EOF)
			vrfid.push_back(rfid);
		fclose(fp);

		for (int ii = 0; ii < vrfid.size(); ii++)
		{
			sprintf(Fname, "%s/Corpus/%d_%.4d.png", Path, cid, ii);
			img = imread(Fname);
			if (img.empty() == 1)
			{
				printLOG("%s\n", Fname);
				exit(1);
			}
			remove(Fname);
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, vrfid[ii]); imwrite(Fname, img, compression_params);
			sprintf(Fname, "%s/Corpus/%d_%.4d.sift", Path, cid, ii); sprintf(Fname2, "%s/%d/%.4d.sift", Path, cid, vrfid[ii]); MyCopyFile(Fname, Fname2);
			remove(Fname);
		}
	}

	return 0;
}
vector<Point2i> GetKeyFrameID2LocalFrameID(char *Path, int  nCams)
{
	char Fname[512];
	vector<Point2i> keyID_To_Cid_LocalFid;

	sprintf(Fname, "%s/Corpus/KeyFrameID2LocalFrameID.txt", Path);
	if (IsFileExist(Fname) == 1)
	{
		int ii, kid, cid;
		sprintf(Fname, "%s/Corpus/KeyFrameID2LocalFrameID.txt", Path); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %d ", &ii, &kid, &cid) != EOF)
			keyID_To_Cid_LocalFid.push_back(Point2i(kid, cid));
		fclose(fp);
	}
	else
	{
		//determine local frameID in the local camera
		vector<int> *Frames2Corpus = new vector<int>[nCams];
		for (int ii = 0; ii < nCams; ii++)
		{
			int cid, kfid, rfid, ftype;
			sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, ii);  FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d %d %d ", &cid, &kfid, &rfid, &ftype) != EOF)
				Frames2Corpus[cid].push_back(rfid);
			fclose(fp);
		}

		int gfid, id = -1, old_cid, cid;
		sprintf(Fname, "%s/Corpus/CameraToBuildCorpus.txt", Path);
		FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			vector<Point2i> a;
			return a;
		}
		while (fscanf(fp, "%d %d ", &gfid, &cid) != EOF)
		{
			if (id == 0)
				old_cid = cid;

			if (cid == old_cid)
				id++;
			else
			{
				id = 0;
				old_cid = cid;
			}
			keyID_To_Cid_LocalFid.push_back(Point2i(cid, Frames2Corpus[cid][id]));
		}
		fclose(fp);

		sprintf(Fname, "%s/Corpus/KeyFrameID2LocalFrameID.txt", Path); fp = fopen(Fname, "w");
		for (size_t ii = 0; ii < keyID_To_Cid_LocalFid.size(); ii++)
			fprintf(fp, "%d %d %d\n", ii, keyID_To_Cid_LocalFid[ii].x, keyID_To_Cid_LocalFid[ii].y);
		fclose(fp);
	}

	return keyID_To_Cid_LocalFid;
}
int GenCorpusImgsFromKeyFrames(char *Path, vector<int> &SelectedCams, vector<Point2i> &rotateImage, vector<CameraData> &InitCamera, int Sample)
{
	char Fname[512], Fname2[512];
	FILE *fp1 = NULL, *fp3 = NULL, *fp2 = NULL, *fp4 = NULL, *fp5 = NULL;

	int lensType, cumnkf = 0;
	double focal = 1000;
	Mat img;

	vector<int> compression_params;
	compression_params.push_back(CV_IMWRITE_JPEG_QUALITY);
	compression_params.push_back(100);

	sprintf(Fname, "%s/Corpus", Path); makeDir(Fname);
	sprintf(Fname, "%s/Corpus/Size", Path); makeDir(Fname);
	sprintf(Fname, "%s/Corpus/CameraToBuildCorpus.txt", Path); fp1 = fopen(Fname, "w+");
	sprintf(Fname, "%s/Corpus/CameraToBuildCorpus2.txt", Path); fp2 = fopen(Fname, "w+");
	sprintf(Fname, "%s/Corpus/ImageList.txt", Path); fp3 = fopen(Fname, "w+");
	sprintf(Fname, "%s/Corpus/SiftList.txt", Path); fp4 = fopen(Fname, "w+");
	sprintf(Fname, "%s/Corpus/CameraToBuildCorpus3.txt", Path); fp5 = fopen(Fname, "w+");
	for (auto cid : SelectedCams)
	{
		printLOG("%d..", cid);
		/*int code = 0;
		for (int ii = 0; ii < (int)rotateImage.size() && code == 0; ii++)
		if (rotateImage[ii].x == cid)
		code = rotateImage[ii].y;

		int fid = 0, frameType = 0;
		while (true)
		{
		sprintf(Fname, "%s/Corpus/%d_%.4d.png", Path, cid], fid);
		if (IsFileExist(Fname) == 1)
		img = imread(Fname), frameType = 0;
		else
		{
		sprintf(Fname, "%s/Corpus/_%d_%.4d.png", Path, cid, fid);
		if (IsFileExist(Fname) == 1)
		img = imread(Fname), frameType = 1;
		else
		break;
		}

		fprintf(fp, "%d %d\n", fid + cumnkf, cid);
		if (frameType == 0)
		{
		if (InitCamera[cid].intrinsic[0] < 1)
		focal = 1.2*img.cols;
		else
		focal = InitCamera[cid].intrinsic[0];
		if (InitCamera[cid].LensModel == RADIAL_TANGENTIAL_PRISM) //make it simple radial
		fprintf(fp2, "%d %d %d %d %d %.1f %.1f %.1f %.1f\n", fid + cumnkf, cid, 2, img.cols, img.rows, focal, 0.5*img.cols, 0.5* img.rows, -InitCamera[cid].distortion[0]);
		else//FOV
		fprintf(fp2, "%d %d %d %d %d %.1f %.1f %.1f %.1f %.1f\n", fid + cumnkf, cid, 7, img.cols, img.rows, focal, focal, 0.5*img.cols, 0.5* img.rows, InitCamera[cid].distortion[0]);
		fprintf(fp3, "%.4d.png\n", fid + cumnkf);
		fprintf(fp4, "%s/Corpus/%.4d.sift\n", Path, fid + cumnkf);
		}

		sprintf(Fname, "%s/Corpus/Size/%.4d.txt", Path, fid + cumnkf); FILE* fp5 = fopen(Fname, "w"); fprintf(fp5, "%d %d", img.cols, img.rows); fclose(fp5);
		sprintf(Fname, "%s/Corpus/%.4d.png", Path, fid + cumnkf); imwrite(Fname, img);
		//sprintf(Fname, "%s/Corpus/%.4d.jpg", Path, fid + cumnkf); imwrite(Fname, img);
		if (frameType == 0)
		sprintf(Fname, "%s/Corpus/%d_%.4d.png", Path, cid, fid);
		else
		sprintf(Fname, "%s/Corpus/_%d_%.4d.png", Path, cid, fid);
		remove(Fname);

		fid++;
		}
		cumnkf += fid;*/

		int kfid, rfid, cfid, dummy;
		vector<int> vrfid, vcfid;
		sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, cid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			exit(1);
		}
		int count = -1;
		while (fscanf(fp, "%d %d %d %d ", &cid, &kfid, &rfid, &dummy) != EOF)
		{
			count++;
			if (count %Sample != 0)
				continue;
			vrfid.push_back(rfid);
		}
		fclose(fp);

		for (int ii = 0; ii < vrfid.size(); ii++)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, vrfid[ii]);
			//sprintf(Fname, "%s/img_%.10d.jpg", Path, vrfid[ii]);
			if (IsFileExist(Fname) == 1)
			{
				sprintf(Fname2, "%s/Corpus/%.4d.jpg", Path, ii + cumnkf);
				if (!MyCopyFile(Fname, Fname2))
				{
					printLOG("Problem renaming %s to %s\n", Fname, Fname2);
					exit(1);
				}
			}
			else
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, cid, vrfid[ii]); Mat img = imread(Fname);
				sprintf(Fname2, "%s/Corpus/%.4d.jpg", Path, ii + cumnkf);
				if (img.empty() == 1)
				{
					printLOG("Problem renaming %s to %s\n", Fname, Fname2);
					exit(1);
				}
				imwrite(Fname2, img);
			}

			fprintf(fp1, "%d %d\n", ii + cumnkf, cid);
			if (InitCamera[cid].intrinsic[0] < 1)
				focal = 1.2*img.cols;
			else
				focal = InitCamera[cid].intrinsic[0];
			if (InitCamera[cid].LensModel == RADIAL_TANGENTIAL_PRISM)
				//fprintf(fp2, "%d %d 2 %d %d %.1f %.1f %.1f %.3f\n", ii + cumnkf, cid, InitCamera[cid].width, InitCamera[cid].height, focal, 0.5*InitCamera[cid].width, 0.5* InitCamera[cid].height, -InitCamera[cid].distortion[0]);  //make it simple radial-->faster to optim
				fprintf(fp2, "%d %d 4 %d %d %.1f %.1f %.1f %.1f %.3f %.3f %.3f %.3f\n", ii + cumnkf, cid, InitCamera[cid].width, InitCamera[cid].height, InitCamera[cid].intrinsic[0], InitCamera[cid].intrinsic[1], InitCamera[cid].intrinsic[3], InitCamera[cid].intrinsic[4], InitCamera[cid].distortion[0], InitCamera[cid].distortion[1], InitCamera[cid].distortion[3], InitCamera[cid].distortion[4]);
			else//FOV
				fprintf(fp2, "%d %d 7 %d %d %.1f %.1f %.1f %.1f %.3f\n", ii + cumnkf, cid, InitCamera[cid].width, InitCamera[cid].height, focal, focal, 0.5*InitCamera[cid].width, 0.5* InitCamera[cid].height, InitCamera[cid].distortion[0]);
			fprintf(fp3, "%.4d.jpg\n", ii + cumnkf);
			fprintf(fp4, "%s/Corpus/%.4d.sift\n", Path, ii + cumnkf);
			fprintf(fp5, "%d %d %d\n", ii + cumnkf, cid, vrfid[ii]);

			sprintf(Fname, "%s/Corpus/Size/%.4d.txt", Path, ii + cumnkf); FILE* fp5 = fopen(Fname, "w"); fprintf(fp5, "%d %d", img.cols, img.rows); fclose(fp5);

			sprintf(Fname, "%s/%d/%.4d.sift", Path, cid, vrfid[ii]);
			sprintf(Fname2, "%s/Corpus/%.4d.sift", Path, ii + cumnkf);
			if (!MyCopyFile(Fname, Fname2))
			{
				printLOG("Problem renaming %s to %s\n", Fname, Fname2);
				exit(1);
			}
		}
		cumnkf += (int)vrfid.size();
	}
	fclose(fp1), fclose(fp2), fclose(fp3), fclose(fp4), fclose(fp5);

	sprintf(Fname, "%s/Logs/OrganizeKF2Corpus.txt", Path); FILE *fp = fopen(Fname, "w"); fclose(fp);

	printLOG(" %d keyframes\n", cumnkf);

	return cumnkf;
}
int GenCorpusImgsFromCachedText(char *Path, int nCams)
{
	/*#ifdef USESIFTGPU
	char Fname[512];
	sprintf(Fname, "%s/Corpus", Path); makeDir(Fname);

	//unable to apply to video seq because ffmpeg does not allow precise frame seeking
	int siftGPU = 1;
	char * argv[] = { "-fo", "-1", "-v", "0", "-tc", "7680", "-nomc", "-p", "1920x1080", "-maxd", "4096", "-mo", "1", "-da" }; //one orienation and smaller expected # feats

	#ifdef _WINDOWS
	#ifdef _DEBUG
	HMODULE  hsiftgpu = LoadLibrary("siftgpu_d.dll");
	#else
	HMODULE  hsiftgpu = LoadLibrary("siftgpu.dll");
	#endif
	#else
	void * hsiftgpu = dlopen("libsiftgpu.so", RTLD_LAZY);
	#endif

	if (hsiftgpu == NULL)
	return 0;

	SiftGPU* (*pCreateNewSiftGPU)(int) = NULL;
	pCreateNewSiftGPU = (SiftGPU* (*) (int)) GET_MYPROC(hsiftgpu, "CreateNewSiftGPU");
	SiftGPU* sift = pCreateNewSiftGPU(1);

	int argc = sizeof(argv) / sizeof(char*);
	sift->ParseParam(argc, argv);
	if (sift->CreateContextGL() != SiftGPU::SIFTGPU_FULL_SUPPORTED)
	siftGPU = 0;

	int  cumnkf = 0;
	Mat imgColor, imgGray;
	for (int cid = 0; cid < nCams; cid++)
	{
	int kfid, rfid, cfid, dummy;
	vector<int> vrfid, vcfid;
	sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, cid); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
	printLOG("Cannot load %s\n", Fname);
	exit(1);
	}
	while (fscanf(fp, "%d %d %d %d ", &cid, &kfid, &rfid, &dummy) != EOF)
	vrfid.push_back(rfid);
	fclose(fp);

	vector<Point2f> Feat;
	for (int ii = 0; ii < vrfid.size(); ii++)
	{
	Feat.clear();
	sprintf(Fname, "%s/%d/%.4d.png", Path, cid, vrfid[ii]);
	if (IsFileExist(Fname) == 0)
	sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, vrfid[ii]);
	Mat imgColor = imread(Fname);
	sprintf(Fname, "%s/Corpus/%d_%.4d.png", Path, cid, ii);
	imwrite(Fname, imgColor);

	cvtColor(imgColor, imgGray, CV_BGR2GRAY);
	ExtractSiftGPU(Path, cid, vrfid[ii], imgGray, Feat, sift, true);
	}
	cumnkf += (int)vrfid.size();
	}
	#endif*/
	return 0;
}
int GenMaskedCorpusFromKeyFrames(char *Path, int nCams)
{
	char Fname[512];
	sprintf(Fname, "%s/Corpus", Path); makeDir(Fname);

	struct TL_BR {
		Point2i tl, br;
	};

	Mat img;
	int  cumnkf = 0;
	for (int cid = 0; cid < nCams; cid++)
	{
		int kfid, rfid, cfid, dummy;
		vector<int> vrfid, vcfid;
		sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, cid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			exit(1);
		}
		while (fscanf(fp, "%d %d %d %d ", &cid, &kfid, &rfid, &dummy) != EOF)
			vrfid.push_back(rfid);
		fclose(fp);

		for (int ii = 0; ii < vrfid.size(); ii++)
		{
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, vrfid[ii]); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
			{
				printLOG("Cannot load %s\n", Fname);
				sprintf(Fname, "%s/CorpusM/%.4d.png", Path, ii + cumnkf);
				img.setTo(cv::Scalar(0, 0, 0));
				imwrite(Fname, img);
				continue;
			}
			double u, v, s;
			vector<Point2d> vuv;
			while (fscanf(fp, "%lf %lf %lf ", &u, &v, &s) != EOF)
				vuv.push_back(Point2d(u, v));
			fclose(fp);

			//find and draw bb of each active tracklet
			vector<TL_BR> allBB;
			int nJoints = 18;
			for (int pid = 0; pid < (int)vuv.size() / nJoints; pid++)
			{
				TL_BR tlbr;
				tlbr.br = Point2i(0, 0), tlbr.tl = Point2i(1920, 1080);
				for (int jid = 0; jid < nJoints; jid++)
				{
					if (vuv[pid * nJoints + jid].x > 0)
					{
						tlbr.tl.x = min(tlbr.tl.x, (int)(vuv[pid * nJoints + jid].x));
						tlbr.tl.y = min(tlbr.tl.y, (int)(vuv[pid * nJoints + jid].y));
						tlbr.br.x = max(tlbr.br.x, (int)(vuv[pid * nJoints + jid].x));
						tlbr.br.y = max(tlbr.br.y, (int)(vuv[pid * nJoints + jid].y));
					}
				}
				tlbr.tl.x = max(tlbr.tl.x - 50, 0);
				tlbr.tl.y = max(tlbr.tl.y - 50, 0);
				tlbr.br.x = min(tlbr.br.x + 50, 1919);
				tlbr.br.y = min(tlbr.br.y + 50, 1079);
				allBB.push_back(tlbr);
			}

			sprintf(Fname, "%s/%d/%.4d.png", Path, cid, vrfid[ii]);
			img = imread(Fname);
			for (int jj = 0; jj < allBB.size(); jj++)
			{
				cv::Rect rect(allBB[jj].tl.x, allBB[jj].tl.y, allBB[jj].br.x - allBB[jj].tl.x, allBB[jj].br.y - allBB[jj].tl.y);
				cv::Mat miniMat = img(rect);
				miniMat.setTo(cv::Scalar(0, 0, 0));
			}

			sprintf(Fname, "%s/CorpusM/%.4d.png", Path, ii + cumnkf);
			imwrite(Fname, img);
		}
		cumnkf += (int)vrfid.size();
	}
	return 0;
}

int DenseMatchingDriver(char *Path, int *sCams, int *sFid, int nchannels, int semiDense)
{
	char Fname[512];

	int hsubset = 11, nscales = 1, scaleStep = 0, step = 1, MatchAglo = 3, InterpAlgo = 1, Convergence_Criteria = 0, IterMax = 20, Analysis_Speed = 0, DisplacementThresh = 1;
	double Gsigma = .707, ssigThresh = 50.0, ZNCCThreshold = 0.89, PSSDab_thresh = 0.02;
	LKParameters LKArg(hsubset, nscales, scaleStep, MatchAglo, InterpAlgo, Gsigma, Convergence_Criteria, IterMax, Analysis_Speed, ZNCCThreshold, PSSDab_thresh, DisplacementThresh);
	LKArg.step = step, LKArg.ssigThresh = ssigThresh; LKArg.checkZNCC = 1; LKArg.Incomplete_Subset_Handling = 0;
	int TimgS = 2 * (hsubset + nscales * scaleStep) + 1, Tlength = TimgS * TimgS;

	char *Imgs = 0;
	int width, height, length;
	for (int ll = 0; ll < 2; ll++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, sCams[ll], sFid[ll]);
		Mat view = imread(Fname, nchannels == 1 ? 0 : 1);
		if (view.data == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return false;
		}
		if (Imgs == NULL)
		{
			width = view.cols, height = view.rows, length = width * height;
			Imgs = new char[2 * length*nchannels];
		}
		for (int kk = 0; kk < nchannels; kk++)
			for (int jj = 0; jj < height; jj++)
				for (int ii = 0; ii < width; ii++)
					Imgs[ii + jj * width + kk * length + ll * length*nchannels] = (char)view.data[nchannels*ii + jj * nchannels*width + kk];
	}

	//Load seeds points
	double x, y;
	vector<Point2d>SPts[2];
	for (int ii = 0; ii < 2; ii++)
	{
		sprintf(Fname, "%s/Dynamic/%d_%.4d.txt", Path, sCams[ii], sFid[ii]); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%lf %lf ", &x, &y) != EOF)
			SPts[ii].push_back(Point2d(x, y));
		fclose(fp);
	}

	//Customize the ROI
	int minX = 50, minY = 50, maxX = width - 50, maxY = height - 50;
	bool *ROI = new bool[length], *lpROI_calculated = new bool[length];
	for (int ii = 0; ii < length; ii++)
	{
		ROI[ii] = false; // 1 - Valid, 0 - Other
		lpROI_calculated[ii] = false; 	// 1 - Calculated, 0 - Other
	}
	for (int jj = minY; jj < maxY; jj++)
		for (int ii = minX; ii < maxX; ii++)
			ROI[ii + jj * width] = true;

	float *WarpingsPara = new float[length * 6];
	for (int ii = 0; ii < 6 * length; ii++)
		WarpingsPara[ii] = 0;

	vector<Point2d> SDPts[2];
	SemiDenseGreedyMatching(Imgs, Imgs + nchannels * length, SDPts[0], SDPts[1], SPts[0], SPts[1], lpROI_calculated, ROI, LKArg, nchannels, width, height, width, height, 1.0, WarpingsPara);
	for (int jj = 0; jj < (int)SDPts[0].size(); jj++)
		SDPts[1][jj].x += +SDPts[0][jj].x, SDPts[1][jj].y += SDPts[0][jj].y;

	/*for (int ii = 0; ii < 2; ii++)
	{
	sprintf(Fname, "%s/Dynamic/sd_%d_%.4d.txt", Path, sCams[ii], sFid[ii]); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
	printLOG("Cannot load %s\n", Fname);
	return 1;
	}
	while (fscanf(fp, "%lf %lf ", &x, &y) != EOF)
	SDPts[ii].push_back(Point2d(x, y));
	fclose(fp);
	}*/

	// Prepare image data
	double *Para = new double[2 * length*nchannels];
	double *lpImageData = new double[2 * length*nchannels];
	for (int kk = 0; kk < nchannels; kk++)
	{
		for (int ii = 0; ii < length; ii++)
			lpImageData[ii + kk * length] = (double)((int)((unsigned char)(Imgs[ii + kk * length])));
		for (int ii = 0; ii < length; ii++)
			lpImageData[ii + (kk + nchannels)*length] = (double)((int)((unsigned char)(Imgs[ii + kk * length + nchannels * length])));
	}
	for (int kk = 0; kk < nchannels; kk++)
	{
		Generate_Para_Spline(lpImageData + kk * length, Para + kk * length, width, height, InterpAlgo);
		Generate_Para_Spline(lpImageData + kk * length + nchannels * length, Para + kk * length + nchannels * length, width, height, InterpAlgo);
	}

	for (int kk = 0; kk < nchannels; kk++)
	{
		for (int ll = 0; ll < (int)SDPts[0].size(); ll++)
		{
			int ii = SDPts[0][ll].x, jj = SDPts[0][ll].y;
			double v, x = SDPts[1][ll].x, y = SDPts[1][ll].y;
			if (x<0 || x>width || y<0 || y>height)
				continue;
			Get_Value_Spline(Para + kk * length + nchannels * length, width, height, x, y, &v, -1, InterpAlgo);
			Imgs[ii + jj * width + kk * length] = (char)(unsigned char)(int)(max(min(v, 255.0), 0.0) + 0.5);
		}
	}
	sprintf(Fname, "%s/w_%d_%.4d.png", Path, sCams[0], sFid[0]);
	SaveDataToImage(Fname, Imgs, width, height, nchannels);

	for (int ii = 0; ii < 2; ii++)
	{
		sprintf(Fname, "%s/Dynamic/sd_%d_%.4d.txt", Path, sCams[ii], sFid[ii]); FILE *fp = fopen(Fname, "w+");
		for (int jj = 0; jj < (int)SDPts[0].size(); jj++)
			fprintf(fp, "%.2f %.2f\n", SDPts[ii][jj].x, SDPts[ii][jj].y);
		fclose(fp);
	}

	delete[]Imgs, delete[]ROI, delete[]lpROI_calculated, delete[]WarpingsPara;

	return 0;
}
int GenerateTrackingVisibilityImage(char *Path, int nCams, int startTrackingF, int stopTrackingF, int increTrackingInstance, int*TimeStamp, int TrackRange, int increF, int maxPts)
{
	char Fname[512];

	float u, v, s, a, w0, w1, w2, w3;
	int  pid, nf, fid, npts;

	if (increTrackingInstance > 0)
	{
		int *CamIPts = new int[maxPts*TrackRange * 2 / increF];
		int *VisI = new int[maxPts*TrackRange * 2 / increF];
		int *AllVis = new int[nCams*maxPts*TrackRange * 2 / increF];

		for (int sTF = startTrackingF; sTF <= stopTrackingF; sTF += increTrackingInstance)
		{
			for (int camID = 0; camID < nCams; camID++)
			{
				sprintf(Fname, "%s/Track2D/Ultimate_%d_%.4d.txt", Path, camID, sTF);
				if (IsFileExist(Fname) == 0)
					sprintf(Fname, "%s/Track2D/RCC_%d_%.4d.txt", Path, camID, sTF);
				FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
				{
					printLOG("Cannot load %s\n", Fname);
					return 1;
				}
				fscanf(fp, "%d ", &npts);
				for (int ii = 0; ii < npts*TrackRange * 2 / increF; ii++)
					CamIPts[ii] = 0;
				while (fscanf(fp, "%d %d ", &pid, &nf) != EOF)
				{
					for (int ii = 0; ii < nf; ii++)
					{
						fscanf(fp, "%d %f %f %f %f %f %f %f %f ", &fid, &u, &v, &s, &a, &w0, &w1, &w2, &w3);
						CamIPts[pid*TrackRange * 2 / increF + (fid - (sTF - TimeStamp[camID]) + TrackRange) / increF] = 255;
					}
				}
				fclose(fp);

				for (int jj = 0; jj < npts; jj++)
					for (int ii = 0; ii < TrackRange * 2 / increF; ii++)
						if (CamIPts[jj*TrackRange * 2 / increF + ii] == 255)
							VisI[jj*TrackRange * 2 / increF + ii] = camID % 2 == 0 ? 255 : 127;
						else
							VisI[jj*TrackRange * 2 / increF + ii] = 0;

				Set_Sub_Mat(VisI, AllVis, TrackRange * 2 / increF, npts, TrackRange * 2 / increF * nCams, TrackRange * 2 / increF * camID, 0);
			}

			sprintf(Fname, "%s/Track2D/VisMat_%.4d.png", Path, sTF);
			SaveDataToImage(Fname, AllVis, TrackRange * 2 / increF * nCams, npts);
		}

		int cumNpts = 0;
		vector<Mat> sAllVis;
		for (int sTF = startTrackingF; sTF <= stopTrackingF; sTF += increTrackingInstance)
		{
			sprintf(Fname, "%s/Track2D/VisMat_%.4d.png", Path, sTF);
			Mat Vis = imread(Fname);
			sAllVis.push_back(Vis);
			cumNpts += Vis.rows;
		}
		printLOG("Total # points: %d\n", cumNpts);

		int crow = 0;
		Mat bAllVis(cumNpts + (int)sAllVis.size() + 1, TrackRange * 2 * nCams / increF, CV_8UC3);
		Mat RedLine(1, TrackRange * 2 * nCams / increF, CV_8UC3, Scalar(0, 0, 255));

		RedLine.copyTo(bAllVis(Rect(0, crow, TrackRange * 2 * nCams / increF, 1)));
		crow += 1;
		for (int ii = 0; ii < (int)sAllVis.size(); ii++)
		{
			sAllVis[ii].copyTo(bAllVis(Rect(0, crow, TrackRange * 2 * nCams / increF, (int)sAllVis[ii].rows)));
			crow += (int)sAllVis[ii].rows;
			RedLine.copyTo(bAllVis(Rect(0, crow, TrackRange * 2 * nCams / increF, 1)));
			crow += 1;
		}
		sprintf(Fname, "%s/Track2D/VisMat.png", Path);
		imwrite(Fname, bAllVis);

		delete[]CamIPts, delete[]VisI, delete[]AllVis;
	}
	else
	{
		int nframes = (stopTrackingF - startTrackingF + 1);
		int *VisI = new int[maxPts*nframes];
		int *AllVis = new int[nCams*maxPts*nframes];
		double *AllVis2 = new double[maxPts*nframes];

		for (int ii = 0; ii < maxPts*nframes; ii++)
			AllVis2[ii] = 0;

		for (int camID = 0; camID < nCams; camID++)
		{
			for (int ii = 0; ii < maxPts*nframes; ii++)
				VisI[ii] = 0;

			sprintf(Fname, "%s/Track2D/Ultimate_%.4d.txt", Path, camID);
			if (IsFileExist(Fname) == 0)
				sprintf(Fname, "%s/Track2D/CC_%d_0.txt", Path, camID);
			FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
			{
				printLOG("Cannot load %s\n", Fname);
				return 1;
			}
			fscanf(fp, "%d ", &npts);
			while (fscanf(fp, "%d %d ", &pid, &nf) != EOF)
			{
				for (int ii = 0; ii < nf; ii++)
				{
					fscanf(fp, "%d %f %f %f %f %f %f %f %f ", &fid, &u, &v, &s, &a, &w0, &w1, &w2, &w3);
					int fake_fid = fid + TimeStamp[camID];
					VisI[pid*nframes + fake_fid - startTrackingF] = 255;
				}
			}
			fclose(fp);

			Set_Sub_Mat(VisI, AllVis, nframes, maxPts, nframes *nCams, nframes *camID, 0);

			//sprintf(Fname, "%s/Track2D/VisMat_%.4d.png", Path, camID);
			//SaveDataToImage(Fname, VisI, nframes , maxPts);
			for (int ii = 0; ii < maxPts*nframes; ii++)
				AllVis2[ii] += VisI[ii];
		}

		sprintf(Fname, "%s/Track2D/VisMat1.png", Path);
		SaveDataToImage(Fname, AllVis, nframes * nCams, maxPts);

		double orgmin, orgmax;
		RescaleMat(AllVis2, orgmin, orgmax, 0, 255.0, maxPts*nframes);
		sprintf(Fname, "%s/Track2D/VisMat2.png", Path);
		SaveDataToImage(Fname, AllVis2, nframes, maxPts);

		delete[]VisI, delete[]AllVis;
	}

	return 0;
}

int TrajectoryReProjectionError(char *Path, int nCams, int npts, int startF, int stopF)
{
	char Fname[512]; FILE *fp = 0;

	//Read calib info
	VideoData *VideoInfo = new VideoData[nCams];
	for (int camID = 0; camID < nCams; camID++)
		if (ReadVideoDataI(Path, VideoInfo[camID], camID, startF, stopF) == 1)
			return 1;

	int frameID, id;
	int nframes = max(MaxnFrames, stopF);

	int nf, cID, fID, dummy[10000];
	double u, v, s, x, y, z, t, P[12], ts[10000];
	ImgPtEle ptEle;
	vector<Point3d> T3D;
	vector<double> TimeStamp;
	vector<int>VectorCamID, VectorFrameID, VisCamID, VisLocalFrameID;
	vector<ImgPtEle> *PerCam_UV = new vector<ImgPtEle>[nCams*npts];

	printLOG("Get 2D ...");
	for (int camID = 0; camID < nCams; camID++)
	{
		for (int pid = 0; pid < npts; pid++)
			PerCam_UV[camID*npts + pid].reserve(stopF - startF + 1);

		sprintf(Fname, "%s/Track2D/Ultimate_%.4d.txt", Path, camID); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		fscanf(fp, "%d ", &npts);
		while (fscanf(fp, "%d %d ", &id, &nf) != EOF)
		{
			for (int pid = 0; pid < nf; pid++)
			{
				fscanf(fp, "%d %lf %lf %lf ", &frameID, &u, &v, &s);
				if (frameID < 0)
					continue;
				if (!VideoInfo[camID].VideoInfo[frameID].valid)
					continue; //camera not localized

				if (u > 0 && v > 0)
				{
					ptEle.pt2D.x = u, ptEle.pt2D.y = v, ptEle.scale = s, ptEle.frameID = frameID, ptEle.imWidth = VideoInfo[camID].VideoInfo[frameID].width, ptEle.imHeight = VideoInfo[camID].VideoInfo[frameID].height;
					LensCorrectionPoint(&ptEle.pt2D, VideoInfo[camID].VideoInfo[frameID].K, VideoInfo[camID].VideoInfo[frameID].distortion);
					PerCam_UV[camID*npts + id].push_back(ptEle);
				}
			}
		}
		fclose(fp);
	}

	printLOG("Get rays info ....");
	for (int pid = 0; pid < npts; pid++)
	{
		for (int camID = 0; camID < nCams; camID++)
		{
			for (int frameID = 0; frameID < PerCam_UV[camID*npts + pid].size(); frameID++)
			{
				int RealFrameID = PerCam_UV[camID*npts + pid][frameID].frameID;
				if (VideoInfo[camID].VideoInfo[RealFrameID].ShutterModel == 0)
					for (int kk = 0; kk < 12; kk++)
						P[kk] = VideoInfo[camID].VideoInfo[RealFrameID].P[kk];
				else if (VideoInfo[camID].VideoInfo[RealFrameID].ShutterModel == 1)
					AssembleP_RS(PerCam_UV[camID*npts + pid][frameID].pt2D, VideoInfo[camID].VideoInfo[RealFrameID], P);
				else
					printLOG("Not supported model for motion prior sync\n");

				for (int kk = 0; kk < 12; kk++)
					PerCam_UV[camID*npts + pid][frameID].P[kk] = P[kk];
				for (int kk = 0; kk < 9; kk++)
					PerCam_UV[camID*npts + pid][frameID].K[kk] = VideoInfo[camID].VideoInfo[RealFrameID].K[kk];
				for (int kk = 0; kk < 7; kk++)
					PerCam_UV[camID*npts + pid][frameID].distortion[kk] = VideoInfo[camID].VideoInfo[RealFrameID].distortion[kk];
			}
		}
	}


	printLOG("Get 3D data:\n");
	for (int pid = 0; pid < npts; pid++)
	{
		TimeStamp.clear(), T3D.clear(), VisCamID.clear(), VisLocalFrameID.clear();
		sprintf(Fname, "%s/Track3D_/frameSynced_Track_%.4d.txt", Path, pid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		while (fscanf(fp, "%lf %lf %lf %lf %d %d", &x, &y, &z, &t, &cID, &fID) != EOF)
		{
			TimeStamp.push_back(t), VisCamID.push_back(cID), VisLocalFrameID.push_back(fID);
			T3D.push_back(Point3d(x, y, z));
		}
		fclose(fp);

		for (int ii = 0; ii < (int)TimeStamp.size(); ii++)
			ts[ii] = TimeStamp[ii], dummy[ii] = ii;
		Quick_Sort_Double(ts, dummy, 0, (int)TimeStamp.size() - 1);

		for (int ii = 0; ii < (int)TimeStamp.size(); ii++)
		{
			int id = dummy[ii], camID = VisCamID[id], frameID = VisLocalFrameID[id];
			ptEle.viewID = camID, ptEle.frameID = frameID, ptEle.timeStamp = TimeStamp[id];

			ptEle.pt3D = T3D[id];
			for (int fid = 0; fid < (int)PerCam_UV[camID*npts + pid].size(); fid++)
			{
				if (PerCam_UV[camID*npts + pid][fid].frameID == frameID)
				{
					PerCam_UV[camID*npts + pid][fid].pt3D = T3D[id];
					break;
				}
			}
		}
	}

	//Compute cost after optim
	int allnpts = 0; double avg = 0.0;
	for (int pid = 0; pid < npts; pid++)
	{
		for (int camID = 0; camID < nCams; camID++)
		{
			for (int frameID = 0; frameID < PerCam_UV[camID*npts + pid].size(); frameID++)
			{
				int RealFrameID = PerCam_UV[camID*npts + pid][frameID].frameID;

				Point2d P2d = PerCam_UV[camID*npts + pid][frameID].pt2D;
				Point3d P3d = PerCam_UV[camID*npts + pid][frameID].pt3D;
				double *P = PerCam_UV[camID*npts + pid][frameID].P;

				double numX = P[0] * P3d.x + P[1] * P3d.y + P[2] * P3d.z + P[3];
				double numY = P[4] * P3d.x + P[5] * P3d.y + P[6] * P3d.z + P[7];
				double denum = P[8] * P3d.x + P[9] * P3d.y + P[10] * P3d.z + P[11];

				Point2d proP2D = Point2d(numX / denum, numY / denum);
				Point2d err = proP2D - P2d;
				PerCam_UV[camID*npts + pid][frameID].pt2DErr = err;
				avg += sqrt(pow(err.x, 2) + pow(err.y, 2));
				allnpts++;
			}
		}
	}
	avg = avg / allnpts;
	printLOG("Avg err: %.3f \n", avg);

	for (int camID = 0; camID < nCams; camID++)
	{
		sprintf(Fname, "%s/Track2D/UltimateErrTri_%.4d.txt", Path, camID); FILE *fp = fopen(Fname, "w+");
		if (fp == NULL)
		{
			printLOG("Cannot write %s\n", Fname);
			return 1;
		}
		fprintf(fp, "%d\n", npts);
		for (int pid = 0; pid < npts; pid++)
		{
			if (PerCam_UV[camID*npts + pid].size() > 0)
				fprintf(fp, "%d %d ", pid, (int)PerCam_UV[camID*npts + pid].size());
			for (int frameID = 0; frameID < PerCam_UV[camID*npts + pid].size(); frameID++)
			{
				int RealFrameID = PerCam_UV[camID*npts + pid][frameID].frameID;
				Point2d p2d = PerCam_UV[camID*npts + pid][frameID].pt2D;
				LensDistortionPoint(&p2d, PerCam_UV[camID*npts + pid][frameID].K, PerCam_UV[camID*npts + pid][frameID].distortion);
				Point2d err = PerCam_UV[camID*npts + pid][frameID].pt2DErr;
				fprintf(fp, "%d %.3f %.3f %.3f %.3f ", RealFrameID, p2d.x, p2d.y, err.x, err.y);
			}
			if (PerCam_UV[camID*npts + pid].size() > 0)
				fprintf(fp, "\n");
		}
		fclose(fp);
	}

	delete[]PerCam_UV;
	return 0;
}
int ComputeRectifiedPatch(char *Path, int viewID, int startF, int hsubset, double expansion)
{
	char Fname[512];
	int npts, pid, nf, InterpAlgo = 1;

	vector<Point2f> *ForeTrackUV, *BackTrackUV = 0;
	vector<int> *ForeFidTrack = 0, *BackFidTrack = 0;
	vector<float> aRef, *ForeScale = 0, *BackScale = 0;
	vector<AffinePara> *cForeWarp = 0, *cBackWarp = 0;

	int maxForeFid = 0, trueStartF = -1;
	sprintf(Fname, "%s/Track2D/FT_%d_%.4d.txt", Path, viewID, startF); FILE *fp = fopen(Fname, "r");
	fscanf(fp, "%d ", &npts);
	if (npts > 0)
	{
		ForeTrackUV = new vector<Point2f>[npts];
		ForeFidTrack = new vector<int>[npts];
		ForeScale = new vector<float>[npts];
		cForeWarp = new vector<AffinePara>[npts];
		aRef.resize(npts);
	}
	for (int ii = 0; ii < npts; ii++)
	{
		fscanf(fp, "%d %d ", &pid, &nf);
		ForeFidTrack[pid].resize(nf); ForeTrackUV[pid].resize(nf), ForeScale[pid].resize(nf), cForeWarp[pid].resize(nf);
		for (int fid = 0; fid < nf; fid++)
		{
			fscanf(fp, "%d %f %f %f %f %lf %lf %lf %lf ", &ForeFidTrack[pid][fid], &ForeTrackUV[pid][fid].x, &ForeTrackUV[pid][fid].y, &ForeScale[pid][fid], &aRef[pid],
				&cForeWarp[pid][fid].warp[0], &cForeWarp[pid][fid].warp[1], &cForeWarp[pid][fid].warp[2], &cForeWarp[pid][fid].warp[3]);
			if (trueStartF == -1)
				trueStartF = ForeFidTrack[pid][fid];
			maxForeFid = max(maxForeFid, nf);
		}
	}
	fclose(fp);

	int maxBackFid = 0;
	sprintf(Fname, "%s/Track2D/BT_%d_%.4d.txt", Path, viewID, startF); fp = fopen(Fname, "r");
	fscanf(fp, "%d ", &npts);
	if (npts > 0)
	{
		BackTrackUV = new vector<Point2f>[npts];
		BackFidTrack = new vector<int>[npts];
		BackScale = new vector<float>[npts];
		cBackWarp = new vector<AffinePara>[npts];
	}
	for (int ii = 0; ii < npts; ii++)
	{
		fscanf(fp, "%d %d ", &pid, &nf);
		BackFidTrack[pid].resize(nf); BackTrackUV[pid].resize(nf), BackScale[pid].resize(nf), cBackWarp[pid].resize(nf);
		for (int fid = 0; fid < nf; fid++)
		{
			fscanf(fp, "%d %f %f %f %f %lf %lf %lf %lf ", &BackFidTrack[pid][fid], &BackTrackUV[pid][fid].x, &BackTrackUV[pid][fid].y, &BackScale[pid][fid], &aRef[pid],
				&cBackWarp[pid][fid].warp[0], &cBackWarp[pid][fid].warp[1], &cBackWarp[pid][fid].warp[2], &cBackWarp[pid][fid].warp[3]);
			if (trueStartF == -1)
				trueStartF = BackFidTrack[pid][fid];
			maxBackFid = max(maxBackFid, nf);
		}
	}
	fclose(fp);

	vector<double*> VForeImgPara;
	unsigned char *Img = 0;
	int height, width;
	for (int ii = 0; ii < maxForeFid; ii++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, ii + trueStartF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, ii + trueStartF);
		Mat cvImg = imread(Fname, 0);
		if (cvImg.empty())
		{
			maxForeFid = ii;
			break;
		}
		height = cvImg.rows, width = cvImg.cols;
		if (Img == NULL)
			Img = new unsigned char[width*height];
		for (int jj = 0; jj < height; jj++)
		{
			const unsigned char* RowJJ = cvImg.ptr<unsigned char>(jj);
			for (int ii = 0; ii < width; ii++)
				Img[ii + jj * width] = RowJJ[ii];
		}
		double *ImgPara = new double[width*height];
		Generate_Para_Spline(Img, ImgPara, width, height, InterpAlgo);
		VForeImgPara.push_back(ImgPara);
	}

	vector<double*> VBackImgPara;
	for (int ii = 0; ii < maxBackFid; ii++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, -ii + trueStartF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, -ii + trueStartF);
		Mat cvImg = imread(Fname, 0);
		if (cvImg.empty())
		{
			maxBackFid = ii;
			break;
		}
		height = cvImg.rows, width = cvImg.cols;
		if (Img == NULL)
			Img = new unsigned char[width*height];
		for (int jj = 0; jj < height; jj++)
		{
			const unsigned char* RowJJ = cvImg.ptr<unsigned char>(jj);
			for (int ii = 0; ii < width; ii++)
				Img[ii + jj * width] = RowJJ[ii];
		}
		double *ImgPara = new double[width*height];
		Generate_Para_Spline(Img, ImgPara, width, height, InterpAlgo);
		VBackImgPara.push_back(ImgPara);
	}

	sprintf(Fname, "%s/Patch", Path); makeDir(Fname);
	sprintf(Fname, "%s/Patch/%d", Path, viewID); makeDir(Fname);
	double *sImg = new double[(2 * hsubset + 1)* (2 * hsubset + 1)];
	for (int ii = 0; ii < npts; ii++)
	{
		if (ForeTrackUV[ii].size() < 1)
			continue;

		double refs = -1.0;
		for (int jj = 0; jj < (int)ForeFidTrack[pid].size() && refs < 0.0; jj++)
			if (cForeWarp[pid][jj].warp[0] == 1.0 && cForeWarp[pid][jj].warp[1] == 0.0)
				refs = ForeScale[pid][jj];

		for (int jj = 0; jj < min((int)ForeFidTrack[ii].size(), maxForeFid); jj++)
		{
			double II, JJ, S, angle = aRef[ii], s = 3.0*ForeScale[pid][jj] / hsubset * expansion;
			Eigen::Matrix3d scalingM, rotM, affineM, transM;
			rotM << cos(angle), -sin(angle), 0, sin(angle), cos(angle), 0, 0, 0, 1;
			scalingM << s, 0, 0, 0, s, 0, 0, 0, 1;
			affineM << cForeWarp[ii][jj].warp[0], cForeWarp[ii][jj].warp[1], ForeTrackUV[ii][jj].x, cForeWarp[ii][jj].warp[2], cForeWarp[ii][jj].warp[3], ForeTrackUV[ii][jj].y, 0, 0, 1;
			transM = affineM * rotM*scalingM;

			for (int jjj = -hsubset; jjj <= hsubset; jjj++)
			{
				for (int iii = -hsubset; iii <= hsubset; iii++)
				{
					II = transM(0, 0) * iii + transM(0, 1) * jjj + transM(0, 2);
					JJ = transM(1, 0) * iii + transM(1, 1) * jjj + transM(1, 2);
					Get_Value_Spline(VForeImgPara[jj], 1920, 1080, II, JJ, &S, -1, InterpAlgo);
					sImg[iii + hsubset + (jjj + hsubset)*(2 * hsubset + 1)] = max(min((int)(S + 0.5), 255), 0);
				}
			}
			sprintf(Fname, "%s/Patch/%d/%d_%.4d.png", Path, viewID, ii, jj + trueStartF);
			SaveDataToImage(Fname, sImg, (2 * hsubset + 1), (2 * hsubset + 1), 1);
		}
	}

	for (int ii = 0; ii < npts; ii++)
	{
		if (BackTrackUV[ii].size() < 1)
			continue;

		double refs = -1.0;
		for (int jj = 0; jj < (int)BackFidTrack[pid].size() && refs < 0.0; jj++)
			if (cBackWarp[pid][jj].warp[0] == 1.0 && cBackWarp[pid][jj].warp[1] == 0.0)
				refs = BackScale[pid][jj];

		for (int jj = 0; jj < min((int)BackFidTrack[ii].size(), maxBackFid); jj++)
		{
			double II, JJ, S, angle = aRef[ii], s = 3.0*refs / hsubset * expansion;
			Eigen::Matrix3d scalingM, rotM, affineM, transM;
			rotM << cos(angle), -sin(angle), 0, sin(angle), cos(angle), 0, 0, 0, 1;
			scalingM << s, 0, 0, 0, s, 0, 0, 0, 1;
			affineM << cBackWarp[ii][jj].warp[0], cBackWarp[ii][jj].warp[1], BackTrackUV[ii][jj].x, cBackWarp[ii][jj].warp[2], cBackWarp[ii][jj].warp[3], BackTrackUV[ii][jj].y, 0, 0, 1;
			transM = affineM * rotM*scalingM;

			for (int jjj = -hsubset; jjj <= hsubset; jjj++)
			{
				for (int iii = -hsubset; iii <= hsubset; iii++)
				{
					II = transM(0, 0) * iii + transM(0, 1) * jjj + transM(0, 2);
					JJ = transM(1, 0) * iii + transM(1, 1) * jjj + transM(1, 2);
					Get_Value_Spline(VBackImgPara[jj], 1920, 1080, II, JJ, &S, -1, InterpAlgo);
					sImg[iii + hsubset + (jjj + hsubset)*(2 * hsubset + 1)] = max(min((int)(S + 0.5), 255), 0);
				}
			}
			sprintf(Fname, "%s/Patch/%d/%d_%.4d.png", Path, viewID, ii, -jj + trueStartF);
			SaveDataToImage(Fname, sImg, (2 * hsubset + 1), (2 * hsubset + 1), 1);
		}
	}

	for (int ii = 0; ii < (int)VForeImgPara.size(); ii++)
		delete[]VForeImgPara[ii];
	for (int ii = 0; ii < (int)VBackImgPara.size(); ii++)
		delete[]VBackImgPara[ii];
	delete[]ForeTrackUV, delete[]BackTrackUV, delete[]ForeFidTrack, delete[]BackFidTrack, delete[]ForeScale, delete[]BackScale, delete[]cForeWarp, delete[]cBackWarp, delete[]sImg;

	return 0;
}
int ComputeRectifiedPatch(char *Path, int viewID, int hsubset, double expansion)
{
	char Fname[512];
	int npts, pid, nf, InterpAlgo = 1;

	vector<Point2f> *TrackUV = 0;
	vector<int> *FidTrack = 0;
	vector<float> aRef, *Scale = 0;
	vector<AffinePara> *cWarp = 0;

	int maxFid = -1, minFid = 9999;
	sprintf(Fname, "%s/Track2D/Ultimate_%.4d.txt", Path, viewID); FILE *fp = fopen(Fname, "r");
	fscanf(fp, "%d ", &npts);
	if (npts > 0)
	{
		TrackUV = new vector<Point2f>[npts];
		FidTrack = new vector<int>[npts];
		Scale = new vector<float>[npts];
		cWarp = new vector<AffinePara>[npts];
		aRef.resize(npts);
	}
	for (int ii = 0; ii < npts; ii++)
	{
		fscanf(fp, "%d %d ", &pid, &nf);
		FidTrack[pid].resize(nf); TrackUV[pid].resize(nf), Scale[pid].resize(nf), cWarp[pid].resize(nf);
		for (int fid = 0; fid < nf; fid++)
		{
			fscanf(fp, "%d %f %f %f %f %lf %lf %lf %lf ", &FidTrack[pid][fid], &TrackUV[pid][fid].x, &TrackUV[pid][fid].y, &Scale[pid][fid], &aRef[pid],
				&cWarp[pid][fid].warp[0], &cWarp[pid][fid].warp[1], &cWarp[pid][fid].warp[2], &cWarp[pid][fid].warp[3]);
			maxFid = max(maxFid, FidTrack[pid][fid]), minFid = min(minFid, FidTrack[pid][fid]);
		}
	}
	fclose(fp);

	vector<double*> VImgPara;
	unsigned char *Img = 0;
	int height, width;
	for (int ii = 0; ii < minFid; ii++)
	{
		double *ImgPara = 0;
		VImgPara.push_back(ImgPara);
	}
	for (int fid = minFid; fid <= maxFid; fid++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, fid);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, fid);
		Mat cvImg = imread(Fname, 0);
		if (cvImg.empty())
		{
			maxFid = fid;
			break;
		}
		height = cvImg.rows, width = cvImg.cols;
		if (Img == NULL)
			Img = new unsigned char[width*height];
		for (int jj = 0; jj < height; jj++)
		{
			const unsigned char* RowJJ = cvImg.ptr<unsigned char>(jj);
			for (int ii = 0; ii < width; ii++)
				Img[ii + jj * width] = RowJJ[ii];
		}
		double *ImgPara = new double[width*height];
		Generate_Para_Spline(Img, ImgPara, width, height, InterpAlgo);
		VImgPara.push_back(ImgPara);
	}

	sprintf(Fname, "%s/Patch", Path); makeDir(Fname);
	sprintf(Fname, "%s/Patch/%d", Path, viewID); makeDir(Fname);
	double *sImg = new double[(2 * hsubset + 1)* (2 * hsubset + 1)];
	for (int pid = 0; pid < npts; pid++)
	{
		if (TrackUV[pid].size() < 1)
			continue;

		double refs = -1.0;
		for (int jj = 0; jj < (int)FidTrack[pid].size() && refs < 0.0; jj++)
			if (cWarp[pid][jj].warp[0] == 1.0 && cWarp[pid][jj].warp[1] == 0.0)
				refs = Scale[pid][jj];

		for (int jj = 0; jj < (int)FidTrack[pid].size(); jj++)
		{
			int fid = FidTrack[pid][jj];
			double II, JJ, S, angle = aRef[pid], s = 3.0*refs / hsubset * expansion;
			Eigen::Matrix3d scalingM, rotM, affineM, transM;
			rotM << cos(angle), -sin(angle), 0, sin(angle), cos(angle), 0, 0, 0, 1;
			scalingM << s, 0, 0, 0, s, 0, 0, 0, 1;
			affineM << cWarp[pid][jj].warp[0], cWarp[pid][jj].warp[1], TrackUV[pid][jj].x, cWarp[pid][jj].warp[2], cWarp[pid][jj].warp[3], TrackUV[pid][jj].y, 0, 0, 1;
			transM = affineM * rotM*scalingM;

			for (int jjj = -hsubset; jjj <= hsubset; jjj++)
			{
				for (int iii = -hsubset; iii <= hsubset; iii++)
				{
					II = transM(0, 0) * iii + transM(0, 1) * jjj + transM(0, 2);
					JJ = transM(1, 0) * iii + transM(1, 1) * jjj + transM(1, 2);
					Get_Value_Spline(VImgPara[fid], width, height, II, JJ, &S, -1, InterpAlgo);
					sImg[iii + hsubset + (jjj + hsubset)*(2 * hsubset + 1)] = max(min((int)(S + 0.5), 255), 0);
				}
			}
			sprintf(Fname, "%s/Patch/%d/%d_%.4d.png", Path, viewID, pid, fid);
			SaveDataToImage(Fname, sImg, (2 * hsubset + 1), (2 * hsubset + 1), 1);
		}
	}

	for (int ii = 0; ii < (int)VImgPara.size(); ii++)
		delete[]VImgPara[ii];
	delete[]TrackUV, delete[]FidTrack, delete[]Scale, delete[]cWarp, delete[]sImg;

	return 0;
}

//model-based matching
std::vector<Eigen::Matrix3d> SequentialHomoRanSac(char *Path, Point2i *cid_fid, SiftGPU* sift)
{
	char Fname[512];
	std::vector < Eigen::Matrix3d > AlleHomo;

	Mat Img1, Img2;
	vector<Point2d> Keys1, Keys2;
	vector<SiftKeypoint> kpts1, kpts2;
	vector<uchar> descU1, descU2;

	printLOG("Getting feature...\n");
	sprintf(Fname, "%s/%d/%.4d.sift", Path, cid_fid[0].x, cid_fid[0].y);
	if (IsFileExist(Fname))
		readVisualSFMSiftGPU(Fname, kpts1, descU1);
	else
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, cid_fid[0].x, cid_fid[0].y);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid_fid[0].x, cid_fid[0].y);
			if (IsFileExist(Fname) == 0)
				return AlleHomo;
		}
		Img1 = imread(Fname, 0);
		ExtractSiftGPU(Path, cid_fid[0].x, cid_fid[0].y, Img1, kpts1, descU1, sift);

		sprintf(Fname, "%s/%d/%.4d.sift", Path, cid_fid[0].x, cid_fid[0].y);
		writeVisualSFMSiftGPU(Fname, kpts1, &descU1[0]);
	}

	sprintf(Fname, "%s/%d/%.4d.sift", Path, cid_fid[1].x, cid_fid[1].y);
	if (IsFileExist(Fname))
		readVisualSFMSiftGPU(Fname, kpts2, descU2);
	else
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, cid_fid[1].x, cid_fid[1].y);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid_fid[1].x, cid_fid[1].y);
			if (IsFileExist(Fname) == 0)
				return AlleHomo;
		}
		Img2 = imread(Fname, 0);
		ExtractSiftGPU(Path, cid_fid[1].x, cid_fid[1].y, Img2, kpts2, descU2, sift);

		sprintf(Fname, "%s/%d/%.4d.sift", Path, cid_fid[1].x, cid_fid[1].y);
		writeVisualSFMSiftGPU(Fname, kpts2, &descU2[0]);
	}

	//Finding nearest neighbor
	printLOG("Running feature matching...\n");
	double start = omp_get_wtime();
	vector<Point2i> RawPairWiseMatchID; RawPairWiseMatchID.reserve(10000);
	RawPairWiseMatchID = MatchTwoViewSIFTBruteForce(descU1, descU2, 128);


	for (int i = 0; i < RawPairWiseMatchID.size(); ++i)
	{
		int id1 = RawPairWiseMatchID[i].x, id2 = RawPairWiseMatchID[i].y;
		Keys1.push_back(Point2d(kpts1[id1].x - 0.5, kpts1[id1].y - 0.5));
		Keys2.push_back(Point2d(kpts2[id2].x - 0.5, kpts2[id2].y - 0.5));
	}
	printLOG("%d matches found... in %.2fs\n", Keys1.size(), omp_get_wtime() - start);

	/*FILE *fp = fopen("C:/temp/x.txt", "w");
	for(int ii=0; ii<Keys1.size(); ii++)
	fprintf(fp, "%.4f %.4f %.4f %.4f\n", Keys1[ii].x, Keys1[ii].y, Keys2[ii].x, Keys2[ii].y);
	fclose(fp);

	double u1, v1, u2, v2;
	FILE *fp = fopen("C:/temp/x.txt", "r");
	while (fscanf(fp, "%lf %lf %lf %lf ", &u1, &v1, &u2, &v2) != EOF)
	Keys1.push_back(Point2d(u1, v1)), Keys2.push_back(Point2d(u2, v2));
	fclose(fp);*/

	int ninlierThresh = 10;
	ConfigParamsHomog cfg;
	cfg.common.confThreshold = 0.99, cfg.common.minSampleSize = 4, cfg.common.inlierThreshold = 4.0;
	cfg.common.maxHypotheses = 850000, cfg.common.maxSolutionsPerSample = 1;
	cfg.common.prevalidateSample = true, cfg.common.prevalidateModel = true, cfg.common.testDegeneracy = true;
	cfg.common.randomSamplingMethod = USACConfig::SAMP_UNIFORM, cfg.common.verifMethod = USACConfig::VERIF_SPRT, cfg.common.localOptMethod = USACConfig::LO_LOSAC;

	cfg.prosac.sortedPointIndices = NULL;
	cfg.sprt.tM = 100.0, cfg.sprt.mS = 1.0, cfg.sprt.delta = 0.01, cfg.sprt.epsilon = 0.2;
	cfg.losac.innerSampleSize = 12, cfg.losac.innerRansacRepetitions = 3, cfg.losac.thresholdMultiplier = 2.0, cfg.losac.numStepsIterative = 4;

	vector<vector<Point2d> > AllMultiInlierKeys1, AllMultiInlierKeys2;
	vector<Point2d> aKey1, aKey2;
	aKey1 = Keys1, aKey2 = Keys2;
	int iter = 0;
	while (true)
	{
		int ninliers = 0;
		double Hmat[9];
		vector<int> InlierIndicator;
		cfg.common.numDataPoints = aKey1.size();
		USAC_FindHomography(cfg, aKey1, aKey2, Hmat, InlierIndicator, ninliers);

		printLOG("Round %d..%d/%d inliers\n", iter, ninliers, aKey1.size());
		iter++;

		if (ninliers > ninlierThresh)
		{
			Eigen::Matrix3d eHomo;
			eHomo << Hmat[0], Hmat[1], Hmat[2],
				Hmat[3], Hmat[4], Hmat[5],
				Hmat[6], Hmat[7], Hmat[8];

			AlleHomo.push_back(eHomo);

			vector<Point2d> AllInlierKeys1, AllInlierKeys2;
			for (int ii = cfg.common.numDataPoints - 1; ii >= 0; ii--)
			{
				if (InlierIndicator[ii] == 1)
				{
					AllInlierKeys1.push_back(aKey1[ii]), AllInlierKeys2.push_back(aKey2[ii]);
					aKey1.erase(aKey1.begin() + ii), aKey2.erase(aKey2.begin() + ii);
				}
			}
			AllMultiInlierKeys1.push_back(AllInlierKeys1), AllMultiInlierKeys2.push_back(AllInlierKeys2);
		}
		else
			break;
	}

	if (1)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, cid_fid[0].x, cid_fid[0].y);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid_fid[0].x, cid_fid[0].y);
			if (IsFileExist(Fname) == 0)
				return AlleHomo;
		}
		Img1 = imread(Fname, 1);
		sprintf(Fname, "%s/%d/%.4d.png", Path, cid_fid[1].x, cid_fid[1].y);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid_fid[1].x, cid_fid[1].y);
			if (IsFileExist(Fname) == 0)
				return AlleHomo;
		}
		Img2 = imread(Fname, 1);

		int modelID = 0;
		static cv::Scalar colors[] = { Scalar(0, 0, 255), Scalar(0, 128, 255), Scalar(0, 255, 255), Scalar(0, 255, 0), Scalar(255, 128, 0), Scalar(255, 255, 0), Scalar(255, 0, 0), Scalar(255, 0, 255), Scalar(255, 255, 255) };

		namedWindow("Image", CV_WINDOW_NORMAL | CV_WINDOW_KEEPRATIO);
		createTrackbar("Control", "Image", &modelID, AlleHomo.size() - 1, NULL);

		while (true)
		{
			cv::Mat BImage(Img1.rows, Img1.cols * 2, Img1.type());
			Img1.copyTo(BImage(cv::Rect(0, 0, Img1.cols, Img1.rows)));
			Img2.copyTo(BImage(cv::Rect(Img1.cols, 0, Img1.cols, Img1.rows)));

			for (size_t ii = 0; ii < AllMultiInlierKeys1[modelID].size(); ii++)
			{
				circle(BImage, cv::Point(AllMultiInlierKeys1[modelID][ii].x, AllMultiInlierKeys1[modelID][ii].y), 3, colors[ii % 8], 8);
				circle(BImage, cv::Point(AllMultiInlierKeys2[modelID][ii].x + Img1.cols, AllMultiInlierKeys2[modelID][ii].y), 3, colors[ii % 8], 8);
				line(BImage, cv::Point(AllMultiInlierKeys1[modelID][ii].x, AllMultiInlierKeys1[modelID][ii].y), cv::Point(AllMultiInlierKeys2[modelID][ii].x + Img1.cols, AllMultiInlierKeys2[modelID][ii].y), colors[ii % 8], 2);
			}
			imshow("Image", BImage);
			int key = waitKey(10);
			if (key == 27)
				break;
		}
	}

	return AlleHomo;
}
int SequentialHomoRanSacDriver(char *Path, Point2i refCid_Fid, Point2i nrCid_Fid)
{
	int maxFeatures = 50000;
	char * argv[] = { "-fo", "-1", "-v", "0", "-tc", "7680", "-nomc", "-p", "1920x1080", "-maxd", "1920", "-mo", "1", "-da" }; //one orienation and smaller expected # feats

																															   //unable to apply to video seq because ffmpeg does not allow precise frame seeking
	int siftGPU = 1;
#ifdef USESIFTGPU
#ifdef _WINDOWS
#ifdef _DEBUG
	HMODULE  hsiftgpu = LoadLibrary("siftgpu_d.dll");
#else
	HMODULE  hsiftgpu = LoadLibrary("siftgpu.dll");
#endif
#else
	void * hsiftgpu = dlopen("libsiftgpu.so", RTLD_LAZY);
#endif

	if (hsiftgpu == NULL)
		return 0;

	SiftGPU* (*pCreateNewSiftGPU)(int) = NULL;
	pCreateNewSiftGPU = (SiftGPU* (*) (int)) GET_MYPROC(hsiftgpu, "CreateNewSiftGPU");
	SiftGPU* sift = pCreateNewSiftGPU(1);

	int argc = sizeof(argv) / sizeof(char*);
	sift->ParseParam(argc, argv);
	if (sift->CreateContextGL() != SiftGPU::SIFTGPU_FULL_SUPPORTED)
		siftGPU = 0;
#else
	siftGPU = 0;
	successConsecutiveTrackingRatio = successConsecutiveTrackingRatio - 0.2; //vlsift does not have darkness adaptation feature
#endif

	Point2i cid_fid[2] = { refCid_Fid, nrCid_Fid };
	SequentialHomoRanSac(Path, cid_fid, sift);


	return 0;
}

//Triangulation and geometric sync
double TriangulatePointsFromArbitaryCameras(char *Path, int nViews, int distortionCorrected, int maxPts, double threshold)
{
	printLOG("Start clicking points for triangulation\n");
	char Fname[512];
	Corpus CorpusInfo;
	CorpusInfo.nCameras = nViews;
	CorpusInfo.camera = new CameraData[nViews];

	double dummy;
	sprintf(Fname, "%s/intrinsic.txt", Path);
	FILE *fp = fopen(Fname, "r");
	for (int ii = 0; ii < nViews; ii++)
	{
		double *intrinsic = CorpusInfo.camera[ii].intrinsic;

		fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf ", &intrinsic[0], &dummy, &intrinsic[3], &dummy,
			&dummy, &intrinsic[1], &intrinsic[4], &dummy,
			&dummy, &dummy, &dummy, &dummy,
			&dummy, &dummy, &dummy, &dummy);
	}
	fclose(fp);


	sprintf(Fname, "%s/extrinsic.txt", Path);
	fp = fopen(Fname, "r");
	for (int ii = 0; ii < nViews; ii++)
	{
		double *R = CorpusInfo.camera[ii].R;
		double *T = CorpusInfo.camera[ii].T;

		fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf ", &R[0], &R[1], &R[2], &T[0],
			&R[3], &R[4], &R[5], &T[1],
			&R[6], &R[7], &R[8], &T[2],
			&dummy, &dummy, &dummy, &dummy);
	}
	fclose(fp);

	distortionCorrected = 1;
	for (int ii = 0; ii < nViews; ii++)
	{
		CorpusInfo.camera[ii].ShutterModel = 0;
		CorpusInfo.camera[ii].threshold = threshold, CorpusInfo.camera[ii].nInlierThresh = 3;

		GetKFromIntrinsic(CorpusInfo.camera[ii]);
		AssembleP(CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].R, CorpusInfo.camera[ii].T, CorpusInfo.camera[ii].P);

		for (int jj = 0; jj < 7; jj++)
			CorpusInfo.camera[ii].distortion[jj] = 0.0;
	}

	int n3D = 1, viewID, ptsCount = 0;
	vector<Point3d> t3D;
	vector<Point2d> uv;
	vector<int> viewIDAll3D;
	vector<Point2d>uvAll3D;
	vector<Point3d>TwoPoints;

	sprintf(Fname, "%s/Points.txt", Path);
	ofstream ofs(Fname);
	if (ofs.fail())
		cerr << "Cannot write " << Fname << endl;
	for (int npts = 0; npts < maxPts; npts++)
	{
		t3D.clear(), uv.clear(), viewIDAll3D.clear(), uvAll3D.clear();
		int currentView = 0;
		while (true)
		{
			currentView = currentView % nViews;
			namedWindow("Image", CV_WINDOW_NORMAL); setMouseCallback("Image", onMouse);
			sprintf(Fname, "%s/%d.png", Path, currentView);
			Mat Img = imread(Fname);
			if (Img.empty())
			{
				printLOG("Cannot load %s\n", Fname);
				return 1;
			}

			CvPoint text_origin = { Img.cols / 30, Img.cols / 30 };
			sprintf(Fname, "Point %d/%d of Image %d/%d", npts + 1, maxPts, currentView + 1, nViews);
			if (npts % 2 == 0)
				putText(Img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * Img.cols / 640, CV_RGB(255, 0, 0), 2);
			else
				putText(Img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * Img.cols / 640, CV_RGB(0, 255, 0), 2);

			bool doTriangulation = false;
			while (true)
			{
				imshow("Image", Img);
				int key = waitKey(33);

				if (clicked)
				{
					cout << "\a";
					viewIDAll3D.push_back(currentView);
					uvAll3D.push_back(Point2d(MousePosX, MousePosY));
					ofs << currentView << " " << MousePosX << " " << MousePosY << endl;

					clicked = 0;
					currentView = (currentView++) % nViews;
					break;
				}
				else if (key == 'n')
				{
					currentView++;
					break;
				}
				else if (key == 'p')
				{
					currentView += nViews;
					currentView--;
					break;
				}
				else if (key == 't')
				{
					doTriangulation = true;
					break; //triangulate now
				}

			}
			if (doTriangulation)
				break;
		}

		//Test if 3D is correct
		ptsCount = (int)uvAll3D.size();
		if (ptsCount < 2)
			continue;

		Point3d xyz;
		double *A = new double[6 * ptsCount];
		double *B = new double[2 * ptsCount];
		double *tPs = new double[12 * ptsCount];
		bool *passed = new bool[ptsCount];
		double *Ps = new double[12 * ptsCount];
		Point2d *match2Dpts = new Point2d[ptsCount];

		vector<int>Inliers[1];  Inliers[0].reserve(ptsCount * 2);
		double ProThresh = 0.99, PercentInlier = 0.25;
		int goodNDplus = 0, iterMax = (int)(log(1.0 - ProThresh) / log(1.0 - pow(PercentInlier, 2)) + 0.5); //log(1-eps) / log(1 - (inlier%)^min_pts_requires)
		int nviewsi = (int)viewIDAll3D.size();
		Inliers[0].clear();
		for (int ii = 0; ii < nviewsi; ii++)
		{
			viewID = viewIDAll3D.at(ii);

			match2Dpts[ii] = uvAll3D.at(ii);
			if (distortionCorrected == 0)
			{
				if (CorpusInfo.camera[viewID].LensModel == RADIAL_TANGENTIAL_PRISM)
					LensCorrectionPoint(&match2Dpts[ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
				else
					//FishEyeCorrectionPoint(&match2Dpts[ii], CorpusInfo.camera[viewID].distortion[0], CorpusInfo.camera[viewID].distortion[1], CorpusInfo.camera[viewID].distortion[2]);
					FishEyeCorrectionPoint(&match2Dpts[ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion[0]);
			}

			if (CorpusInfo.camera[viewID].ShutterModel == 0)
				for (int kk = 0; kk < 12; kk++)
					Ps[12 * ii + kk] = CorpusInfo.camera[viewID].P[kk];
			else
				AssembleP_RS(match2Dpts[ii], CorpusInfo.camera[viewID], Ps + 12 * ii);
		}

		double error = NviewTriangulationRANSAC(match2Dpts, Ps, &xyz, passed, Inliers, nviewsi, 1, 2, iterMax, PercentInlier, CorpusInfo.camera[0].threshold, A, B, tPs);
		if (passed[0])
		{
			printLOG("3D: %f %f %f Error: %f\n", xyz.x, xyz.y, xyz.z, error);
			ofs << xyz.x << " " << xyz.y << " " << xyz.z << endl;
			if (maxPts == 2)
				TwoPoints.push_back(xyz);
		}
	}
	ofs.close();

	if (maxPts == 2)
		return Distance3D(TwoPoints[0], TwoPoints[1]);
	else
		return 0;
}
double TriangulatePointsFromCorpusCameras(char *Path, int distortionCorrected, int maxPts, double threshold)
{
	printLOG("Start clicking points for triangulation\n");
	char Fname[512];
	Corpus CorpusInfo;
	sprintf(Fname, "%s/BA_Camera_AllParams_after.txt", Path);
	if (!readBundleAdjustedNVMResults(Fname, CorpusInfo))
		return -1;

	int nviews = CorpusInfo.nCameras;
	for (int ii = 0; ii < nviews; ii++)
	{
		CorpusInfo.camera[ii].threshold = threshold, CorpusInfo.camera[ii].nInlierThresh = 50, CorpusInfo.camera[ii];
		GetrtFromRT(CorpusInfo.camera[ii].rt, CorpusInfo.camera[ii].R, CorpusInfo.camera[ii].T);
		GetIntrinsicFromK(CorpusInfo.camera[ii]);
		AssembleP(CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].R, CorpusInfo.camera[ii].T, CorpusInfo.camera[ii].P);
		if (distortionCorrected == 1)
			for (int jj = 0; jj < 7; jj++)
				CorpusInfo.camera[ii].distortion[jj] = 0.0;
	}

	sprintf(Fname, "%s/ImageList4Scale.txt", Path);
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return -1;
	}
	int imgID;
	vector<int> ImageIDList;
	while (fscanf(fp, "%d ", &imgID) != EOF)
		ImageIDList.push_back(imgID);
	fclose(fp);

	int n3D = 1, viewID, ptsCount = 0;
	vector<Point3d> t3D;
	vector<Point2d> uv;
	vector<int> viewIDAll3D;
	vector<Point2d>uvAll3D;
	vector<Point3d>TwoPoints;

	sprintf(Fname, "%s/Points.txt", Path);
	ofstream ofs(Fname);
	if (ofs.fail())
		cerr << "Cannot write " << Fname << endl;
	for (int npts = 0; npts < maxPts; npts++)
	{
		t3D.clear(), uv.clear(), viewIDAll3D.clear(), uvAll3D.clear();
		for (int ii = 0; ii < ImageIDList.size(); ii++)
		{
			namedWindow("Image", CV_WINDOW_NORMAL); setMouseCallback("Image", onMouse);
			sprintf(Fname, "%s/%.4d.jpg", Path, ImageIDList[ii]);
			if (IsFileExist(Fname) == 0)
				sprintf(Fname, "%s/%.4d.png", Path, ImageIDList[ii]);
			Mat Img = imread(Fname);
			if (Img.empty())
			{
				printLOG("Cannot load %s\n", Fname);
				return 1;
			}

			CvPoint text_origin = { Img.cols / 30, Img.cols / 30 };
			sprintf(Fname, "Point %d/%d of Image %d/%d", npts + 1, maxPts, ii + 1, ImageIDList.size());
			if (npts % 2 == 0)
				putText(Img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * Img.cols / 640, CV_RGB(255, 0, 0), 2);
			else
				putText(Img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * Img.cols / 640, CV_RGB(0, 255, 0), 2);

			imshow("Image", Img), waitKey(0); cout << "\a";
			viewIDAll3D.push_back(ImageIDList[ii]);
			uvAll3D.push_back(Point2d(MousePosX, MousePosY));
			ofs << MousePosX << " " << MousePosY << endl;
		}

		//Test if 3D is correct
		ptsCount = (int)uvAll3D.size();
		Point3d xyz;
		double *A = new double[6 * ptsCount];
		double *B = new double[2 * ptsCount];
		double *tPs = new double[12 * ptsCount];
		bool *passed = new bool[ptsCount];
		double *Ps = new double[12 * ptsCount];
		Point2d *match2Dpts = new Point2d[ptsCount];

		vector<int>Inliers[1];  Inliers[0].reserve(ptsCount * 2);
		double ProThresh = 0.99, PercentInlier = 0.25;
		int goodNDplus = 0, iterMax = (int)(log(1.0 - ProThresh) / log(1.0 - pow(PercentInlier, 2)) + 0.5); //log(1-eps) / log(1 - (inlier%)^min_pts_requires)
		int nviewsi = (int)viewIDAll3D.size();
		Inliers[0].clear();
		for (int ii = 0; ii < nviewsi; ii++)
		{
			viewID = viewIDAll3D.at(ii);

			match2Dpts[ii] = uvAll3D.at(ii);
			if (CorpusInfo.camera[viewID].LensModel == RADIAL_TANGENTIAL_PRISM)
				LensCorrectionPoint(&match2Dpts[ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
			else
				//FishEyeCorrectionPoint(&match2Dpts[ii], CorpusInfo.camera[viewID].distortion[0], CorpusInfo.camera[viewID].distortion[1], CorpusInfo.camera[viewID].distortion[2]);
				FishEyeCorrectionPoint(&match2Dpts[ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion[0]);

			if (CorpusInfo.camera[viewID].ShutterModel == 0)
				for (int kk = 0; kk < 12; kk++)
					Ps[12 * ii + kk] = CorpusInfo.camera[viewID].P[kk];
			else
				AssembleP_RS(match2Dpts[ii], CorpusInfo.camera[viewID], Ps + 12 * ii);
		}

		double error = NviewTriangulationRANSAC(match2Dpts, Ps, &xyz, passed, Inliers, nviewsi, 1, 2, iterMax, PercentInlier, CorpusInfo.camera[0].threshold, A, B, tPs);
		if (passed[0])
		{
			printLOG("3D: %f %f %f Error: %f\n", xyz.x, xyz.y, xyz.z, error);
			ofs << xyz.x << " " << xyz.y << " " << xyz.z << endl;
			if (maxPts == 2)
				TwoPoints.push_back(xyz);
		}
	}
	ofs.close();

	if (maxPts == 2)
		return Distance3D(TwoPoints[0], TwoPoints[1]);
	else
		return 0;
}
double TriangulatePointsFromNonCorpusCameras(char *Path, vector<int> SelectedCams, int stopF, int distortionCorrected, int maxPts, double threshold)
{
	printLOG("Start clicking points for triangulation\n");
	char Fname[512];

	int nCams = (int)SelectedCams.size();
	VideoData *VideoI = new VideoData[nCams];
	for (int ii = 0; ii < nCams; ii++)
	{
		if (ReadVideoDataI(Path, VideoI[ii], SelectedCams[ii], -1, -1) == 1)
			continue;
	}

	Mat Img;
	int n3D = 1, viewID = 0, frameID = 0, oviewID = -1, oframeID = -1, ptsCount = 0;
	vector<Point3d> t3D;
	vector<Point2d> uv;
	vector<int> viewIDAll3D, frameIDAll3D;
	vector<Point2d>uvAll3D;
	vector<Point3d>TwoPoints;

	namedWindow("Image", CV_WINDOW_NORMAL);
	setMouseCallback("Image", onMouse);
	createTrackbar("Cid", "Image", &viewID, nCams, NULL);
	createTrackbar("Fid", "Image", &frameID, stopF, NULL);

	sprintf(Fname, "%s/Points.txt", Path);
	ofstream ofs(Fname);
	if (ofs.fail())
		cerr << "Cannot write " << Fname << endl;
	for (int npts = 0; npts < maxPts; npts++)
	{
		t3D.clear(), uv.clear(), viewIDAll3D.clear(), frameIDAll3D.clear(), uvAll3D.clear();
		int currentView = 0, currentFrame = 0;
		while (true)
		{
			if (!VideoI[currentView].VideoInfo[currentFrame].valid)
			{
				currentFrame++;
				if (currentFrame == stopF)
					currentView++;
				continue;
			}

			currentView = currentView % nCams;
			currentFrame = currentFrame % stopF;

			cvSetTrackbarPos("Cid", "Image", currentView);
			cvSetTrackbarPos("Fid", "Image", currentFrame);

			sprintf(Fname, "%s/%d/%.4d.jpg", Path, currentView, currentFrame);
			if (viewID != oviewID || oframeID != frameID)
			{
				oviewID = viewID, oframeID = frameID;
				Img = imread(Fname);
				if (Img.empty())
				{
					printLOG("Cannot load %s\n", Fname);
					return 1;
				}
			}

			CvPoint text_origin = { Img.cols / 30, Img.cols / 30 };
			sprintf(Fname, "Point %d/%d of Image %d/%d", npts + 1, maxPts, currentView + 1, nCams);
			if (npts % 2 == 0)
				putText(Img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * Img.cols / 640, CV_RGB(255, 0, 0), 2);
			else
				putText(Img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * Img.cols / 640, CV_RGB(0, 255, 0), 2);

			bool doTriangulation = false;
			while (true)
			{
				imshow("Image", Img);
				int key = waitKey(33);

				if (clicked)
				{
					cout << "\a";
					viewIDAll3D.push_back(currentView);
					frameIDAll3D.push_back(currentFrame);
					uvAll3D.push_back(Point2d(MousePosX, MousePosY));
					ofs << currentView << " " << currentFrame << " " << MousePosX << " " << MousePosY << endl;

					circle(Img, Point2i(MousePosX, MousePosY), 2, CV_RGB(255, 0, 0), 2);
					clicked = 0;

					break;
				}
				else if (key == 'n')
				{
					currentView++;
					currentView = currentView % nCams;
					break;
				}
				else if (key == 'f')
				{
					currentFrame++;
					currentFrame = currentFrame % stopF;
					break;
				}
				else if (key == 'p')
				{
					currentFrame--;
					currentFrame = currentFrame % stopF;
					break;
				}
				else if (key == 't')
				{
					doTriangulation = true;
					break; //triangulate now
				}
			}

			if (doTriangulation)
				break;
		}

		//Test if 3D is correct
		ptsCount = (int)uvAll3D.size();
		if (ptsCount < 2)
			continue;

		Point3d xyz;
		double *A = new double[6 * ptsCount];
		double *B = new double[2 * ptsCount];
		double *tPs = new double[12 * ptsCount];
		bool *passed = new bool[ptsCount];
		double *Ps = new double[12 * ptsCount];
		Point2d *match2Dpts = new Point2d[ptsCount];

		vector<int>Inliers[1];  Inliers[0].reserve(ptsCount * 2);
		double ProThresh = 0.99, PercentInlier = 0.25;
		int goodNDplus = 0, iterMax = (int)(log(1.0 - ProThresh) / log(1.0 - pow(PercentInlier, 2)) + 0.5); //log(1-eps) / log(1 - (inlier%)^min_pts_requires)
		int nviewsi = (int)viewIDAll3D.size();
		Inliers[0].clear();
		for (int ii = 0; ii < nviewsi; ii++)
		{
			viewID = viewIDAll3D[ii], frameID = frameIDAll3D[ii];
			match2Dpts[ii] = uvAll3D[ii];

			if (distortionCorrected == 0)
			{
				if (VideoI[viewID].VideoInfo[frameID].LensModel == RADIAL_TANGENTIAL_PRISM)
					LensCorrectionPoint(&match2Dpts[ii], VideoI[viewID].VideoInfo[frameID].K, VideoI[viewID].VideoInfo[frameID].distortion);
				else
					FishEyeCorrectionPoint(&match2Dpts[ii], VideoI[viewID].VideoInfo[frameID].K, VideoI[viewID].VideoInfo[frameID].distortion[0]);
			}

			if (VideoI[viewID].VideoInfo[frameID].ShutterModel == 0)
				for (int kk = 0; kk < 12; kk++)
					Ps[12 * ii + kk] = VideoI[viewID].VideoInfo[frameID].P[kk];
			else
				AssembleP_RS(match2Dpts[ii], VideoI[viewID].VideoInfo[frameID], Ps + 12 * ii);
		}

		double error = NviewTriangulationRANSAC(match2Dpts, Ps, &xyz, passed, Inliers, nviewsi, 1, 2, iterMax, PercentInlier, threshold, A, B, tPs);
		if (passed[0])
		{
			printLOG("3D: %f %f %f Error: %f\n", xyz.x, xyz.y, xyz.z, error);
			ofs << xyz.x << " " << xyz.y << " " << xyz.z << endl;
			if (maxPts == 2)
				TwoPoints.push_back(xyz);
		}
	}

	if (maxPts == 2)
	{
		printf("Enter the real distance: ");
		double realDistance;
		cin >> realDistance;
		ofs << Distance3D(TwoPoints[0], TwoPoints[1]) << " " << realDistance << endl;
	}
	ofs.close();

	if (maxPts == 2)
		return Distance3D(TwoPoints[0], TwoPoints[1]);
	else
		return 0;
}
int TriangulatePointsFromNonCorpusCameras(char *Path, vector<int> SelectedCams, int *timeStamp, int refFid)
{
	char Fname[512];

	VideoData *VideoInfo = new VideoData[(int)SelectedCams.size()];
	for (int ii = 0; ii < (int)SelectedCams.size(); ii++)
		if (ReadVideoDataI(Path, VideoInfo[ii], SelectedCams[ii], -1, -1) == 1)
			continue;

	Point3d xyz;
	vector<Point2d> uvAll[1], puvAll;
	double *A = new double[6 * (int)SelectedCams.size()];
	double *B = new double[2 * (int)SelectedCams.size()];
	double *Ps = new double[12 * (int)SelectedCams.size()];

	namedWindow("Image", CV_WINDOW_NORMAL); setMouseCallback("Image", onMouse);
	createTrackbar("RefFid", "Image", &refFid, 10000, NULL);

	int npts = 0, oRefFid = refFid;
	while (true)
	{
		setTrackbarPos("RefFid", "Image", refFid);

		uvAll[0].clear();
		int cnt = 0;
		for (int ii = 0; ii < (int)SelectedCams.size(); ii++)
		{
			int camID = SelectedCams[ii];
			CameraData *camI = &VideoInfo[ii].VideoInfo[refFid - timeStamp[camID]];
			if (!camI[0].valid)
				continue;

			clicked = 0;
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, SelectedCams[ii], refFid - timeStamp[camID]);
			if (IsFileExist(Fname) == 0)
				sprintf(Fname, "%s/%d/%.4d.png", Path, SelectedCams[ii], refFid - timeStamp[camID]);
			Mat Img = imread(Fname);
			if (Img.empty())
			{
				printLOG("Cannot load %s\n", Fname);
				break;
			}

			CvPoint text_origin = { Img.cols / 30, Img.cols / 30 };
			sprintf(Fname, "Point %d/%d of (C, f): (%d, %d) ", ii + 1, SelectedCams.size(), SelectedCams[ii], refFid - timeStamp[camID]);
			putText(Img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * Img.cols / 640, CV_RGB(255, 0, 0), 3);
			imshow("Image", Img);
			int key = cv::waitKey(0);
			if (key == 10) //enter
				break;
			if (key == 27) //exit
				exit(0);

			if (clicked == 1)
			{
				uvAll[0].push_back(Point2d(MousePosX, MousePosY));
				if (camI[0].LensModel == RADIAL_TANGENTIAL_PRISM)
					LensCorrectionPoint(&uvAll[0].back(), camI[0].K, camI[0].distortion);
				else
					//FishEyeCorrectionPoint(&uvAll[0][ii], camI[0].distortion[0], camI[0].distortion[1], camI[0].distortion[2]);
					FishEyeCorrectionPoint(&uvAll[0].back(), camI[0].K, camI[0].distortion[0]);

				if (camI[0].ShutterModel == 0)
				{
					for (int kk = 0; kk < 12; kk++)
						Ps[12 * cnt + kk] = VideoInfo[ii].VideoInfo[refFid - timeStamp[camID]].P[kk];
				}
				else if (camI[0].ShutterModel == 1)
					AssembleP_RS(uvAll[0].back(), camI[0], Ps + 12 * cnt);
				else
					printLOG("Not supported model for motion prior sync\n");
				cnt++;
			}
		}
		if (cnt == 0)
			continue;
		NviewTriangulation(uvAll, Ps, &xyz, cnt, 1, NULL, A, B);

		puvAll = uvAll[0];
		ProjectandDistort(xyz, puvAll, Ps, NULL, NULL);

		double finalerror = 0.0;
		for (int ii = 0; ii < uvAll[0].size(); ii++)
			finalerror += pow(puvAll[ii].x - uvAll[0][ii].x, 2) + pow(puvAll[ii].y - uvAll[0][ii].y, 2);
		finalerror = sqrt(finalerror / (int)SelectedCams.size());
		printLOG("%d %f %f %f Error: %f\n", npts, xyz.x, xyz.y, xyz.z, finalerror);
		//fprintf(fp, "%d %f %f %f %f\n", npts, xyz.x, xyz.y, xyz.z, finalerror);
		npts++;
	}
	//fclose(fp);

	return 0;
}
int GeometricConstraintSyncDriver(char *Path, int nCams, int npts, int realStartFrame, int startF, int stopTime, int Range, bool GivenF, double *OffsetInfo, bool HasInitOffset)
{
	if (OffsetInfo == NULL)
	{
		OffsetInfo = new double[nCams];
		for (int ii = 0; ii < nCams; ii++)
			OffsetInfo[ii] = 0;
	}
	if (!HasInitOffset)
		for (int ii = 0; ii < nCams; ii++)
			OffsetInfo[ii] = 0;

	printLOG("Geometric sync:\n");
	char Fname[512]; sprintf(Fname, "%s/GeoSync.txt", Path); 	FILE *fp = fopen(Fname, "w+");
	for (int jj = 0; jj < nCams - 1; jj++)
	{
		for (int ii = jj + 1; ii < nCams; ii++)
		{
			int SelectedCams[2] = { jj, ii }, Offset[] = { OffsetInfo[jj], OffsetInfo[ii] };
			FmatSyncBruteForce2DStereo(Path, SelectedCams, realStartFrame, startF, stopTime, npts, Offset, -Range, Range, GivenF);
			printLOG("Between (%d, %d): %d\n", jj, ii, Offset[0] - Offset[1]);
			fprintf(fp, "%d %d %d\n", jj, ii, Offset[0] - Offset[1]);
		}
	}
	fclose(fp);

	PrismMST(Path, "GeoSync", nCams);
	AssignOffsetFromMST(Path, "GeoSync", nCams, OffsetInfo);
	printLOG("Done.\n\n***NOTE: FGeoSync is in time stamp format (f = f_ref - offset) ***\n");

	return 0;
}
int GeometricSyncAllInstancesDriver(char *Path, int nCams, int npts, vector<int> &TrackingInstance, int TrajRange, int startF, int stopF, int increImgFrames, int SearchRange, double TriangThresh, double *TimeStampOffset, bool HasInitOffset)
{
	char Fname[512];

	if (TimeStampOffset == NULL)
	{
		TimeStampOffset = new double[nCams];
		for (int ii = 0; ii < nCams; ii++)
			TimeStampOffset[ii] = 0;
	}
	if (!HasInitOffset)
		for (int ii = 0; ii < nCams; ii++)
			TimeStampOffset[ii] = 0;

	vector<ImgPtEle> *PerCam_UV = new vector<ImgPtEle>[2 * npts];
	for (int camID = 0; camID < 2; camID++)
		for (int pid = 0; pid < npts; pid++)
			PerCam_UV[camID*npts + pid].reserve(2 * TrajRange + 1);

	printLOG("Geometric sync:\n");
	for (int ii = 0; ii < nCams; ii++)
	{
		sprintf(Fname, "%s/Track2D/UltimateID_%.4d.txt", Path, ii);
		FILE *fp = fopen(Fname, "w+"); fclose(fp);
	}

	sprintf(Fname, "%s/GeoSync.txt", Path); FILE *fp = fopen(Fname, "w+");
	for (int jj = 0; jj < nCams - 1; jj++)
	{
		for (int ii = jj + 1; ii < nCams; ii++)
		{
			int SelectedCams[2] = { jj, ii }, Offset[] = { TimeStampOffset[jj], TimeStampOffset[ii] };
			//FmatSyncBruteForce2DStereoAllInstances(Path, SelectedCams, TrackingInstance, TrajRange, startF, stopF, increImgFrames, npts, Offset, -SearchRange, SearchRange, GivenF, PerCam_UV, true);
			//FmatSyncRobustBruteForce2DStereoAllInstances(Path, SelectedCams, TrackingInstance, TrajRange, startF, stopF, increImgFrames, npts, Offset, -SearchRange, SearchRange, PerCam_UV, false);
			TriangulationSyncRobustBruteForce2DStereoAllInstances(Path, SelectedCams, TrackingInstance, TrajRange, startF, stopF, increImgFrames, npts, Offset, -SearchRange, SearchRange, PerCam_UV, TriangThresh, true);
			printLOG("%d %d %d\n", jj, ii, Offset[1] - Offset[0]);
			fprintf(fp, "%d %d %d\n", jj, ii, Offset[1] - Offset[0]);
		}
	}
	fclose(fp);

	PrismMST(Path, "GeoSync", nCams);
	AssignOffsetFromMST(Path, "GeoSync", nCams, TimeStampOffset);

	printLOG("Done.\n\n***NOTE: FGeoSync is in time stamp format (f = f_ref - offset) ***\n");

	delete[]PerCam_UV;

	return 0;
}

//Spatial calib: checkerboard
int AssembleCheckerboardTrajectory(char *Path, int selectedCam, int startF, int stopF, int npts)
{
	char Fname[512];

	float u, v;
	vector<ImgPtEle> *Traj = new vector<ImgPtEle>[npts];

	for (int fid = startF; fid <= stopF; fid++)
	{
		sprintf(Fname, "%s/%d/Corner/CV_%.4d.txt", Path, selectedCam, fid);
		FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		for (int pid = 0; pid < npts; pid++)
		{
			fscanf(fp, "%f %f ", &u, &v);
			ImgPtEle pt; pt.frameID = fid, pt.pt2D.x = u, pt.pt2D.y = v, pt.scale = 1.0;
			Traj[pid].push_back(pt);
		}
		fclose(fp);
	}

	sprintf(Fname, "%s/Track2D", Path); makeDir(Fname);
	sprintf(Fname, "%s/Track2D/CC_%d_0.txt", Path, selectedCam);
	FILE *fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", npts);
	for (int pid = 0; pid < npts; pid++)
	{
		int nf = (int)Traj[pid].size();
		fprintf(fp, "%d %d ", pid, nf);
		for (int fid = 0; fid < nf; fid++)
			fprintf(fp, "%d %.4f %.4f 1.0 ", Traj[pid][fid].frameID, Traj[pid][fid].pt2D.x, Traj[pid][fid].pt2D.y);
		fprintf(fp, "\n");
	}
	fclose(fp);

	return 0;
}
void calcBoardCornerPositions(Size boardSize, float squareSize, vector<Point3f>& corners, int boardType)
{
	corners.clear();

	switch (boardType)
	{
	case 1://CHESSBOARD:
	case 2://CIRCLES_GRID:
		for (int i = 0; i < boardSize.height; ++i)
			for (int j = 0; j < boardSize.width; ++j)
				corners.push_back(Point3f(float(j*squareSize), float(i*squareSize), 0));
		break;

	case 3://ASYMMETRIC_CIRCLES_GRID
		for (int i = 0; i < boardSize.height; i++)
			for (int j = 0; j < boardSize.width; j++)
				corners.push_back(Point3f(float((2 * j + i % 2)*squareSize), float(i*squareSize), 0));
		break;
	default:
		break;
	}
}
double computeReprojectionErrors(const vector<vector<Point3f> >& objectPoints, const vector<vector<Point2f> >& imagePoints, const vector<Mat>& rvecs, const vector<Mat>& tvecs, const Mat& cameraMatrix, const Mat& distCoeffs, vector<float>& perViewErrors)
{
	vector<Point2f> imagePoints2;
	int i, totalPoints = 0;
	double totalErr = 0, err;
	perViewErrors.resize(objectPoints.size());

	for (i = 0; i < (int)objectPoints.size(); ++i)
	{
		projectPoints(Mat(objectPoints[i]), rvecs[i], tvecs[i], cameraMatrix, distCoeffs, imagePoints2);
		err = norm(Mat(imagePoints[i]), Mat(imagePoints2), CV_L2);

		int n = (int)objectPoints[i].size();
		perViewErrors[i] = (float)std::sqrt(err*err / n);
		totalErr += err * err;
		totalPoints += n;
	}

	return std::sqrt(totalErr / totalPoints);
}
int CheckerBoardDetection(char *Path, int viewID, int startF, int stopF, int bw, int bh)
{
	char Fname[1024];

	// Initializations
	int elem_size, found, count;
	CvSize board_size = { bw, bh }, img_size = { 0, 0 };
	CvMemStorage* storage;
	CvSeq* image_points_seq = 0;
	CvPoint2D32f* cornerPts = 0;

	// Allocate memory
	elem_size = board_size.width*board_size.height * sizeof(cornerPts[0]);
	storage = cvCreateMemStorage(MAX(elem_size * 4, 1 << 16));
	cornerPts = (CvPoint2D32f*)cvAlloc(elem_size);
	image_points_seq = cvCreateSeq(0, sizeof(CvSeq), elem_size, storage);

	bool firsttime = true;
	IplImage *view = 0, *viewGray = 0;
	for (int fid = startF; fid < stopF; fid++)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, viewID, fid);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, viewID, fid);
		view = cvLoadImage(Fname, 1);
		if (view == NULL)
			continue;
		if (firsttime)
		{
			viewGray = cvCreateImage(cvGetSize(view), 8, 1), firsttime = false;
			sprintf(Fname, "%s/%d/Corner", Path, viewID), makeDir(Fname);
		}

		img_size = cvGetSize(view);
		found = cvFindChessboardCorners(view, board_size, cornerPts, &count, CV_CALIB_CB_ADAPTIVE_THRESH | CV_CALIB_CB_FAST_CHECK | CV_CALIB_CB_NORMALIZE_IMAGE);

		if (found == 1)
		{
			//not so good result for low res images
			cvCvtColor(view, viewGray, CV_BGR2GRAY);
			cvFindCornerSubPix(viewGray, cornerPts, count, cvSize(11, 11), cvSize(-1, -1), cvTermCriteria(CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 100, 0.001));

			cvDrawChessboardCorners(view, board_size, cornerPts, count, found);
			//cvShowImage("Detected corners", view);
			//cvWaitKey(1);
			sprintf(Fname, "%s/%d/Corner/CV_%.4d.jpg", Path, viewID, fid); cvSaveImage(Fname, view);

			sprintf(Fname, "%s/%d/Corner/CV_%.4d.txt", Path, viewID, fid); FILE *fp = fopen(Fname, "w+");
			for (int ii = 0; ii < count; ii++)
				fprintf(fp, "%.3f %.3f\n", cornerPts[ii].x, cornerPts[ii].y);
			fclose(fp);
		}

		cvReleaseImage(&view);
	}

	return 0;
}
int SingleCameraCalibration(char *Path, int camID, int startF, int stopF, int bw, int bh, bool hasPoint, int step, float squareSize, int calibrationPattern, int width, int height, bool showUndistorsed)
{
	int calibFlag = 0;
	calibFlag |= CV_CALIB_FIX_K4 | CV_CALIB_FIX_K5; //CV_CALIB_FIX_PRINCIPAL_POINT

	char Fname[512];
	const Scalar RED(0, 0, 255);
	Size imageSize, boardSize(bw, bh);

	vector<int>ValidFrame;
	vector<Point2f> pointBuf;
	vector<vector<Point2f> > imagePoints;
	vector<vector<Point3f> > objectPoints(1);

	vector<Mat> rvecs, tvecs;
	Mat cameraMatrix = Mat::eye(3, 3, CV_64F), distCoeffs = Mat::zeros(8, 1, CV_64F);

	//Get 2d points

	if (!hasPoint)
	{
		sprintf(Fname, "%s/%d/Corner", Path, camID); makeDir(Fname);
		Mat view, viewGray;
		for (int ii = startF; ii <= stopF; ii += step)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, camID, ii);
			if (IsFileExist(Fname) == 0)
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, camID, ii);
			view = imread(Fname);
			if (view.empty())
				continue;

			imageSize = view.size();  // Format input image.
			pointBuf.clear();

			bool found;
			switch (calibrationPattern) // Find feature points on the input format
			{
			case 1: //Checkerboard
				found = findChessboardCorners(view, boardSize, pointBuf, CV_CALIB_CB_ADAPTIVE_THRESH | CV_CALIB_CB_FAST_CHECK | CV_CALIB_CB_NORMALIZE_IMAGE);
				break;
			case 2: //CIRCLES_GRID :
				found = findCirclesGrid(view, boardSize, pointBuf);
				break;
			case 3://ASYMMETRIC_CIRCLES_GRID:
				found = findCirclesGrid(view, boardSize, pointBuf, CALIB_CB_ASYMMETRIC_GRID);
				break;
			}

			if (found)
			{
				if (calibrationPattern == 1) // improve the found corners' coordinate accuracy for chessboard
				{
					cvtColor(view, viewGray, COLOR_BGR2GRAY);
					cornerSubPix(viewGray, pointBuf, Size(11, 11), Size(-1, -1), TermCriteria(CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 30, 0.1));
				}

				imagePoints.push_back(pointBuf);
				drawChessboardCorners(view, boardSize, Mat(pointBuf), found);

				sprintf(Fname, "%s/%d/Corner/CV_%.4d.txt", Path, camID, ii); FILE *fp = fopen(Fname, "w+");
				for (int jj = 0; jj < bw*bh; jj++)
					fprintf(fp, "%f %f ", pointBuf[jj].x, pointBuf[jj].y);
				fclose(fp);
			}

			int baseLine = 0;
			sprintf(Fname, "Frame: %d/%d", ii / step + 1, (stopF - startF) / step);
			Size textSize = getTextSize(Fname, 1, 1, 1, &baseLine);
			Point textOrigin(view.cols - 2 * textSize.width - 10, view.rows - 2 * baseLine - 10);
			putText(view, Fname, textOrigin, 1, 1, RED);

			//imshow("Image View", view);
			//if (waitKey(10) == 27)
			//	break;

			ValidFrame.push_back(ii);
			pointBuf.clear();
		}
	}
	else
	{
		float u, v;
		for (int ii = startF; ii <= stopF; ii += step)
		{
			sprintf(Fname, "%s/%d/Corner/CV_%.4d.txt", Path, camID, ii); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			for (int jj = 0; jj < bw*bh; jj++)
			{
				fscanf(fp, "%f %f ", &u, &v);
				pointBuf.push_back(Point2f(u, v));
			}
			fclose(fp);

			imagePoints.push_back(pointBuf);

			ValidFrame.push_back(ii);
			pointBuf.clear();
		}

		imageSize.width = width, imageSize.height = height;
	}

	//Calibration routine:
	switch (calibrationPattern)//Create 3D pattern
	{
	case 1://CHESSBOARD:
	case 2://CIRCLES_GRID:
		if (0)//Matlab detection
			for (int i = 0; i < boardSize.width; ++i)
				for (int j = 0; j < boardSize.height; ++j)
					objectPoints[0].push_back(Point3f(float(i*squareSize), float(j*squareSize), 0));
		else//OpenCV detection
			for (int i = 0; i < boardSize.height; ++i)
				for (int j = 0; j < boardSize.width; ++j)
					objectPoints[0].push_back(Point3f(float(j*squareSize), float(i*squareSize), 0));
		break;

	case 3://ASYMMETRIC_CIRCLES_GRID
		for (int i = 0; i < boardSize.height; i++)
			for (int j = 0; j < boardSize.width; j++)
				objectPoints[0].push_back(Point3f(float((2 * j + i % 2)*squareSize), float(i*squareSize), 0));
		break;
	default:
		break;
	}

	objectPoints.resize(imagePoints.size(), objectPoints[0]); 	//Make sure points size match

	TermCriteria criteria = TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 100, DBL_EPSILON);
	double rms = calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, calibFlag, criteria);

	vector<float> reprojErrs; //all reprojection error
	double totalAvgErr = computeReprojectionErrors(objectPoints, imagePoints, rvecs, tvecs, cameraMatrix, distCoeffs, reprojErrs);

#pragma omp critical
	{
		if (!(checkRange(cameraMatrix) && checkRange(distCoeffs)))
		{
			printLOG("Problem with camera %d calibration. Abort!", camID);
			abort();
		}
		printLOG("Cam %.4d.  Avg reprojection error: %.3f\n", camID, totalAvgErr);
		cout << cameraMatrix << "\t" << distCoeffs << endl;

		//Save Data
		sprintf(Fname, "%s/Mono_Intrinsic_%.4d.txt", Path, camID);	FILE *fp = fopen(Fname, "w+");
		for (int ii = 0; ii < (int)ValidFrame.size(); ii++)
			fprintf(fp, "%d 0 0 %d %d %.6f %.6f 0.0 %.6f %.6f  %.6f %.6f  %.6f %.6f %.6f 0.0 0.0\n", ValidFrame[ii], imageSize.width, imageSize.height, cameraMatrix.at<double>(0, 0), cameraMatrix.at<double>(1, 1), cameraMatrix.at<double>(0, 2), cameraMatrix.at<double>(1, 2),
				distCoeffs.at<double>(0), distCoeffs.at<double>(1), distCoeffs.at<double>(4), distCoeffs.at<double>(3), distCoeffs.at<double>(2)); //OpenCV tangential distortion is a bit different from mine.
		fclose(fp);

		sprintf(Fname, "%s/Mono_CamPose_%.4d.txt", Path, camID); fp = fopen(Fname, "w+");
		for (int ii = 0; ii < (int)ValidFrame.size(); ii++)
			fprintf(fp, "%d %.16f %.16f %.16f %.16f %.16f %.16f\n",
				ValidFrame[ii], rvecs[ii].at<double>(0), rvecs[ii].at<double>(1), rvecs[ii].at<double>(2), tvecs[ii].at<double>(0), tvecs[ii].at<double>(1), tvecs[ii].at<double>(2));
		fclose(fp);

		//Additional data for rolling shutter BA: vector<Point3d>  &Vxyz, vector < vector<int>> viewIdAll3D, vector<vector<Point2d>> uvAll3D,
	}

	//Visualization routine
	if (!hasPoint && showUndistorsed)
	{
		Mat view, rview, map1, map2;
		initUndistortRectifyMap(cameraMatrix, distCoeffs, Mat(), getOptimalNewCameraMatrix(cameraMatrix, distCoeffs, imageSize, 1, imageSize, 0), imageSize, CV_16SC2, map1, map2);

		for (int ii = startF; ii <= stopF; ii += step)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, camID, ii);
			if (IsFileExist(Fname) == 0)
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, camID, ii);
			view = imread(Fname);
			if (view.empty())
				continue;

			remap(view, rview, map1, map2, INTER_LINEAR);
			imshow("Image View", rview);
			if (waitKey(500) == 27)
				break;
		}
	}

	return 0;
}

int LocalizeCameraToCorpusDriver(char *Path, int startF, int stopF, int increF, int module, int selectedCam, int distortionCorrected, int nInlierThresh, int GetIntrinsicFromCorpus)
{
	//Required calibrated cameras if Fisheye or lens with large distortion is used.
	char Fname[512];
	const int maxNN = 100;
	const float nndrRatio = 0.7f, projThresh = 8.0f;

	sprintf(Fname, "%s/%d/PnP", Path, selectedCam); makeDir(Fname);

	vector<int> queryFrames;
	sprintf(Fname, "%s/%d/querry.txt", Path, selectedCam); std::ifstream file(Fname);
	if (file.is_open())
	{
		std::string line;
		while (std::getline(file, line))
		{
			StringTrim(&line);
			if (line.empty())
				continue;
			std::size_t found = line.find(".");
			std::string NameOnly = line.substr(0, found);
			if (atoi(NameOnly.c_str()) >= startF && atoi(NameOnly.c_str()) <= stopF)
				queryFrames.push_back(atoi(NameOnly.c_str()));
		}
		file.close();
	}
	else
	{
		for (int frameID = startF; frameID <= stopF; frameID += increF)
			queryFrames.push_back(frameID);
	}

	int fid, nV2M, toMatch;
	vector<int> CorpusViewToMatch;
	vector<int> *CorpusViewToMatchI = 0;
	if (module == 0)
	{
		CorpusViewToMatch.reserve(50);
		CorpusViewToMatchI = new vector<int>[stopF - startF + 1];

		sprintf(Fname, "%s/%d/ToMatch2.txt", Path, selectedCam);
		FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%d %d ", &fid, &nV2M) != EOF)
		{
			if (fid >= startF && fid <= stopF)
				CorpusViewToMatchI[fid - startF].reserve(nV2M);
			for (int vid = 0; vid < nV2M; vid++)
			{
				fscanf(fp, "%d ", &toMatch);
				if (fid >= startF && fid <= stopF)
				{
					if (CorpusViewToMatchI[fid - startF].size() > maxNN)
						continue;
					CorpusViewToMatchI[fid - startF].push_back(toMatch);
					CorpusViewToMatch.push_back(toMatch);
				}
			}
			std::sort(CorpusViewToMatch.begin(), CorpusViewToMatch.end());
			CorpusViewToMatch.erase(std::unique(CorpusViewToMatch.begin(), CorpusViewToMatch.end()), CorpusViewToMatch.end());
		}
		fclose(fp);
		std::sort(CorpusViewToMatch.begin(), CorpusViewToMatch.end());
		CorpusViewToMatch.erase(std::unique(CorpusViewToMatch.begin(), CorpusViewToMatch.end()), CorpusViewToMatch.end());
	}

	Corpus CorpusInfo;
	if (module == 0)
	{
		sprintf(Fname, "%s/Corpus", Path);
		ReadCorpusInfo(Fname, CorpusInfo, false, false, CorpusViewToMatch);
	}
	else
	{
		//adapter to legacy code using PInliers.
		bool readCorpus = false;
		for (size_t ii = 0; ii < queryFrames.size() && !readCorpus; ii++)
		{
			int frameID = queryFrames[ii];
			sprintf(Fname, "%s/%d/PnP/_PInliers_%.4d.txt", Path, selectedCam, frameID);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/Corpus", Path);
				ReadCorpusInfo(Fname, CorpusInfo, false, true);
				readCorpus = true;
			}
		}
		if (!readCorpus)
		{
			char Fname[512];
			sprintf(Fname, "%s/Corpus/nHCorpus_3D.txt", Path);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
				if (IsFileExist(Fname) == 0)
					sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
			}
			FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
			{
				printLOG("Cannot load %s\n", Fname);
				return 1;
			}
			fscanf(fp, "%d %d", &CorpusInfo.nCameras, &CorpusInfo.n3dPoints);
			fclose(fp);
		}
	}

	///****NOTE: Required calibrated cameras if Fisheye or lens with large distortion is used***///
	int fixIntrinsic = 1, fixDistortion = 1;
	CameraData CamInfoI;
	if (!ReadIntrinsicResultI(Path, selectedCam, CamInfoI))
	{
		if (distortionCorrected == 1)///perfectly pre-calibrated
		{
			printLOG("Using precalibrated camera but its info cannot be found\n");
			exit(1);
		}

		sprintf(Fname, "%s/%d/imgInfo.txt", Path, selectedCam); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		fscanf(fp, "%d %d %d %d", &CamInfoI.width, &CamInfoI.height, &CamInfoI.LensModel, &CamInfoI.ShutterModel); fclose(fp);
		CamInfoI.ShutterModel = 0; //optimizing RS without intrinsic does not give much better results

		printLOG("UNCALIBRATED CASE: The output 2D-3D correspondences will NOT be corrected for lens distortion\n");
		fixIntrinsic = 0, fixDistortion = 0;

		CamInfoI.notCalibrated = true, CamInfoI.threshold = projThresh * 2.0, CamInfoI.nInlierThresh = nInlierThresh;
		for (int jj = 0; jj < 7; jj++)
			CamInfoI.distortion[jj] = 0.0;
	}
	else
	{
		printLOG("CALIBRATED CASE: The output 2D-3D correspondences will be corrected for lens distortion\n");
		CamInfoI.notCalibrated = false, CamInfoI.threshold = projThresh, CamInfoI.nInlierThresh = nInlierThresh;
	}
	if (CamInfoI.LensModel == FISHEYE && distortionCorrected == 0 && !CamInfoI.notCalibrated)
	{
		printLOG("Using FOV model without pre-calib info is not supported!");
		return 1;
	}

	double start = omp_get_wtime();
	if (module == 0)
	{
		///NOTE: 2d points in Corpus are corrected. 2D points in the image-to-be-localized are not distorted if camera is not calibrated///
		omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic, 2)
		for (int ii = 0; ii < queryFrames.size(); ii++)
		{
			int frameID = queryFrames[ii];
			printLOG("\n%d: ", frameID);
			MatchCameraToCorpus(Path, CorpusInfo, CamInfoI, selectedCam, frameID, distortionCorrected, CorpusViewToMatchI[frameID - startF], nndrRatio, nInlierThresh); //use Fmat instead of PnP to avoid dealing with uncalib images
		}

		if (CamInfoI.notCalibrated)
			printLOG("UNCALIBRATED CASE. The output 2D-3D correspondences are NOT corrected for lens distortion\n");
		else
			printLOG("CALIBRATED CASE: The output 2D-3D correspondences are corrected for lens distortion\n");
	}
	else
	{
		CameraData *SelectedCameraInfo = new CameraData[stopF - startF + 1];
		for (size_t ii = 0; ii < queryFrames.size(); ii++)
		{
			int frameID = queryFrames[ii];
			CopyCamereInfo(CamInfoI, SelectedCameraInfo[frameID - startF]);
			SelectedCameraInfo[frameID - startF].valid = 0;

			int ninliers = LocalizeCameraToCorpus(Path, CorpusInfo, SelectedCameraInfo[frameID - startF], selectedCam, fixIntrinsic, fixDistortion, CamInfoI.notCalibrated ? 0 : distortionCorrected, frameID); //3D_2D files contain corrected data
			if (ninliers > CamInfoI.nInlierThresh)
				SelectedCameraInfo[frameID - startF].valid = 1;
			printLOG("\n");
		}

		sprintf(Fname, "%s/Intrinsic_%.4d.txt", Path, selectedCam); FILE*fp1 = fopen(Fname, "w");
		sprintf(Fname, "%s/CamPose_%.4d.txt", Path, selectedCam); FILE*fp2 = fopen(Fname, "w");
		for (size_t ii = 0; ii < queryFrames.size(); ii++)
		{
			int frameID = queryFrames[ii];
			if (SelectedCameraInfo[frameID - startF].valid == 1)
			{
				fprintf(fp1, "%d %d %d %d %d ", frameID, SelectedCameraInfo[frameID - startF].LensModel, SelectedCameraInfo[frameID - startF].ShutterModel, SelectedCameraInfo[frameID - startF].width, SelectedCameraInfo[frameID - startF].height);
				for (int jj = 0; jj < 5; jj++)
					fprintf(fp1, "%f ", SelectedCameraInfo[frameID - startF].intrinsic[jj]);
				if (SelectedCameraInfo[frameID - startF].LensModel == RADIAL_TANGENTIAL_PRISM)
					for (int jj = 0; jj < 7; jj++)
						fprintf(fp1, "%f ", SelectedCameraInfo[frameID - startF].distortion[jj]);
				else
					for (int jj = 0; jj < 3; jj++)
						fprintf(fp1, "%f ", SelectedCameraInfo[frameID - startF].distortion[jj]);
				fprintf(fp1, "\n");

				fprintf(fp2, "%d ", frameID);
				for (int jj = 0; jj < 6; jj++)
					fprintf(fp2, "%.16f ", SelectedCameraInfo[frameID - startF].rt[jj]);
				if (SelectedCameraInfo[frameID - startF].ShutterModel == 1)
					for (int jj = 0; jj < 6; jj++)
						fprintf(fp2, "%.16f ", SelectedCameraInfo[frameID - startF].wt[jj]);
				fprintf(fp2, "\n");
			}
		}
		fclose(fp1), fclose(fp2);

		printLOG("Finished estimating poses for camera %d\n", selectedCam);
		delete[]SelectedCameraInfo;
	}

	printLOG("Total time %d: %.3fs\n", selectedCam, omp_get_wtime() - start);

	delete[]CorpusViewToMatchI;

	return 0;
}
int LocalizeCameraToCorpus1StepDriver(char *Path, int startF, int stopF, int increF, int selectedCam, int distortionCorrected, int GetIntrinsicFromCorpus, int LensType)
{
	//Required calibrated cameras if Fisheye or lens with large distortion is used.
	char Fname[512];
	const int ninlierThresh = 10, maxNN = 40;
	const float nndrRatio = 0.7f, projThresh = 8.0f;

	vector<int> queryFrames;
	sprintf(Fname, "%s/%d/querry.txt", Path, selectedCam); std::ifstream file(Fname);
	if (file.is_open())
	{
		std::string line;
		while (std::getline(file, line))
		{
			StringTrim(&line);
			if (line.empty())
				continue;
			std::size_t found = line.find(".");
			std::string NameOnly = line.substr(0, found);
			queryFrames.push_back(atoi(NameOnly.c_str()));
		}
	}
	else
	{
		for (int frameID = startF; frameID <= stopF; frameID += increF)
			queryFrames.push_back(frameID);
	}

	int fid, nV2M, toMatch;
	vector<int> CorpusViewToMatch;
	vector<int> *CorpusViewToMatchI = 0;
	CorpusViewToMatch.reserve(50);
	CorpusViewToMatchI = new vector<int>[stopF - startF + 1];

	sprintf(Fname, "%s/%d/ToMatch2.txt", Path, selectedCam);
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	while (fscanf(fp, "%d %d ", &fid, &nV2M) != EOF)
	{
		if (fid >= startF && fid <= stopF)
			CorpusViewToMatchI[fid - startF].reserve(nV2M);
		for (int vid = 0; vid < nV2M; vid++)
		{
			fscanf(fp, "%d ", &toMatch);
			if (fid >= startF && fid <= stopF)
			{
				if (CorpusViewToMatchI[fid - startF].size() > maxNN)
					continue;
				CorpusViewToMatchI[fid - startF].push_back(toMatch);
				CorpusViewToMatch.push_back(toMatch);
			}
		}
		std::sort(CorpusViewToMatch.begin(), CorpusViewToMatch.end());
		CorpusViewToMatch.erase(std::unique(CorpusViewToMatch.begin(), CorpusViewToMatch.end()), CorpusViewToMatch.end());
	}
	fclose(fp);
	std::sort(CorpusViewToMatch.begin(), CorpusViewToMatch.end());
	CorpusViewToMatch.erase(std::unique(CorpusViewToMatch.begin(), CorpusViewToMatch.end()), CorpusViewToMatch.end());

	Corpus CorpusInfo;
	sprintf(Fname, "%s/Corpus", Path);
	ReadCorpusInfo(Fname, CorpusInfo, false, false, CorpusViewToMatch);


	///NOTE: Required calibrated cameras if Fisheye or lens with large distortion is used///
	int fixIntrinsic = 1, fixDistortion = 1;
	CameraData CamInfoI;
	if (!ReadIntrinsicResultI(Path, selectedCam, CamInfoI))
	{
		if (distortionCorrected == 2)///perfectly pre-calibrated
		{
			printLOG("Using precalibrated camera but its info cannot be found\n");
			exit(1);
		}

		if (GetIntrinsicFromCorpus > 0) //only make sense when corpus is built from multiple still images, not videos
		{
			printLOG("Calibrated information extracted from Corpus cameras. The output 2D-3D correspondences will be corrected for lens distortion\n");
			for (int jj = 0; jj < 5; jj++)
				CamInfoI.intrinsic[jj] = CorpusInfo.camera[GetIntrinsicFromCorpus].intrinsic[jj];
			GetKFromIntrinsic(CamInfoI);
			CamInfoI.notCalibrated = false;

			CamInfoI.LensModel = LensType, CamInfoI.threshold = projThresh, CamInfoI.nInlierThresh = ninlierThresh;
			for (int jj = 0; jj < 7; jj++)
				CamInfoI.distortion[jj] = CorpusInfo.camera[GetIntrinsicFromCorpus].distortion[jj];
			CamInfoI.width = CorpusInfo.camera[GetIntrinsicFromCorpus].width, CamInfoI.height = CorpusInfo.camera[GetIntrinsicFromCorpus].height;
		}
		else
		{
			sprintf(Fname, "%s/%d/imgInfo.txt", Path, selectedCam); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
			{
				printLOG("Cannot load %s\n", Fname);
				return 1;
			}
			fscanf(fp, "%d %d %d %d", &CamInfoI.width, &CamInfoI.height, &CamInfoI.LensModel, &CamInfoI.ShutterModel); fclose(fp);
			CamInfoI.ShutterModel = 0; //well, optimizing RS without intrinsic does not give much better results

			printLOG("UNCALIBRATED CASE: The output 2D-3D correspondences will NOT be corrected for lens distortion\n");
			fixIntrinsic = 0, fixDistortion = 0;

			CamInfoI.notCalibrated = true, CamInfoI.threshold = projThresh * 2.0, CamInfoI.nInlierThresh = ninlierThresh;
			for (int jj = 0; jj < 7; jj++)
				CamInfoI.distortion[jj] = 0.0;
		}
	}
	else
	{
		printLOG("CALIBRATED CASE: The output 2D-3D correspondences will be corrected for lens distortion\n");
		CamInfoI.notCalibrated = false, CamInfoI.threshold = projThresh, CamInfoI.nInlierThresh = ninlierThresh;
	}

	double start = omp_get_wtime();
	CameraData *SelectedCameraInfo = new CameraData[stopF - startF + 1];

	///NOTE: 2d points in Corpus are corrected. 2D points in the image-to-be-localized are not distorted if camera is not calibrated///
	omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic,8)
	for (int ii = 0; ii < queryFrames.size(); ii++)
	{
		int frameID = queryFrames[ii];
		printLOG("\n%d: ", frameID);
		//if CamInfoI.notCalibrated == true --> points will not be corrected
		MatchCameraToCorpus(Path, CorpusInfo, CamInfoI, selectedCam, frameID, distortionCorrected, CorpusViewToMatchI[frameID - startF], nndrRatio, ninlierThresh); //use Fmat for fine corres--> can search for focal length later in p4pf

		CopyCamereInfo(CamInfoI, SelectedCameraInfo[frameID - startF]);

		int ninliers = LocalizeCameraToCorpus(Path, CorpusInfo, SelectedCameraInfo[frameID - startF], selectedCam, fixIntrinsic, fixDistortion, CamInfoI.notCalibrated ? 0 : distortionCorrected, frameID); //3D_2D files contain corrected data, ether from perfect or rough intrinsics
		if (ninliers > CamInfoI.nInlierThresh)
		{
			sprintf(Fname, "%s/Intrinsic_%.4d.txt", Path, selectedCam); FILE*fp = fopen(Fname, "a+");
			fprintf(fp, "%d %d %d %d %d ", frameID, SelectedCameraInfo[frameID - startF].LensModel, SelectedCameraInfo[frameID - startF].ShutterModel, SelectedCameraInfo[frameID - startF].width, SelectedCameraInfo[frameID - startF].height);
			for (int jj = 0; jj < 5; jj++)
				fprintf(fp, "%f ", SelectedCameraInfo[frameID - startF].intrinsic[jj]);
			if (SelectedCameraInfo[frameID - startF].LensModel == RADIAL_TANGENTIAL_PRISM)
				for (int jj = 0; jj < 7; jj++)
					fprintf(fp, "%f ", SelectedCameraInfo[frameID - startF].distortion[jj]);
			else
				for (int jj = 0; jj < 3; jj++)
					fprintf(fp, "%f ", SelectedCameraInfo[frameID - startF].distortion[jj]);
			fprintf(fp, "\n");
			fclose(fp);

			sprintf(Fname, "%s/CamPose_%.4d.txt", Path, selectedCam); fp = fopen(Fname, "a+");
			fprintf(fp, "%d ", frameID);
			for (int jj = 0; jj < 6; jj++)
				fprintf(fp, "%.16f ", SelectedCameraInfo[frameID - startF].rt[jj]);
			if (SelectedCameraInfo[frameID - startF].ShutterModel == 1)
				for (int jj = 0; jj < 6; jj++)
					fprintf(fp, "%.16f ", SelectedCameraInfo[frameID - startF].wt[jj]);
			fprintf(fp, "\n");
			fclose(fp);
		}
		printLOG("\n");
	}

	if (CamInfoI.notCalibrated)
		printLOG("UNCALIBRATED CASE. The output 2D-3D correspondences are NOT corrected for lens distortion\n");
	else
		printLOG("\nCALIBRATED CASE: The output 2D-3D correspondences are corrected for lens distortion\n");
	printLOG("Finished estimating poses for camera %d. Total time %d: %.3fs\n", selectedCam, omp_get_wtime() - start);

	delete[]SelectedCameraInfo, delete[]CorpusViewToMatchI;

	return 0;
}
int ForceLocalizeCameraToCorpusDriver(char *Path, int startF, int stopF, int increF, int selectedCam, int distortionCorrected, int nInlierThresh, int fromKeyFrameTracking)
{
	//Required calibrated cameras if Fisheye or lens with large distortion is used.
	char Fname[512];
	int ninliers;
	float projThresh = 100.0;

	VideoData VideoI;
	if (ReadVideoDataI(Path, VideoI, selectedCam, startF, stopF) == 1)
		return 1;

	CameraData CamInfoI;
	if (ReadIntrinsicResultI(Path, selectedCam, CamInfoI))
		CamInfoI.notCalibrated = false, CamInfoI.threshold = projThresh, CamInfoI.nInlierThresh = nInlierThresh;

	int fixIntrinsic = 0, fixDistortion = 0;
	if (distortionCorrected == 1)
		fixIntrinsic = 1, fixDistortion = 1;

	double start = omp_get_wtime();
	int *index = new int[stopF - startF + 1];
	float*distToAvailFrames = new float[stopF - startF + 1];
	for (int frameID = startF; frameID <= stopF; frameID += increF)
	{
		bool foundInitGuess = false;
		int count = 0;
		for (int fid = startF; fid <= stopF; fid++)
		{
			if (VideoI.VideoInfo[fid].valid)
			{
				index[count] = fid;
				distToAvailFrames[count] = frameID > fid ? 1.f*frameID - fid + .1 : //favor next frame more
					1.f*fid - frameID;
				count++;
			}
		}
		if (count > 0)
		{
			foundInitGuess = true;
			Quick_Sort_Float(distToAvailFrames, index, 0, count - 1);
			int nearestFid = index[0];
			CopyCamereInfo(VideoI.VideoInfo[nearestFid], VideoI.VideoInfo[frameID]);
		}

		VideoI.VideoInfo[frameID].nInlierThresh = nInlierThresh, VideoI.VideoInfo[frameID].threshold = projThresh;
		if (foundInitGuess)
			ninliers = ForceLocalizeCameraToCorpus(Path, VideoI.VideoInfo[frameID], selectedCam, fixIntrinsic, fixDistortion, distortionCorrected, frameID, fromKeyFrameTracking, VideoI.VideoInfo[frameID].rt); //optimize pose directly
		else
		{
			if (CamInfoI.notCalibrated)
				continue;
			CopyCamereInfo(CamInfoI, VideoI.VideoInfo[frameID], false);
			printLOG("Frame: %d\n", frameID);
			ninliers = ForceLocalizeCameraToCorpus(Path, VideoI.VideoInfo[frameID], selectedCam, fixIntrinsic, fixDistortion, distortionCorrected, frameID, fromKeyFrameTracking); //need to do ransac for pose first
		}
		if (ninliers > nInlierThresh)
			VideoI.VideoInfo[frameID].valid = true;
		else
		{
			VideoI.VideoInfo[frameID].valid = false;
			for (int jj = 0; jj < 5; jj++)
				VideoI.VideoInfo[frameID].intrinsic[jj] = 0;
			for (int jj = 0; jj < 7; jj++)
				VideoI.VideoInfo[frameID].intrinsic[jj] = 0;
			for (int jj = 0; jj < 6; jj++)
				VideoI.VideoInfo[frameID].rt[jj] = 0, VideoI.VideoInfo[frameID].wt[jj] = 0;
		}

		if (frameID % 5000 == 0) //cache result
		{
			sprintf(Fname, "%s/Intrinsic_%.4d.txt", Path, selectedCam); FILE*fp = fopen(Fname, "w");
			for (int frameID = startF; frameID <= stopF; frameID += increF)
			{
				if (!VideoI.VideoInfo[frameID].valid)
					continue;
				fprintf(fp, "%d %d %d %d %d ", frameID, VideoI.VideoInfo[frameID].LensModel, VideoI.VideoInfo[frameID].ShutterModel, VideoI.VideoInfo[frameID].width, VideoI.VideoInfo[frameID].height);
				for (int ii = 0; ii < 5; ii++)
					fprintf(fp, "%f ", VideoI.VideoInfo[frameID].intrinsic[ii]);
				if (VideoI.VideoInfo[frameID].LensModel == RADIAL_TANGENTIAL_PRISM)
					for (int ii = 0; ii < 7; ii++)
						fprintf(fp, "%f ", VideoI.VideoInfo[frameID].distortion[ii]);
				else
					for (int ii = 0; ii < 3; ii++)
						fprintf(fp, "%f ", VideoI.VideoInfo[frameID].distortion[ii]);
				fprintf(fp, "\n");
			}
			fclose(fp);

			sprintf(Fname, "%s/CamPose_%.4d.txt", Path, selectedCam); fp = fopen(Fname, "w");
			for (int frameID = startF; frameID <= stopF; frameID += increF)
			{
				if (!VideoI.VideoInfo[frameID].valid)
					continue;
				fprintf(fp, "%d ", frameID);
				for (int jj = 0; jj < 6; jj++)
					fprintf(fp, "%.16f ", VideoI.VideoInfo[frameID].rt[jj]);
				if (VideoI.VideoInfo[frameID].ShutterModel == ROLLING_SHUTTER)
					for (int jj = 0; jj < 6; jj++)
						fprintf(fp, "%.16f ", VideoI.VideoInfo[frameID].wt[jj]);
				fprintf(fp, "\n");
			}
			fclose(fp);
		}
	}
	delete[]index, delete[]distToAvailFrames;

	sprintf(Fname, "%s/Intrinsic_%.4d.txt", Path, selectedCam); FILE*fp = fopen(Fname, "w");
	for (int frameID = startF; frameID <= stopF; frameID += increF)
	{
		if (!VideoI.VideoInfo[frameID].valid)
			continue;
		fprintf(fp, "%d %d %d %d %d ", frameID, VideoI.VideoInfo[frameID].LensModel, VideoI.VideoInfo[frameID].ShutterModel, VideoI.VideoInfo[frameID].width, VideoI.VideoInfo[frameID].height);
		for (int ii = 0; ii < 5; ii++)
			fprintf(fp, "%f ", VideoI.VideoInfo[frameID].intrinsic[ii]);
		if (VideoI.VideoInfo[frameID].LensModel == RADIAL_TANGENTIAL_PRISM)
			for (int ii = 0; ii < 7; ii++)
				fprintf(fp, "%f ", VideoI.VideoInfo[frameID].distortion[ii]);
		else
			for (int ii = 0; ii < 3; ii++)
				fprintf(fp, "%f ", VideoI.VideoInfo[frameID].distortion[ii]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/CamPose_%.4d.txt", Path, selectedCam); fp = fopen(Fname, "w");
	for (int frameID = startF; frameID <= stopF; frameID += increF)
	{
		if (!VideoI.VideoInfo[frameID].valid)
			continue;
		fprintf(fp, "%d ", frameID);
		for (int jj = 0; jj < 6; jj++)
			fprintf(fp, "%.16f ", VideoI.VideoInfo[frameID].rt[jj]);
		if (VideoI.VideoInfo[frameID].ShutterModel == ROLLING_SHUTTER)
			for (int jj = 0; jj < 6; jj++)
				fprintf(fp, "%.16f ", VideoI.VideoInfo[frameID].wt[jj]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	printLOG("Finished estimating poses for camera %d in %.3fs\n", selectedCam, omp_get_wtime() - start);

	return 0;
}

int GenericBundleAdjustmentDriver(char *Path, int nViews, int distortionCorrected, vector< int> sharedIntrinsicCamID, int nViewsPlus, int LossType)
{
	printLOG("Reading Corpus and camera info\n");

	Corpus CorpusInfo;
	char Fname[512]; sprintf(Fname, "%s/Corpus", Path);
	ReadCorpusInfo(Fname, CorpusInfo, false, true);

	for (int ii = 0; ii < nViews; ii++)
	{
		CorpusInfo.camera[ii].threshold = 5.0;
		sharedIntrinsicCamID.push_back(0);
	}

	//Get back the distorted 2d points
	for (int jj = 0; jj < CorpusInfo.n3dPoints; jj++)
	{
		for (int ii = 0; ii < (int)CorpusInfo.uvAll3D[jj].size(); ii++)
		{
			int viewID = CorpusInfo.viewIdAll3D[jj][ii];
			LensDistortionPoint(&CorpusInfo.uvAll3D[jj][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
		}
	}

	/*//Simulate 2d points
	double start = omp_get_wtime();

	vector<vector<int>> IdToDel;
	int n3D = (int)CorpusInfo.xyz.size();
	for (int kk = 0; kk < n3D; kk++)
	{
	vector<int> toDel;
	IdToDel.push_back(toDel);
	}

	int numThreads = omp_get_max_threads();
	omp_set_num_threads(numThreads);

	//#pragma omp parallel for schedule(dynamic,1)
	for (int kk = 0; kk < n3D; kk++)
	{
	vector<int> toDel;
	for (int ll = 0; ll < (int)CorpusInfo.uvAll3D[kk].size(); ll++)
	{
	int viewID = CorpusInfo.viewIdAll3D[kk][ll];
	Point2d uv = CorpusInfo.uvAll3D[kk][ll];
	int nsolution = CayleyDistortionProjection(CorpusInfo.camera[viewID].intrinsic, CorpusInfo.camera[viewID].distortion, CorpusInfo.camera[viewID].rt, CorpusInfo.camera[viewID].wt, uv, CorpusInfo.xyz[kk], CorpusInfo.camera[viewID].width, CorpusInfo.camera[viewID].height);
	if (nsolution != 1)
	{
	#pragma omp critical
	printLOG("Problem at 3D point %d, view %d \n", kk, ll);
	//toDel.push_back(ll);
	}
	else
	CorpusInfo.uvAll3D[kk][ll] = uv;
	}
	IdToDel[kk] = toDel;

	#pragma omp critical
	if (kk % 1000 == 0 && omp_get_thread_num() == 0)
	printLOG("@\r# %.2f%% (%.2fs) Simulating rolling shutter 2d points..", 100.0*kk*numThreads / n3D, omp_get_wtime() - start);
	}
	printLOG("@\r# %.2f%% (%.2fs) \n", 100.0, omp_get_wtime() - start);

	/*for (int jj = 0; jj < (int)IdToDel.size(); jj++)
	{
	for (int ii = (int)IdToDel[jj].size() - 1; ii >= 0; ii--)//start from last to first when deleting vector stack of data
	{
	int viewID = IdToDel[jj][ii];
	if (viewID >CorpusInfo.viewIdAll3D[jj].size() - 1)
	printLOG("%d\n", jj);
	else
	{
	CorpusInfo.viewIdAll3D[jj].erase(CorpusInfo.viewIdAll3D[jj].begin() + viewID);
	CorpusInfo.pointIdAll3D[jj].erase(CorpusInfo.pointIdAll3D[jj].begin() + viewID);
	CorpusInfo.uvAll3D[jj].erase(CorpusInfo.uvAll3D[jj].begin() + viewID);
	CorpusInfo.scaleAll3D[jj].erase(CorpusInfo.scaleAll3D[jj].begin() + viewID);
	}
	}
	}
	//sprintf(Fname, "%s/Corpus", Path);/SaveCorpusInfo(Fname, CorpusInfo, false, false);*/

	int fixSkew = 0, fixPrism = 0;
	GenericBundleAdjustment(Path, CorpusInfo.camera, CorpusInfo.xyz, CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D, sharedIntrinsicCamID, nViews, 1, 1, 1, 0, 0, 0, fixSkew, fixPrism, distortionCorrected, nViewsPlus, LossType, false, true, false);

	GenericBundleAdjustment(Path, CorpusInfo.camera, CorpusInfo.xyz, CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D, sharedIntrinsicCamID, nViews, 1, 1, 1, 0, 0, 0, 0, 0, 0, distortionCorrected, nViewsPlus, LossType, false, true, false);

	SaveCorpusInfo(Path, CorpusInfo, false, false);

	return 0;
}

int ClassifyPointsFromTriangulationSingleCam(char *Path, int CamID, int startFInst, int stopFInst, int increFInst, int trackingRange, int increF, int nInlierThresh, double TriangThesh)
{
	char Fname[512];

	VideoData VideoI;
	if (ReadVideoDataI(Path, VideoI, CamID, max(startFInst - trackingRange, 0), stopFInst + trackingRange) == 1)
		return 1;

	int pid, npts, nframes = 2 * trackingRange / increF + 1;
	double u, v, s, TriangThesh2 = TriangThesh * TriangThesh;

	Point3d P3d;
	Point2d *pts = new Point2d[nframes], *ppts = new Point2d[nframes];
	double *A = new double[6 * nframes], *B = new double[2 * nframes], *P = new double[12 * nframes];

	Mat img;
	for (int instF = startFInst; instF <= stopFInst; instF += increFInst)
	{
		//Read all points
		sprintf(Fname, "%s/%d/Harris/%d_%.4d.txt", Path, CamID, instF, instF); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot read %s\n", Fname);
			continue;
		}
		fscanf(fp, "%d", &npts);
		Point2d *allPts = new Point2d[npts*nframes];
		float *allS = new float[npts*nframes];
		for (int ii = 0; ii < npts*nframes; ii++)
			allPts[ii] = Point2d(-1, 1);
		for (int ii = 0; ii < npts; ii++)
		{
			fscanf(fp, "%d %lf %lf %lf ", &pid, &u, &v, &s);
			allPts[pid*nframes + trackingRange / increF].x = u, allPts[pid*nframes + trackingRange / increF].y = v, allS[pid*nframes + trackingRange / increF] = s;
		}
		fclose(fp);

		for (int fid = increF; fid <= trackingRange; fid += increF)
		{
			sprintf(Fname, "%s/%d/Harris/%d_%.4d.txt", Path, CamID, instF, instF + fid); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			fscanf(fp, "%d", &npts);
			for (int ii = 0; ii < npts; ii++)
			{
				fscanf(fp, "%d %lf %lf %lf ", &pid, &u, &v, &s);
				allPts[pid*nframes + (trackingRange + fid) / increF].x = u, allPts[pid*nframes + (trackingRange + fid) / increF].y = v, allS[pid*nframes + (trackingRange + fid) / increF] = s;
			}
			fclose(fp);

			sprintf(Fname, "%s/%d/Harris/%d_%.4d.txt", Path, CamID, instF, instF - fid); fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			fscanf(fp, "%d", &npts);
			for (int ii = 0; ii < npts; ii++)
			{
				fscanf(fp, "%d %lf %lf %lf ", &pid, &u, &v, &s);
				allPts[pid*nframes + (trackingRange - fid) / increF].x = u, allPts[pid*nframes + (trackingRange - fid) / increF].y = v, allS[pid*nframes + (trackingRange - fid) / increF] = s;
			}
			fclose(fp);
		}

		//check for visiblity, undistort, and triangulate
		int nStatic = 0;
		bool *staticPoint = new bool[npts];
		Point3d *xyz = new Point3d[npts];
		for (pid = 0; pid < npts; pid++)
		{
			staticPoint[pid] = 0;

			int nvis = 0;
			for (int fid = -trackingRange; fid <= trackingRange; fid += increF)
				if (allPts[pid*nframes + (fid + trackingRange) / increF].x > 0 && allPts[pid*nframes + (fid + trackingRange) / increF].y > 0)
					nvis++;
			if (nvis < trackingRange / increF / 2)
				continue;

			nvis = 0;
			for (int fid = -trackingRange; fid <= trackingRange; fid += increF)
			{
				if (allPts[pid*nframes + (fid + trackingRange) / increF].x > 0 && allPts[pid*nframes + (fid + trackingRange) / increF].y > 0)
				{
					if (VideoI.VideoInfo[instF + fid].valid == 0)
						continue;
					pts[nvis] = allPts[pid*nframes + (fid + trackingRange) / increF];
					LensCorrectionPoint(&pts[nvis], VideoI.VideoInfo[instF + fid].K, VideoI.VideoInfo[instF + fid].distortion);

					if (VideoI.VideoInfo[instF + fid].ShutterModel == 0)
						for (int ll = 0; ll < 12; ll++)
							P[12 * nvis + ll] = VideoI.VideoInfo[instF + fid].P[ll];
					else
						AssembleP_RS(pts[nvis], VideoI.VideoInfo[instF + fid], P + 12 * nvis);
					nvis++;
				}
			}

			NviewTriangulation(pts, P, &P3d, nvis, 1, NULL, A, B);
			ProjectandDistort(P3d, ppts, P, NULL, NULL, nvis);

			int ninliers = 0;
			double resi, res = 0.0;
			for (int ll = 0; ll < nvis; ll++)
			{
				resi = pow(ppts[ll].x - pts[ll].x, 2) + pow(ppts[ll].y - pts[ll].y, 2);
				res += resi;
				if (resi < TriangThesh2)
					ninliers++;
			}
			res = res / (nvis + 0.001);
			if (res < TriangThesh2)
				staticPoint[pid] = 1, xyz[pid] = P3d, nStatic++;//static
		}

		sprintf(Fname, "%s/%d/Harris/", Path, CamID); makeDir(Fname);
		sprintf(Fname, "%s/%d/Harris/Inliers_%.4d.txt", Path, CamID, instF); fp = fopen(Fname, "w+");
		fprintf(fp, "%d\n", nStatic);
		nStatic = 0;
		for (int pid = 0; pid < npts; pid++)
		{
			if (staticPoint[pid] == true)
			{
				int nvis = 0;
				for (int fid = -trackingRange; fid <= trackingRange; fid += increF)
					if (allPts[pid*nframes + (fid + trackingRange) / increF].x > 0 && allPts[pid*nframes + (fid + trackingRange) / increF].y > 0)
						nvis++;
				fprintf(fp, "%d %d %.4e %.4e %.4e ", nStatic, nvis, xyz[pid].x, xyz[pid].y, xyz[pid].z);
				for (int fid = -trackingRange; fid <= trackingRange; fid += increF)
					if (allPts[pid*nframes + (fid + trackingRange) / increF].x > 0 && allPts[pid*nframes + (fid + trackingRange) / increF].y > 0)
						fprintf(fp, "%d %.3f %.3f %.2f ", instF + fid, allPts[pid*nframes + (fid + trackingRange) / increF].x, allPts[pid*nframes + (fid + trackingRange) / increF].y, allS[pid*nframes + (fid + trackingRange) / increF]);
				fprintf(fp, "\n");
				nStatic++;
			}
		}
		fclose(fp);
		printLOG("(V %d, F %d): %d/%d static points\n", CamID, instF, nStatic, npts);

#ifdef ABC
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, CamID, instF); img = imread(Fname, 1);
		namedWindow("img", CV_WINDOW_NORMAL);

		nStatic = 0;
		for (int pid = 0; pid < npts; pid++)
			if (staticPoint[pid] == true)
				circle(img, allPts[pid*nframes + trackingRange / increF], 2, Scalar(0, 255, 0), 2);

		CvPoint text_origin = { img.cols / 30, img.cols / 30 };
		sprintf(Fname, "(C: %d Inst: %d)", CamID, instF);
		putText(img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0 * img.cols / 1080, CV_RGB(255, 0, 0), 2);
		imshow("img", img);
		sprintf(Fname, "%s/%d/Track2D/H%.4d.jpg", Path, CamID, instF); imwrite(Fname, img);
		waitKey(1000);
#endif

		delete[]allPts, delete[]allS, delete[]staticPoint;
	}

	delete[]pts, delete[]ppts, delete[]A, delete[]B, delete[]P;

	return 0;
}
int LocalBA_HarrisTracking_And_SiftMatching(char *Path, int selectedCamID, int InstF, int nInst, int increInstF, int rangeF, int increF, int CorpusDistortionCorrected, int fixIntrinsic, int fixDistortion, int fixPose, int fix3D, int fixSkew, int fixPrism, double weightHvsC, int nplus, double threshold, int sharedIntrinsic)
{
	char Fname[512];
	int nframes = 2 * rangeF / increF + 1;

	VideoData mov;
	if (ReadVideoDataI(Path, mov, selectedCamID, max(InstF - nInst * increInstF - rangeF, 0), InstF + nInst * increInstF + rangeF) == 1)
		return 1;

	//Read all tracked points
	printLOG("Reading tracking data\n");
	float s; Point2d uv;
	int pid, fid, npts, nptsAll = 0;
	for (int inst = -nInst; inst < nInst; inst++)
	{
		sprintf(Fname, "%s/%d/Harris/Inliers_%.4d.txt", Path, selectedCamID, InstF + inst * increInstF);  FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		fscanf(fp, "%d ", &npts); fclose(fp);
		nptsAll += npts;
	}

	vector<Point3d>  Vxyz; Point3d xyz;
	vector < vector<int> > frameIDAll3D;	vector<int> frameIDPer3D;
	vector<vector<Point2d> > uvAll3D;	vector<Point2d> uvPer3D;
	vector<vector<double> > scaleAll3D; vector<double> scalePer3D;
	for (int ii = 0; ii < nptsAll; ii++)
	{
		frameIDAll3D.push_back(frameIDPer3D), frameIDAll3D[ii].reserve(2 * rangeF + 1);
		uvAll3D.push_back(uvPer3D), uvAll3D[ii].reserve(2 * rangeF + 1);
		scaleAll3D.push_back(scalePer3D), scaleAll3D[ii].reserve(2 * rangeF + 1);
	}

	int cumNpts = 0;
	for (int inst = -nInst; inst < nInst; inst++)
	{
		int fnpts, pid;
		sprintf(Fname, "%s/%d/Harris/Inliers_%.4d.txt", Path, selectedCamID, InstF + inst * increInstF);  FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		fscanf(fp, "%d ", &npts);
		while (fscanf(fp, "%d %d %lf %lf %lf ", &pid, &fnpts, &xyz.x, &xyz.y, &xyz.z) != EOF)
		{
			Vxyz.push_back(xyz);
			for (int ii = 0; ii < fnpts; ii++)
			{
				fscanf(fp, "%d %lf %lf %f\n", &fid, &uv.x, &uv.y, &s);
				frameIDAll3D[pid + cumNpts].push_back(fid), uvAll3D[pid + cumNpts].push_back(uv), scaleAll3D[pid + cumNpts].push_back(s);
			}
		}
		fclose(fp);;
		cumNpts += npts;
	}

	//Read all corpus points
	printLOG("Reading corpus data\n");
	Corpus CorpusInfo;
	int dummy, nPoints, useColor;
	sprintf(Fname, "%s/Corpus/nHCorpus_3D.txt", Path);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
			if (IsFileExist(Fname) == 0)
			{
				printLOG("Cannot load %s\n", Fname);
				return 1;
			}
		}
	}
	FILE *fp = fopen(Fname, "r");
	fscanf(fp, "%d %d %d", &dummy, &nPoints, &useColor);
	CorpusInfo.nCameras = nframes;
	CorpusInfo.n3dPoints = nPoints;

	Point3i rgb;
	CorpusInfo.xyz.reserve(nPoints);
	if (useColor)
	{
		CorpusInfo.rgb.reserve(nPoints);
		for (int jj = 0; jj < nPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
			CorpusInfo.xyz.push_back(xyz);
			CorpusInfo.rgb.push_back(rgb);
		}
	}
	else
	{
		CorpusInfo.rgb.reserve(nPoints);
		for (int jj = 0; jj < nPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
			CorpusInfo.xyz.push_back(xyz);
		}
	}
	fclose(fp);

	//Generate CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D
	for (int ii = 0; ii < nPoints; ii++)
	{
		CorpusInfo.viewIdAll3D.push_back(frameIDPer3D); CorpusInfo.viewIdAll3D.back().reserve(2 * nInst + 1);
		CorpusInfo.uvAll3D.push_back(uvPer3D); CorpusInfo.uvAll3D.back().reserve(2 * nInst + 1);
		CorpusInfo.scaleAll3D.push_back(scalePer3D); CorpusInfo.scaleAll3D.back().reserve(2 * nInst + 1);
	}

	for (int fid = InstF - nInst * increInstF - rangeF; fid <= InstF + nInst * increInstF + rangeF; fid++)
	{
		sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, selectedCamID, fid); fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		while (fscanf(fp, "%d %lf %lf %lf %lf %lf %f", &pid, &xyz.x, &xyz.y, &xyz.z, &uv.x, &uv.y, &s) != EOF)
		{
			if (pid < 0 || pid >nPoints)
				continue;
			if (s < 1.0)
				continue;
			CorpusInfo.viewIdAll3D[pid].push_back(fid);
			CorpusInfo.uvAll3D[pid].push_back(uv);
			CorpusInfo.scaleAll3D[pid].push_back(s*weightHvsC); //smaller scale, larger weight
		}
		fclose(fp);
	}

	if (2 * nInst*increInstF + 1 + 2 * rangeF + 1 > 100) //only need to clean the mem when the range is huge
	{
		printLOG("Clean up memory\n");
		//Find 3d points with less than 2 views
		vector<int> NotOftenVisible;
		for (int ii = 0; ii < CorpusInfo.n3dPoints; ii++)
			if (CorpusInfo.viewIdAll3D[ii].size() < 2)
				NotOftenVisible.push_back(ii);
		printLOG("(%d/%d) corpus points not visible by at least %d frames\n", NotOftenVisible.size(), CorpusInfo.n3dPoints, 2);

		//Clean from bottom to top
		for (int ii = (int)NotOftenVisible.size() - 1; ii >= 0; ii--)
		{
			pid = NotOftenVisible[ii];
			CorpusInfo.viewIdAll3D[pid].erase(CorpusInfo.viewIdAll3D[pid].begin(), CorpusInfo.viewIdAll3D[pid].end());
			CorpusInfo.uvAll3D[pid].erase(CorpusInfo.uvAll3D[pid].begin(), CorpusInfo.uvAll3D[pid].end());
			CorpusInfo.scaleAll3D[pid].erase(CorpusInfo.scaleAll3D[pid].begin(), CorpusInfo.scaleAll3D[pid].end());
		}
	}

	if (CorpusDistortionCorrected == 1) //add distortion to get back the raw points
		for (int jj = 0; jj < CorpusInfo.n3dPoints; jj++)
			for (int ii = 0; ii < (int)CorpusInfo.uvAll3D[jj].size(); ii++)
			{
				int fid = CorpusInfo.viewIdAll3D[jj][ii];
				if (fid > 0 || mov.VideoInfo[fid].valid == 1)
					LensDistortionPoint(&CorpusInfo.uvAll3D[jj][ii], mov.VideoInfo[fid].K, mov.VideoInfo[fid].distortion);
			}

	//combine data
	for (int jj = 0; jj < CorpusInfo.n3dPoints; jj++)
		if (CorpusInfo.viewIdAll3D[jj].size() > nplus)
			Vxyz.push_back(CorpusInfo.xyz[jj]), frameIDAll3D.push_back(CorpusInfo.viewIdAll3D[jj]), uvAll3D.push_back(CorpusInfo.uvAll3D[jj]), scaleAll3D.push_back(CorpusInfo.scaleAll3D[jj]);

	vector<int> sharedInstrinsicCamID;
	//for (int fid = max(0, InstF - nInst*increInstF - rangeF); fid <= InstF + nInst*increInstF + rangeF; fid++)
	if (sharedIntrinsic == 1)
		for (int fid = 0; fid <= InstF + nInst * increInstF + rangeF; fid++) //so that SharedCameraToBuildCorpus[InstF + nInst*increInstF + rangeF-1] is not out of range
			sharedInstrinsicCamID.push_back(0);

	//Run a local BA with the 3D from corpus fixed
	for (int fid = max(0, InstF - nInst * increInstF - rangeF); fid <= InstF + nInst * increInstF + rangeF; fid++)
		mov.VideoInfo[fid].threshold = threshold;

	int fixFirstCamPose = 0, fixLocalPose = 0, distortionCorrected = 0;
	GenericBundleAdjustment(Path, mov.VideoInfo, Vxyz, frameIDAll3D, uvAll3D, scaleAll3D, sharedInstrinsicCamID, InstF + nInst * increInstF + rangeF + 1, fixIntrinsic, fixDistortion, fixPose, fixFirstCamPose, fixLocalPose, fix3D, fixSkew, fixPrism, distortionCorrected, nplus, 0, false, false, false, 5);

	sprintf(Fname, "%s/Good.txt", Path), remove(Fname);

	//write video data
	vector<int> computedTime;
	for (int fid = max(0, InstF - nInst * increInstF - rangeF); fid <= InstF + nInst * increInstF + rangeF; fid++)
		if (mov.VideoInfo[fid].valid)
			computedTime.push_back(fid);
	sprintf(Fname, "%s/vHIntrinsic_%.4d.txt", Path, selectedCamID);	SaveVideoCameraIntrinsic(Fname, mov.VideoInfo, computedTime, selectedCamID, 0);
	sprintf(Fname, "%s/vHCamPose_RSCayley_%.4d.txt", Path, selectedCamID);	SaveVideoCameraPoses(Fname, mov.VideoInfo, computedTime, selectedCamID, 0);
	printLOG("Done!\n");

	return 0;
}
int Video_BA_HarrisTracking_And_SiftMatching(char *Path, int selectedCamID, int startInstF, int stopInstF, int increInstF, int HarrisTrackingRangeF, int CorpusDistortionCorrected, int fixIntrinsic, int fixDistortion, int fixPose, int fix3D, int fixSkew, int fixPrism, double weightHvsC, int nplus, int RobustLoss, int doubleRefinement, double threshold)
{
	char Fname[512];
	int nframes = stopInstF - startInstF + 1;

	VideoData mov;
	if (ReadVideoDataI(Path, mov, selectedCamID, startInstF, stopInstF) == 1)
		return 1;

	//Sweep through the data to create storage mem
	printLOG("Prepare data storage...");
	int nCorpusCams, nCorpusPoints, useColor;
	sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	fscanf(fp, "%d %d %d", &nCorpusCams, &nCorpusPoints, &useColor);
	fclose(fp);

	int npts, nHarrisPoints = 0;
	for (int fid = startInstF; fid <= stopInstF; fid += increInstF * 5)
	{
		sprintf(Fname, "%s/%d/Harris/Inliers_%.4d.txt", Path, selectedCamID, fid);  FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		fscanf(fp, "%d ", &npts); fclose(fp);
		nHarrisPoints += npts;
	}
	printLOG("\n%d Corpus points and %d Harris Points\n", nCorpusPoints, nHarrisPoints);

	vector<Point3d>  Vxyz; Point3d xyz;
	vector<Point3i> Vrgb; Point3i rgb;
	vector < vector<int> > frameIDAll3D;	vector<int> frameIDPer3D;
	vector<vector<Point2f> > uvAll3D;	vector<Point2f> uvPer3D;
	vector<vector<float> > scaleAll3D; vector<float> scalePer3D;

	Vxyz.reserve(nCorpusPoints + nHarrisPoints);
	frameIDAll3D.reserve(nCorpusPoints + nHarrisPoints);
	uvAll3D.reserve(nCorpusPoints + nHarrisPoints);
	scaleAll3D.reserve(nCorpusPoints + nHarrisPoints);
	printLOG("Caching Corpus points....");
	for (int ii = 0; ii < nCorpusPoints; ii++)
	{
		frameIDAll3D.push_back(frameIDPer3D); frameIDAll3D.back().reserve(nframes / increInstF / 5);//say approx. 20% frames see the point
		uvAll3D.push_back(uvPer3D); uvAll3D.back().reserve(nframes / increInstF / 5);
		scaleAll3D.push_back(scalePer3D); scaleAll3D.back().reserve(nframes / increInstF / 5);
	}
	printLOG("Harris points...");
	for (int ii = 0; ii < nHarrisPoints; ii++)
	{
		frameIDAll3D.push_back(frameIDPer3D), frameIDAll3D[ii].reserve(2 * HarrisTrackingRangeF / increInstF + 1);
		uvAll3D.push_back(uvPer3D), uvAll3D[ii].reserve(2 * HarrisTrackingRangeF / increInstF + 1);
		scaleAll3D.push_back(scalePer3D), scaleAll3D[ii].reserve(2 * HarrisTrackingRangeF / increInstF + 1);
	}
	printLOG("\n");

	printLOG("Reading Corpus 3D\n");
	sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
	fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	printLOG("Loaded %s\n", Fname);
	fscanf(fp, "%d %d %d", &nCorpusCams, &nCorpusPoints, &useColor);
	if (useColor)
	{
		Vrgb.reserve(nCorpusPoints);
		for (int jj = 0; jj < nCorpusPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
			Vxyz.push_back(xyz);
			Vrgb.push_back(rgb);
		}
	}
	else
	{
		for (int jj = 0; jj < nCorpusPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
			Vxyz.push_back(xyz);
		}
	}
	fclose(fp);

	printLOG("Reading Corpus PnP data\n");
	float s; Point2f uv;
	int pid;
	for (int fid = startInstF; fid <= stopInstF; fid += increInstF)
	{
		sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, selectedCamID, fid); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			//printLOG("Cannot load %s\n", Fname);
			continue;
		}
		while (fscanf(fp, "%d %lf %lf %lf %f %f %f", &pid, &xyz.x, &xyz.y, &xyz.z, &uv.x, &uv.y, &s) != EOF)
		{
			if (pid < 0 || pid >nCorpusPoints)
				continue;
			if (s < 1.0)
				continue;
			frameIDAll3D[pid].push_back(fid);
			uvAll3D[pid].push_back(uv);
			scaleAll3D[pid].push_back(s*weightHvsC); //smaller scale, larger weight
		}
		fclose(fp);
	}

	printLOG("Reading Harris data\n");
	int cumNpts = nCorpusPoints;
	for (int fid = startInstF; fid <= stopInstF; fid += increInstF * 5)
	{
		int fnpts, pid, fid2;
		sprintf(Fname, "%s/%d/Harris/Inliers_%.4d.txt", Path, selectedCamID, fid);  FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		fscanf(fp, "%d ", &npts);
		while (fscanf(fp, "%d %d %lf %lf %lf ", &pid, &fnpts, &xyz.x, &xyz.y, &xyz.z) != EOF)
		{
			Vxyz.push_back(xyz);
			for (int ii = 0; ii < fnpts; ii++)
			{
				fscanf(fp, "%d %f %f %f\n", &fid2, &uv.x, &uv.y, &s);
				frameIDAll3D[pid + cumNpts].push_back(fid2), uvAll3D[pid + cumNpts].push_back(uv), scaleAll3D[pid + cumNpts].push_back(s);
			}
		}
		fclose(fp);
		cumNpts += npts;
	}
	printLOG("done!\n");

	if (CorpusDistortionCorrected == 1) //distort the points to redo BA
	{
		CorpusDistortionCorrected = 0;
		for (int jj = 0; jj < nCorpusPoints; jj++)
		{
			for (int ii = 0; ii < (int)uvAll3D[jj].size(); ii++)
			{
				int fid = frameIDAll3D[jj][ii];
				if (fid > 0 || mov.VideoInfo[fid].valid == 1)
				{
					Point2d uv = uvAll3D[jj][ii];
					LensDistortionPoint(&uv, mov.VideoInfo[fid].K, mov.VideoInfo[fid].distortion);
					uvAll3D[jj][ii] = uv;
				}
			}
		}
	}

	vector<int> SharedCameraToBuildCorpus;//size must be equal to the size of AllVideoInfo
	SharedCameraToBuildCorpus.reserve(mov.nframesI);
	int sharedIntrinsic = 0;
	sprintf(Fname, "%s/CamerasWithFixedIntrinsic.txt", Path);
	if (IsFileExist(Fname) == 1)
	{
		int camID;
		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d ", &camID) != EOF)
		{
			if (camID == selectedCamID)
			{
				sharedIntrinsic = 1;
				break;
			}
		}
		fclose(fp);
	}
	for (int ii = 0; ii < mov.nframesI; ii++)
		if (sharedIntrinsic == 0)
			SharedCameraToBuildCorpus.push_back(-1);
		else
			SharedCameraToBuildCorpus.push_back(1);

	vector<int> vFix3D; vFix3D.reserve(Vxyz.size());
	for (int ii = 0; ii < nCorpusPoints; ii++)
	{
		if (fix3D == 1)
			vFix3D.push_back(1);
		else
			vFix3D.push_back(0);
	}
	for (int ii = nCorpusPoints; ii < (int)Vxyz.size(); ii++)
		vFix3D.push_back(0);

	for (int ii = startInstF; ii < stopInstF; ii++)
		mov.VideoInfo[ii].threshold = !doubleRefinement ? threshold : threshold * 6.0; //make sure that most points are inliers
	int fixLocalPose = 0;
	//GenericBundleAdjustment(Path, mov.VideoInfo, Vxyz, frameIDAll3D, uvAll3D, scaleAll3D,
	//	SharedCameraToBuildCorpus, mov.nframesI, fixIntrinsic, fixDistortion, fixPose, 0, fixLocalPose, vFix3D, fixSkew, fixPrism, CorpusDistortionCorrected, nplus, RobustLoss, false, false);

	if (doubleRefinement == 1)
	{
		for (int ii = startInstF; ii < stopInstF; ii++)
			mov.VideoInfo[ii].threshold = threshold;

		RobustLoss = 0;
		//GenericBundleAdjustment(Path, mov.VideoInfo, Vxyz, frameIDAll3D, uvAll3D, scaleAll3D,
		//	SharedCameraToBuildCorpus, mov.nframesI, fixIntrinsic, fixDistortion, fixPose, 0, fixLocalPose, vFix3D, fixSkew, fixPrism, CorpusDistortionCorrected, nplus, RobustLoss, false, false);
	}
	sprintf(Fname, "%s/Good.txt", Path), remove(Fname);


	//write video data
	printLOG("Writing refined poses ....");
	vector<int> computedTime;
	for (int ii = startInstF; ii <= stopInstF; ii++)
		if (mov.VideoInfo[ii].valid)
			computedTime.push_back(ii);
	sprintf(Fname, "%s/vHIntrinsic_%.4d.txt", Path, selectedCamID); SaveVideoCameraIntrinsic(Fname, mov.VideoInfo, computedTime, selectedCamID, 0);
	sprintf(Fname, "%s/vHCamPose_RSCayley_%.4d.txt", Path, selectedCamID); SaveVideoCameraPoses(Fname, mov.VideoInfo, computedTime, selectedCamID, 0);
	printLOG("done\n");

	return 0;
}
int AllVideos_BA_HarrisTracking_And_SiftMatching(char *Path, int nCams, int startInstF, int stopInstF, int increInstF, int HarrisTrackingRangeF, int CorpusDistortionCorrected, int fixIntrinsic, int fixDistortion, int fixPose, int fix3D, int fixSkew, int fixPrism, double weightHvsC, int nplus, int RobustLoss, int doubleRefinement, double threshold)
{
	char Fname[512];
	int nframes = stopInstF - startInstF + 1;
	printLOG("Working on all %d cameras\n", nCams);

	VideoData AllVideoInfo;
	if (ReadVideoData(Path, AllVideoInfo, nCams, startInstF, stopInstF) == 1)
		return 1;

	//Sweep through the data to create storage mem
	printLOG("Prepare data storage...");
	int nCorpusCams, nCorpusPoints, useColor;
	sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	fscanf(fp, "%d %d %d", &nCorpusCams, &nCorpusPoints, &useColor);
	fclose(fp);

	int npts, nHarrisPoints = 0;
	for (int cid = 0; cid < nCams; cid++)
	{
		printLOG("%d: ", cid);
		int cumi = 0;
		for (int fid = startInstF; fid <= stopInstF; fid += increInstF * 4)
		{
			sprintf(Fname, "%s/%d/Harris/Inliers_%.4d.txt", Path, cid, fid);  FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			fscanf(fp, "%d ", &npts); fclose(fp);
			nHarrisPoints += npts;
			cumi += npts;
		}
		printLOG("%d ..", cumi);
	}
	printLOG("\n%d Corpus points and %d Harris Points\n", nCorpusPoints, nHarrisPoints);

	vector<Point3d>  Vxyz; Point3d xyz;
	vector<Point3i> Vrgb; Point3i rgb;
	vector < vector<int> > frameIDAll3D;	vector<int> frameIDPer3D;
	vector<vector<Point2f> > uvAll3D;	vector<Point2f> uvPer3D;
	vector<vector<float> > scaleAll3D; vector<float> scalePer3D;

	Vxyz.reserve(nCorpusPoints + nHarrisPoints);
	frameIDAll3D.reserve(nCorpusPoints + nHarrisPoints);
	uvAll3D.reserve(nCorpusPoints + nHarrisPoints);
	scaleAll3D.reserve(nCorpusPoints + nHarrisPoints);
	printLOG("Caching Corpus points....");
	for (int ii = 0; ii < nCorpusPoints; ii++)
	{
		frameIDAll3D.push_back(frameIDPer3D); frameIDAll3D.back().reserve(nframes / increInstF * nCams / 4);//say approx. 25% frames see the point
		uvAll3D.push_back(uvPer3D); uvAll3D.back().reserve(nframes / increInstF * nCams / 4);
		scaleAll3D.push_back(scalePer3D); scaleAll3D.back().reserve(nframes / increInstF * nCams / 4);
	}
	printLOG("Harris points...");
	for (int ii = 0; ii < nHarrisPoints; ii++)
	{
		frameIDAll3D.push_back(frameIDPer3D), frameIDAll3D[ii].reserve(2 * HarrisTrackingRangeF / increInstF + 1);
		uvAll3D.push_back(uvPer3D), uvAll3D[ii].reserve(2 * HarrisTrackingRangeF / increInstF + 1);
		scaleAll3D.push_back(scalePer3D), scaleAll3D[ii].reserve(2 * HarrisTrackingRangeF / increInstF + 1);
	}
	printLOG("\n");

	printLOG("Reading Corpus 3D\n");
	sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
	fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	printLOG("Loaded %s\n", Fname);
	fscanf(fp, "%d %d %d", &nCorpusCams, &nCorpusPoints, &useColor);
	if (useColor)
	{
		Vrgb.reserve(nCorpusPoints);
		for (int jj = 0; jj < nCorpusPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
			Vxyz.push_back(xyz);
			Vrgb.push_back(rgb);
		}
	}
	else
	{
		for (int jj = 0; jj < nCorpusPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
			Vxyz.push_back(xyz);
		}
	}
	fclose(fp);

	printLOG("Reading Corpus PnP data:");
	float s; Point2f uv;
	int pid;
	for (int cid = 0; cid < nCams; cid++)
	{
		printLOG("%d ..", cid);
		int videoID = AllVideoInfo.nframesI*cid;
		for (int fid = startInstF; fid <= stopInstF; fid += increInstF)
		{
			sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, cid, fid); fp = fopen(Fname, "r");
			if (fp == NULL)
			{
				//printLOG("Cannot load %s\n", Fname);
				continue;
			}
			while (fscanf(fp, "%d %lf %lf %lf %f %f %f", &pid, &xyz.x, &xyz.y, &xyz.z, &uv.x, &uv.y, &s) != EOF)
			{
				if (pid < 0 || pid >nCorpusPoints)
					continue;
				if (s < 1.0)
					continue;
				frameIDAll3D[pid].push_back(fid + videoID);
				uvAll3D[pid].push_back(uv);
				scaleAll3D[pid].push_back(s*weightHvsC); //smaller scale, larger weight
			}
			fclose(fp);
		}
	}

	printLOG("Reading Harris data: ");
	int cumNpts = nCorpusPoints;
	for (int cid = 0; cid < nCams; cid++)
	{
		printLOG("%d ..", cid);
		int videoID = AllVideoInfo.nframesI*cid;
		for (int fid = startInstF; fid <= stopInstF; fid += increInstF * 4)
		{
			int fnpts, pid, fid2;
			sprintf(Fname, "%s/%d/Harris/Inliers_%.4d.txt", Path, cid, fid);  FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			fscanf(fp, "%d ", &npts);
			while (fscanf(fp, "%d %d %lf %lf %lf ", &pid, &fnpts, &xyz.x, &xyz.y, &xyz.z) != EOF)
			{
				Vxyz.push_back(xyz);
				for (int ii = 0; ii < fnpts; ii++)
				{
					fscanf(fp, "%d %f %f %f\n", &fid2, &uv.x, &uv.y, &s);
					if ((fid2 - fid) % increInstF == 0)
						frameIDAll3D[pid + cumNpts].push_back(fid2 + videoID), uvAll3D[pid + cumNpts].push_back(uv), scaleAll3D[pid + cumNpts].push_back(s);
				}
			}
			fclose(fp);
			cumNpts += npts;
		}
	}
	printLOG("done!\n");

	if (CorpusDistortionCorrected == 1) //distort the points to redo BA
	{
		CorpusDistortionCorrected = 0;
		for (int jj = 0; jj < nCorpusPoints; jj++)
		{
			for (int ii = 0; ii < (int)uvAll3D[jj].size(); ii++)
			{
				int fid = frameIDAll3D[jj][ii];
				if (fid > 0 || AllVideoInfo.VideoInfo[fid].valid == 1)
				{
					Point2d uv = uvAll3D[jj][ii];
					LensDistortionPoint(&uv, AllVideoInfo.VideoInfo[fid].K, AllVideoInfo.VideoInfo[fid].distortion);
					uvAll3D[jj][ii] = uv;
				}
			}
		}
	}

	vector<int> SharedCameraToBuildCorpus;//size must be equal to the size of AllVideoInfo
	SharedCameraToBuildCorpus.reserve(nCams*AllVideoInfo.nframesI);
	for (int camID = 0; camID < nCams; camID++)
		for (int ii = 0; ii < AllVideoInfo.nframesI; ii++)
			SharedCameraToBuildCorpus.push_back(-1);
	sprintf(Fname, "%s/CamerasWithFixedIntrinsic.txt", Path);
	if (IsFileExist(Fname) == 1)
	{
		int camID, count = 0;
		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d ", &camID) != EOF)
		{
			if (camID > nCams - 1)
				continue;
			count++;
			for (int ii = 0; ii < AllVideoInfo.nframesI; ii++)
				SharedCameraToBuildCorpus[camID*AllVideoInfo.nframesI + ii] = camID;
		}
		fclose(fp);
		if (count > 0)
			printLOG("Shared-Intrinsic enforces for %d cameras\n", count);
	}

	for (int camID = 0; camID < nCams; camID++)
	{
		int videoID = AllVideoInfo.nframesI*camID;
		for (int ii = startInstF; ii < stopInstF; ii++)
			AllVideoInfo.VideoInfo[ii + videoID].threshold = !doubleRefinement ? threshold : threshold * 2.0; //make sure that most points are inliers
	}
	int fixLocalPose = 0;
	//	GenericBundleAdjustment(Path, AllVideoInfo.VideoInfo, Vxyz, frameIDAll3D, uvAll3D, scaleAll3D,
	//	SharedCameraToBuildCorpus, AllVideoInfo.nframesI* nCams, fixIntrinsic, fixDistortion, fixPose, 0, fixLocalPose, fix3D, fixSkew, fixPrism, CorpusDistortionCorrected, nplus, RobustLoss, false, false);

	if (doubleRefinement == 1)
	{
		for (int camID = 0; camID < nCams; camID++)
		{
			int videoID = AllVideoInfo.nframesI*camID;
			for (int ii = startInstF; ii < stopInstF; ii++)
				AllVideoInfo.VideoInfo[ii + videoID].threshold = threshold;
		}

		RobustLoss = 0;
		//GenericBundleAdjustment(Path, AllVideoInfo.VideoInfo, Vxyz, frameIDAll3D, uvAll3D, scaleAll3D,
		//	SharedCameraToBuildCorpus, AllVideoInfo.nframesI*nCams, fixIntrinsic, fixDistortion, fixPose, 0, fixLocalPose, fix3D, fixSkew, fixPrism, CorpusDistortionCorrected, nplus, RobustLoss, false, false);
	}
	sprintf(Fname, "%s/Good.txt", Path), remove(Fname);


	//write video data
	printLOG("Writing refined poses ....");
	for (int camID = 0; camID < nCams; camID++)
	{
		int videoID = AllVideoInfo.nframesI*camID;
		vector<int> computedTime;
		for (int ii = startInstF; ii <= stopInstF; ii++)
			if (AllVideoInfo.VideoInfo[ii + videoID].valid)
				computedTime.push_back(ii);
		sprintf(Fname, "%s/avHIntrinsic_%.4d.txt", Path, camID); SaveVideoCameraIntrinsic(Fname, &AllVideoInfo.VideoInfo[videoID], computedTime, camID, 0);
		sprintf(Fname, "%s/avHCamPose_RSCayley_%.4d.txt", Path, camID); SaveVideoCameraPoses(Fname, &AllVideoInfo.VideoInfo[videoID], computedTime, camID, 0);
	}
	printLOG("done\n");


	if (fix3D == 0)
	{
		printLOG("ReSave corpus 3D points ...");
		sprintf(Fname, "%s/Corpus/nHCorpus_3D.txt", Path);	fp = fopen(Fname, "w+");
		fprintf(fp, "%d %d ", nCorpusCams, (int)Vxyz.size());
		if (Vrgb.size() == 0)
		{
			fprintf(fp, "0\n");
			for (int jj = 0; jj < Vxyz.size(); jj++)
				fprintf(fp, "%f %f %f \n", Vxyz[jj].x, Vxyz[jj].y, Vxyz[jj].z);
		}
		else
		{
			fprintf(fp, "1\n");
			for (int jj = 0; jj < nCorpusPoints; jj++)
				fprintf(fp, "%f %f %f %d %d %d\n", Vxyz[jj].x, Vxyz[jj].y, Vxyz[jj].z, Vrgb[jj].x, Vrgb[jj].y, Vrgb[jj].z);
			for (int jj = nCorpusPoints; jj < (int)Vxyz.size(); jj++)
				fprintf(fp, "%f %f %f %d %d %d\n", Vxyz[jj].x, Vxyz[jj].y, Vxyz[jj].z, 255, 255, 255);
		}
		fclose(fp);

		sprintf(Fname, "%s/Corpus/nH3dGL.xyz", Path);	fp = fopen(Fname, "w+");
		if (Vrgb.size() == 0)
			for (int jj = 0; jj < Vxyz.size(); jj++)
				fprintf(fp, "%d %lf %lf %lf \n", jj, Vxyz[jj].x, Vxyz[jj].y, Vxyz[jj].z);
		else
		{
			for (int jj = 0; jj < nCorpusPoints; jj++)
				fprintf(fp, "%d %f %f %f %d %d %d\n", jj, Vxyz[jj].x, Vxyz[jj].y, Vxyz[jj].z, Vrgb[jj].x, Vrgb[jj].y, Vrgb[jj].z);
			for (int jj = nCorpusPoints; jj < (int)Vxyz.size(); jj++)
				fprintf(fp, "% %f %f %f %d %d %d\n", jj, Vxyz[jj].x, Vxyz[jj].y, Vxyz[jj].z, 255, 255, 255);
		}
		fclose(fp);
		printLOG("done\n");
	}

	return 0;
}
int Virtual3D_RS_BA_Driver(char *Path, int selectedCam, int startF, int stopF, int increF, int LossType)
{
	VideoData CamI;
	if (ReadVideoDataI(Path, CamI, selectedCam, startF, stopF) == 1)
		return 1;

	int nCorpusCams, n3DPoints, useColor;
	char Fname[512];  sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	printLOG("Loaded %s\n", Fname);

	Corpus CorpusInfo;
	fscanf(fp, "%d %d %d", &nCorpusCams, &n3DPoints, &useColor);
	CorpusInfo.nCameras = nCorpusCams;
	CorpusInfo.n3dPoints = n3DPoints;

	Point3d xyz;	Point3i rgb;
	CorpusInfo.xyz.reserve(n3DPoints);
	if (useColor)
	{
		CorpusInfo.rgb.reserve(n3DPoints);
		for (int jj = 0; jj < n3DPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
			CorpusInfo.xyz.push_back(xyz);
			CorpusInfo.rgb.push_back(rgb);
		}
	}
	else
	{
		CorpusInfo.rgb.reserve(n3DPoints);
		for (int jj = 0; jj < n3DPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
			CorpusInfo.xyz.push_back(xyz);
		}
	}
	fclose(fp);

	//Generate CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D
	CorpusInfo.viewIdAll3D.reserve(n3DPoints);
	CorpusInfo.uvAll3D.reserve(n3DPoints);
	CorpusInfo.scaleAll3D.reserve(n3DPoints);
	vector<int> selectedCamID3D;
	vector<Point2d> uv3D;
	vector<double> scale3D;
	int nframes = (stopF - startF + increF) / increF;
	for (int ii = 0; ii < n3DPoints; ii++)
	{
		CorpusInfo.viewIdAll3D.push_back(selectedCamID3D); CorpusInfo.viewIdAll3D.back().reserve(nframes);
		CorpusInfo.uvAll3D.push_back(uv3D); CorpusInfo.uvAll3D.back().reserve(nframes);
		CorpusInfo.scaleAll3D.push_back(scale3D); CorpusInfo.scaleAll3D.back().reserve(nframes);
	}

	int pid; double s; Point2d uv;
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, selectedCam, fid); fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		while (fscanf(fp, "%d %lf %lf %lf %lf %lf %lf", &pid, &xyz.x, &xyz.y, &xyz.z, &uv.x, &uv.y, &s) != EOF)
		{
			if (pid < 0 || pid > CorpusInfo.n3dPoints)
				continue;
			if (s < 1.0)
				continue;
			if (CamI.VideoInfo[fid].valid == true)
			{
				CorpusInfo.viewIdAll3D[pid].push_back(fid);
				CorpusInfo.uvAll3D[pid].push_back(uv);
				CorpusInfo.scaleAll3D[pid].push_back(s);
			}
		}
		fclose(fp);
	}

	//remove any outliers
	double *Vxyz = new double[3 * n3DPoints];
	vector<vector<int> > fidPer3D; vector<vector<Point2d> > uvPer3D; vector<vector<float> > sPer3D;
	fidPer3D.reserve(n3DPoints), uvPer3D.reserve(n3DPoints), sPer3D.reserve(n3DPoints);
	vector<float> scale3Df;
	for (int ii = 0; ii < n3DPoints; ii++)
	{
		fidPer3D.push_back(selectedCamID3D); fidPer3D.back().reserve(nframes);
		uvPer3D.push_back(uv3D); uvPer3D.back().reserve(nframes);
		sPer3D.push_back(scale3Df); sPer3D.back().reserve(nframes);
	}

	int validProjections = 0, totalProjections = 0;
	for (int pid = 0; pid < n3DPoints; pid++)
	{
		bool once = true;
		int validViewcount = 0;
		double residuals[2], pointErrX = 0.0, pointErrY = 0.0;
		for (int ii = 0; ii < (int)CorpusInfo.viewIdAll3D[pid].size(); ii++)
		{
			int fid = CorpusInfo.viewIdAll3D[pid][ii];
			CayleyReprojectionDebug(CamI.VideoInfo[fid].intrinsic, CamI.VideoInfo[fid].rt, CamI.VideoInfo[fid].wt, CorpusInfo.uvAll3D[pid][ii], CorpusInfo.xyz[pid], CamI.VideoInfo[fid].width, CamI.VideoInfo[fid].height, residuals);

			if (abs(residuals[0]) < CamI.VideoInfo[fid].threshold && abs(residuals[1]) < CamI.VideoInfo[fid].threshold)
			{
				validProjections++;
				fidPer3D[pid].push_back(fid), uvPer3D[pid].push_back(CorpusInfo.uvAll3D[pid][ii]), sPer3D[pid].push_back(CorpusInfo.scaleAll3D[pid][ii]);
			}
			totalProjections++;
		}
		Vxyz[3 * pid] = CorpusInfo.xyz[pid].x, Vxyz[3 * pid + 1] = CorpusInfo.xyz[pid].y, Vxyz[3 * pid + 2] = CorpusInfo.xyz[pid].z;
	}
	printLOG("Valid projections: %d/%d (%.1f%%) \n", validProjections, totalProjections, 100.0*validProjections / totalProjections);

	/*sprintf(Fname, "%s/StaticTrack2D", Path); makeDir(Fname);
	sprintf(Fname, "%s/StaticTrack2D/%.4d.txt", Path, selectedCam);fp = fopen(Fname, "w+");
	fprintf(fp, "%d\n", n3DPoints);
	for (int pid = 0; pid < n3DPoints; pid++)
	{
	if (fidPer3D[pid].size() < 1)
	continue;

	fprintf(fp, "%d %d ", pid, (int)fidPer3D[pid].size());
	for (int fid = 0; fid < (int)fidPer3D[pid].size(); fid++)
	fprintf(fp, "%d %.2f %.2f 1.0 1.0 1.0 0.0 0.0 1.0 ", fidPer3D[pid][fid], uvPer3D[pid][fid].x, uvPer3D[pid][fid].y);
	fprintf(fp, "\n");
	}
	fclose(fp);
	exit(0);*/

	int height;
	double *intrinsics = new double[5 * (stopF + 1)];
	double *rt = new double[6 * (stopF + 1)];
	bool *valid = new bool[stopF + 1];
	for (int fid = startF; fid <= stopF; fid++)
	{
		if (CamI.VideoInfo[fid].valid)
		{
			valid[fid] = 1;
			height = CamI.VideoInfo[fid].height;
			for (int ii = 0; ii < 5; ii++)
				intrinsics[5 * fid + ii] = CamI.VideoInfo[fid].intrinsic[ii];
			for (int ii = 0; ii < 6; ii++)
				rt[6 * fid + ii] = CamI.VideoInfo[fid].rt[ii];
		}
		else
			valid[fid] = 0;
	}

	double rollingshutter_Percent = 0.7;
	Virtual3D_RS_BA(rollingshutter_Percent, intrinsics, rt, valid, Vxyz, fidPer3D, uvPer3D, sPer3D, height, stopF - startF + 1, LossType, 0);

	sprintf(Fname, "%s/RP_%.4d.txt", Path, selectedCam);
	fp = fopen(Fname, "w+");
	fprintf(fp, "%d %.8f\n", selectedCam, rollingshutter_Percent);
	fclose(fp);

	delete[]Vxyz, delete[]intrinsics, delete[]rt;
	return 0;
}

int BundleAdjustDomeTableCorres(char *Path, int startF_HD, int stopF_HD, int startF_VGA, int stopF_VGA, bool fixIntrinsicHD, bool fixDistortionHD, bool fixPoseHD, bool fixIntrinsicVGA, bool fixDistortionVGA, bool fixPoseVGA, bool debug)
{
	double threshold = 15.0;
	const int nHDs = 30, nPanels = 20, nVGAPanel = 24, nVGAs = nPanels * nVGAPanel;
	int nHDUsed = 20, notUsedHD = 14;
	char Fname[512];
	Corpus CorpusInfo;

	sprintf(Fname, "%s/BA_Camera_AllParams_after.txt", Path);
	readBundleAdjustedNVMResults(Fname, CorpusInfo);

	//Get 2D corres
	{
		int frameID;
		Point2d *TableHD = new Point2d[(stopF_HD - startF_HD + 1)*nHDs];
		int *frame3D_HD = new int[stopF_HD - startF_HD + 1];
		for (int ii = startF_HD; ii <= stopF_HD; ii++)
		{
			frame3D_HD[ii - startF_HD] = ii;
			for (int jj = 0; jj < nHDs; jj++)
				TableHD[(ii - startF_HD)*nHDs + jj].x = -1, TableHD[(ii - startF_HD)*nHDs + jj].y = -1;
		}

		sprintf(Fname, "%s/Correspondences_HD.txt", Path);	FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%d ", &frameID) != EOF)
		{
			frame3D_HD[frameID - startF_HD] = frameID;
			for (int jj = 0; jj < nHDs; jj++)
				fscanf(fp, "%lf %lf ", &TableHD[(frameID - startF_HD)*nHDs + jj].x, &TableHD[(frameID - startF_HD)*nHDs + jj].y);
		}
		fclose(fp);

		//Get 3D init
		double *P3D_HD = new double[3 * (stopF_HD - startF_HD + 1)];
		for (int ii = 0; ii < 3 * (stopF_HD - startF_HD + 1); ii++)
			P3D_HD[ii] = 0.0;

		sprintf(Fname, "%s/C0_0.txt", Path); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%d ", &frameID) != EOF)
			fscanf(fp, "%lf %lf %lf", &P3D_HD[3 * (frameID - startF_HD)], &P3D_HD[3 * (frameID - startF_HD) + 1], &P3D_HD[3 * (frameID - startF_HD) + 2]);
		fclose(fp);

		printLOG("Set up BA ...");
		ceres::Problem problem;

		if (debug)
#ifdef _WINDOWS
			sprintf(Fname, "C:/temp/reprojectionB.txt"), fp = fopen(Fname, "w+");
#else
			sprintf(Fname, "reprojectionB.txt"), fp = fopen(Fname, "w+");
#endif

		vector<double> ReProjectionErrorX; ReProjectionErrorX.reserve(stopF_HD - startF_HD + 1);
		vector<double> ReProjectionErrorY; ReProjectionErrorY.reserve(stopF_HD - startF_HD + 1);

		int totalProjections = 0, nPossibleProjections = 0, minInliers = 999;
		for (int ii = startF_HD; ii < stopF_HD; ii++)
		{
			if (abs(P3D_HD[3 * (ii - startF_HD)]) + abs(P3D_HD[3 * (ii - startF_HD) + 1]) + abs(P3D_HD[3 * (ii - startF_HD) + 2]) < 0.01)
				continue;

			if (debug)
				fprintf(fp, "%d %.4f %.4f %.4f ", ii, P3D_HD[3 * (ii - startF_HD)], P3D_HD[3 * (ii - startF_HD) + 1], P3D_HD[3 * (ii - startF_HD) + 2]);

			int nvalidViews = 0;
			double pointErrX = 0, pointErrY = 0, residuals[2];
			for (int jj = 0; jj < nHDUsed; jj++)
			{
				if (jj == notUsedHD)
					continue;
				if (TableHD[(ii - startF_HD)*nHDs + jj].x < 0 || TableHD[(ii - startF_HD)*nHDs + jj].y < 0)
					continue;

				nPossibleProjections++;
				PinholeDistortionReprojectionDebug(CorpusInfo.camera[jj].intrinsic, CorpusInfo.camera[jj].distortion, CorpusInfo.camera[jj].rt, TableHD[(ii - startF_HD)*nHDs + jj],
					Point3d(P3D_HD[3 * (ii - startF_HD)], P3D_HD[3 * (ii - startF_HD) + 1], P3D_HD[3 * (ii - startF_HD) + 2]), residuals);
				if (abs(residuals[0]) + abs(residuals[1]) > threshold)
					continue;

				pointErrX += pow(residuals[0], 2), pointErrY += pow(residuals[1], 2), nvalidViews++;
				totalProjections++;

				if (debug)
					fprintf(fp, "%d %.4f %.4f %.4f %.4f ", jj, TableHD[(ii - startF_HD)*nHDs + jj].x, TableHD[(ii - startF_HD)*nHDs + jj].y, residuals[0], residuals[1]);
			}
			if (debug)
				fprintf(fp, "\n");

			if (minInliers > nvalidViews)
				minInliers = nvalidViews;
			ReProjectionErrorX.push_back(sqrt(pointErrX / nvalidViews)), ReProjectionErrorY.push_back(sqrt(pointErrY / nvalidViews));


			for (int jj = 0; jj < nHDUsed; jj++)
			{
				if (jj == notUsedHD)
					continue;
				if (TableHD[(ii - startF_HD)*nHDs + jj].x < 0 || TableHD[(ii - startF_HD)*nHDs + jj].y < 0)
					continue;

				PinholeDistortionReprojectionDebug(CorpusInfo.camera[jj].intrinsic, CorpusInfo.camera[jj].distortion, CorpusInfo.camera[jj].rt, TableHD[(ii - startF_HD)*nHDs + jj],
					Point3d(P3D_HD[3 * (ii - startF_HD)], P3D_HD[3 * (ii - startF_HD) + 1], P3D_HD[3 * (ii - startF_HD) + 2]), residuals);

				if (abs(residuals[0]) + abs(residuals[1]) > threshold)
					continue;

				ceres::CostFunction* cost_function = PinholeDistortionReprojectionError::Create(TableHD[(ii - startF_HD)*nHDs + jj].x, TableHD[(ii - startF_HD)*nHDs + jj].y, 1.0);
				problem.AddResidualBlock(cost_function, NULL, CorpusInfo.camera[jj].intrinsic, CorpusInfo.camera[jj].distortion, CorpusInfo.camera[jj].rt, &P3D_HD[3 * (ii - startF_HD)]);

				if (fixIntrinsicHD)
					problem.SetParameterBlockConstant(CorpusInfo.camera[jj].intrinsic);
				if (fixDistortionHD)
					problem.SetParameterBlockConstant(CorpusInfo.camera[jj].distortion);
				if (fixPoseHD)
					problem.SetParameterBlockConstant(CorpusInfo.camera[jj].rt);
			}
		}
		if (debug)
			fclose(fp);

		printLOG("Done with problem building\n");

		double miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end()), maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
		double avgX = MeanArray(ReProjectionErrorX), stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
		double miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end()), maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
		double avgY = MeanArray(ReProjectionErrorY), stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
		printLOG("Reprojection error before BA \n Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
		printLOG("Total projections: %d/%.4d. Min inliers: %d\n", totalProjections, nPossibleProjections, minInliers);


		printLOG("...run BA...\n");
		ceres::Solver::Options options;
		options.num_threads = 4;
		options.max_num_iterations = 30;
		options.linear_solver_type = ceres::DENSE_SCHUR;
		options.minimizer_progress_to_stdout = true;
		options.trust_region_strategy_type = ceres::DOGLEG;
		options.use_nonmonotonic_steps = false;

		ceres::Solver::Summary summary;
		ceres::Solve(options, &problem, &summary);
		//std::cout << summary.BriefReport() << "\n";
		std::cout << summary.FullReport() << "\n";

		totalProjections = 0;
		ReProjectionErrorX.clear(), ReProjectionErrorY.clear();
		if (debug)
#ifdef _WINDOWS
			sprintf(Fname, "C:/temp/reprojectionA.txt"), fp = fopen(Fname, "w+");
#else
			sprintf(Fname, "reprojectionA.txt"), fp = fopen(Fname, "w+");
#endif
		for (int ii = startF_HD; ii < stopF_HD; ii++)
		{
			if (abs(P3D_HD[3 * (ii - startF_HD)]) + abs(P3D_HD[3 * (ii - startF_HD) + 1]) + abs(P3D_HD[3 * (ii - startF_HD) + 2]) < 0.01)
				continue;

			if (debug)
				fprintf(fp, "%d %.f %.f %.f ", ii, P3D_HD[3 * (ii - startF_HD)], P3D_HD[3 * (ii - startF_HD) + 1], P3D_HD[3 * (ii - startF_HD) + 2]);
			int nvalidViews = 0;
			double pointErrX = 0, pointErrY = 0, residuals[2];
			for (int jj = 0; jj < nHDUsed; jj++)
			{
				if (jj == notUsedHD)
					continue;
				if (TableHD[(ii - startF_HD)*nHDs + jj].x < 0 || TableHD[(ii - startF_HD)*nHDs + jj].y < 0)
					continue;

				PinholeDistortionReprojectionDebug(CorpusInfo.camera[jj].intrinsic, CorpusInfo.camera[jj].distortion, CorpusInfo.camera[jj].rt, TableHD[(ii - startF_HD)*nHDs + jj],
					Point3d(P3D_HD[3 * (ii - startF_HD)], P3D_HD[3 * (ii - startF_HD) + 1], P3D_HD[3 * (ii - startF_HD) + 2]), residuals);

				if (abs(residuals[0]) + abs(residuals[1]) > threshold * 3)
					continue;

				pointErrX += pow(residuals[0], 2), pointErrY += pow(residuals[1], 2), nvalidViews++;
				totalProjections++;

				if (debug)
					fprintf(fp, "%d %.4f %.4f %.4f %.4f ", jj, TableHD[(ii - startF_HD)*nHDs + jj].x, TableHD[(ii - startF_HD)*nHDs + jj].y, residuals[0], residuals[1]);
			}
			if (debug)
				fprintf(fp, "\n");
			ReProjectionErrorX.push_back(sqrt(pointErrX / nvalidViews)), ReProjectionErrorY.push_back(sqrt(pointErrY / nvalidViews));
		}
		if (debug)
			fclose(fp);

		miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end()), maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
		avgX = MeanArray(ReProjectionErrorX), stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
		miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end()), maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
		avgY = MeanArray(ReProjectionErrorY), stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
		printLOG("Reprojection error after BA \n Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
		printLOG("Total projections: %d/%d\n", totalProjections, nPossibleProjections);

		sprintf(Fname, "%s/BA_Camera_AllParams_after2.txt", Path);
		ReSaveBundleAdjustedNVMResults(Fname, CorpusInfo, 1.0);

		delete[]P3D_HD, delete[]TableHD, delete[] frame3D_HD;
	}

	{
		int frameID;
		Point2d *TableVGA = new Point2d[(stopF_VGA - startF_VGA + 1)*nVGAs];
		int *frame3D_VGA = new int[stopF_VGA - startF_VGA + 1];
		for (int ii = startF_VGA; ii <= stopF_VGA; ii++)
		{
			frame3D_VGA[ii - startF_VGA] = ii;
			for (int jj = 0; jj < nVGAs; jj++)
				TableVGA[(ii - startF_VGA)*nVGAs + jj].x = -1, TableVGA[(ii - startF_VGA)*nVGAs + jj].y = -1;
		}

		sprintf(Fname, "%s/Correspondences_VGA.txt", Path);	FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%d ", &frameID) != EOF)
		{
			frame3D_VGA[frameID - startF_VGA] = frameID;
			for (int jj = 0; jj < nVGAs; jj++)
				fscanf(fp, "%lf %lf ", &TableVGA[(frameID - startF_VGA)*nVGAs + jj].x, &TableVGA[(frameID - startF_VGA)*nVGAs + jj].y);
		}
		fclose(fp);

		//Get 3D init
		double *P3D_VGA = new double[3 * (stopF_VGA - startF_VGA + 1)];
		for (int ii = 0; ii < 3 * (stopF_VGA - startF_VGA + 1); ii++)
			P3D_VGA[ii] = 0.0;

		sprintf(Fname, "%s/C1_0.txt", Path); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%d ", &frameID) != EOF)
			fscanf(fp, "%lf %lf %lf", &P3D_VGA[3 * (frameID - startF_VGA)], &P3D_VGA[3 * (frameID - startF_VGA) + 1], &P3D_VGA[3 * (frameID - startF_VGA) + 2]);
		fclose(fp);

		printLOG("Set up BA ...");
		ceres::Problem problem;

		if (debug)
#ifdef _WINDOWS
			sprintf(Fname, "C:/temp/reprojectionB2.txt"), fp = fopen(Fname, "w+");
#else
			sprintf(Fname, "reprojectionB2.txt"), fp = fopen(Fname, "w+");
#endif

		vector<double> ReProjectionErrorX; ReProjectionErrorX.reserve(stopF_VGA - startF_VGA + 1);
		vector<double> ReProjectionErrorY; ReProjectionErrorY.reserve(stopF_VGA - startF_VGA + 1);

		int totalProjections = 0, nPossibleProjections = 0, minInliers = 999;
		for (int ii = startF_VGA; ii < stopF_VGA; ii++)
		{
			if (abs(P3D_VGA[3 * (ii - startF_VGA)]) + abs(P3D_VGA[3 * (ii - startF_VGA) + 1]) + abs(P3D_VGA[3 * (ii - startF_VGA) + 2]) < 0.01)
				continue;

			if (debug)
				fprintf(fp, "%d %.4f %.4f %.4f ", ii, P3D_VGA[3 * (ii - startF_VGA)], P3D_VGA[3 * (ii - startF_VGA) + 1], P3D_VGA[3 * (ii - startF_VGA) + 2]);

			int nvalidViews = 0;
			double pointErrX = 0, pointErrY = 0, residuals[2];
			for (int jj = 0; jj < nVGAs; jj++)
			{
				if (TableVGA[(ii - startF_VGA)*nVGAs + jj].x < 0 || TableVGA[(ii - startF_VGA)*nVGAs + jj].y < 0)
					continue;

				if (abs(CorpusInfo.camera[jj + nHDs].LensModel) != 0)
					continue;

				nPossibleProjections++;
				PinholeDistortionReprojectionDebug(CorpusInfo.camera[jj + nHDs].intrinsic, CorpusInfo.camera[jj + nHDs].distortion, CorpusInfo.camera[jj + nHDs].rt, TableVGA[(ii - startF_VGA)*nVGAs + jj],
					Point3d(P3D_VGA[3 * (ii - startF_VGA)], P3D_VGA[3 * (ii - startF_VGA) + 1], P3D_VGA[3 * (ii - startF_VGA) + 2]), residuals);

				if (!IsNumber(residuals[0]) || !IsFiniteNumber(residuals[0]))
					continue;

				//printLOG("%d %d %f %f\n", ii, jj, residuals[0], residuals[1]);
				if (abs(residuals[0]) + abs(residuals[1]) > threshold)
					continue;

				pointErrX += pow(residuals[0], 2), pointErrY += pow(residuals[1], 2), nvalidViews++;
				totalProjections++;

				if (debug)
					fprintf(fp, "%d %.4f %.4f %.4f %.4f ", jj, TableVGA[(ii - startF_VGA)*nVGAs + jj].x, TableVGA[(ii - startF_VGA)*nVGAs + jj].y, residuals[0], residuals[1]);
			}
			if (debug)
				fprintf(fp, "\n");

			if (minInliers > nvalidViews)
				minInliers = nvalidViews;
			ReProjectionErrorX.push_back(sqrt(pointErrX / nvalidViews)), ReProjectionErrorY.push_back(sqrt(pointErrY / nvalidViews));


			for (int jj = 0; jj < nVGAs; jj++)
			{
				if (TableVGA[(ii - startF_VGA)*nVGAs + jj].x < 0 || TableVGA[(ii - startF_VGA)*nVGAs + jj].y < 0)
					continue;

				if (abs(CorpusInfo.camera[jj + nHDs].LensModel) != 0)
					continue;

				if (!IsNumber(residuals[0]) || !IsFiniteNumber(residuals[0]))
					continue;

				PinholeDistortionReprojectionDebug(CorpusInfo.camera[jj + nHDs].intrinsic, CorpusInfo.camera[jj + nHDs].distortion, CorpusInfo.camera[jj + nHDs].rt, TableVGA[(ii - startF_VGA)*nVGAs + jj],
					Point3d(P3D_VGA[3 * (ii - startF_VGA)], P3D_VGA[3 * (ii - startF_VGA) + 1], P3D_VGA[3 * (ii - startF_VGA) + 2]), residuals);
				if (abs(residuals[0]) + abs(residuals[1]) > threshold)
					continue;

				ceres::CostFunction* cost_function = PinholeDistortionReprojectionError::Create(TableVGA[(ii - startF_VGA)*nVGAs + jj].x, TableVGA[(ii - startF_VGA)*nVGAs + jj].y, 1.0);
				problem.AddResidualBlock(cost_function, NULL, CorpusInfo.camera[jj + nHDs].intrinsic, CorpusInfo.camera[jj + nHDs].distortion, CorpusInfo.camera[jj + nHDs].rt, &P3D_VGA[3 * (ii - startF_VGA)]);

				if (fixIntrinsicVGA)
					problem.SetParameterBlockConstant(CorpusInfo.camera[jj + nHDs].intrinsic);
				if (fixDistortionVGA)
					problem.SetParameterBlockConstant(CorpusInfo.camera[jj + nHDs].distortion);
				if (fixPoseVGA)
					problem.SetParameterBlockConstant(CorpusInfo.camera[jj + nHDs].rt);
			}
		}
		if (debug)
			fclose(fp);

		printLOG("Done with problem building\n");

		double miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end()), maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
		double avgX = MeanArray(ReProjectionErrorX), stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
		double miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end()), maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
		double avgY = MeanArray(ReProjectionErrorY), stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
		printLOG("Reprojection error before BA \n Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
		printLOG("Total projections: %d/%.4d. Min inliers: %d\n", totalProjections, nPossibleProjections, minInliers);


		printLOG("...run BA...\n");
		ceres::Solver::Options options;
		options.num_threads = 4;
		options.max_num_iterations = 15;
		options.linear_solver_type = ceres::DENSE_SCHUR;
		options.minimizer_progress_to_stdout = true;
		options.trust_region_strategy_type = ceres::DOGLEG;
		options.use_nonmonotonic_steps = false;

		ceres::Solver::Summary summary;
		ceres::Solve(options, &problem, &summary);
		//std::cout << summary.BriefReport() << "\n";
		std::cout << summary.FullReport() << "\n";

		totalProjections = 0;
		ReProjectionErrorX.clear(), ReProjectionErrorY.clear();
		if (debug)
#ifdef _WINDOWS
			sprintf(Fname, "C:/temp/reprojectionA2.txt"), fp = fopen(Fname, "w+");
#else
			sprintf(Fname, "reprojectionA2.txt"), fp = fopen(Fname, "w+");
#endif

		for (int ii = startF_VGA; ii < stopF_VGA; ii++)
		{
			if (abs(P3D_VGA[3 * (ii - startF_VGA)]) + abs(P3D_VGA[3 * (ii - startF_VGA) + 1]) + abs(P3D_VGA[3 * (ii - startF_VGA) + 2]) < 0.01)
				continue;

			if (debug)
				fprintf(fp, "%d %.4f %.4f %.4f ", ii, P3D_VGA[3 * (ii - startF_VGA)], P3D_VGA[3 * (ii - startF_VGA) + 1], P3D_VGA[3 * (ii - startF_VGA) + 2]);
			int nvalidViews = 0;
			double pointErrX = 0, pointErrY = 0, residuals[2];
			for (int jj = 0; jj < nVGAs; jj++)
			{
				if (TableVGA[(ii - startF_VGA)*nVGAs + jj].x < 0 || TableVGA[(ii - startF_VGA)*nVGAs + jj].y < 0)
					continue;

				if (abs(CorpusInfo.camera[jj + nHDs].LensModel) != 0)
					continue;

				PinholeDistortionReprojectionDebug(CorpusInfo.camera[jj + nHDs].intrinsic, CorpusInfo.camera[jj + nHDs].distortion, CorpusInfo.camera[jj + nHDs].rt, TableVGA[(ii - startF_VGA)*nVGAs + jj],
					Point3d(P3D_VGA[3 * (ii - startF_VGA)], P3D_VGA[3 * (ii - startF_VGA) + 1], P3D_VGA[3 * (ii - startF_VGA) + 2]), residuals);

				if (!IsNumber(residuals[0]) || !IsFiniteNumber(residuals[0]))
					continue;

				if (abs(residuals[0]) + abs(residuals[1]) > threshold *1.5)
					continue;

				pointErrX += pow(residuals[0], 2), pointErrY += pow(residuals[1], 2), nvalidViews++;
				totalProjections++;

				if (debug)
					fprintf(fp, "%d %.4f %.4f %.4f %.4f ", jj, TableVGA[(ii - startF_VGA)*nVGAs + jj].x, TableVGA[(ii - startF_VGA)*nVGAs + jj].y, residuals[0], residuals[1]);
			}
			if (debug)
				fprintf(fp, "\n");
			ReProjectionErrorX.push_back(sqrt(pointErrX / nvalidViews)), ReProjectionErrorY.push_back(sqrt(pointErrY / nvalidViews));
		}
		if (debug)
			fclose(fp);

		miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end()), maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
		avgX = MeanArray(ReProjectionErrorX), stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
		miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end()), maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
		avgY = MeanArray(ReProjectionErrorY), stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
		printLOG("Reprojection error after BA \n Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
		printLOG("Total projections: %d/%d\n", totalProjections, nPossibleProjections);

		sprintf(Fname, "%s/BA_Camera_AllParams_after3.txt", Path);
		ReSaveBundleAdjustedNVMResults(Fname, CorpusInfo, 1.0);

		delete[]P3D_VGA, delete[]TableVGA, delete[] frame3D_VGA;
	}

	return 0;
}
int BundleAdjustDomeMultiNVM(char *Path, int nNvm, int maxPtsPerNvM, bool fixIntrinsic, bool fixDistortion, bool fixPose, bool debug)
{
	char Fname[512];
	Corpus CorpusInfo;

	const int maxCams = 30 + 24 * 20;
	double thresh = 4.0;

	sprintf(Fname, "%s/BA_Camera_AllParams_after.txt", Path);
	readBundleAdjustedNVMResults(Fname, CorpusInfo);

	printLOG("Set up BA ...");
	ceres::Problem problem;

	vector<int> *AllViewIDList = new vector<int>[maxPtsPerNvM * nNvm];
	vector<Point2d>* AllUVList = new vector<Point2d>[maxPtsPerNvM * nNvm];

	int nvis, viewID, curPid = 0;
	double u, v;
	FILE *fp = 0;
	for (int nvmID = 1; nvmID <= nNvm; nvmID++)
	{
		//Read correspondences
		sprintf(Fname, "%s/calib%d_corres.txt", Path, nvmID); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%d", &nvis) != EOF)
		{
			AllViewIDList[curPid].reserve(nvis), AllUVList[curPid].reserve(nvis);
			for (int ii = 0; ii < nvis; ii++)
			{
				fscanf(fp, "%d %lf %lf", &viewID, &u, &v);
				AllViewIDList[curPid].push_back(viewID);
				AllUVList[curPid].push_back(Point2d(u, v));
			}
			curPid++;
		}
	}
	printLOG("Finished loading data\n");

	Point3d p3d;
	int minInliers, nLargeErr = 0, curValidPid = 0;
	double minInliersPercent = 1.0, residuals[2];
	double P[12 * maxCams];
	double *A = new double[6 * maxCams], *B = new double[2 * maxCams], *tP = new double[12 * maxCams];
	vector<double> ReProjectionError; ReProjectionError.reserve(curPid);
	double *Allp3D = new double[curPid * 3];
	int *ValidPid = new int[curPid];

	if (debug)
#ifdef _WINDOWS
		sprintf(Fname, "C:/temp/reprojectionB.txt"), fp = fopen(Fname, "w+");
#else
		sprintf(Fname, "reprojectionB.txt"), fp = fopen(Fname, "w+");
#endif


	vector<int> viewIDList, Inliers;
	vector<Point2d> uvList, uvListUndistorted;
	for (int pid = 0; pid < curPid; pid++)
	{
		ValidPid[pid] = 0;
		nvis = (int)AllViewIDList[pid].size();
		viewIDList.clear(), uvList.clear(), uvListUndistorted.clear();
		for (int ii = 0; ii < nvis; ii++)
		{
			viewIDList.push_back(AllViewIDList[pid][ii]);
			uvList.push_back(AllUVList[pid][ii]);
			uvListUndistorted.push_back(AllUVList[pid][ii]);
		}

		//triangulate
		for (int jj = 0; jj < nvis; jj++)
		{
			int viewID = viewIDList[jj];
			LensCorrectionPoint(&uvListUndistorted[jj], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
			for (int kk = 0; kk < 12; kk++)
				P[12 * jj + kk] = CorpusInfo.camera[viewID].P[kk];
		}

		bool passed;
		Inliers.clear();
		double avgerror = NviewTriangulationRANSAC(&uvListUndistorted, P, &p3d, &passed, &Inliers, nvis, 1, 2, 100, 0.7, thresh, A, B, tP, false, false);
		if (!passed)
		{
			nLargeErr++;
			printLOG("Ave Error is larger than %f at point %d \n", thresh, pid);
			continue;
		}
		else
		{
			int ninlier = 0;
			for (int kk = 0; kk < Inliers.size(); kk++)
				if (Inliers.at(kk))
					ninlier++;

			if (ninlier < 3)
			{
				//printLOG("Two few matches at point %d \n", pid);
				continue;
			}

			ReProjectionError.push_back(avgerror);
			double inlierPercent = 1.0*ninlier / Inliers.size();
			if (minInliersPercent > inlierPercent)
				minInliersPercent = inlierPercent, minInliers = ninlier;
		}
		Allp3D[pid * 3] = p3d.x, Allp3D[pid * 3 + 1] = p3d.y, Allp3D[pid * 3 + 2] = p3d.z;
		ValidPid[pid] = 1;

		if (debug)
			fprintf(fp, "%d %.4f %.4f %.4f ", pid, p3d.x, p3d.y, p3d.z);

		for (int jj = 0; jj < nvis; jj++)
		{
			if (Inliers[jj] == 0)
				continue;

			PinholeDistortionReprojectionDebug(CorpusInfo.camera[viewIDList[jj]].intrinsic, CorpusInfo.camera[viewIDList[jj]].distortion, CorpusInfo.camera[viewIDList[jj]].rt, uvList[jj], p3d, residuals);
			if (abs(residuals[0]) + abs(residuals[1]) > thresh)
				continue;

			if (debug)
				fprintf(fp, "%d %.4f %.4f %.4f %.4f ", jj, uvList[jj].x, uvList[jj].y, residuals[0], residuals[1]);

			ceres::CostFunction* cost_function = PinholeDistortionReprojectionError::Create(uvList[jj].x, uvList[jj].y, 1.0);
			problem.AddResidualBlock(cost_function, NULL, CorpusInfo.camera[viewIDList[jj]].intrinsic, CorpusInfo.camera[viewIDList[jj]].distortion, CorpusInfo.camera[viewIDList[jj]].rt, &Allp3D[3 * pid]);

			if (fixIntrinsic)
				problem.SetParameterBlockConstant(CorpusInfo.camera[viewIDList[jj]].intrinsic);
			if (fixDistortion)
				problem.SetParameterBlockConstant(CorpusInfo.camera[viewIDList[jj]].distortion);
			if (fixPose)
				problem.SetParameterBlockConstant(CorpusInfo.camera[viewIDList[jj]].rt);
		}
		curValidPid++;

		if (debug)
			fprintf(fp, "\n");
	}
	if (debug)
		fclose(fp);

	printLOG("Done with problem building\n");

	double miniE = *min_element(ReProjectionError.begin(), ReProjectionError.end()), maxiE = *max_element(ReProjectionError.begin(), ReProjectionError.end());
	double avgE = MeanArray(ReProjectionError), stdE = sqrt(VarianceArray(ReProjectionError, avgE));
	printLOG("Reprojection error after BA \nMin: %.2f Max: %.2f Mean: %.2f Std: %.2f\n", miniE, maxiE, avgE, stdE);
	printLOG("Total points: %d/%.4d. #Large error: %.4d. Min inliers: %.2f%% (%d)\n", curValidPid, curPid, nLargeErr, minInliersPercent, minInliers);


	printLOG("...run BA...\n");
	ceres::Solver::Options options;
	options.num_threads = 4;
	options.max_num_iterations = 50;
	if (CorpusInfo.nCameras < 200)
	{
		options.linear_solver_type = ceres::DENSE_SCHUR;
		options.trust_region_strategy_type = ceres::DOGLEG;
		options.use_nonmonotonic_steps = true;
	}
	else
	{
#ifdef _WINDOWS
		options.linear_solver_type = ceres::ITERATIVE_SCHUR;
		options.preconditioner_type = ceres::PreconditionerType::JACOBI;
		options.visibility_clustering_type = ceres::VisibilityClusteringType::CANONICAL_VIEWS;
		options.sparse_linear_algebra_library_type = ceres::SUITE_SPARSE;
		options.minimizer_progress_to_stdout = true;
#else
		printLOG("Error! Only works for windows\n");
#endif
	}

	ceres::Solver::Summary summary;
	ceres::Solve(options, &problem, &summary);
	std::cout << summary.FullReport() << "\n";


	if (debug)
#ifdef _WINDOWS
		sprintf(Fname, "C:/temp/reprojectionA.txt"), fp = fopen(Fname, "w+");
#else
		sprintf(Fname, "reprojectionA.txt"), fp = fopen(Fname, "w+");
#endif


	ReProjectionError.clear();
	for (int pid = 0; pid < curPid; pid++)
	{
		if (ValidPid[pid] == 0)
			continue;

		nvis = (int)AllViewIDList[pid].size();
		viewIDList.clear(), uvList.clear();
		for (int ii = 0; ii < nvis; ii++)
		{
			viewIDList.push_back(AllViewIDList[pid][ii]);
			uvList.push_back(AllUVList[pid][ii]);
		}
		p3d.x = Allp3D[pid * 3], p3d.y = Allp3D[pid * 3 + 1], p3d.z = Allp3D[pid * 3 + 2];

		if (debug)
			fprintf(fp, "%d %.4f %.4f %.4f ", pid, Allp3D[pid * 3], Allp3D[pid * 3 + 1], Allp3D[pid * 3 + 2]);

		int jj, nvalidprojections = 0;
		double Error = 0.0;
		for (jj = 0; jj < nvis; jj++)
		{
			PinholeDistortionReprojectionDebug(CorpusInfo.camera[viewIDList[jj]].intrinsic, CorpusInfo.camera[viewIDList[jj]].distortion, CorpusInfo.camera[viewIDList[jj]].rt, uvList[jj], p3d, residuals);
			if (abs(residuals[0]) + abs(residuals[1]) > 2 * thresh)
				continue;
			nvalidprojections++;
			Error += residuals[0] * residuals[0] + residuals[1] * residuals[1];

			if (debug)
				fprintf(fp, "%d %.4f %.4f %.4f %.4f ", jj, uvList[jj].x, uvList[jj].y, residuals[0], residuals[1]);
		}
		if (jj > 0)
			ReProjectionError.push_back(sqrt(Error / nvalidprojections));

		if (debug)
			fprintf(fp, "\n");
	}
	if (debug)
		fclose(fp);

	sprintf(Fname, "%s/3Dpts.txt", Path);	fp = fopen(Fname, "w+");
	for (int pid = 0; pid < curPid; pid++)
	{
		if (ValidPid[pid] == 0)
			continue;
		fprintf(fp, "%f %f %f \n", Allp3D[pid * 3], Allp3D[pid * 3 + 1], Allp3D[pid * 3 + 2]);
	}
	fclose(fp);

	miniE = *min_element(ReProjectionError.begin(), ReProjectionError.end()), maxiE = *max_element(ReProjectionError.begin(), ReProjectionError.end());
	avgE = MeanArray(ReProjectionError), stdE = sqrt(VarianceArray(ReProjectionError, avgE));
	printLOG("Reprojection error after BA \nMin: %.2f Max: %.2f Mean: %.2f Std: %.2f\n", miniE, maxiE, avgE, stdE);
	printLOG("Total points: %d/%.4d. Min inliers: %.2f%% (%d)\n", curValidPid, curPid, minInliersPercent, minInliers);

	sprintf(Fname, "%s/BA_Camera_AllParams_after2.txt", Path);
	saveBundleAdjustedNVMResults(Fname, CorpusInfo);

	delete[]Allp3D, delete[]ValidPid, delete[]A, delete[]B, delete[]tP;
	return 0;
}
int ReCalibratedFromGroundTruthCorrespondences(char *Path, int camID, int startF, int stopF, int Allnpts, int ShutterModel)
{
	char Fname[1024]; FILE *fp = 0;
	int fixIntrinsic = 1, fixDistortion = 1, fixPose = 1, fixfirstCamPose = 1, distortionCorrected = 0, fixSkew = 0, fixPrism = 0, nViewsPlus = 3;

	Corpus CorpusInfo;
	sprintf(Fname, "%s/Corpus/BA_Camera_AllParams_after.txt", Path);
	if (!readBundleAdjustedNVMResults(Fname, CorpusInfo))
		return 1;

	vector<int>AvailableViews;
	for (int fid = startF; fid <= stopF; fid++)
	{
		if (CorpusInfo.camera[fid].valid)
		{
			AvailableViews.push_back(fid);
			CorpusInfo.camera[fid].threshold = 1000000.0; //make sure that all points are inliers
			CorpusInfo.camera[fid].ShutterModel = ShutterModel;
		}
	}

	//Setup 2d point correspondences for all views according to the frame-level sync result
	vector<Point3d> P3D(Allnpts);
	vector <vector<int> > viewIdAll3D;
	vector<vector<Point2d> >  uvAll3D;
	vector<vector<double> > scaleAll3D;

	vector<int>viewID3D;
	vector<double>scale3D;
	for (int fid = startF; fid <= stopF; fid++)
		viewID3D.push_back(fid),
		scale3D.push_back(1.0);

	int  nframes = stopF - startF + 1;
	Point2d *Correspondences = new Point2d[Allnpts*nframes];
	vector<int> NotAvail;
	for (int fid = startF; fid <= stopF; fid++)
	{
		sprintf(Fname, "%s/%d/Corner/CV_%.4d.txt", Path, camID, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot open %s\n", Fname);

			for (int pid = 0; pid < Allnpts; pid++)
				Correspondences[fid + pid * nframes] = Point2d(-1, -1);

			CorpusInfo.camera[fid].valid = false;
			continue;
		}
		for (int pid = 0; pid < Allnpts; pid++)
			fscanf(fp, "%lf %lf ", &Correspondences[fid + pid * nframes].x, &Correspondences[fid + pid * nframes].y);
		fclose(fp);
	}

	vector<Point2d> uv3D;
	for (int pid = 0; pid < Allnpts; pid++)
	{
		viewIdAll3D.push_back(viewID3D);
		scaleAll3D.push_back(scale3D);

		uv3D.clear();
		for (int fid = 0; fid < nframes; fid++)
			uv3D.push_back(Correspondences[fid + pid * nframes]);

		uvAll3D.push_back(uv3D);
	}

	//Retriangulate, assuming global shutter
	/*double error, point3d[3];
	double *P = new double[12 * nframes], *A = new double[6 * nframes], *B = new double[2 * nframes], *points2d = new double[nframes * 2];

	Point3d p3d;
	vector<Point2d> p2d;
	for (int ii = 0; ii < Allnpts; ii++)
	{
	if (viewIdAll3D[ii].size() > 1)
	{
	p2d.clear();
	int count = 0;
	for (int jj = 0; jj < viewIdAll3D[ii].size(); jj++)
	{
	if (CorpusInfo.camera[viewIdAll3D[ii][jj]].valid)
	{
	for (int kk = 0; kk < 12; kk++)
	P[count * 12 + kk] = CorpusInfo.camera[viewIdAll3D[ii][jj]].P[kk];
	p2d.push_back(uvAll3D[ii][jj]);

	int viewID = viewIdAll3D[ii][jj];
	LensCorrectionPoint(&p2d[count], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
	count++;
	}
	}

	NviewTriangulation(&p2d, P, &p3d, count, 1, NULL, A, B);
	P3D[ii] = p3d;
	}
	}
	delete[]P, delete[]A, delete[]B, delete[]points2d;*/
	NviewTriangulation(CorpusInfo.camera, CorpusInfo.nCameras, viewIdAll3D, uvAll3D, P3D);

	//Re-adjust the bundle
	vector<int>sharedCam;
	for (int ii = 0; ii < nframes; ii++)
		sharedCam.push_back(0);
	vector<bool>GoodPoints;

	int fixlocalPose = 0, fix3D = 0;
	GenericBundleAdjustment(Path, CorpusInfo.camera, P3D, viewIdAll3D, uvAll3D, scaleAll3D,
		sharedCam, (int)AvailableViews.size(), fixIntrinsic, fixDistortion, fixPose, fixfirstCamPose, fixlocalPose, fix3D, fixSkew, fixPrism, distortionCorrected, nViewsPlus, 0, false, false, false);

	//sprintf(Fname, "%s/rBA_Camera_AllParams_after.txt", Path);
	//ReSaveBundleAdjustedNVMResults(Fname, CorpusInfo);

	sprintf(Fname, "%s/Corpus", Path);
	vector<Point3i> dummy; SaveCurrentSfmGL(Fname, CorpusInfo.camera, AvailableViews, P3D, dummy);
	vector<int> vFrames;
	for (int ii = 0; ii < nframes; ii++)
		vFrames.push_back(ii);
	//visualizationDriver(Path, vFrames, startF, stopF, increF, false, false, false, false, false, 0, ShutterModel);

	delete[]Correspondences;
	return 0;
}
int RefineVisualSfMAndCreateCorpus(char *Path, int nimages, int ShutterModel, double threshold, int fixIntrinsic, int fixDistortion, int fixPose, int fixfirstCamPose, int fixSkew, int fixPrism, int distortionCorrected, int nViewsPlus, int LossType, int doubleRefinement)
{
	char Fname[512];

	vector<Point2i> ImgSize;
	for (int ii = 0; ii < nimages; ii++)
	{
		sprintf(Fname, "%s/Size/%.4d.txt", Path, ii);
		if (IsFileExist(Fname) == 0)
		{
			printLOG("Cannot load %s.", Fname);
			ImgSize.push_back(Point2i(0, 0));
		}
		else
		{
			FILE *fp = fopen(Fname, "r");
			int width, height;  fscanf(fp, "%d %d", &width, &height);
			fclose(fp);
			ImgSize.push_back(Point2i(width, height));
		}
	}

	//read all visualsfm sift. Assume all cameras are reconstructed
	printLOG("Reading sift points ...");
	vector<KeyPoint> *AllKeyPts = new vector<KeyPoint>[nimages];
	Mat *AllDesc = new Mat[nimages];
	for (int ii = 0; ii < nimages; ii++)
	{
		sprintf(Fname, "%s/%.4d.sift", Path, ii);
		readVisualSFMSiftGPU(Fname, AllKeyPts[ii], AllDesc[ii]);
	}
	if (AllDesc == NULL)
		printLOG("\n\nCorpus does not contain feature descriptor\n\n");
	printLOG("\n");

	//Fill up the visSfm corpus data. Assume all cameras are reconstructed
	printLOG("Reading corpus info ....\n");
	Corpus CorpusInfo;
	if (!readColMap(Path, CorpusInfo, nViewsPlus, AllKeyPts, AllDesc, nimages))
		return 1;
	delete[]AllKeyPts, delete[]AllDesc;
	printLOG("%d %d+ 3D points", CorpusInfo.n3dPoints, nViewsPlus);

	int nSift, totalSift = 0;
	CorpusInfo.IDCumView.reserve(nimages + 1);
	for (int ii = 0; ii < nimages; ii++)
	{
		CorpusInfo.IDCumView.push_back(totalSift);
		nSift = (int)CorpusInfo.uvAllViews[ii].size();
		totalSift += nSift;
	}
	CorpusInfo.IDCumView.push_back(totalSift);
	printLOG("Done\n");

	//Setup frames/camearas with shared intrinsic
	vector<int>SharedCameraToBuildCorpus, SharedIntrinsicCameras;
	sprintf(Fname, "%s/CamerasWithFixedIntrinsic.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int camID;
		while (fscanf(fp, "%d ", &camID) != EOF)
			SharedIntrinsicCameras.push_back(camID);
		fclose(fp);
	}

	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
		SharedCameraToBuildCorpus.push_back(-1); //first visible camera is the reference camera to build the corpus

	int nDevices = 0;
	if (SharedIntrinsicCameras.size() > 0) //some shares
	{
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int camID, deviceID;
			while (fscanf(fp, "%d %d", &camID, &deviceID) != EOF)
			{
				nDevices = max(nDevices, deviceID);
				bool shared = false;
				for (size_t ii = 0; ii < SharedIntrinsicCameras.size() && !shared; ii++)
					if (SharedIntrinsicCameras[ii] == deviceID)
						shared = true;
				if (shared)
					SharedCameraToBuildCorpus[camID] = deviceID;
			}
			fclose(fp);
		}
	}

	//Setup lens and shutter Model
	int LensModel = RADIAL_TANGENTIAL_PRISM;
	vector<Point2i> CameraLensModel;
	sprintf(Fname, "%s/CameraLensModel.txt", Path); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int CameraGroup;
		while (fscanf(fp, "%d %d ", &CameraGroup, &LensModel) != EOF)
			CameraLensModel.push_back(Point2i(CameraGroup, LensModel));
		fclose(fp);
	}

	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
		CorpusInfo.camera[ii].LensModel = RADIAL_TANGENTIAL_PRISM;
	if (CameraLensModel.size() > 0)
	{
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int CorpusCamID, deviceID;
			while (fscanf(fp, "%d %d", &CorpusCamID, &deviceID) != EOF)
				for (size_t ii = 0; ii < CameraLensModel.size(); ii++)
					if (CameraLensModel[ii].x == deviceID)
						CorpusInfo.camera[CorpusCamID].LensModel = CameraLensModel[ii].y;
			fclose(fp);
		}
	}

	//Refine visSfm corpus
	printLOG("Refine corpus ....\n");
	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
	{
		CorpusInfo.camera[ii].threshold = threshold * 20; //make sure that most points are inliers
		CorpusInfo.camera[ii].ShutterModel = ShutterModel;
	}

	for (int pid = 0; pid < CorpusInfo.scaleAll3D.size(); pid++)
		for (int fid = 0; fid < CorpusInfo.scaleAll3D[pid].size(); fid++)
			CorpusInfo.scaleAll3D[pid][fid] = 1.0;

	int fixLocalPose = 0, fix3D = 0;
	vector<bool>GoodPoints;
	GenericBundleAdjustment(Path, CorpusInfo.camera, CorpusInfo.xyz, CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D, SharedCameraToBuildCorpus, nimages,
		fixIntrinsic, fixDistortion, fixPose, fixfirstCamPose, fixLocalPose, fix3D, fixSkew, fixPrism, distortionCorrected, nViewsPlus, LossType, false, false, true);

	if (doubleRefinement)
	{
		for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
			CorpusInfo.camera[ii].threshold = threshold;

		GenericBundleAdjustment(Path, CorpusInfo.camera, CorpusInfo.xyz, CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D, SharedCameraToBuildCorpus, nimages,
			fixIntrinsic, fixDistortion, fixPose, fixfirstCamPose, fixLocalPose, fix3D, fixSkew, fixPrism, distortionCorrected, nViewsPlus, LossType, false, false, true);
	}
	printLOG("\n");

	//Now, can undistort points
	if (distortionCorrected == 0)
	{
		for (int jj = 0; jj < (int)CorpusInfo.xyz.size(); jj++)
		{
			for (int ii = 0; ii < (int)CorpusInfo.uvAll3D[jj].size(); ii++)
			{
				int viewID = CorpusInfo.viewIdAll3D[jj][ii];
				GetKFromIntrinsic(CorpusInfo.camera[viewID]);
				if (CorpusInfo.camera[viewID].LensModel == FISHEYE)
					FishEyeCorrectionPoint(&CorpusInfo.uvAll3D[jj][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion[0]);
				else
					LensCorrectionPoint(&CorpusInfo.uvAll3D[jj][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
			}
		}

		for (int viewID = 0; viewID < CorpusInfo.nCameras; viewID++)
		{
			for (int ii = 0; ii < (int)CorpusInfo.uvAllViews[viewID].size(); ii++)
			{
				GetKFromIntrinsic(CorpusInfo.camera[viewID]);
				if (CorpusInfo.camera[viewID].LensModel == FISHEYE)
					FishEyeCorrectionPoint(&CorpusInfo.uvAllViews[viewID][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion[0]);
				else
					LensCorrectionPoint(&CorpusInfo.uvAllViews[viewID][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
			}
		}
	}

	//write CorpusInfo
	printLOG("Write corpus info ....");
	sprintf(Fname, "%s/BA_Camera_AllParams_after.txt", Path);
	ReSaveBundleAdjustedNVMResults(Fname, CorpusInfo);
	SaveCorpusInfo(Path, CorpusInfo);

	/*//Please run mode 5, module 10, useNewPose after the video BA
	printLOG("Write Colmap dense mvs input\n");
	CorpusInfo.twoDIdAllViews = new vector<int>[CorpusInfo.nCameras];
	for (int vid = 0; vid < CorpusInfo.nCameras; vid++)
	{
		for (int pid = 0; pid < CorpusInfo.uvAllViews[vid].size(); pid++)
		{
			int TwoDiD = CorpusInfo.SiftIdAllViews[vid][pid];
			CorpusInfo.twoDIdAllViews[vid].push_back(TwoDiD);

		}
	}
	writeColMap4DenseStereo(Path, CorpusInfo); //need twoDIdAllViews*/

	if (SharedCameraToBuildCorpus.size() > 0)
	{
		SharedCameraToBuildCorpus.clear();
		for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
			SharedCameraToBuildCorpus.push_back(-1); //first visible camera is the reference camera to build the corpus
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); FILE *fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int camID, group;
			while (fscanf(fp, "%d %d", &camID, &group) != EOF)
				SharedCameraToBuildCorpus[camID] = group;
			fclose(fp);
		}
		SaveAvgIntrinsicResults(Path, CorpusInfo.camera, SharedCameraToBuildCorpus);
	}

	vector<int>AvailViews;
	for (int ii = 0; ii < nimages; ii++)
		AvailViews.push_back(ii);
	SaveCurrentSfmGL(Path, CorpusInfo.camera, AvailViews, CorpusInfo.xyz, CorpusInfo.rgb);

	printLOG("****NOTE: 2d points in Corpus are corrected***\n");

	return 0;
}

int GetNumValid3Ds(vector<Point3d> &Vxyz)
{
	int nvalid3D = 0;
	for (size_t ii = 0; ii < Vxyz.size(); ii++)
		if (IsValid3D(Vxyz[ii]))
			nvalid3D++;
	return nvalid3D;
}
Point2i GetGlobalAndLocalPointsStat(vector <vector<int> > &viewIdAll3D, vector<int>&GlobalAnchor3DId, vector<Point3d> &Vxyz)
{
	Point2i globalLocal(0, 0);
	for (int pid = 0; pid < Vxyz.size(); pid++)
	{
		if (!IsValid3D(Vxyz[pid]))
			continue;
		if (viewIdAll3D[pid].size() > 0 && GlobalAnchor3DId[pid] > -1)
			globalLocal.x++;
		else if (viewIdAll3D[pid].size() > 0 && GlobalAnchor3DId[pid] == -1)
			globalLocal.y++;
	}
	return globalLocal;
}

inline bool HasPointPositiveDepth(double *P, Point3d &xyz)
{
	return (P[8] * xyz.x + P[9] * xyz.y + P[10] * xyz.z + 1.0) > std::numeric_limits<double>::epsilon();
}
double CalculateTriangulationAngle(double *center1, double * center2, double *point)
{
	Map< const Vector3d > proj_center1(center1, 3);
	Map< const Vector3d > proj_center2(center2, 3);
	Map< const Vector3d > point3D(point, 3);
	const double baseline2 = (proj_center1 - proj_center2).squaredNorm();

	const double ray1 = (point3D - proj_center1).norm();
	const double ray2 = (point3D - proj_center2).norm();

	// Angle between rays at point within the enclosing triangle
	const double angle = std::abs(std::acos((ray1 * ray1 + ray2 * ray2 - baseline2) / (2 * ray1 * ray2)));

	if (!IsNumber(angle))
		return 0;
	else
		return min(angle, M_PI - angle) / M_PI * 180.0;// Triangulation is unstable for acute angles (far away points) and obtuse angles (close points), so always compute the minimum angle between the two intersecting rays.
}
vector<double> CalculateTriangulationAngles(double *C1, double *C2, vector<Point3d> &XYZ)
{
	// Baseline length between cameras.
	const double baseline2 = pow(C1[0] - C2[0], 2) + pow(C1[1] - C2[1], 2) + pow(C1[2] - C2[2], 2);

	vector<double> angles(XYZ.size());

	for (size_t i = 0; i < XYZ.size(); ++i)
	{
		// Ray lengths from cameras to point.
		const double ray1 = pow(C1[0] - XYZ[i].x, 2) + pow(C1[1] - XYZ[i].y, 2) + pow(C1[2] - XYZ[i].z, 2);
		const double ray2 = pow(C2[0] - XYZ[i].x, 2) + pow(C2[1] - XYZ[i].y, 2) + pow(C2[2] - XYZ[i].z, 2);

		// Angle between rays at point within the enclosing triangle, see "law of cosines".
		const double angle = std::abs(std::acos((ray1 + ray2 - baseline2) / (2 * sqrt(ray1 * ray2))));

		if (!IsNumber(angle))
			angles[i] = 0;
		else
			angles[i] = min(angle, M_PI - angle); // Triangulation is unstable for acute angles (far away points) and obtuse angles (close points), so always compute the minimum angle between the two intersecting rays.
	}

	return angles;
}
bool FilterPoints3DWithSmallTriangulationAngle(Corpus &VCorpusInfo, vector<int> &Vcid, Point3d &xyz, double tri_local_min_tri_angle)
{
	if (Vcid.size() < 2)
		return false;

	// Minimum triangulation angle in radians.
	const double min_tri_angle_rad = tri_local_min_tri_angle / 180 * Pi;

	// Calculate triangulation angle for all pairwise combinations of image poses in the track. Only delete point if none of the combinations has a sufficient triangulation angle.
	bool keep_point = false;
	vector<Point3d> Vxyz(1); Vxyz[0] = xyz;
	for (size_t ii = 0; ii < Vcid.size() - 1; ii++)
	{
		for (size_t jj = ii + 1; jj < Vcid.size(); jj++)
		{
			vector<double> angle = CalculateTriangulationAngles(VCorpusInfo.camera[Vcid[ii]].camCenter, VCorpusInfo.camera[Vcid[jj]].camCenter, Vxyz);
			if (angle[0] >= min_tri_angle_rad)
			{
				keep_point = true;
				break;
			}
		}
	}
	if (!keep_point)
		xyz.x = 0, xyz.y = 0, xyz.z = 0;

	return keep_point;
}

Point2i FindTheBestStartingTwoViews(Corpus &CorpusInfo, int minNpts = 10)
{
	int nCams = CorpusInfo.nCameras;
	double CostBest = 0;
	Point2i BestPair;
	for (int cid0 = 0; cid0 < nCams - 1; cid0++)
	{
		for (int cid1 = cid0 + 1; cid1 < nCams; cid1++)
		{
			int nPoints = 0;
			double dist2D = 0;
			for (int pid = 0; pid < CorpusInfo.n3dPoints; pid++)
			{
				vector<int> vid;
				for (int ii = 0; vid.size() < 2 && ii < CorpusInfo.viewIdAll3D[pid].size(); ii++)
				{
					if (CorpusInfo.viewIdAll3D[pid][ii] == cid0)
						vid.push_back(ii);
					if (CorpusInfo.viewIdAll3D[pid][ii] == cid1)
						vid.push_back(ii);
				}
				if (vid.size() == 2)
					dist2D += norm(CorpusInfo.uvAll3D[pid][vid[0]] - CorpusInfo.uvAll3D[pid][vid[1]]), nPoints++;
			}
			double Cost = dist2D;// dist2D*nPoints;
			if (Cost > CostBest && nPoints > minNpts)
				CostBest = Cost, BestPair.x = cid0, BestPair.y = cid1;
		}
	}
	return BestPair;
}
int FindNextCameraToAdd(Corpus &CorpusInfo, vector<int> &addedCameras, vector<int> &CameraInQueue, int penalizedCamera = -1, int minNptsPerCam = 10)
{
	int bestCamera = CameraInQueue[0];
	double bestScore = 0;
	for (int ii = 0; ii < (int)CameraInQueue.size(); ii++)
	{
		int cid0 = CameraInQueue[ii];
		if (cid0 == penalizedCamera)
			continue;

		int nptsCommon = 0; double dist2D = 0;
		for (int jj = 0; jj < (int)addedCameras.size(); jj++)
		{
			int cid1 = addedCameras[jj];
			for (int pid = 0; pid < CorpusInfo.n3dPoints; pid++)
			{
				vector<int> vid;
				for (int ii = 0; vid.size() < 2 && ii < CorpusInfo.viewIdAll3D[pid].size(); ii++)
				{
					if (CorpusInfo.viewIdAll3D[pid][ii] == cid0)
						vid.push_back(ii);
					if (CorpusInfo.viewIdAll3D[pid][ii] == cid1)
						vid.push_back(ii);
				}
				if (vid.size() == 2)
					dist2D += norm(CorpusInfo.uvAll3D[pid][vid[0]] - CorpusInfo.uvAll3D[pid][vid[1]]), nptsCommon++;
			}
		}
		if (nptsCommon > minNptsPerCam && dist2D > bestScore)
			bestScore = dist2D, bestCamera = cid0;
	}

	return bestCamera;
}
//Note that pts1 and pts2 will be undistored. Becareful when passing them as reference!
bool TwoViewReconstruction(CameraData &Cam1, CameraData &Cam2, vector<Point2d> &pts1, vector<Point2d> &pts2, vector<Point3d> &P3D, SfMPara mySfMPara, int verbose = 0)
{
	if (pts1.size() < mySfMPara.nInliersThresh || pts2.size() < mySfMPara.nInliersThresh)
		return false;

	if (mySfMPara.distortionCorrected == 0)
	{
		if (Cam1.LensModel == FISHEYE)
			FishEyeCorrectionPoint(pts1, Cam1.K, Cam1.distortion[0]);
		else
			LensCorrectionPoint(pts1, Cam1.K, Cam1.distortion);

		if (Cam2.LensModel == FISHEYE)
			FishEyeCorrectionPoint(pts2, Cam2.K, Cam2.distortion[0]);
		else
			LensCorrectionPoint(pts2, Cam2.K, Cam2.distortion);
	}

	Mat cvInliers, cvK1 = Mat(3, 3, CV_64F, Cam1.K), cvK2 = Mat(3, 3, CV_64F, Cam2.K);
	Mat E = findEssentialMat(pts1, pts2, cvK1, cvK2, 8, 0.99, mySfMPara.reProjectionBAThresh, cvInliers);
	int ninliers = 0;
	for (int ii = 0; ii < cvInliers.cols; ii++)
		if (cvInliers.at<bool>(ii))
			ninliers++;

	Mat R_5pt, rvec_5pt, tvec_5pt;
	if (recoverPose(E, pts1, pts2, R_5pt, tvec_5pt, cvK1, cvK2, noArray()) < 6)
		return 9e9;

	Rodrigues(R_5pt, rvec_5pt);
	if (ninliers >= 5)
	{
		P3D.clear();
		Rodrigues(R_5pt, rvec_5pt);
		for (int ii = 0; ii < 3; ii++)
			Cam1.rt[ii] = 0, Cam1.rt[ii + 3] = 0, Cam2.rt[ii] = rvec_5pt.at<double>(ii), Cam2.rt[ii + 3] = tvec_5pt.at<double>(ii);

		vector<int> validCorres;
		double rmse = CalibratedTwoViewBA(Cam1.intrinsic, Cam2.intrinsic, Cam1.rt, Cam2.rt, pts1, pts2, P3D, validCorres, mySfMPara.reProjectionBAThresh, 0, verbose); //Since the points are undistorted, simple pinhole model can be used.

		getRfromr(Cam1.rt, Cam1.R), getRfromr(Cam2.rt, Cam2.R);
		GetCfromT(Cam1.R, Cam1.rt + 3, Cam1.camCenter), GetCfromT(Cam2.R, Cam2.rt + 3, Cam2.camCenter);
		double angle = Median(CalculateTriangulationAngles(Cam1.camCenter, Cam2.camCenter, P3D)) / M_PI * 180.0;

		//if (verbose == 1)
		//	printLOG("Median angle: %2f. Cost: %.3e\n\n", angle / M_PI*180.0, rmse / angle);

		//if (results.first > minInliers)
		//	return results.second / results.first / angle;
		double txtz = Cam2.rt[3] / Cam2.rt[5], tytz = Cam2.rt[4] / Cam2.rt[5];
		if (validCorres.size() > mySfMPara.nInliersThresh && rmse < mySfMPara.reProjectionBAThresh && angle > mySfMPara.Init_min_tri_angle &&   max(txtz, tytz) > mySfMPara.InitForwadMotionRatioThresh)//forward motion
			return true;
	}
	return false;
}

int sSfM_FirstTwoViews(Corpus &VCorpusInfo, SfMPara &mySfMPara, int debug)
{
	vector<Point3d> P3D;
	vector<Point2d>  pts1, pts2;

	CameraData BestCam1, BestCam2;

	//let sort pairs according to the #ninlers
	vector<Point2i> CidICidJ;
	vector<int> NumInliers, SNumInliers; vector<size_t> SIndex;
	for (int cidI = 0; cidI < VCorpusInfo.nCameras - 1; cidI++)
	{
		for (int cidJ = cidI + 1; cidJ < VCorpusInfo.nCameras; cidJ++)
		{
			int npairs = 0;
			for (size_t pid = 0; pid < VCorpusInfo.uvAll3D.size(); pid++)
				if (VCorpusInfo.uvAllViews2[cidI][pid].x > 0 && VCorpusInfo.uvAllViews2[cidJ][pid].x > 0)
					npairs++;

			if (npairs < mySfMPara.nInliersThresh)
				continue;

			CidICidJ.push_back(Point2i(cidI, cidJ));
			NumInliers.push_back(-npairs); //descending order
		}
	}
	SortWithIndex(NumInliers, SNumInliers, SIndex);

	for (int jj = 0; jj < SIndex.size(); jj++)
	{
		int pairId = SIndex[jj];
		int cidI = CidICidJ[pairId].x, cidJ = CidICidJ[pairId].y;
		if (-NumInliers[jj] < mySfMPara.nInliersThresh)
			continue;

		pts1.clear(), pts2.clear(), P3D.clear();
		for (size_t pid = 0; pid < VCorpusInfo.uvAll3D.size(); pid++)
			if (VCorpusInfo.uvAllViews2[cidI][pid].x > 0 && VCorpusInfo.uvAllViews2[cidJ][pid].x > 0)
				pts1.push_back(VCorpusInfo.uvAllViews2[cidI][pid]), pts2.push_back(VCorpusInfo.uvAllViews2[cidJ][pid]);

		CameraData Cam1, Cam2;
		CopyCamereInfo(VCorpusInfo.camera[cidI], Cam1);
		CopyCamereInfo(VCorpusInfo.camera[cidJ], Cam2);
		if (TwoViewReconstruction(Cam1, Cam2, pts1, pts2, P3D, mySfMPara, debug))
		{
			CopyCamereInfo(Cam1, VCorpusInfo.camera[cidI]);
			CopyCamereInfo(Cam2, VCorpusInfo.camera[cidJ]);
			for (int ii = 0; ii < 6; ii++)
				VCorpusInfo.camera[cidI].rt[ii] = 0;
			GetRTFromrt(VCorpusInfo.camera[cidI]), GetRTFromrt(VCorpusInfo.camera[cidJ]);
			AssembleP(VCorpusInfo.camera[cidI]), AssembleP(VCorpusInfo.camera[cidJ]);

			VCorpusInfo.camera[cidI].valid = true, VCorpusInfo.camera[cidJ].valid = true;
			VCorpusInfo.camera[cidI].nTouches2Views++, VCorpusInfo.camera[cidJ].nTouches2Views++;

			for (size_t pid = 0; pid < VCorpusInfo.uvAll3D.size(); pid++)
			{
				if (IsValid3D(P3D[pid]))
				{
					VCorpusInfo.xyz[pid] = P3D[pid];
					VCorpusInfo.threeDIdAllViews2[cidI][pid] = pid;
					VCorpusInfo.threeDIdAllViews2[cidJ][pid] = pid;
				}
			}
			printLOG("Initalized SfM using camera %d and %d\n\n", cidI, cidJ);
			break;
		}
	}

	return 0;
}
int sSfM_CleanInliers(Corpus &VCorpusInfo, SfMPara mySfMPara)
{
	int npts = (int)VCorpusInfo.xyz.size();
	double residuals[2];

	for (int jj = 0; jj < npts; jj++)
	{
		if (!IsValid3D(VCorpusInfo.xyz[jj]))
		{
			for (int ii = 0; ii < (int)VCorpusInfo.viewIdAll3D[jj].size(); ii++)
			{
				int viewID = VCorpusInfo.viewIdAll3D[jj][ii], pid = VCorpusInfo.pointIdAll3D[jj][ii];
				VCorpusInfo.InlierAllViews2[viewID][pid] = false;
			}
			continue;
		}

		for (int ii = 0; ii < (int)VCorpusInfo.viewIdAll3D[jj].size(); ii++)
		{
			int viewID = VCorpusInfo.viewIdAll3D[jj][ii], pid = VCorpusInfo.pointIdAll3D[jj][ii];
			Point2d uv = VCorpusInfo.uvAll3D[jj][ii];
			VCorpusInfo.InlierAllViews2[viewID][pid] = true;

			if (uv.x < 0 || uv.y < 0 || uv.x > VCorpusInfo.camera[viewID].width - 1 || uv.y >VCorpusInfo.camera[viewID].height - 1)
			{
				VCorpusInfo.InlierAllViews2[viewID][pid] = false;
				continue;
			}

			if (VCorpusInfo.camera[viewID].valid)
			{
				if (mySfMPara.distortionCorrected == 0)
				{
					if (VCorpusInfo.camera[viewID].LensModel == RADIAL_TANGENTIAL_PRISM)
						if (VCorpusInfo.camera[viewID].ShutterModel == GLOBAL_SHUTTER)
							PinholeDistortionReprojectionDebug(VCorpusInfo.camera[viewID].intrinsic, VCorpusInfo.camera[viewID].distortion, VCorpusInfo.camera[viewID].rt, uv, VCorpusInfo.xyz[jj], residuals);
						else
							CayleyDistortionReprojectionDebug(VCorpusInfo.camera[viewID].intrinsic, VCorpusInfo.camera[viewID].distortion, VCorpusInfo.camera[viewID].rt, VCorpusInfo.camera[viewID].wt, uv, VCorpusInfo.xyz[jj], VCorpusInfo.camera[viewID].width, VCorpusInfo.camera[viewID].height, residuals);
					else
						if (VCorpusInfo.camera[viewID].ShutterModel == GLOBAL_SHUTTER)
							FOVReprojectionDistortion2Debug(VCorpusInfo.camera[viewID].intrinsic, VCorpusInfo.camera[viewID].distortion, VCorpusInfo.camera[viewID].rt, uv, VCorpusInfo.xyz[jj], residuals);
						else
							CayleyFOVReprojection2Debug(VCorpusInfo.camera[viewID].intrinsic, VCorpusInfo.camera[viewID].distortion, VCorpusInfo.camera[viewID].rt, VCorpusInfo.camera[viewID].wt, uv, VCorpusInfo.xyz[jj], VCorpusInfo.camera[viewID].width, VCorpusInfo.camera[viewID].height, residuals);
				}
				else
				{
					if (VCorpusInfo.camera[viewID].ShutterModel == GLOBAL_SHUTTER)
						PinholeReprojectionDebug(VCorpusInfo.camera[viewID].intrinsic, VCorpusInfo.camera[viewID].rt, uv, VCorpusInfo.xyz[jj], residuals);
					else
						CayleyReprojectionDebug(VCorpusInfo.camera[viewID].intrinsic, VCorpusInfo.camera[viewID].rt, VCorpusInfo.camera[viewID].wt, uv, VCorpusInfo.xyz[jj], VCorpusInfo.camera[viewID].width, VCorpusInfo.camera[viewID].height, residuals);
				}

				if (abs(residuals[0]) > VCorpusInfo.camera[viewID].threshold || abs(residuals[1]) > VCorpusInfo.camera[viewID].threshold)
					VCorpusInfo.InlierAllViews2[viewID][pid] = false;
			}
			else
				VCorpusInfo.InlierAllViews2[viewID][pid] = false;
		}
	}

	return 0;
}
int sSfM_reTri(int KF2Process, Corpus &VCorpusInfo, SfMPara &mySfMPara)
{
	if (!VCorpusInfo.camera[KF2Process].valid)
		return 0;

	int nthreads = omp_get_max_threads();

	vector<int> newlyadded(nthreads);
	vector<int> *usedVCid = new vector<int>[nthreads],
		*usedVCid2 = new vector<int>[nthreads],
		*Inliers = new vector<int>[nthreads];
	bool*Passed = new bool[VCorpusInfo.nCameras * 2 * nthreads];
	Point2d *allUV = new Point2d[VCorpusInfo.nCameras * 2 * nthreads],
		*pallUV = new Point2d[VCorpusInfo.nCameras * 2 * nthreads];
	double *A = new double[6 * VCorpusInfo.nCameras * 2 * nthreads],
		*B = new double[2 * VCorpusInfo.nCameras * 2 * nthreads],
		*allP = new double[12 * VCorpusInfo.nCameras * 2 * nthreads],
		*tallP = new double[12 * VCorpusInfo.nCameras * 2 * nthreads];

	int TobeTriangulated = 0;
	for (int pid = 0; pid < VCorpusInfo.n2DPointsPerView[KF2Process]; pid++)
	{
		Point3d P3D; double reprojectionErr;
		int threadID = omp_get_thread_num(), offset = VCorpusInfo.nCameras * 2 * threadID;
		usedVCid[threadID].clear();

		int threeDId = VCorpusInfo.threeDIdAllViews2[KF2Process][pid];
		if (threeDId < 0)
			continue;
		if (VCorpusInfo.GlobalAnchor3DId[threeDId] > -1) //assume global corpus point is fixed
			continue;

		int cnt = 0;
		for (int lcid = 0; lcid < VCorpusInfo.viewIdAll3D[threeDId].size(); lcid++)
		{
			if (!VCorpusInfo.camera[VCorpusInfo.viewIdAll3D[threeDId][lcid]].valid)
				continue;
			cnt++;
		}
		if (cnt > VCorpusInfo.nCameras * 2 || cnt < 2)
			continue;

		if (!IsValid3D(VCorpusInfo.xyz[threeDId]))
			TobeTriangulated++;
	}
	if (1.0*TobeTriangulated / VCorpusInfo.n2DPointsPerView[KF2Process] > mySfMPara.underTriangulationRatio)
	{
		printLOG("...%d/%d to be triangulated...already well triangulated. Skip futher steps...", TobeTriangulated, VCorpusInfo.n2DPointsPerView[KF2Process]);
		return 0;
	}
	else
		printLOG("...%d/%d to be triangulated...", TobeTriangulated, VCorpusInfo.n2DPointsPerView[KF2Process]);

	omp_set_num_threads(nthreads);
	//#pragma omp parallel for schedule(dynamic,4)
	for (int pid = 0; pid < VCorpusInfo.n2DPointsPerView[KF2Process]; pid++)
	{
		Point3d P3D; double reprojectionErr;
		int threadID = omp_get_thread_num(), offset = VCorpusInfo.nCameras * 2 * threadID;
		usedVCid[threadID].clear();

		int threeDId = VCorpusInfo.threeDIdAllViews2[KF2Process][pid];
		if (threeDId < 0)
			continue;
		if (VCorpusInfo.GlobalAnchor3DId[threeDId] > -1) //assume global corpus point is fixed
			continue;

		int cnt = 0;
		for (int lcid = 0; lcid < VCorpusInfo.viewIdAll3D[threeDId].size(); lcid++)
		{
			if (VCorpusInfo.camera[VCorpusInfo.viewIdAll3D[threeDId][lcid]].valid)
				cnt++;
		}
		if (cnt < 2 || cnt > VCorpusInfo.nCameras * 2)
			continue;

		for (int lcid = 0; lcid < VCorpusInfo.viewIdAll3D[threeDId].size(); lcid++)
		{
			int cid = VCorpusInfo.viewIdAll3D[threeDId][lcid], twoDid = VCorpusInfo.pointIdAll3D[threeDId][lcid];
			if (!VCorpusInfo.camera[cid].valid)
				continue;

			allUV[usedVCid[threadID].size() + offset].x = (double)VCorpusInfo.uvAllViews2[cid][twoDid].x;
			allUV[usedVCid[threadID].size() + offset].y = (double)VCorpusInfo.uvAllViews2[cid][twoDid].y;
			usedVCid[threadID].push_back(cid);
		}

		for (size_t ii = 0; ii < usedVCid[threadID].size(); ii++)
		{
			int cid = usedVCid[threadID][ii];
			if (VCorpusInfo.camera[cid].ShutterModel == ROLLING_SHUTTER)
				AssembleP_RS(allUV[ii + offset], VCorpusInfo.camera[cid], allP + 12 * ii + 12 * offset);
			else
				for (int jj = 0; jj < 12; jj++)
					allP[12 * ii + jj + 12 * offset] = VCorpusInfo.camera[cid].P[jj];

			if (mySfMPara.distortionCorrected == 0) //not perfectly corrected--> use the current guess and correct
			{
				if (VCorpusInfo.camera[cid].LensModel == RADIAL_TANGENTIAL_PRISM)
					LensCorrectionPoint(&allUV[ii + offset], VCorpusInfo.camera[cid].K, VCorpusInfo.camera[cid].distortion);
				else
					FishEyeCorrectionPoint(&allUV[ii + offset], VCorpusInfo.camera[cid].K, VCorpusInfo.camera[cid].distortion[0]);
			}
		}

		if (mySfMPara.useRanSac)
		{
			Inliers[threadID].clear();
			reprojectionErr = NviewTriangulationRANSAC(allUV + offset, allP + 12 * offset, &P3D, Passed + offset, &Inliers[threadID], usedVCid[threadID].size(),
				1, 2, 1000, 0.8, mySfMPara.reProjectionTrianguatlionThresh, A + 6 * offset, B + 2 * offset, tallP + 12 * offset, false, true); //corres have been filtered by Fmat

			if (reprojectionErr < mySfMPara.reProjectionTrianguatlionThresh)
			{
				bool yes = true;
				for (size_t ii = 0; ii < usedVCid[threadID].size() && yes; ii++)
					if (Inliers[threadID][ii] == 1)
						if (!HasPointPositiveDepth(allP + 12 * offset + 12 * ii, P3D))
							yes = false;
				if (yes)
				{
					usedVCid2[threadID].clear();
					for (size_t ii = 0; ii < usedVCid[threadID].size(); ii++)
						if (Inliers[threadID][ii] == 1)
							usedVCid2[threadID].push_back(usedVCid[threadID][ii]);
					if (!FilterPoints3DWithSmallTriangulationAngle(VCorpusInfo, usedVCid2[threadID], P3D, mySfMPara.tri_local_min_tri_angle))
						yes = false;
				}

				if (yes)
				{
					if (!IsValid3D(VCorpusInfo.xyz[threeDId]))
						newlyadded[threadID]++;
					VCorpusInfo.xyz[threeDId] = P3D;
				}
				else
					VCorpusInfo.xyz[threeDId].x = 0, VCorpusInfo.xyz[threeDId].y = 0, VCorpusInfo.xyz[threeDId].z = 0;
			}
		}
		else
		{
			NviewTriangulation(allUV + offset, allP + 12 * offset, &P3D, usedVCid[threadID].size(), 1, NULL, A + 6 * offset, B + 2 * offset);
			ProjectandDistort(P3D, pallUV + offset, allP + 12 * offset, NULL, NULL, (int)usedVCid[threadID].size());

			double errorX = 0, errorY = 0;
			for (int ii = 0; ii < usedVCid[threadID].size(); ii++)
				errorX += abs(allUV[ii + offset].x - pallUV[ii + offset].x),
				errorY += abs(allUV[ii + offset].y - pallUV[ii + offset].y);
			errorX /= usedVCid[threadID].size(), errorY /= usedVCid[threadID].size();
			reprojectionErr = sqrt(pow(errorX, 2) + pow(errorY, 2));

			if (reprojectionErr < mySfMPara.reProjectionTrianguatlionThresh)
			{
				bool yes = true;
				for (size_t ii = 0; ii < usedVCid[threadID].size() && yes; ii++)
					if (!HasPointPositiveDepth(allP + 12 * offset + 12 * ii, P3D))
						yes = false;

				if (yes && !FilterPoints3DWithSmallTriangulationAngle(VCorpusInfo, usedVCid[threadID], P3D, mySfMPara.tri_local_min_tri_angle))
					yes = false;
				if (yes)
				{
					if (!IsValid3D(VCorpusInfo.xyz[threeDId]))
						newlyadded[threadID]++;
					VCorpusInfo.xyz[threeDId] = P3D;
				}
				else
					VCorpusInfo.xyz[threeDId].x = 0, VCorpusInfo.xyz[threeDId].y = 0, VCorpusInfo.xyz[threeDId].z = 0;
			}
		}
	}

	int new3Dcnt = 0;
	for (int ii = 0; ii < nthreads; ii++)
		new3Dcnt += newlyadded[ii];

	delete[]allUV, delete[]pallUV, delete[]A, delete[]B, delete[]allP, delete[]tallP, delete[]Passed, delete[]Inliers, delete[]usedVCid, delete[]usedVCid2;
	return new3Dcnt;
}
int sSfM_reTri(Corpus &VCorpusInfo, SfMPara &mySfMPara)
{
	int nthreads = omp_get_max_threads();

	vector<int> newlyadded(nthreads);
	vector<int> *usedVCid = new vector<int>[nthreads],
		*usedVCid2 = new vector<int>[nthreads],
		*Inliers = new vector<int>[nthreads];
	bool*Passed = new bool[VCorpusInfo.nCameras * 2 * nthreads];
	Point2d *allUV = new Point2d[VCorpusInfo.nCameras * 2 * nthreads],
		*pallUV = new Point2d[VCorpusInfo.nCameras * 2 * nthreads];
	double *A = new double[6 * VCorpusInfo.nCameras * 2 * nthreads],
		*B = new double[2 * VCorpusInfo.nCameras * 2 * nthreads],
		*allP = new double[12 * VCorpusInfo.nCameras * 2 * nthreads],
		*tallP = new double[12 * VCorpusInfo.nCameras * 2 * nthreads];

	int increP = 5;
	omp_set_num_threads(nthreads);
#pragma omp parallel for schedule(dynamic,100)
	for (int pid = 0; pid < VCorpusInfo.xyz.size(); pid++)
	{
		if (VCorpusInfo.GlobalAnchor3DId[pid] > -1) //assume global corpus point is fixed
			continue;

#pragma omp critical
		if (100 * pid / VCorpusInfo.xyz.size() > increP)
		{
			printLOG("%d..", increP);
			increP += 5;
		}

		int threadID = omp_get_thread_num(), offset = VCorpusInfo.nCameras * 2 * threadID;

		Point3d P3D;
		double reprojectionErr;

		int cnt = 0;
		for (int lcid = 0; lcid < VCorpusInfo.viewIdAll3D[pid].size(); lcid++)
		{
			if (!VCorpusInfo.camera[VCorpusInfo.viewIdAll3D[pid][lcid]].valid)
				continue;
			cnt++;
		}
		if (cnt < 2 || cnt > VCorpusInfo.nCameras * 2)
			continue;

		usedVCid[threadID].clear();
		for (int lcid = 0; lcid < VCorpusInfo.viewIdAll3D[pid].size(); lcid++)
		{
			int cid = VCorpusInfo.viewIdAll3D[pid][lcid], twoDid = VCorpusInfo.pointIdAll3D[pid][lcid];
			if (!VCorpusInfo.camera[cid].valid)
				continue;

			allUV[usedVCid[threadID].size() + offset].x = (double)VCorpusInfo.uvAllViews2[cid][twoDid].x;
			allUV[usedVCid[threadID].size() + offset].y = (double)VCorpusInfo.uvAllViews2[cid][twoDid].y;
			usedVCid[threadID].push_back(cid);
		}

		for (size_t ii = 0; ii < usedVCid[threadID].size(); ii++)
		{
			int cid = usedVCid[threadID][ii];
			if (VCorpusInfo.camera[cid].ShutterModel == ROLLING_SHUTTER)
				AssembleP_RS(allUV[ii + offset], VCorpusInfo.camera[cid], allP + 12 * ii + 12 * offset);
			else
				for (int jj = 0; jj < 12; jj++)
					allP[12 * ii + jj + 12 * offset] = VCorpusInfo.camera[cid].P[jj];

			if (mySfMPara.distortionCorrected == 0) //not perfectly corrected--> use the current guess and correct
			{
				if (VCorpusInfo.camera[cid].LensModel == RADIAL_TANGENTIAL_PRISM)
					LensCorrectionPoint(&allUV[ii + offset], VCorpusInfo.camera[cid].K, VCorpusInfo.camera[cid].distortion);
				else
					FishEyeCorrectionPoint(&allUV[ii + offset], VCorpusInfo.camera[cid].K, VCorpusInfo.camera[cid].distortion[0]);
			}
		}

		if (mySfMPara.useRanSac)
		{
			Inliers[threadID].clear();
			reprojectionErr = NviewTriangulationRANSAC(allUV + offset, allP + 12 * offset, &P3D, Passed + offset, &Inliers[threadID], usedVCid[threadID].size(),
				1, 2, 1000, 0.8, mySfMPara.reProjectionTrianguatlionThresh, A + 6 * offset, B + 2 * offset, tallP + 12 * offset, false, true); //corres have been filtered by Fmat

			if (reprojectionErr < mySfMPara.reProjectionTrianguatlionThresh)
			{
				bool yes = true;
				for (size_t ii = 0; ii < usedVCid[threadID].size() && yes; ii++)
					if (Inliers[threadID][ii] == 1)
						if (!HasPointPositiveDepth(allP + 12 * offset + 12 * ii, P3D))
							yes = false;

				if (yes)
				{
					usedVCid2[threadID].clear();
					for (size_t ii = 0; ii < usedVCid[threadID].size(); ii++)
						if (Inliers[threadID][ii] == 1)
							usedVCid2[threadID].push_back(usedVCid[threadID][ii]);
					if (!FilterPoints3DWithSmallTriangulationAngle(VCorpusInfo, usedVCid2[threadID], P3D, mySfMPara.tri_local_min_tri_angle))
						yes = false;
				}

				if (yes)
				{
					if (!IsValid3D(VCorpusInfo.xyz[pid]))
						newlyadded[threadID]++;
					VCorpusInfo.xyz[pid] = P3D;
				}
				else
					VCorpusInfo.xyz[pid].x = 0, VCorpusInfo.xyz[pid].y = 0, VCorpusInfo.xyz[pid].z = 0;
			}
		}
		else
		{
			NviewTriangulation(allUV + offset, allP + 12 * offset, &P3D, usedVCid[threadID].size(), 1, NULL, A + 6 * offset, B + 2 * offset);
			ProjectandDistort(P3D, pallUV + offset, allP + 12 * offset, NULL, NULL, usedVCid[threadID].size());

			double errorX = 0, errorY = 0;
			for (int ii = 0; ii < usedVCid[threadID].size(); ii++)
				errorX += abs(allUV[ii + offset].x - pallUV[ii + offset].x),
				errorY += abs(allUV[ii + offset].y - pallUV[ii + offset].y);
			errorX /= usedVCid[threadID].size(), errorY /= usedVCid[threadID].size();
			reprojectionErr = sqrt(pow(errorX, 2) + pow(errorY, 2));

			if (reprojectionErr < mySfMPara.reProjectionTrianguatlionThresh)
			{
				bool yes = true;
				for (size_t ii = 0; ii < usedVCid[threadID].size() && yes; ii++)
					if (Inliers[threadID][ii] == 1)
						if (!HasPointPositiveDepth(allP + 12 * offset + 12 * ii, P3D))
							yes = false;

				if (yes && !FilterPoints3DWithSmallTriangulationAngle(VCorpusInfo, usedVCid[threadID], P3D, mySfMPara.tri_local_min_tri_angle))
					yes = false;

				if (yes)
				{
					if (!IsValid3D(VCorpusInfo.xyz[pid]))
						newlyadded[threadID]++;
					VCorpusInfo.xyz[pid] = P3D;
				}
				else
					VCorpusInfo.xyz[pid].x = 0, VCorpusInfo.xyz[pid].y = 0, VCorpusInfo.xyz[pid].z = 0;
			}
		}
	}
	printLOG("100\n");

	int new3Dcnt = 0;
	for (int ii = 0; ii < nthreads; ii++)
		new3Dcnt += newlyadded[ii];

	delete[]allUV, delete[]pallUV, delete[]A, delete[]B, delete[]allP, delete[]tallP, delete[]Passed, delete[]Inliers, delete[]usedVCid, delete[]usedVCid2;
	return new3Dcnt;
}
int BA_Driver(char *Path, Corpus &VCorpusInfo, SfMPara mySfMPara)
{
	vector<int> SharedCameraToBuildCorpus;
	for (int ii = 0; ii < VCorpusInfo.nCameras; ii++)
	{
		if (mySfMPara.sharedIntrinsic)
			SharedCameraToBuildCorpus.push_back(0);
		VCorpusInfo.camera[ii].threshold = mySfMPara.reProjectionBAThresh;
	}

	//int orgLossType = mySfMPara.LossType;
	int fixedGlobalCorpus = 1, fixedLocalCorpus = 0;
	for (int iter = 0; iter < mySfMPara.BARefinementIter; iter++)
	{
		//if (iter >= 1)
		//	mySfMPara.LossType = 0; //L2-loss

		for (int ii = 0; ii < VCorpusInfo.nCameras; ii++)
			VCorpusInfo.camera[ii].threshold = mySfMPara.reProjectionBAThresh*(mySfMPara.BARefinementIter - iter);

		//unless perfectly undistorted (option 2), the 2D points will be raw
		GenericBundleAdjustment(Path, VCorpusInfo.camera, VCorpusInfo.xyz, VCorpusInfo.viewIdAll3D, VCorpusInfo.uvAll3D, VCorpusInfo.scaleAll3D, SharedCameraToBuildCorpus, VCorpusInfo.nCameras,
			mySfMPara.fixIntrinsic, mySfMPara.fixDistortion, 0, 0, false, VCorpusInfo.GlobalAnchor3DId, fixedGlobalCorpus, fixedLocalCorpus, mySfMPara.fixSkew, mySfMPara.fixPrism, mySfMPara.distortionCorrected, mySfMPara.nViewsPlusBA, mySfMPara.LossType, false, false, true);
	}
	//mySfMPara.LossType = orgLossType;

	for (int ii = 0; ii < VCorpusInfo.nCameras; ii++)
		VCorpusInfo.camera[ii].threshold = mySfMPara.reProjectionBAThresh;

	return 0;
}

int SimpleBodyPoseSfM(char *Path, int fid, Corpus &CorpusInfo, SfMPara mySfMPara, int nMaxPeople, int verbose)
{
	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 0));
	colors.push_back(Scalar(128, 128, 0));
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(128, 0, 128));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(255, 0, 128));
	colors.push_back(Scalar(0, 0, 128));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(0, 128, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(0, 128, 128));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));
	colors.push_back(Scalar(128, 0, 0));

	char Fname[512];

	int minInliers = 9, nJoints = 18, npts = nJoints * nMaxPeople;
	double thresh = 100.0, reliablePredictionThresh = 0.6;

	int nCams = CorpusInfo.nCameras;
	ReadIntrinsicResults(Path, CorpusInfo.camera);

	CorpusInfo.n3dPoints = npts;
	CorpusInfo.xyz.clear(), CorpusInfo.viewIdAll3D.clear(), CorpusInfo.uvAll3D.clear(), CorpusInfo.scaleAll3D.clear();
	CorpusInfo.xyz.resize(npts), CorpusInfo.viewIdAll3D.resize(npts), CorpusInfo.uvAll3D.resize(npts), CorpusInfo.scaleAll3D.resize(npts);
	for (int cid = 0; cid < nCams; cid++)
	{
		sprintf(Fname, "%s/JBC/%.4d/%d.txt", Path, fid, cid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		int pid; float u, v, s;
		while (fscanf(fp, "%d %f %f %f ", &pid, &u, &v, &s) != EOF)
		{
			CorpusInfo.viewIdAll3D[pid].push_back(cid);
			if (s > 0.5) //weighting based on conf score does not work well
				CorpusInfo.uvAll3D[pid].push_back(Point2d(u, v));
			else
				CorpusInfo.uvAll3D[pid].push_back(Point2d(0, 0));
			CorpusInfo.scaleAll3D[pid].push_back(1.0);// -min(s, 1.f) + 1e-16); //larger conf -> more trusted
		}
		fclose(fp);
	}

	CameraData *currentCameras = new CameraData[nCams];
	vector<Point3d> currentXYZ; currentXYZ.reserve(npts);
	vector <vector<int> > currentViewIdAll3D; //3D -> visiable views index
	vector<vector<Point2d> > currentUVAll3D; //3D -> uv of that point in those visible views
	vector<vector<double> > currentScaleAll3D; //3D -> scale of that point in those visible views
	for (int pid = 0; pid < npts; pid++)
	{
		currentViewIdAll3D.push_back(vector<int>());
		currentUVAll3D.push_back(vector<Point2d>());
		currentScaleAll3D.push_back(vector<double>());
	}


	vector<int> inliers, id, id2;
	vector<Point2d> pts, pts1, pts2;
	vector<Point3d> P3D;

	//Initialize the SfM
	Point2i bestPair;
	CameraData BestCam1, BestCam2;
	double minCost = 9e9;
	for (int jj = 0; jj < nCams - 1; jj++)
	{
		for (int ii = jj + 1; ii < nCams; ii++)
		{
			pts1.clear(), pts2.clear(), id.clear();
			for (int pid = 0; pid < CorpusInfo.n3dPoints; pid++)
			{
				for (int kk = 0; kk < CorpusInfo.viewIdAll3D[pid].size(); kk++)
				{
					if (CorpusInfo.viewIdAll3D[pid][kk] == jj)
					{
						for (int ll = 0; ll < CorpusInfo.viewIdAll3D[pid].size(); ll++)
						{
							if (CorpusInfo.viewIdAll3D[pid][ll] == ii)
							{
								if (CorpusInfo.uvAll3D[pid][kk].x > 0 && CorpusInfo.uvAll3D[pid][kk].y > 0 && CorpusInfo.uvAll3D[pid][ll].x > 0 && CorpusInfo.uvAll3D[pid][ll].y > 0)
								{
									pts1.push_back(CorpusInfo.uvAll3D[pid][kk]);
									pts2.push_back(CorpusInfo.uvAll3D[pid][ll]);
									id.push_back(pid);
									break;
								}
							}
						}
						break;
					}
					if (CorpusInfo.viewIdAll3D[pid][kk] == ii)
					{
						for (int ll = 0; ll < CorpusInfo.viewIdAll3D[pid].size(); ll++)
						{
							if (CorpusInfo.viewIdAll3D[pid][ll] == jj)
							{
								if (CorpusInfo.uvAll3D[pid][kk].x > 0 && CorpusInfo.uvAll3D[pid][kk].y > 0 && CorpusInfo.uvAll3D[pid][ll].x > 0 && CorpusInfo.uvAll3D[pid][ll].y > 0)
								{
									pts2.push_back(CorpusInfo.uvAll3D[pid][kk]);
									pts1.push_back(CorpusInfo.uvAll3D[pid][ll]);
									id.push_back(pid);
									break;
								}
							}
						}
						break;
					}
				}
			}

			if (verbose)
			{
				/*if (pts1.size() > 0)
				{
				sprintf(Fname, "%s/JBC/%.4d/%d.jpg", Path, fid, jj);
				Mat frame = imread(Fname);
				for (int kk = 0; kk < pts1.size(); kk++)
				{
				CvPoint text_origin = { pts1[kk].x, pts1[kk].y - frame.rows / 20 };
				sprintf(Fname, "%d", kk), putText(frame, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * frame.cols / 640, colors[kk % colors.size()], 2);
				}
				imwrite("C:/temp/1.png", frame);

				sprintf(Fname, "%s/JBC/%.4d/%d.jpg", Path, fid, ii);
				frame = imread(Fname);
				for (int kk = 0; kk < pts2.size(); kk++)
				{
				CvPoint text_origin = { pts2[kk].x, pts2[kk].y - frame.rows / 20 };
				sprintf(Fname, "%d", kk), putText(frame, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * frame.cols / 640, colors[kk % colors.size()], 2);
				}
				imwrite("C:/temp/2.png", frame);
				}*/
				printLOG("****************************\nTrying pair (%d-%d): %d points...\n", jj, ii, pts1.size());
			}

			CameraData Cam1, Cam2;
			CopyCamereInfo(CorpusInfo.camera[jj], Cam1);
			CopyCamereInfo(CorpusInfo.camera[ii], Cam2);
			double cost = TwoViewReconstruction(Cam1, Cam2, pts1, pts2, P3D, mySfMPara, verbose);
			if (cost < minCost)
			{
				bestPair.x = jj, bestPair.y = ii;
				CopyCamereInfo(Cam1, BestCam1);
				CopyCamereInfo(Cam2, BestCam2);
				minCost = cost;
				for (int ii = 0; ii < npts; ii++)
					CorpusInfo.xyz[ii] = Point3d(0, 0, 0); //clear out everything
				for (int ii = 0; ii < (int)id.size(); ii++)
					CorpusInfo.xyz[id[ii]] = P3D[ii];
			}
		}
	}
	CopyCamereInfo(BestCam1, CorpusInfo.camera[bestPair.x]);
	CopyCamereInfo(BestCam2, CorpusInfo.camera[bestPair.y]);
	CorpusInfo.camera[bestPair.x].processed = true;
	CorpusInfo.camera[bestPair.y].processed = true;
	GetRTFromrt(CorpusInfo.camera[bestPair.y]);

	printLOG("Initalized SfM using camera %d and %d\n\n", bestPair.x, bestPair.y);

	//Start incremental SfM
	int nGoodProjections = 0;
	Point2d *allPts = new Point2d[nCams * 2];
	double *A = new double[6 * nCams * 2], *B = new double[2 * nCams * 2], *allP = new double[12 * nCams * 2];
	vector<int> addedCameras, CameraInQueue, BadCameraFlag;
	addedCameras.push_back(bestPair.x), addedCameras.push_back(bestPair.y);
	for (int ii = 0; ii < nCams; ii++)
	{
		int used = 0;
		for (int jj = 0; jj < (int)addedCameras.size() && used == 0; jj++)
			if (ii == addedCameras[jj])
				used = 1;
		if (used == 0)
			CameraInQueue.push_back(ii);
	}
	for (int ii = 0; ii < nCams; ii++)
		BadCameraFlag.push_back(0);

	int penalizedCamera = -1;
	while (CameraInQueue.size() > 0)
	{
		//printLOG("Press key to continue...");
		//int dummy;  cin >> dummy;
		//system("Pause");
		//mySleep(2000);
		int nextCamera = FindNextCameraToAdd(CorpusInfo, addedCameras, CameraInQueue, penalizedCamera, minInliers*(int)addedCameras.size());
		printLOG("****************************\nAdding camera %d\n", nextCamera);

		pts.clear(), P3D.clear(), id.clear(), inliers.clear();
		for (int pid = 0; pid < CorpusInfo.n3dPoints; pid++)
		{
			int foundCamID = -1, count = 0;
			for (int ii = 0; ii < CorpusInfo.viewIdAll3D[pid].size(); ii++)
			{
				if (CorpusInfo.viewIdAll3D[pid][ii] == nextCamera)
				{
					if (abs(CorpusInfo.xyz[pid].x) + abs(CorpusInfo.xyz[pid].y) + abs(CorpusInfo.xyz[pid].z) > 0)
					{
						if (CorpusInfo.uvAll3D[pid][ii].x > 0 && CorpusInfo.uvAll3D[pid][ii].y > 0)// && CorpusInfo.scaleAll3D[pid][ii] < 1.0 - reliablePredictionThresh)
							id.push_back(pid), pts.push_back(CorpusInfo.uvAll3D[pid][ii]), P3D.push_back(CorpusInfo.xyz[pid]);
						break;
					}
				}
			}
		}
		int nInliers = EstimatePoseAndInliers(CorpusInfo.camera[nextCamera].K, CorpusInfo.camera[nextCamera].distortion, CorpusInfo.camera[nextCamera].LensModel, CorpusInfo.camera[nextCamera].ShutterModel,
			CorpusInfo.camera[nextCamera].R, CorpusInfo.camera[nextCamera].T, CorpusInfo.camera[nextCamera].wt, pts, P3D, inliers, thresh, 1, 0, CorpusInfo.camera[nextCamera].minFratio, CorpusInfo.camera[nextCamera].maxFratio, CorpusInfo.camera[nextCamera].width, CorpusInfo.camera[nextCamera].height, PnP::EPNP);

		if (nInliers > minInliers)
		{

			GetrtFromRT(CorpusInfo.camera[nextCamera]);

			//retriangulate
			addedCameras.push_back(nextCamera);
			std::sort(addedCameras.begin(), addedCameras.end()); //assume corresponding views are also sorted

			currentXYZ.clear(), inliers.clear();
			for (int ii = 0; ii < currentUVAll3D.size(); ii++)
				currentViewIdAll3D[ii].clear(), currentUVAll3D[ii].clear(), currentScaleAll3D[ii].clear();

			for (int pid = 0; pid < CorpusInfo.n3dPoints; pid++)
			{
				id.clear(), id2.clear();
				for (int ii = 0; ii < CorpusInfo.viewIdAll3D[pid].size(); ii++)
				{
					for (int jj = 0; jj < (int)addedCameras.size(); jj++)
					{
						if (CorpusInfo.viewIdAll3D[pid][ii] == addedCameras[jj])
						{
							if (CorpusInfo.uvAll3D[pid][ii].x > 0 && CorpusInfo.uvAll3D[pid][ii].y > 0)
							{
								id.push_back(ii), id2.push_back(jj);
								break;
							}
						}
					}
				}

				if (id.size() > 1)
				{
					double RT[12];
					for (int ii = 0; ii < (int)id.size(); ii++)
					{
						int cid = CorpusInfo.viewIdAll3D[pid][id[ii]];
						allPts[ii] = CorpusInfo.uvAll3D[pid][id[ii]];

						if (CorpusInfo.camera[cid].LensModel == RADIAL_TANGENTIAL_PRISM)
							LensCorrectionPoint(&allPts[ii], CorpusInfo.camera[cid].K, CorpusInfo.camera[cid].distortion);
						else
							//FishEyeCorrectionPoint(&allPts[ii], CorpusInfo.camera[cid].distortion[0], CorpusInfo.camera[cid].distortion[1], CorpusInfo.camera[cid].distortion[2]);
							FishEyeCorrectionPoint(&allPts[ii], CorpusInfo.camera[cid].K, CorpusInfo.camera[cid].distortion[0]);

						AssembleRT(CorpusInfo.camera[cid].R, CorpusInfo.camera[cid].T, RT);
						AssembleP(CorpusInfo.camera[cid].K, RT, allP + 12 * ii);

						currentViewIdAll3D[inliers.size()].push_back(id2[ii]);
						currentUVAll3D[inliers.size()].push_back(allPts[ii]);
						currentScaleAll3D[inliers.size()].push_back(CorpusInfo.scaleAll3D[pid][id[ii]]);
					}
					inliers.push_back(pid);
					currentXYZ.push_back(Point3d(0, 0, 0));

					NviewTriangulation(allPts, allP, &currentXYZ.back(), (int)id.size(), 1, NULL, A, B);
				}
			}

			//BA
			for (int ii = 0; ii < (int)addedCameras.size(); ii++)
			{
				CopyCamereInfo(CorpusInfo.camera[addedCameras[ii]], currentCameras[ii]);
				currentCameras[ii].threshold = thresh * 3;
				currentCameras[ii].valid = true;
			}
			vector<int> dummy;
			nGoodProjections = GenericBundleAdjustment(Path, currentCameras, currentXYZ, currentViewIdAll3D, currentUVAll3D, currentScaleAll3D, dummy, (int)addedCameras.size(), 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 2, false, 1, false, true);

			//Write data
			for (int ii = 0; ii < (int)addedCameras.size(); ii++)
			{
				CopyCamereInfo(currentCameras[ii], CorpusInfo.camera[addedCameras[ii]]);
				CorpusInfo.camera[addedCameras[ii]].processed = true;
			}
			for (int ii = 0; ii < (int)inliers.size(); ii++)
				CorpusInfo.xyz[inliers[ii]] = currentXYZ[ii];

			for (int ii = 0; ii < (int)CameraInQueue.size(); ii++)
			{
				if (CameraInQueue[ii] == nextCamera)
				{
					CameraInQueue.erase(CameraInQueue.begin() + ii);
					break;
				}
			}
			//mySleep(50);
		}
		else
		{
			if (BadCameraFlag[nextCamera] > 2)
			{
				for (int ii = 0; ii < (int)CameraInQueue.size(); ii++)
				{
					if (CameraInQueue[ii] == nextCamera)
					{
						CameraInQueue.erase(CameraInQueue.begin() + ii);
						break;
					}
				}
			}
			penalizedCamera = nextCamera;
			BadCameraFlag[nextCamera]++;
		}
	}

	sprintf(Fname, "%s/JBC/%.4d/BA.txt", Path, fid);  FILE *fp = fopen(Fname, "w+");
	fprintf(fp, "%d %d\n", nCams, nGoodProjections);
	for (int ii = 0; ii < nCams; ii++)
	{
		if (BadCameraFlag[ii] > 2)
			for (int jj = 0; jj < 6; jj++)
				CorpusInfo.camera[ii].rt[jj] = 0;

		double fx, fy, skew, u0, v0, r1, r2, r3, t1, t2, p1, p2, omega, DistCtrX, DistCtrY, rt[6];

		CameraData *camI = &CorpusInfo.camera[ii];
		fprintf(fp, "%.4d %d %d %d %d ", ii, camI->LensModel, camI->ShutterModel, camI->width, camI->height);

		fx = camI->intrinsic[0], fy = camI->intrinsic[1], skew = camI->intrinsic[2], u0 = camI->intrinsic[3], v0 = camI->intrinsic[4];

		if (camI->LensModel == RADIAL_TANGENTIAL_PRISM)
		{
			r1 = camI->distortion[0], r2 = camI->distortion[1], r3 = camI->distortion[2], t1 = camI->distortion[3], t2 = camI->distortion[4], p1 = camI->distortion[5], p2 = camI->distortion[6];
			fprintf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %.16f %.16f %.16f %.16f %.16f %.16f\n", fx, fy, skew, u0, v0, r1, r2, r3, t1, t2, p1, p2, camI->rt[0], camI->rt[1], camI->rt[2], camI->rt[3], camI->rt[4], camI->rt[5]);
		}
		else
		{
			omega = camI->distortion[0], DistCtrX = camI->distortion[1], DistCtrY = camI->distortion[2];
			fprintf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %.16f %.16f %.16f %.16f %.16f %.16f\n", fx, fy, skew, u0, v0, omega, DistCtrX, DistCtrY, rt[0], rt[1], rt[2], rt[3], rt[4], rt[5]);
		}
	}
	fclose(fp);


	/*CorpusInfo.xyz.clear();
	CorpusInfo.xyz.resize(nJoints*nMaxPeople);
	bool *passTri = new bool[nCams * 2];
	double *tallP = new double[12 * nCams * 2];
	for (auto cid : addedCameras)
	AssembleP(CorpusInfo.camera[cid].K, CorpusInfo.camera[cid].R, CorpusInfo.camera[cid].T, CorpusInfo.camera[cid].P);
	for (size_t pid = 0; pid < CorpusInfo.uvAll3D.size(); pid++)
	{
	int count = 0;
	for (size_t ii = 0; ii < addedCameras.size(); ii++)
	{
	for (size_t jj = 0; jj < CorpusInfo.viewIdAll3D[pid].size(); jj++)
	{
	int cid = addedCameras[ii];
	if (cid == CorpusInfo.viewIdAll3D[pid][jj])
	{
	allPts[ii] = CorpusInfo.uvAll3D[pid][jj];
	if (CorpusInfo.camera[cid].LensModel == RADIAL_TANGENTIAL_PRISM)
	LensCorrectionPoint(&allPts[count], CorpusInfo.camera[cid].K, CorpusInfo.camera[cid].distortion);
	else
	//FishEyeCorrectionPoint(&allPts[count], CorpusInfo.camera[cid].distortion[0], CorpusInfo.camera[cid].distortion[1], CorpusInfo.camera[cid].distortion[2]);
	FishEyeCorrectionPoint(&allPts[count], CorpusInfo.camera[cid].K, CorpusInfo.camera[cid].distortion[0]);
	for (int kk = 0; kk < 12; kk++)
	allP[count * 12 + kk] = CorpusInfo.camera[cid].P[kk];
	count++;
	}
	}
	}
	if (count < 2)
	continue;
	vector<int> Inliers[1]; Point3d xyz;
	NviewTriangulationRANSAC(allPts, allP, &xyz, passTri, Inliers, count, 1, 2, 10, 0.7, 7.0, A, B, tallP);
	CorpusInfo.xyz[pid] = xyz;
	} d
	elete[]tallP, delete[]passTri;
	*/

	sprintf(Fname, "%s/JBC/%.4d/3dGL.txt", Path, fid); fp = fopen(Fname, "w+");
	for (size_t ii = 0; ii < CorpusInfo.xyz.size(); ii++)
		fprintf(fp, "%d %.16f %.16f %.16f\n", ii, CorpusInfo.xyz[ii].x, CorpusInfo.xyz[ii].y, CorpusInfo.xyz[ii].z);
	fclose(fp);

	delete[]A, delete[]B, delete[]allP, delete[]allPts, delete[]currentCameras;

	return 0;
}

int NormalizeSfMRecon(vector<CameraData *> &AllCameras, vector<vector<Point3d> *>&AllXYZ, int nCams, int nframes, int npts)
{
	//scale all the 3D points so that theirs L2 norm is not too small (~100)
	int count = 0;
	double stdx = 0, stdy = 0, stdz = 0, meanx = 0, meany = 0, meanz = 0;
	for (int fid = 0; fid < nframes; fid++)
	{
		for (int jj = 0; jj < npts; jj++)
		{
			vector<Point3d> *XYZ = AllXYZ[fid];
			if (abs(XYZ[0][jj].x) + abs(XYZ[0][jj].y) + abs(XYZ[0][jj].z) > LIMIT3D)
				meanx += XYZ[0][jj].x, meany += XYZ[0][jj].y, meanz += XYZ[0][jj].z, count++;
		}
	}
	meanx = meanx / count, meany = meany / count, meanz = meanz / count;

	for (int fid = 0; fid < nframes; fid++)
	{
		for (int jj = 0; jj < npts; jj++)
		{
			vector<Point3d> *XYZ = AllXYZ[fid];
			if (abs(XYZ[0][jj].x) + abs(XYZ[0][jj].y) + abs(XYZ[0][jj].z) > LIMIT3D)
				stdx += pow(XYZ[0][jj].x - meanx, 2), stdy += pow(XYZ[0][jj].y - meany, 2), stdz += pow(XYZ[0][jj].z - meanz, 2);
		}
	}

	//(X2 - T)*s = X1 --> X2 =X1/s+T; [u,v,1] = K*[R2*X2+T2]; -->[u,v,1] = K*[R2 * X1  + s*(R2*T+ T2)]
	double scale = 100.0 / sqrt((stdx + stdy + stdz) / count);
	double R2[9], T2[3], R1[9], T1[3], T[3] = { meanx, meany, meanz };
	for (int fid = 0; fid < nframes; fid++)
	{
		for (int cid = 0; cid < nCams; cid++)
		{
			GetRTFromrt(AllCameras[fid][cid].rt, R2, T2);
			Map < Vector3d > eT(T, 3), eT2(T2, 3), eT1(T1, 3);
			Map < Matrix < double, 3, 3, RowMajor > > eR2(R2, 3, 3), eR1(R1, 3, 3);
			eR1 = eR2, eT1 = (eR2*eT + eT2)*scale;
			GetrtFromRT(AllCameras[fid][cid].rt, R1, T1);
		}
	}
	for (int fid = 0; fid < nframes; fid++)
	{
		for (int jj = 0; jj < npts; jj++)
		{
			vector<Point3d> *XYZ = AllXYZ[fid];
			if (abs(XYZ[0][jj].x) + abs(XYZ[0][jj].y) + abs(XYZ[0][jj].z) > LIMIT3D)
			{
				XYZ[0][jj].x = (XYZ[0][jj].x - T[0])*scale;
				XYZ[0][jj].y = (XYZ[0][jj].y - T[1])*scale;
				XYZ[0][jj].z = (XYZ[0][jj].z - T[2])*scale;
			}
			else
				XYZ[0][jj] = Point3d(0, 0, 0);
		}
	}

	return 0;
}
int MultiFrameDynamicBA(const vector<CameraData *> AllCameras, vector<vector<Point3d> *>AllXYZ, vector<vector < vector<int> > *> AllviewIdAll3D, vector<vector<vector<Point2d> > *>AlluvAll3D, vector<double> &Weights, vector<double> &sigmaParas, int nCams, double fps, int nViewsPlus, int LossType, bool debug, bool silent)
{
	const int nJoints = 18;
	double ialpha = 1.0 / fps, Tscale = 1.0;
	double sigma_i2DPoint = 1.0 / sigmaParas[0], //pixel
		sigma_iLimbLenght = 1.0 / sigmaParas[1],// mm
		sigma_iVel = 1.0 / sigmaParas[2], //mm/s
		sigma_iCenterVel = 1.0 / sigmaParas[3]; //mm/s


	ceres::Problem problem;
	ceres::LossFunction *loss_funcion = 0;
	if (LossType == 1) //Huber
		loss_funcion = new ceres::HuberLoss(5.0);

	int viewID, nframes = (int)AllCameras.size(), npts = (int)AllXYZ[0]->size();
	double residuals[3];

	vector<bool *> discard3Dpoint;
	vector<vector<bool> *> Good;
	for (int fid = 0; fid < nframes; fid++)
	{
		vector<vector<int> > * viewIdAll3D = AllviewIdAll3D[fid];
		bool *discard = new bool[npts];
		vector<bool> *goodi = new vector<bool>[npts];
		for (int pid = 0; pid < npts; pid++)
			discard[pid] = false, goodi[pid].reserve(viewIdAll3D[0][pid].size());

		discard3Dpoint.push_back(discard);
		Good.push_back(goodi);
	}
	bool *ValidCameras = new bool[nframes*nCams];
	for (int ii = 0; ii < nframes*nCams; ii++)
		ValidCameras[ii] = false;

	int nBadCounts = 0, goodCount = 0;
	vector<double> ReProjectionErrorX; ReProjectionErrorX.reserve(npts);
	vector<double> ReProjectionErrorY; ReProjectionErrorY.reserve(npts);
	double maxOutlierX = 0.0, maxOutlierY = 0.0;

	printLOG("Setup geometric cost... ");
	int firstValidViewID = -1, refCam = -1, nProjections = 0, nPossibleProjections = 0;
	vector<int> validCamID;
	for (size_t fid = 0; fid < nframes; fid++)
	{
		CameraData *camera = AllCameras[fid];
		vector<Point3d> *XYZ = AllXYZ[fid];
		vector<vector<int> > * viewIdAll3D = AllviewIdAll3D[fid];
		vector < vector<Point2d> > * uvAll3D = AlluvAll3D[fid];
		vector<bool> *goodi = Good[fid];
		bool *discard = discard3Dpoint[fid];
		for (int jj = 0; jj < npts; jj++)
		{
			discard[jj] = true;
			if (abs(XYZ[0][jj].x) < 0.0000001)
				continue;
			int nvisibles = (int)viewIdAll3D[0][jj].size();
			for (int ii = 0; ii < nvisibles; ii++)
			{
				viewID = viewIdAll3D[0][jj][ii];
				if (!camera[viewID].valid)
					goodi[jj].push_back(false);
				else
				{
					bool found = false;
					for (int kk = 0; kk < (int)validCamID.size() && !found; kk++)
						if (viewID == validCamID[kk])
							found = true;
					if (!found)
						validCamID.push_back(viewID);

					if (uvAll3D[0][jj][ii].x < 0 || uvAll3D[0][jj][ii].y < 0)
					{
						goodi[jj].push_back(false);
						continue;
					}

					PinholeReprojectionDebug(camera[viewID].intrinsic, camera[viewID].rt, uvAll3D[0][jj][ii], XYZ[0][jj], residuals);
					if (abs(residuals[0]) > camera[0].threshold || abs(residuals[1]) > camera[0].threshold)
					{
						goodi[jj].push_back(false);
						if (abs(residuals[0]) > maxOutlierX) 	maxOutlierX = residuals[0];
						if (abs(residuals[1]) > maxOutlierY)	maxOutlierY = residuals[1];
						nBadCounts++;
					}
					else
					{
						goodi[jj].push_back(true);
						goodCount++;
					}
				}
			}

			//Discard point
			int count = 0;
			for (int ii = 0; ii < viewIdAll3D[0][jj].size(); ii++)
				if (goodi[jj][ii] == true)
					count++;
			if (count > 1)
				discard[jj] = false;
			else
				continue;

			//add 3D point and its 2D projections to Ceres
			bool once = true;
			int validViewcount = 0;
			double pointErrX = 0.0, pointErrY = 0.0;
			for (int ii = 0; ii < viewIdAll3D[0][jj].size(); ii++)
			{
				if (!goodi[jj][ii])
					continue;

				nPossibleProjections++;
				viewID = viewIdAll3D[0][jj][ii];

				ceres::CostFunction* cost_function = PinholeDistortionReprojectionError_PosePoint::Create(AllCameras[fid][viewID].intrinsic, uvAll3D[0][jj][ii].x, uvAll3D[0][jj][ii].y, sigma_i2DPoint);
				problem.AddResidualBlock(cost_function, loss_funcion, AllCameras[fid][viewID].rt, &XYZ[0][jj].x);
				//ceres::CostFunction* cost_function = PinholeReprojectionError::Create(uvAll3D[0][jj][ii].x, uvAll3D[0][jj][ii].y, sigma_i2DPoint);
				//problem.AddResidualBlock(cost_function, loss_funcion, camera[viewID].intrinsic, camera[viewID].rt, &XYZ[0][jj].x);
				//problem.SetParameterBlockConstant(camera[viewID].intrinsic);

				if (firstValidViewID == -1)
				{
					firstValidViewID = viewID;
					problem.SetParameterBlockConstant(camera[firstValidViewID].rt);
				}

				ValidCameras[nCams*fid + viewID] = true;

				PinholeReprojectionDebug(camera[viewID].intrinsic, camera[viewID].rt, uvAll3D[0][jj][ii], XYZ[0][jj], residuals);
				pointErrX += pow(residuals[0], 2), pointErrY += pow(residuals[1], 2);
				validViewcount++;
			}
			if (validViewcount > 1)
			{
				ReProjectionErrorX.push_back(sqrt(pointErrX / validViewcount));
				ReProjectionErrorY.push_back(sqrt(pointErrY / validViewcount));
			}
		}
	}

	printLOG("joint length cost for points ...");
	Point2i Joints2Limb[] = { Point2i(0, 1), Point2i(1, 2), Point2i(2, 3), Point2i(3, 4), Point2i(1, 5), Point2i(5, 6), Point2i(6, 7),
		Point2i(1, 8), Point2i(8, 9), Point2i(9, 10), Point2i(1, 11), Point2i(11, 12), Point2i(12, 13), Point2i(0, 14), Point2i(0, 15), Point2i(14, 16), Point2i(15, 17) };

	vector<vector<double> >allMeanLimbLength;
	for (int pid = 0; pid < npts / nJoints; pid++)
	{
		vector<int> vCount(17);
		vector<double> meanLimbLength(17);
		for (int fid = 0; fid < nframes; fid++)
		{
			for (int ii = 0; ii < 17; ii++)
			{
				int ii1 = pid * nJoints + Joints2Limb[ii].x, ii2 = pid * nJoints + Joints2Limb[ii].y;
				if (!discard3Dpoint[fid][ii1] && !discard3Dpoint[fid][ii2])
					meanLimbLength[ii] += norm(AllXYZ[fid][0][ii1] - AllXYZ[fid][0][ii2]), vCount[ii]++;
			}
		}

		for (int ii = 0; ii < 17; ii++)
		{
			if (vCount[ii] == 0)
				meanLimbLength[ii] = 0.0;
			else
				meanLimbLength[ii] /= vCount[ii];
		}
		allMeanLimbLength.push_back(meanLimbLength);
	}

	vector<double> ConstLimbLengthCost; ConstLimbLengthCost.reserve(nframes*npts);
	for (int pid = 0; pid < npts / nJoints; pid++)
	{
		for (int fid = 0; fid < nframes; fid++)
		{
			for (int ii = 0; ii < 17; ii++)
			{
				int ii1 = pid * nJoints + Joints2Limb[ii].x, ii2 = pid * nJoints + +Joints2Limb[ii].y;
				if (!discard3Dpoint[fid][ii1] && !discard3Dpoint[fid][ii2] && allMeanLimbLength[pid][ii] > 0.0)
				{
					//ceres::CostFunction* cost_function = LeastMotionPriorCost3DCeres::CreateAutoDiff(ialpha*fid, ialpha*(fid + 1), 0.0, sigma_iVel, 2); // (v/sigma_iVel)^2*dt) =  ((dX/dt)/sigma_iVel)^2*dt =  (dX/sigma_iVel)^2/dt
					ceres::CostFunction* cost_function = ConstantLimbLengthCost3DCeres::CreateAutoDiff(allMeanLimbLength[pid][ii], sigma_iLimbLenght);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, Weights[0], ceres::TAKE_OWNERSHIP);

					vector<double *> paras; paras.push_back(&AllXYZ[fid][0][ii1].x), paras.push_back(&AllXYZ[fid][0][ii2].x);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ConstLimbLengthCost.push_back(residuals[0]);

					problem.AddResidualBlock(cost_function, ScaleLoss, &AllXYZ[fid][0][ii1].x, &AllXYZ[fid][0][ii2].x);
				}
			}
		}
	}

	printLOG("dynamic cost for points ...");
	vector<double> PointDynamicCost; PointDynamicCost.reserve(nframes*npts);
	for (int fid = 0; fid < nframes - 1; fid++)
	{
		for (int pid = 0; pid < npts; pid++)
		{
			if (!discard3Dpoint[fid][pid] && !discard3Dpoint[fid + 1][pid])
			{
				//ceres::CostFunction* cost_function = LeastMotionPriorCost3DCeres::CreateAutoDiff(ialpha*fid, ialpha*(fid + 1), 0.0, sigma_iVel, 2); // (v/sigma_iVel)^2*dt) =  ((dX/dt)/sigma_iVel)^2*dt =  (dX/sigma_iVel)^2/dt
				ceres::CostFunction* cost_function = LeastMotionPriorCost3DCeres2::CreateAutoDiff(ialpha*fid, ialpha*(fid + 1), sigma_iVel);
				ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, Weights[1], ceres::TAKE_OWNERSHIP);

				vector<double *> paras; paras.push_back(&AllXYZ[fid][0][pid].x), paras.push_back(&AllXYZ[fid + 1][0][pid].x);
				cost_function->Evaluate(&paras[0], residuals, NULL);
				PointDynamicCost.push_back(sqrt(residuals[0] * residuals[0] + residuals[1] * residuals[1] + residuals[2] * residuals[2]));

				problem.AddResidualBlock(cost_function, ScaleLoss, &AllXYZ[fid][0][pid].x, &AllXYZ[fid + 1][0][pid].x);
			}
		}
	}

	printLOG("and camera center motion cost\n");
	vector<double> CameraCenterDynamicCost; CameraCenterDynamicCost.reserve(nframes*npts);
	for (int fid = 0; fid < nframes - 1; fid++)
	{
		for (int cid = 0; cid < nCams; cid++)
		{
			if (ValidCameras[nCams*fid + viewID] && ValidCameras[nCams*(fid + 1) + viewID])
			{
				ceres::CostFunction* cost_function1 = LeastMotionPriorCostCameraCeres::CreateAutoDiff(ialpha*fid, ialpha*(fid + 1), sigma_iCenterVel); // (v/sigma)^2*dt) =  ((dX/dt)/sigma)^2*dt =  dX^2/dt/sigma^2
				ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, Weights[2], ceres::TAKE_OWNERSHIP);

				vector<double *> paras; paras.push_back(AllCameras[fid][cid].rt), paras.push_back(AllCameras[fid + 1][cid].rt);
				cost_function1->Evaluate(&paras[0], residuals, NULL);
				for (int ii = 0; ii < 3; ii++)
					CameraCenterDynamicCost.push_back(residuals[ii]);

				problem.AddResidualBlock(cost_function1, ScaleLoss, AllCameras[fid][cid].rt, AllCameras[fid + 1][cid].rt);
			}
		}
	}

	double miniX, maxiX, avgX, stdX, miniY, maxiY, avgY, stdY;
	if (ReProjectionErrorX.size() == 0 || ReProjectionErrorY.size() == 0)
		printLOG("Error. The BA gives 0 inliers!");
	else
	{
		miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
		maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
		avgX = MeanArray(ReProjectionErrorX);
		stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
		miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
		maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
		avgY = MeanArray(ReProjectionErrorY);
		stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
		printLOG("(%d/%d) bad projections with maximum reprojection error of (%.2f %.2f) \n", nBadCounts, nBadCounts + goodCount, maxOutlierX, maxOutlierY);
		printLOG("Reprojection error before BA: Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
	}

	double mini, maxi, avg, std_;
	if (ConstLimbLengthCost.size() > 0)
	{
		mini = *min_element(ConstLimbLengthCost.begin(), ConstLimbLengthCost.end());
		maxi = *max_element(ConstLimbLengthCost.begin(), ConstLimbLengthCost.end());
		avg = MeanArray(ConstLimbLengthCost);
		std_ = sqrt(VarianceArray(ConstLimbLengthCost, avg));
		printLOG("Const limb length cost before BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No points for BA!");

	if (PointDynamicCost.size() > 0)
	{
		mini = *min_element(PointDynamicCost.begin(), PointDynamicCost.end());
		maxi = *max_element(PointDynamicCost.begin(), PointDynamicCost.end());
		avg = MeanArray(PointDynamicCost);
		std_ = sqrt(VarianceArray(PointDynamicCost, avg));
		printLOG("Point dynamic cost before BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No points for BA!");

	if (CameraCenterDynamicCost.size() > 0)
	{
		mini = *min_element(CameraCenterDynamicCost.begin(), CameraCenterDynamicCost.end());
		maxi = *max_element(CameraCenterDynamicCost.begin(), CameraCenterDynamicCost.end());
		avg = MeanArray(CameraCenterDynamicCost);
		std_ = sqrt(VarianceArray(CameraCenterDynamicCost, avg));
		printLOG("Camera center dynamic cost before BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No camera center for BA!\n");

	ceres::Solver::Options options;
	options.num_threads = omp_get_max_threads();
	options.num_linear_solver_threads = omp_get_max_threads();
	options.max_num_iterations = 100;
	options.linear_solver_type = ceres::CGNR;
	options.preconditioner_type = ceres::JACOBI;
	options.function_tolerance = 1.0e-6;
	options.max_solver_time_in_seconds = 300.0;
	options.minimizer_progress_to_stdout = silent ? false : true;
	options.trust_region_strategy_type = ceres::LEVENBERG_MARQUARDT;
	options.use_nonmonotonic_steps = false;

	ceres::Solver::Summary summary;
	ceres::Solve(options, &problem, &summary);
	if (silent)
		std::cout << summary.BriefReport() << "\n";
	else
		std::cout << summary.FullReport() << "\n";

	ReProjectionErrorX.clear(), ReProjectionErrorY.clear();
	for (int fid = 0; fid < nframes; fid++)
	{
		for (int jj = 0; jj < npts; jj++)
		{
			CameraData *camera = AllCameras[fid];
			vector<Point3d> *XYZ = AllXYZ[fid];
			vector<vector<int> > * viewIdAll3D = AllviewIdAll3D[fid];
			vector < vector<Point2d> > * uvAll3D = AlluvAll3D[fid];
			vector<bool> *goodi = Good[fid];
			bool *discard = discard3Dpoint[fid];

			if (abs(XYZ[0][jj].x) > LIMIT3D && !discard[jj])
			{
				int validViewcount = 0;
				double pointErrX = 0.0, pointErrY = 0.0;
				for (int ii = 0; ii < viewIdAll3D[0][jj].size(); ii++)
				{
					if (!goodi[jj][ii] || uvAll3D[0][jj][ii].x < 0)
						continue;

					viewID = viewIdAll3D[0][jj][ii];
					PinholeReprojectionDebug(camera[viewID].intrinsic, camera[viewID].rt, uvAll3D[0][jj][ii], XYZ[0][jj], residuals);

					pointErrX += pow(residuals[0], 2), pointErrY += pow(residuals[1], 2);
					validViewcount++;
				}

				ReProjectionErrorX.push_back(sqrt(pointErrX / validViewcount));
				ReProjectionErrorY.push_back(sqrt(pointErrY / validViewcount));
			}
		}
	}

	ConstLimbLengthCost.clear();
	for (int pid = 0; pid < npts / nJoints; pid++)
	{
		for (int fid = 0; fid < nframes; fid++)
		{
			for (int ii = 0; ii < 17; ii++)
			{
				int ii1 = pid * nJoints + Joints2Limb[ii].x, ii2 = pid * nJoints + +Joints2Limb[ii].y;
				if (!discard3Dpoint[fid][ii1] && !discard3Dpoint[fid][ii2] && allMeanLimbLength[pid][ii] > 0.0)
				{
					ceres::CostFunction* cost_function = ConstantLimbLengthCost3DCeres::CreateAutoDiff(allMeanLimbLength[pid][ii], sigma_iLimbLenght);
					vector<double *> paras; paras.push_back(&AllXYZ[fid][0][ii1].x), paras.push_back(&AllXYZ[fid][0][ii2].x);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ConstLimbLengthCost.push_back(residuals[0]);
				}
			}
		}
	}

	PointDynamicCost.clear();
	for (int fid = 0; fid < nframes - 1; fid++)
	{
		for (int pid = 0; pid < npts; pid++)
		{
			if (!discard3Dpoint[fid][pid] && !discard3Dpoint[fid + 1][pid])
			{
				ceres::CostFunction* cost_function = LeastMotionPriorCost3DCeres::CreateAutoDiff(ialpha*fid, ialpha*(fid + 1), 0.0, sigma_iVel, 2); //Weight* (v/sigma_iVel)^2*dt) = Weight* ((dX/dt)/sigma_iVel)^2*dt = W * dX^2/dt/sigma_iVel^2
				vector<double *> paras; paras.push_back(&AllXYZ[fid][0][pid].x), paras.push_back(&AllXYZ[fid + 1][0][pid].x);
				cost_function->Evaluate(&paras[0], residuals, NULL);
				PointDynamicCost.push_back(residuals[0]);
			}
		}
	}

	CameraCenterDynamicCost.clear();
	for (int fid = 0; fid < nframes - 1; fid++)
	{
		for (int cid = 0; cid < nCams; cid++)
		{
			if (ValidCameras[nCams*fid + viewID] && ValidCameras[nCams*(fid + 1) + viewID])
			{
				ceres::CostFunction* cost_function1 = LeastMotionPriorCostCameraCeres::CreateAutoDiff(ialpha*fid, ialpha*(fid + 1), sigma_iCenterVel); // (v/sigma)^2*dt) =  ((dX/dt)/sigma)^2*dt =  dX^2/dt/sigma^2
				vector<double *> paras; paras.push_back(AllCameras[fid][cid].rt), paras.push_back(AllCameras[fid + 1][cid].rt);
				cost_function1->Evaluate(&paras[0], residuals, NULL);
				for (int ii = 0; ii < 3; ii++)
					CameraCenterDynamicCost.push_back(residuals[ii]);
			}
		}
	}

	if (ReProjectionErrorX.size() > 0)
	{
		double miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
		double maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
		double avgX = MeanArray(ReProjectionErrorX);
		double stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
		double miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
		double maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
		double avgY = MeanArray(ReProjectionErrorY);
		double stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
		printLOG("Reprojection error after BA: Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
	}

	if (ConstLimbLengthCost.size() > 0)
	{
		mini = *min_element(ConstLimbLengthCost.begin(), ConstLimbLengthCost.end());
		maxi = *max_element(ConstLimbLengthCost.begin(), ConstLimbLengthCost.end());
		avg = MeanArray(ConstLimbLengthCost);
		std_ = sqrt(VarianceArray(ConstLimbLengthCost, avg));
		printLOG("Const limb length cost after BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No points for BA!");

	if (PointDynamicCost.size() > 0)
	{
		mini = *min_element(PointDynamicCost.begin(), PointDynamicCost.end());
		maxi = *max_element(PointDynamicCost.begin(), PointDynamicCost.end());
		avg = MeanArray(PointDynamicCost);
		std_ = sqrt(VarianceArray(PointDynamicCost, avg));
		printLOG("Point dynamic cost after BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No points for BA!");

	if (CameraCenterDynamicCost.size() > 0)
	{
		mini = *min_element(CameraCenterDynamicCost.begin(), CameraCenterDynamicCost.end());
		maxi = *max_element(CameraCenterDynamicCost.begin(), CameraCenterDynamicCost.end());
		avg = MeanArray(CameraCenterDynamicCost);
		std_ = sqrt(VarianceArray(CameraCenterDynamicCost, avg));
		printLOG("Camera center dynamic cost after BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No camera center for BA!\n");

	delete[]ValidCameras;
	for (int fid = 0; fid < nframes; fid++)
		delete[]Good[fid], delete[]discard3Dpoint[fid];

	return goodCount;
}
int MultiFrameDynamicBA_SimilarityTransform(vector<CameraData *> &AllCameras, vector<vector<Point3d> *>&AllXYZ, vector<vector < vector<int> > *> &AllviewIdAll3D, vector<vector<vector<Point2d> > *>&AlluvAll3D, double *Weights, double *sigmaParas, int nCams, double fps, int nViewsPlus, int LossType, bool debug, bool silent)
{
	const int nJoints = 18;
	double ialpha = 1.0 / fps, Tscale = 1.0;
	double sigma_iLimbLenght = 1.0 / sigmaParas[0],// mm
		sigma_iVel = 1.0 / sigmaParas[1], //mm/s
		sigma_iCenterVel = 1.0 / sigmaParas[2]; //mm/s

	ceres::Problem problem;
	ceres::LossFunction *loss_funcion = 0;
	if (LossType == 1) //Huber
		loss_funcion = new ceres::HuberLoss(5.0);

	int viewID, nframes = (int)AllCameras.size(), npts = (int)AllXYZ[0]->size();
	double residuals[3];

	double *srt = new double[7 * nframes];
	for (int ii = 0; ii < nframes; ii++)
		srt[7 * ii] = 1.0, srt[7 * ii + 1] = 0, srt[7 * ii + 2] = 0, srt[7 * ii + 3] = 0, srt[7 * ii + 4] = 0, srt[7 * ii + 5] = 0, srt[7 * ii + 6] = 0;

	vector<bool *> discard3Dpoint;
	vector<vector<bool> *> Good;
	for (int fid = 0; fid < nframes; fid++)
	{
		vector<vector<int> > * viewIdAll3D = AllviewIdAll3D[fid];
		bool *discard = new bool[npts];
		vector<bool> *goodi = new vector<bool>[npts];
		for (int pid = 0; pid < npts; pid++)
			discard[pid] = false, goodi[pid].reserve(viewIdAll3D[0][pid].size());

		discard3Dpoint.push_back(discard);
		Good.push_back(goodi);
	}
	bool *ValidCameras = new bool[nframes*nCams];
	for (int ii = 0; ii < nframes*nCams; ii++)
		ValidCameras[ii] = false;

	int nBadCounts = 0, goodCount = 0;
	vector<double> ReProjectionErrorX; ReProjectionErrorX.reserve(npts);
	vector<double> ReProjectionErrorY; ReProjectionErrorY.reserve(npts);
	double maxOutlierX = 0.0, maxOutlierY = 0.0;

	int firstValidViewID = -1, refCam = -1, nProjections = 0, nPossibleProjections = 0;
	vector<int> validCamID;
	for (size_t fid = 0; fid < nframes; fid++)
	{
		CameraData *camera = AllCameras[fid];
		vector<Point3d> *XYZ = AllXYZ[fid];
		vector<vector<int> > * viewIdAll3D = AllviewIdAll3D[fid];
		vector < vector<Point2d> > * uvAll3D = AlluvAll3D[fid];
		vector<bool> *goodi = Good[fid];
		bool *discard = discard3Dpoint[fid];
		for (int jj = 0; jj < npts; jj++)
		{
			discard[jj] = true;
			if (abs(XYZ[0][jj].x) + abs(XYZ[0][jj].y) + abs(XYZ[0][jj].z) < LIMIT3D)
				continue;
			int nvisibles = (int)viewIdAll3D[0][jj].size();
			for (int ii = 0; ii < nvisibles; ii++)
			{
				viewID = viewIdAll3D[0][jj][ii];
				if (!camera[viewID].valid)
					goodi[jj].push_back(false);
				else
				{
					bool found = false;
					for (int kk = 0; kk < (int)validCamID.size() && !found; kk++)
						if (viewID == validCamID[kk])
							found = true;
					if (!found)
						validCamID.push_back(viewID);

					if (uvAll3D[0][jj][ii].x < 0 || uvAll3D[0][jj][ii].y < 0)
					{
						goodi[jj].push_back(false);
						continue;
					}

					PinholeReprojectionDebug(camera[viewID].intrinsic, camera[viewID].rt, uvAll3D[0][jj][ii], XYZ[0][jj], residuals);
					if (abs(residuals[0]) > camera[0].threshold || abs(residuals[1]) > camera[0].threshold)
					{
						goodi[jj].push_back(false);
						if (abs(residuals[0]) > maxOutlierX) 	maxOutlierX = residuals[0];
						if (abs(residuals[1]) > maxOutlierY)	maxOutlierY = residuals[1];
						nBadCounts++;
					}
					else
					{
						goodi[jj].push_back(true);
						goodCount++;
					}
				}
			}

			//Discard point
			int count = 0;
			for (int ii = 0; ii < viewIdAll3D[0][jj].size(); ii++)
				if (goodi[jj][ii] == true)
					count++;
			if (count > 1)
				discard[jj] = false;

			//add 3D point and its 2D projections to Ceres
			bool once = true;
			int validViewcount = 0;
			double pointErrX = 0.0, pointErrY = 0.0;
			for (int ii = 0; ii < viewIdAll3D[0][jj].size(); ii++)
			{
				if (!goodi[jj][ii])
					continue;

				nPossibleProjections++;
				viewID = viewIdAll3D[0][jj][ii];
				ValidCameras[nCams*fid + viewID] = true;

				PinholeReprojectionDebug(camera[viewID].intrinsic, camera[viewID].rt, uvAll3D[0][jj][ii], XYZ[0][jj], residuals);
				pointErrX += pow(residuals[0], 2), pointErrY += pow(residuals[1], 2);
				validViewcount++;
			}
			if (validViewcount > 1)
			{
				ReProjectionErrorX.push_back(sqrt(pointErrX / validViewcount));
				ReProjectionErrorY.push_back(sqrt(pointErrY / validViewcount));
			}
		}
	}

	printLOG("const joint length cost ...");
	Point2i Joints2Limb[] = { Point2i(0, 1), Point2i(1, 2), Point2i(2, 3), Point2i(3, 4), Point2i(1, 5), Point2i(5, 6), Point2i(6, 7),
		Point2i(1, 8), Point2i(8, 9), Point2i(9, 10), Point2i(1, 11), Point2i(11, 12), Point2i(12, 13), Point2i(0, 14), Point2i(0, 15), Point2i(14, 16), Point2i(15, 17) };

	vector<vector<double> >allMeanLimbLength;
	for (int pid = 0; pid < npts / nJoints; pid++)
	{
		vector<int> vCount(17);
		vector<double> meanLimbLength(17);
		for (int fid = 0; fid < nframes; fid++)
		{
			for (int ii = 0; ii < 17; ii++)
			{
				int ii1 = pid * nJoints + Joints2Limb[ii].x, ii2 = pid * nJoints + Joints2Limb[ii].y;
				if (!discard3Dpoint[fid][ii1] && !discard3Dpoint[fid][ii2])
					meanLimbLength[ii] += norm(AllXYZ[fid][0][ii1] - AllXYZ[fid][0][ii2]), vCount[ii]++;
			}
		}

		for (int ii = 0; ii < 17; ii++)
		{
			if (vCount[ii] == 0)
				meanLimbLength[ii] = 0.0;
			else
				meanLimbLength[ii] /= vCount[ii];
		}
		allMeanLimbLength.push_back(meanLimbLength);
	}

	vector<double> ConstLimbLengthCost; ConstLimbLengthCost.reserve(nframes*npts);
	for (int pid = 0; pid < npts / nJoints; pid++)
	{
		for (int fid = 0; fid < nframes; fid++)
		{
			for (int ii = 0; ii < 17; ii++)
			{
				int ii1 = pid * nJoints + Joints2Limb[ii].x, ii2 = pid * nJoints + +Joints2Limb[ii].y;
				if (!discard3Dpoint[fid][ii1] && !discard3Dpoint[fid][ii2] && allMeanLimbLength[pid][ii] > 0.0)
				{
					ceres::CostFunction* cost_function = ConstantLimbLengthCost3D_SimilarityTrans_Ceres::CreateAutoDiff(AllXYZ[fid][0][ii1], AllXYZ[fid][0][ii2], allMeanLimbLength[pid][ii], sigma_iLimbLenght);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, Weights[0], ceres::TAKE_OWNERSHIP);

					vector<double *> paras; paras.push_back(&srt[7 * fid]);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ConstLimbLengthCost.push_back(residuals[0]);

					problem.AddResidualBlock(cost_function, NULL, &srt[7 * fid]);
					if (fid == 0) //the reference coordinate.
						problem.SetParameterBlockConstant(&srt[7 * fid]);
				}
			}
		}
	}

	printLOG("dynamic cost for points ...");
	vector<double> PointDynamicCost; PointDynamicCost.reserve(nframes*npts);
	for (int fid = 0; fid < nframes - 1; fid++)
	{
		for (int pid = 0; pid < npts; pid++)
		{
			if (!discard3Dpoint[fid][pid] && !discard3Dpoint[fid + 1][pid])
			{
				ceres::CostFunction* cost_function = LeastMotionPriorCost3D_SimilarityTrans_Ceres::CreateAutoDiff(AllXYZ[fid][0][pid], AllXYZ[fid + 1][0][pid], ialpha*fid, ialpha*(fid + 1), sigma_iVel);  // (v/sigma_iVel)^2*dt) =  ((dX/dt)/sigma_iVel)^2*dt =  (dX/sigma_iVel)^2/dt
				ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, Weights[1], ceres::TAKE_OWNERSHIP);

				vector<double *> paras; paras.push_back(&srt[7 * fid]), paras.push_back(&srt[7 * (fid + 1)]);
				cost_function->Evaluate(&paras[0], residuals, NULL);
				PointDynamicCost.push_back(sqrt(residuals[0] * residuals[0] + residuals[1] * residuals[1] + residuals[2] * residuals[2]));

				problem.AddResidualBlock(cost_function, ScaleLoss, &srt[7 * fid], &srt[7 * (fid + 1)]);
				if (fid == 0) //the reference coordinate.
					problem.SetParameterBlockConstant(&srt[7 * fid]);
			}
		}
	}

	printLOG("and camera center motion cost\n");
	vector<double> CameraCenterDynamicCost; CameraCenterDynamicCost.reserve(nframes*npts);
	for (int fid = 0; fid < nframes; fid++)
	{
		CameraData *camera = AllCameras[fid];
		for (int cid = 0; cid < nCams; cid++)
		{
			GetRTFromrt(camera[cid].rt, camera[cid].R, camera[cid].T);
			GetCfromT(camera[cid].R, camera[cid].T, camera[cid].camCenter);
		}
	}
	for (int fid = 0; fid < nframes - 1; fid++)
	{
		for (int cid = 0; cid < nCams; cid++)
		{
			if (ValidCameras[nCams*fid + cid] && ValidCameras[nCams*(fid + 1) + cid])
			{
				Point3d cam1(AllCameras[fid][cid].camCenter[0], AllCameras[fid][cid].camCenter[1], AllCameras[fid][cid].camCenter[2]);
				Point3d cam2(AllCameras[fid + 1][cid].camCenter[0], AllCameras[fid + 1][cid].camCenter[1], AllCameras[fid + 1][cid].camCenter[2]);

				ceres::CostFunction* cost_function = LeastMotionPriorCost3D_SimilarityTrans_Ceres::CreateAutoDiff(cam1, cam2, ialpha*fid, ialpha*(fid + 1), sigma_iCenterVel); // (v/sigma)^2*dt) =  ((dX/dt)/sigma)^2*dt =  dX^2/dt/sigma^2
				ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, Weights[2], ceres::TAKE_OWNERSHIP);

				vector<double *> paras; paras.push_back(&srt[7 * fid]), paras.push_back(&srt[7 * (fid + 1)]);
				cost_function->Evaluate(&paras[0], residuals, NULL);
				CameraCenterDynamicCost.push_back(sqrt(residuals[0] * residuals[0] + residuals[1] * residuals[1] + residuals[2] * residuals[2]));

				problem.AddResidualBlock(cost_function, ScaleLoss, &srt[7 * fid], &srt[7 * (fid + 1)]);
				if (fid == 0) //the reference coordinate.
					problem.SetParameterBlockConstant(&srt[7 * fid]);
			}
		}
	}

	double miniX, maxiX, avgX, stdX, miniY, maxiY, avgY, stdY;
	if (ReProjectionErrorX.size() == 0 || ReProjectionErrorY.size() == 0)
		printLOG("Error. No points for 2D reprojection BA!\n");
	else
	{
		miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
		maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
		avgX = MeanArray(ReProjectionErrorX);
		stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
		miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
		maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
		avgY = MeanArray(ReProjectionErrorY);
		stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
		printLOG("(%d/%d) bad projections with maximum reprojection error of (%.2f %.2f) \n", nBadCounts, nBadCounts + goodCount, maxOutlierX, maxOutlierY);
		printLOG("Reprojection error before BA: Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
	}

	double mini, maxi, avg, std_;
	if (ConstLimbLengthCost.size() > 0)
	{
		mini = *min_element(ConstLimbLengthCost.begin(), ConstLimbLengthCost.end());
		maxi = *max_element(ConstLimbLengthCost.begin(), ConstLimbLengthCost.end());
		avg = MeanArray(ConstLimbLengthCost);
		std_ = sqrt(VarianceArray(ConstLimbLengthCost, avg));
		printLOG("Const limb length cost before BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No points for limb preserving BA!\n");

	if (PointDynamicCost.size() > 0)
	{
		mini = *min_element(PointDynamicCost.begin(), PointDynamicCost.end());
		maxi = *max_element(PointDynamicCost.begin(), PointDynamicCost.end());
		avg = MeanArray(PointDynamicCost);
		std_ = sqrt(VarianceArray(PointDynamicCost, avg));
		printLOG("Point dynamic cost before BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No points for point motion BA!\n");

	if (CameraCenterDynamicCost.size() > 0)
	{
		mini = *min_element(CameraCenterDynamicCost.begin(), CameraCenterDynamicCost.end());
		maxi = *max_element(CameraCenterDynamicCost.begin(), CameraCenterDynamicCost.end());
		avg = MeanArray(CameraCenterDynamicCost);
		std_ = sqrt(VarianceArray(CameraCenterDynamicCost, avg));
		printLOG("Camera center dynamic cost before BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No camera center for BA!\n");

	ceres::Solver::Options options;
	options.num_threads = omp_get_max_threads();
	options.num_linear_solver_threads = omp_get_max_threads();
	options.max_num_iterations = 100;
	options.linear_solver_type = ceres::SPARSE_NORMAL_CHOLESKY;
	options.function_tolerance = 1.0e-6;
	options.max_solver_time_in_seconds = 300.0;
	options.minimizer_progress_to_stdout = silent ? false : true;
	options.trust_region_strategy_type = ceres::LEVENBERG_MARQUARDT;
	options.use_nonmonotonic_steps = false;

	ceres::Solver::Summary summary;
	ceres::Solve(options, &problem, &summary);
	if (silent)
		std::cout << summary.BriefReport() << "\n";
	else
		std::cout << summary.FullReport() << "\n";

	printLOG("Esimated similarity transformed:\n");
	for (int fid = 0; fid < nframes; fid++)
		printLOG("%d %f %f %f %f %f %f %f\n", AllCameras[fid][0].frameID, srt[7 * fid], srt[7 * fid + 1], srt[7 * fid + 2], srt[7 * fid + 2], srt[7 * fid + 3], srt[7 * fid + 4], srt[7 * fid + 5], srt[7 * fid + 6]);
	printLOG("\n");

	ConstLimbLengthCost.clear();
	for (int pid = 0; pid < npts / nJoints; pid++)
	{
		for (int fid = 0; fid < nframes; fid++)
		{
			for (int ii = 0; ii < 17; ii++)
			{
				int ii1 = pid * nJoints + Joints2Limb[ii].x, ii2 = pid * nJoints + +Joints2Limb[ii].y;
				if (!discard3Dpoint[fid][ii1] && !discard3Dpoint[fid][ii2] && allMeanLimbLength[pid][ii] > 0.0)
				{
					ceres::CostFunction* cost_function = ConstantLimbLengthCost3D_SimilarityTrans_Ceres::CreateAutoDiff(AllXYZ[fid][0][ii1], AllXYZ[fid][0][ii2], allMeanLimbLength[pid][ii], sigma_iLimbLenght);
					vector<double *> paras; paras.push_back(&srt[7 * fid]);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ConstLimbLengthCost.push_back(residuals[0]);
				}
			}
		}
	}

	PointDynamicCost.clear();
	for (int fid = 0; fid < nframes - 1; fid++)
	{
		for (int pid = 0; pid < npts; pid++)
		{
			if (!discard3Dpoint[fid][pid] && !discard3Dpoint[fid + 1][pid])
			{
				srt[7 * (fid + 1)], srt[7 * (fid + 1) + 1], srt[7 * (fid + 1) + 2], srt[7 * (fid + 1) + 3], srt[7 * (fid + 1) + 4], srt[7 * (fid + 1) + 5], srt[7 * (fid + 1) + 6];
				ceres::CostFunction* cost_function = LeastMotionPriorCost3D_SimilarityTrans_Ceres::CreateAutoDiff(AllXYZ[fid][0][pid], AllXYZ[fid + 1][0][pid], ialpha*fid, ialpha*(fid + 1), sigma_iVel);  // (v/sigma_iVel)^2*dt) =  ((dX/dt)/sigma_iVel)^2*dt =  (dX/sigma_iVel)^2/dt
				vector<double *> paras; paras.push_back(&srt[7 * fid]), paras.push_back(&srt[7 * (fid + 1)]);
				cost_function->Evaluate(&paras[0], residuals, NULL);
				PointDynamicCost.push_back(sqrt(residuals[0] * residuals[0] + residuals[1] * residuals[1] + residuals[2] * residuals[2]));
			}
		}
	}

	CameraCenterDynamicCost.clear();
	for (int fid = 0; fid < nframes - 1; fid++)
	{
		for (int cid = 0; cid < nCams; cid++)
		{
			if (ValidCameras[nCams*fid + cid] && ValidCameras[nCams*(fid + 1) + cid])
			{
				Point3d cam1(AllCameras[fid][cid].camCenter[0], AllCameras[fid][cid].camCenter[1], AllCameras[fid][cid].camCenter[2]);
				Point3d cam2(AllCameras[fid + 1][cid].camCenter[0], AllCameras[fid + 1][cid].camCenter[1], AllCameras[fid + 1][cid].camCenter[2]);

				ceres::CostFunction* cost_function = LeastMotionPriorCost3D_SimilarityTrans_Ceres::CreateAutoDiff(cam1, cam2, ialpha*fid, ialpha*(fid + 1), sigma_iCenterVel); // (v/sigma)^2*dt) =  ((dX/dt)/sigma)^2*dt =  dX^2/dt/sigma^2
				vector<double *> paras; paras.push_back(&srt[7 * fid]), paras.push_back(&srt[7 * (fid + 1)]);
				cost_function->Evaluate(&paras[0], residuals, NULL);
				CameraCenterDynamicCost.push_back(sqrt(residuals[0] * residuals[0] + residuals[1] * residuals[1] + residuals[2] * residuals[2]));
			}
		}
	}
	if (ConstLimbLengthCost.size() > 0)
	{
		mini = *min_element(ConstLimbLengthCost.begin(), ConstLimbLengthCost.end());
		maxi = *max_element(ConstLimbLengthCost.begin(), ConstLimbLengthCost.end());
		avg = MeanArray(ConstLimbLengthCost);
		std_ = sqrt(VarianceArray(ConstLimbLengthCost, avg));
		printLOG("Const limb length cost after BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No points for limb length preserving BA\n!");

	if (PointDynamicCost.size() > 0)
	{
		mini = *min_element(PointDynamicCost.begin(), PointDynamicCost.end());
		maxi = *max_element(PointDynamicCost.begin(), PointDynamicCost.end());
		avg = MeanArray(PointDynamicCost);
		std_ = sqrt(VarianceArray(PointDynamicCost, avg));
		printLOG("Point dynamic cost after BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No points for joint motion BA!\n");

	if (CameraCenterDynamicCost.size() > 0)
	{
		mini = *min_element(CameraCenterDynamicCost.begin(), CameraCenterDynamicCost.end());
		maxi = *max_element(CameraCenterDynamicCost.begin(), CameraCenterDynamicCost.end());
		avg = MeanArray(CameraCenterDynamicCost);
		std_ = sqrt(VarianceArray(CameraCenterDynamicCost, avg));
		printLOG("Camera center dynamic cost after BA: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f.\n", mini, maxi, avg, std_);
	}
	else
		printLOG("Error. No camera center for BA!\n");

	//transform the orginal camera pose and XYZ
	double R[9], T[3], R1[9], T1[3];
	for (int fid = 0; fid < nframes; fid++)
	{
		for (int cid = 0; cid < nCams; cid++)
		{
			//sR*X2 + T = X1 --> X2 = R^T(X1-T)/s; amda*[u,v,1] = K*[R2X+T2]; -->s*lamda*[u,v,1] = K*[R2 * R^T *X1 - R2*R^T *T+ T2s]
			GetRTFromrt(&srt[7 * fid + 1], R, T);
			Map < Vector3d > eT(T, 3), eT2(AllCameras[fid][cid].T, 3), eT1(T1, 3);
			Map < Matrix < double, 3, 3, RowMajor > > eR(R, 3, 3), eR2(AllCameras[fid][cid].R, 3, 3), eR1(R1, 3, 3);
			eR1 = eR2 * eR.transpose(), eT1 = -eR2 * eR.transpose()*eT + eT2 * srt[7 * fid];
			GetrtFromRT(AllCameras[fid][cid].rt, R1, T1);  //transform fid to a common ref coordinate
		}
	}
	for (int fid = 0; fid < nframes; fid++)
	{
		for (int jj = 0; jj < npts; jj++)
		{
			vector<Point3d> *XYZ = AllXYZ[fid];
			if (!discard3Dpoint[fid][jj])
			{
				double tpoint[3], point[3] = { XYZ[0][jj].x, XYZ[0][jj].y, XYZ[0][jj].z };
				ceres::AngleAxisRotatePoint(&srt[7 * fid + 1], point, tpoint);
				XYZ[0][jj].x = tpoint[0] * srt[7 * fid] + srt[7 * fid + 4], XYZ[0][jj].y = tpoint[1] * srt[7 * fid] + srt[7 * fid + 5], XYZ[0][jj].z = tpoint[2] * srt[7 * fid] + srt[7 * fid + 6];
			}
			else
				XYZ[0][jj] = Point3d(0, 0, 0);
		}
	}

	/*for (int fid = 0; fid < nframes; fid++)
	{
	sprintf(Fname, "E:/Park/n3dGL_%d.txt", AllCameras[fid][0].frameID); FILE *fp = fopen(Fname, "w+");
	for (size_t ii = 0; ii < AllXYZ[fid][0].size(); ii++)
	fprintf(fp, "%d %.16f %.16f %.16f\n", ii, AllXYZ[fid][0][ii].x, AllXYZ[fid][0][ii].y, AllXYZ[fid][0][ii].z);
	fclose(fp);
	}

	ReProjectionErrorX.clear(), ReProjectionErrorY.clear();
	for (int fid = 0; fid < nframes; fid++)
	{
	for (int jj = 0; jj < npts; jj++)
	{
	vector<Point3d> *XYZ = AllXYZ[fid];
	CameraData *camera = AllCameras[fid];
	vector < vector<Point2d> > * uvAll3D = AlluvAll3D[fid];
	vector<vector<int> > * viewIdAll3D = AllviewIdAll3D[fid];

	if (!discard3Dpoint[fid][jj])
	{
	int validViewcount = 0;
	double pointErrX = 0.0, pointErrY = 0.0;
	for (int ii = 0; ii < viewIdAll3D[0][jj].size(); ii++)
	{
	if (!Good[fid][jj][ii] || uvAll3D[0][jj][ii].x < 0)
	continue;

	viewID = viewIdAll3D[0][jj][ii];
	PinholeReprojectionDebug(camera[viewID].intrinsic, camera[viewID].rt, uvAll3D[0][jj][ii], XYZ[0][jj], residuals);

	pointErrX += pow(residuals[0], 2), pointErrY += pow(residuals[1], 2);
	validViewcount++;
	}

	ReProjectionErrorX.push_back(sqrt(pointErrX / validViewcount)), ReProjectionErrorY.push_back(sqrt(pointErrY / validViewcount));
	}
	}
	}

	if (ReProjectionErrorX.size() > 0)
	{
	double miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
	double maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
	double avgX = MeanArray(ReProjectionErrorX);
	double stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
	double miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
	double maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
	double avgY = MeanArray(ReProjectionErrorY);
	double stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
	printLOG("Reprojection error after BA: Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
	}*/

	delete[]ValidCameras, delete[]srt;
	for (int fid = 0; fid < nframes; fid++)
		delete[]Good[fid], delete[]discard3Dpoint[fid];

	return goodCount;
}
int SimpleBodyPoseSfM_Tracking(char *Path, int refF, int rangeF, int nCams, int nMaxPeople)
{
	char Fname[512];
	int  nJoints = 18, npts = nMaxPeople * nJoints;
	double thresh = 50;

	vector<double > weights, sigmaParas; double fps = 30;
	weights.push_back(1e3), //const limbLength
		weights.push_back(1e6), //joints dynamic cost weight
		weights.push_back(10);  //cam cen dyna cost weight
	sigmaParas.push_back(10.0),//pixel std
		sigmaParas.push_back(30.0), //const limbLength (mm)
		sigmaParas.push_back(500), //joint 3D vel std (500 mm/s)
		sigmaParas.push_back(5); //cam center vel std (mm)

	printLOG("Weights: %.2e %2e %.2e. Sigma: %.2e %.2e %.2e %.2e\n", weights[0], weights[1], weights[2], sigmaParas[0], sigmaParas[1], sigmaParas[2], sigmaParas[3]);

	//Initalize all the data
	CameraData *RefIntrinsic = new CameraData[nCams];
	ReadIntrinsicResults(Path, RefIntrinsic);

	Corpus *AllCorpus = new Corpus[2 * rangeF + 1];
	for (int fid = -rangeF; fid <= rangeF; fid++)
	{
		if (fid + rangeF < 0)
			continue;
		AllCorpus[fid + rangeF].nCameras = nCams, AllCorpus[fid + rangeF].n3dPoints = npts;
		AllCorpus[fid + rangeF].camera = new CameraData[nCams];
		AllCorpus[fid + rangeF].xyz.reserve(npts);
		for (int pid = 0; pid < npts; pid++)
		{
			AllCorpus[fid + rangeF].viewIdAll3D.push_back(vector<int>());
			AllCorpus[fid + rangeF].uvAll3D.push_back(vector<Point2d>());
		}
		for (int cid = 0; cid < nCams; cid++)
		{
			CopyCamereInfo(RefIntrinsic[cid], AllCorpus[fid + rangeF].camera[cid]);
			AllCorpus[fid + rangeF].camera[cid].threshold = thresh;
			AllCorpus[fid + rangeF].camera[cid].frameID = refF + fid, AllCorpus[fid + rangeF].camera[cid].valid = true;
		}
	}

	//Prepare the reference frame
	sprintf(Fname, "%s/JBC/%.4d/BA.txt", Path, refF); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return false;
	}
	int cid, lensType, idummy;
	double fdummy, rt[6];

	fscanf(fp, "%d %d ", &idummy, &idummy);
	while (fscanf(fp, "%d %d %d %d %d", &cid, &lensType, &idummy, &idummy, &idummy) != EOF)
	{
		if (lensType == RADIAL_TANGENTIAL_PRISM)
			fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf ", &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &rt[0], &rt[1], &rt[2], &rt[3], &rt[4], &rt[5]);
		else
			fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf ", &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &fdummy, &rt[0], &rt[1], &rt[2], &rt[3], &rt[4], &rt[5]);
		for (int jj = 0; jj < 6; jj++)
			AllCorpus[rangeF].camera[cid].rt[jj] = rt[jj];
	}
	fclose(fp);

	//use uniform feature scale as conf score is only good at yes-no idication
	vector<vector<double> > currentScaleAll3D; //3D -> scale of that point in those visible views
	for (int pid = 0; pid < npts; pid++)
	{
		currentScaleAll3D.push_back(vector<double>());
		for (int ii = 0; ii < nMaxPeople; ii++)
			currentScaleAll3D.back().push_back(1.0);
	}

	//Read joints info
	for (int fid = -rangeF; fid <= rangeF; fid++)
	{
		for (int cid = 0; cid < nCams; cid++)
		{
			if (fid + rangeF < 0)
				continue;

			sprintf(Fname, "%s/JBC/%.4d/%d.txt", Path, refF + fid, cid); fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			int pid; float s;  Point2f uv;
			while (fscanf(fp, "%d %f %f %f ", &pid, &uv.x, &uv.y, &s) != EOF)
			{
				AllCorpus[fid + rangeF].viewIdAll3D[pid].push_back(cid);
				if (s > 0.5) //weighting based on conf score does not work well
				{
					if (AllCorpus[rangeF].camera[cid].LensModel == RADIAL_TANGENTIAL_PRISM)
						LensCorrectionPoint(&uv, AllCorpus[rangeF].camera[cid].K, AllCorpus[rangeF].camera[cid].distortion);
					else
						//FishEyeCorrectionPoint(&uv, AllCorpus[rangeF].camera[cid].distortion[0], AllCorpus[rangeF].camera[cid].distortion[1], AllCorpus[rangeF].camera[cid].distortion[2]);
						FishEyeCorrectionPoint(&uv, AllCorpus[rangeF].camera[cid].K, AllCorpus[rangeF].camera[cid].distortion[0]);
					AllCorpus[fid + rangeF].uvAll3D[pid].push_back(uv);
				}
				else
					AllCorpus[fid + rangeF].uvAll3D[pid].push_back(Point2d(0, 0));
			}
			fclose(fp);
		}
	}

	//Triagulate:
	printLOG("**********************\nWorking on reference frame (%d)\n", refF);
	double error = 9e9;
	vector<int> id, id2;
	Point2d *allPts = new Point2d[nCams * 2];
	double *A = new double[6 * nCams * 2], *B = new double[2 * nCams * 2], *allP = new double[12 * nCams * 2];
	vector<int> addedCameras; //assume all cameras are processed for the reference frame
	for (int cid = 0; cid < nCams; cid++)
	{
		addedCameras.push_back(cid);
		AllCorpus[rangeF].camera[cid].viewID = cid;
		AllCorpus[rangeF].camera[cid].threshold = thresh * 3;
		GetRTFromrt(AllCorpus[rangeF].camera[cid].rt, AllCorpus[rangeF].camera[cid].R, AllCorpus[rangeF].camera[cid].T);
		AssembleP(AllCorpus[rangeF].camera[cid].K, AllCorpus[rangeF].camera[cid].R, AllCorpus[rangeF].camera[cid].T, AllCorpus[rangeF].camera[cid].P);
	}

	int nBad = 0;
	vector<double> allError;
	for (int pid = 0; pid < npts; pid++)
	{
		id.clear(), id2.clear();
		for (int ii = 0; ii < AllCorpus[rangeF].viewIdAll3D[pid].size(); ii++)
		{
			for (int jj = 0; jj < (int)addedCameras.size(); jj++)
			{
				if (AllCorpus[rangeF].viewIdAll3D[pid][ii] == addedCameras[jj])
				{
					if (AllCorpus[rangeF].uvAll3D[pid][ii].x > 0 && AllCorpus[rangeF].uvAll3D[pid][ii].y > 0)
					{
						id.push_back(ii), id2.push_back(jj);
						break;
					}
				}
			}
		}

		AllCorpus[rangeF].xyz.push_back(Point3d(0, 0, 0));
		if (id.size() > 1)
		{
			for (int ii = 0; ii < (int)id.size(); ii++)
			{
				int cid = AllCorpus[rangeF].viewIdAll3D[pid][id[ii]];
				allPts[ii] = AllCorpus[rangeF].uvAll3D[pid][id[ii]];
				for (int jj = 0; jj < 12; jj++)
					allP[12 * ii + jj] = AllCorpus[rangeF].camera[cid].P[jj];
			}

			NviewTriangulation(allPts, allP, &AllCorpus[rangeF].xyz.back(), (int)id.size(), 1, NULL, A, B);
			NviewTriangulationNonLinear(allP, allPts, &AllCorpus[rangeF].xyz.back(), &error, (int)id.size(), 1);
			allError.push_back(error);
		}
		else
			nBad++;
	}
	double mini = *min_element(allError.begin(), allError.end());
	double maxi = *max_element(allError.begin(), allError.end());
	double avg = MeanArray(allError);
	double var = sqrt(VarianceArray(allError, avg));
	printLOG("(%d/%d) good points. Reprojection error: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f\n\n", npts - nBad, npts, mini, maxi, avg, var);

	vector<int> vdummy;
	GenericBundleAdjustment(Path, AllCorpus[rangeF].camera, AllCorpus[rangeF].xyz, AllCorpus[rangeF].viewIdAll3D, AllCorpus[rangeF].uvAll3D, currentScaleAll3D, vdummy, nCams, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, false, 0, false, true);

	//Start incremental tracking and smoothing
	vector<int> backfore; backfore.push_back(-1), backfore.push_back(1);
	for (int fid = 1; fid <= rangeF; fid++)
	{
		printLOG("\n**********************EXANDING BA WINDOW (%d, %d)**********************\n", max(0, refF - fid), refF + fid);
		for (auto next : backfore)
		{
			if (rangeF + next * fid < 0)
				continue;

			printLOG("**********************\nWorking on %d: \n", refF + next * fid);
			//Initialize next frame's cameras
			for (int cid = 0; cid < nCams; cid++)
			{
				CopyCamereInfo(AllCorpus[rangeF + next * (fid - 1)].camera[cid], AllCorpus[rangeF + next * fid].camera[cid]);
				GetRTFromrt(AllCorpus[rangeF + next * fid].camera[cid]);
				AssembleP(AllCorpus[rangeF + next * fid].camera[cid]);
				AllCorpus[rangeF + next * fid].camera[cid].valid = true;
				AllCorpus[rangeF + next * fid].camera[cid].threshold = thresh * 3;
				AllCorpus[rangeF + next * fid].camera[cid].viewID = cid;
				AllCorpus[rangeF + next * fid].camera[cid].frameID = refF + next * fid;
			}

			//Triagulate:
			for (int pid = 0; pid < npts; pid++)
			{
				id.clear(), id2.clear();
				for (int ii = 0; ii < AllCorpus[rangeF + next * fid].viewIdAll3D[pid].size(); ii++)
				{
					for (int jj = 0; jj < (int)addedCameras.size(); jj++)
					{
						if (AllCorpus[rangeF + next * fid].viewIdAll3D[pid][ii] == addedCameras[jj])
						{
							if (AllCorpus[rangeF + next * fid].uvAll3D[pid][ii].x > 0 && AllCorpus[rangeF + next * fid].uvAll3D[pid][ii].y > 0)
							{
								id.push_back(ii), id2.push_back(jj);
								break;
							}
						}
					}
				}

				if (next < 0)
					AllCorpus[rangeF + next * fid].xyz.push_back(AllCorpus[next*(fid - 1) + rangeF].xyz[pid]);
				else if (next > 0)
					AllCorpus[rangeF + next * fid].xyz.push_back(AllCorpus[next*(fid - 1) + rangeF].xyz[pid]);

				if (id.size() > 1)
				{
					for (int ii = 0; ii < (int)id.size(); ii++)
					{
						int cid = AllCorpus[rangeF + next * fid].viewIdAll3D[pid][id[ii]];
						allPts[ii] = AllCorpus[rangeF + next * fid].uvAll3D[pid][id[ii]];
						for (int jj = 0; jj < 12; jj++)
							allP[12 * ii + jj] = AllCorpus[rangeF + next * fid].camera[cid].P[jj];
					}
					NviewTriangulation(allPts, allP, &AllCorpus[rangeF + next * fid].xyz.back(), (int)id.size(), 1, NULL, A, B);
					NviewTriangulationNonLinear(allP, allPts, &AllCorpus[rangeF + next * fid].xyz.back(), &error, (int)id.size(), 1);
				}
			}

			GenericBundleAdjustment(Path, AllCorpus[rangeF + next * fid].camera, AllCorpus[rangeF + next * fid].xyz, AllCorpus[rangeF + next * fid].viewIdAll3D, AllCorpus[rangeF + next * fid].uvAll3D, currentScaleAll3D, vdummy, nCams, 1, 0, 0, 1, 0, 0, 0, 0, 1, 2, false, 1, false, true);
		}

		//Scale SfM's unit to physical unit using human body info.
		double scale = 1.0;
		if (abs(AllCorpus[rangeF].xyz[2].x) > 0.00001 && abs(AllCorpus[rangeF].xyz[5].x) > 0)
		{
			double realShoulderDist = 450; //mm
			double sfmShoulderDist = norm(AllCorpus[rangeF].xyz[2] - AllCorpus[rangeF].xyz[5]);
			scale = realShoulderDist / sfmShoulderDist;
		}
		else if (abs(AllCorpus[rangeF].xyz[2].x) > 0.00001 && abs(AllCorpus[rangeF].xyz[3].x) > 0)
		{
			double realHalfArm = 250; //mm
			double sfmHalfArm = norm(AllCorpus[rangeF].xyz[2] - AllCorpus[rangeF].xyz[5]);
			scale = realHalfArm / sfmHalfArm;
		}
		else if (abs(AllCorpus[rangeF].xyz[3].x) > 0.00001 && abs(AllCorpus[rangeF].xyz[4].x) > 0)
		{
			double realHalfArm = 250; //mm
			double sfmHalfArm = norm(AllCorpus[rangeF].xyz[3] - AllCorpus[rangeF].xyz[4]);
			scale = realHalfArm / sfmHalfArm;
		}
		else if (abs(AllCorpus[rangeF].xyz[5].x) > 0.00001 && abs(AllCorpus[rangeF].xyz[6].x) > 0)
		{
			double realHalfArm = 250; //mm
			double sfmHalfArm = norm(AllCorpus[rangeF].xyz[6] - AllCorpus[rangeF].xyz[5]);
			scale = realHalfArm / sfmHalfArm;
		}
		else if (abs(AllCorpus[rangeF].xyz[6].x) > 0.00001 && abs(AllCorpus[rangeF].xyz[7].x) > 0)
		{
			double realHalfArm = 250; //mm
			double sfmHalfArm = norm(AllCorpus[rangeF].xyz[6] - AllCorpus[rangeF].xyz[7]);
			scale = realHalfArm / sfmHalfArm;
		}

		for (int fid2 = -fid; fid2 <= fid; fid2++)
		{
			for (int pid = 0; pid < npts; pid++)
				AllCorpus[rangeF + fid2].xyz[pid].x *= scale, AllCorpus[rangeF + fid2].xyz[pid].y *= scale, AllCorpus[rangeF + fid2].xyz[pid].z *= scale;
			for (int cid = 0; cid < nCams; cid++)
				for (int ii = 3; ii < 6; ii++)
					AllCorpus[rangeF + fid2].camera[cid].rt[ii] *= scale;
		}

		//STBA
		vector<CameraData *> AllCameras;
		vector<vector<Point3d> *>AllXYZ;
		vector<vector < vector<int> > *>AllviewIDAll3D;
		vector<vector<vector<Point2d> > *>AlluvAll3D;
		for (int fid2 = -fid; fid2 <= fid; fid2++)
		{
			if (rangeF + fid2 < 0)
				continue;
			AllCameras.push_back(AllCorpus[rangeF + fid2].camera), AllXYZ.push_back(&AllCorpus[rangeF + fid2].xyz), AllviewIDAll3D.push_back(&AllCorpus[rangeF + fid2].viewIdAll3D), AlluvAll3D.push_back(&AllCorpus[rangeF + fid2].uvAll3D);

			/*sprintf(Fname, "%s/xyz_%d.txt", Path, refF + fid2); fp = fopen(Fname, "w+");
			for (size_t ii = 0; ii < AllCorpus[rangeF + fid].xyz.size(); ii++)
			fprintf(fp, "%d %.16f %.16f %.16f\n", ii, AllCorpus[rangeF + fid2].xyz[ii].x, AllCorpus[rangeF + fid2].xyz[ii].y, AllCorpus[rangeF + fid2].xyz[ii].z);
			fclose(fp);*/
		}

		printLOG("**********************\nMulti-frame Dynamic BA:\n");
		//MultiFrameDynamicBA(AllCameras, AllXYZ, AllviewIDAll3D, AlluvAll3D, weights, sigmaParas, nCams, fps, 2, 1, false, true);
		MultiFrameDynamicBA_SimilarityTransform(AllCameras, AllXYZ, AllviewIDAll3D, AlluvAll3D, &weights[0], &sigmaParas[1], nCams, fps, 2, 1, false, true);
		NormalizeSfMRecon(AllCameras, AllXYZ, nCams, (int)AllCameras.size(), (int)AllXYZ[0]->size());
	}

	printLOG("\nYes. All done!\n");
	for (int fid = -rangeF; fid <= rangeF; fid++)
	{
		if (rangeF + fid < 0 || refF + fid < 0)
			continue;
		sprintf(Fname, "%s/JBC/%.4d/s_nBA_%d.txt", Path, refF + fid, refF);  FILE *fp = fopen(Fname, "w+");
		if (fp == NULL)
			continue;

		fprintf(fp, "%d %d\n", nCams, 0);
		for (int ii = 0; ii < nCams; ii++)
		{
			double fx, fy, skew, u0, v0, r1, r2, r3, t1, t2, p1, p2, omega, DistCtrX, DistCtrY;

			CameraData *camI = &AllCorpus[rangeF + fid].camera[ii];
			fprintf(fp, "%.4d %d %d %d %d ", ii, camI->LensModel, camI->ShutterModel, camI->width, camI->height);

			fx = camI->intrinsic[0], fy = camI->intrinsic[1], skew = camI->intrinsic[2], u0 = camI->intrinsic[3], v0 = camI->intrinsic[4];
			if (camI->LensModel == RADIAL_TANGENTIAL_PRISM)
			{
				r1 = camI->distortion[0], r2 = camI->distortion[1], r3 = camI->distortion[2], t1 = camI->distortion[3], t2 = camI->distortion[4], p1 = camI->distortion[5], p2 = camI->distortion[6];
				fprintf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %.16f %.16f %.16f %.16f %.16f %.16f\n", fx, fy, skew, u0, v0, r1, r2, r3, t1, t2, p1, p2, camI->rt[0], camI->rt[1], camI->rt[2], camI->rt[3], camI->rt[4], camI->rt[5]);
			}
			else
			{
				omega = camI->distortion[0], DistCtrX = camI->distortion[1], DistCtrY = camI->distortion[2];
				fprintf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %.16f %.16f %.16f %.16f %.16f %.16f\n", fx, fy, skew, u0, v0, omega, DistCtrX, DistCtrY, camI->rt[0], camI->rt[1], camI->rt[2], camI->rt[3], camI->rt[4], camI->rt[5]);
			}
		}
		fclose(fp);

		AllCorpus[rangeF + fid].xyz.clear();
		AllCorpus[rangeF + fid].xyz.resize(nJoints*nMaxPeople);
		bool *passTri = new bool[nCams * 2];
		double *tallP = new double[12 * nCams * 2];
		for (auto cid : addedCameras)
		{
			GetRTFromrt(AllCorpus[rangeF + fid].camera[cid].rt, AllCorpus[rangeF + fid].camera[cid].R, AllCorpus[rangeF + fid].camera[cid].T);
			AssembleP(AllCorpus[rangeF + fid].camera[cid].K, AllCorpus[rangeF + fid].camera[cid].R, AllCorpus[rangeF + fid].camera[cid].T, AllCorpus[rangeF + fid].camera[cid].P);
		}
		for (size_t pid = 0; pid < AllCorpus[rangeF + fid].uvAll3D.size(); pid++)
		{
			int count = 0;
			for (size_t ii = 0; ii < nCams; ii++)
			{
				for (size_t jj = 0; jj < AllCorpus[rangeF + fid].viewIdAll3D[pid].size(); jj++)
				{
					int cid = addedCameras[ii];
					if (cid == AllCorpus[rangeF + fid].viewIdAll3D[pid][jj])
					{
						allPts[ii] = AllCorpus[rangeF + fid].uvAll3D[pid][jj];
						for (int kk = 0; kk < 12; kk++)
							allP[count * 12 + kk] = AllCorpus[rangeF + fid].camera[cid].P[kk];
						count++;
					}
				}
			}
			if (count < 2)
				continue;
			vector<int> Inliers[1]; Point3d xyz;
			NviewTriangulationRANSAC(allPts, allP, &xyz, passTri, Inliers, count, 1, 2, 10, 0.7, 7.0, A, B, tallP);
			AllCorpus[rangeF + fid].xyz[pid] = xyz;
		}

		sprintf(Fname, "%s/JBC/%.4d/s_n3dGL_%d.txt", Path, refF + fid, refF); fp = fopen(Fname, "w+");
		for (size_t ii = 0; ii < AllCorpus[rangeF + fid].xyz.size(); ii++)
			fprintf(fp, "%d %.16f %.16f %.16f\n", ii, AllCorpus[rangeF + fid].xyz[ii].x, AllCorpus[rangeF + fid].xyz[ii].y, AllCorpus[rangeF + fid].xyz[ii].z);
		fclose(fp);
	}

	delete[]A, delete[]B, delete[]allP, delete[]allPts, delete[]AllCorpus;

	return 0;
}

int SequenceSfM_GenerateAllView_2D_And_Corres_Info(char *Path, int selectedCamId, vector<int> &vrfid, Corpus &LocalCorpus)
{
	//ViewIDAll3D, UVAll3D, ScalleAll3D: some 3D points may not have any inliers
	//threeDIdAllViews2: each 2d point is assigned a 3D pointID, among which may not be active
	//matchedCidICidJ: cidI to cidJ
	//matchedCidIPidICidJPidJ: pidIofCidI to pidJofCidJ
	//XYZ: (0,0,0) means deactive points
	char Fname[512];

	int startF = vrfid[0], stopF = vrfid.back();

	//correspondences are specialized for tracking for now. The follow code is to adapt to the tracking format
	sprintf(Fname, "%s/Track2D/Ultimate_%d.txt", Path, selectedCamId);
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	float  s; Point2f uv;
	int npts, pid, fid, nf;
	fscanf(fp, "%d ", &npts);
	LocalCorpus.n3dPoints = npts;
	LocalCorpus.xyz.resize(npts);
	LocalCorpus.GlobalAnchor3DId.resize(npts);
	for (int ii = 0; ii < vrfid.size(); ii++)
	{
		LocalCorpus.n2DPointsPerView.push_back(npts);

		Point2f *puv = new Point2f[vrfid.size()];
		float *ps = new float[vrfid.size()];
		int *ppid = new int[vrfid.size()];
		bool*pinliers = new bool[vrfid.size()];
		LocalCorpus.InlierAllViews2.push_back(pinliers);
		LocalCorpus.threeDIdAllViews2.push_back(ppid);
		LocalCorpus.uvAllViews2.push_back(puv);
		LocalCorpus.scaleAllViews2.push_back(ps);
	}
	for (int ii = 0; ii < npts; ii++)
	{
		LocalCorpus.GlobalAnchor3DId[ii] = -1;
		LocalCorpus.viewIdAll3D.push_back(vector<int>());
		LocalCorpus.pointIdAll3D.push_back(vector<int>());
		LocalCorpus.uvAll3D.push_back(vector<Point2d>());
		LocalCorpus.scaleAll3D.push_back(vector<double>());
	}
	for (int jj = 0; jj < npts; jj++)
	{
		fscanf(fp, "%d %d ", &pid, &nf);
		for (int ii = 0; ii < nf; ii++)
		{
			fscanf(fp, "%d %f %f %f ", &fid, &uv.x, &uv.y, &s);
			if (fid < startF || fid>stopF || LocalCorpus.camera[fid - startF].notCalibrated)
				continue;

			if (LocalCorpus.camera[fid - startF].LensModel == RADIAL_TANGENTIAL_PRISM)
				LensCorrectionPoint(&uv, LocalCorpus.camera[fid - startF].K, LocalCorpus.camera[fid - startF].distortion);
			else
				FishEyeCorrectionPoint(&uv, LocalCorpus.camera[fid - startF].K, LocalCorpus.camera[fid - startF].distortion[0]);

			LocalCorpus.uvAllViews2[fid - startF][pid] = uv;
			LocalCorpus.scaleAllViews2[fid - startF][pid] = s;
			LocalCorpus.threeDIdAllViews2[fid - startF][pid] = pid;

			LocalCorpus.pointIdAll3D[pid].push_back(pid);
			LocalCorpus.viewIdAll3D[pid].push_back(fid - startF);
			LocalCorpus.uvAll3D[pid].push_back((Point2d)(uv));
			LocalCorpus.scaleAll3D[pid].push_back(s);
		}
	}
	fclose(fp);

	return 0;
}
int SequenceSfMDriver(char *Path, int sCamId, int startF, int stopF, SfMPara mySfMPara, int debug)
{
	char Fname[512], Fname1[512], Fname2[512];

	mySfMPara.fixIntrinsic = 1, mySfMPara.fixDistortion = 1, mySfMPara.distortionCorrected = 1;

	vector<int> vrfid;
	for (int fid = startF; fid <= stopF; fid++)
		vrfid.push_back(fid);

	Corpus VCorpusInfo;
	VCorpusInfo.nCameras = (int)vrfid.size();
	VCorpusInfo.camera = new CameraData[vrfid.size()];
	for (int kflid = 0; kflid < (int)vrfid.size(); kflid++)
		VCorpusInfo.camera[kflid].frameID = vrfid[kflid], VCorpusInfo.camera[kflid].valid = false, VCorpusInfo.camera[kflid].notCalibrated = true;

	//in case the camera intrinsic is not initialized before PnP, this intrinsic file will not contain the distortion info.
	sprintf(Fname, "%s/Intrinsic_%.4d.txt", Path, sCamId); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int rfid, lfid, LensType, ShutterModel, width, height, cnt = 0;;
		double intrinsic[5], distortion[7];
		while (fscanf(fp, "%d %d %d %d %d %lf %lf %lf %lf %lf ", &rfid, &LensType, &ShutterModel, &width, &height, &intrinsic[0], &intrinsic[1], &intrinsic[2], &intrinsic[3], &intrinsic[4]) != EOF)
		{
			if (LensType == RADIAL_TANGENTIAL_PRISM)
				fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf ", &distortion[0], &distortion[1], &distortion[2], &distortion[3], &distortion[4], &distortion[5], &distortion[6]);
			else
				fscanf(fp, "%lf %lf %lf ", &distortion[0], &distortion[1], &distortion[2]);
			std::vector<int>::iterator iter = find(vrfid.begin(), vrfid.end(), rfid);
			if (iter != vrfid.end())
			{
				cnt++;
				lfid = std::distance(vrfid.begin(), iter);
				VCorpusInfo.camera[lfid - startF].LensModel = LensType, VCorpusInfo.camera[lfid - startF].ShutterModel = ShutterModel;
				VCorpusInfo.camera[lfid - startF].width = width, VCorpusInfo.camera[lfid - startF].height = height;
				for (int jj = 0; jj < 5; jj++)
					VCorpusInfo.camera[lfid - startF].intrinsic[jj] = intrinsic[jj];
				if (LensType == RADIAL_TANGENTIAL_PRISM)
					for (int jj = 0; jj < 7; jj++)
						VCorpusInfo.camera[lfid - startF].distortion[jj] = distortion[jj];
				else
					for (int jj = 0; jj < 3; jj++)
						VCorpusInfo.camera[lfid - startF].distortion[jj] = distortion[jj];

				GetKFromIntrinsic(VCorpusInfo.camera[lfid - startF]);
				VCorpusInfo.camera[lfid - startF].notCalibrated = false; //if not calibrated, ignore ther frame
			}
			if (cnt == startF - stopF + 1)
				break;
		}
	}

	for (int ii = 0; ii < VCorpusInfo.nCameras; ii++)
		VCorpusInfo.camera[ii].ShutterModel = GLOBAL_SHUTTER;

	//Get corres info, assuming they are cleaned
	SequenceSfM_GenerateAllView_2D_And_Corres_Info(Path, sCamId, vrfid, VCorpusInfo);

	//Determine init pair
	sSfM_FirstTwoViews(VCorpusInfo, mySfMPara, debug);

	//Start iSfM
	Point2i globalLocal;
	vector<int> Inliers;
	vector<Point2d> pts;
	vector<Point3d> t3D;

	int orgNviewPlus = mySfMPara.nViewsPlusBA;
	if (mySfMPara.nViewsPlusBA != 2)
		mySfMPara.nViewsPlusBA = 2;

	int nAddedFrames = 2, nUnlocalizedFrames = 0, nLocalizedFrames = 2, nFramesSinceLastBA = 2, nPointsSinceLastBA = VCorpusInfo.xyz.size();
	vector<int> nPassesPerFrame(vrfid.size()), nPassesWoPnPPerFrame(vrfid.size()), vKF2Process(vrfid.size());
	for (int fid = 0; fid < VCorpusInfo.nCameras; fid++)
	{
		if (VCorpusInfo.camera[fid].notCalibrated || VCorpusInfo.camera[fid].valid)
			nPassesPerFrame[fid] = mySfMPara.maxPassesPerImage, vKF2Process[fid] = 0;
		else
		{
			nPassesPerFrame[fid] = 0, vKF2Process[fid] = 1, nUnlocalizedFrames++;

			int cnt = 0;
			for (size_t pid = 0; pid < VCorpusInfo.n2DPointsPerView[fid]; pid++)
				if (VCorpusInfo.threeDIdAllViews2[fid][pid] > -1) // at least, has corres accross views
					cnt++;
			if (cnt < mySfMPara.nInliersThresh)
				nPassesPerFrame[fid] = mySfMPara.maxPassesPerImage; //none of the PnP works
		}
	}

	vector<int> sorted(VCorpusInfo.nCameras), order(VCorpusInfo.nCameras);
	for (int iter = 0; iter < mySfMPara.maxGlobalPass; iter++)
	{
		printLOG("\n******************\n");
		printLOG("\n******(global pass #%d) ******\n", iter);
		for (size_t fid = 0; fid < VCorpusInfo.nCameras; fid++)
		{
			nPassesPerFrame[fid] = 0, nPassesWoPnPPerFrame[fid] = 0;
			if (!VCorpusInfo.camera[fid].valid) //let's detect cameras left out by the BA
				vKF2Process[fid] == 1;
		}

		while (true)
		{
			//determine uncalib/not exceeding max pass kf with highest number of avail3D
			int cnt = 0;
			for (size_t fid = 0; fid < VCorpusInfo.nCameras; fid++)
			{
				if (vKF2Process[fid] == 0 || nPassesPerFrame[fid] > mySfMPara.maxPassesPerImage || nPassesWoPnPPerFrame[fid] > mySfMPara.maxPassesPerImage * 10)
					continue;

				sorted[cnt] = 0;
				for (int pid = 0; pid < VCorpusInfo.n2DPointsPerView[fid]; pid++)
				{
					int threeDId = VCorpusInfo.threeDIdAllViews2[fid][pid];
					if (threeDId > -1 && IsValid3D(VCorpusInfo.xyz[threeDId]))
						sorted[cnt]--; //for sorting descding order
				}
				sorted[cnt] -= rand() % 10;
				order[cnt] = fid;
				cnt++;
			}
			if (cnt == 0) //may need to be retriangulate for more PnP corres or you cannot localize any further
				break;

			Quick_Sort_Int(&sorted[0], &order[0], 0, cnt - 1);

			for (int ii = 0; ii < cnt; ii++) //do PnP until #inlier drops below threshold or retriangulation/BA is called
			{
				int KF2Process = order[ii], cnt2 = 0;
				if (-sorted[ii] < mySfMPara.nInliersThresh)
				{
					nPassesWoPnPPerFrame[KF2Process]++;
					break;
				}

				printLOG("\n******Registering frame %d (%d) (%d of %d localized)******\n", KF2Process, vrfid[KF2Process], nAddedFrames + 1, nUnlocalizedFrames);

				//PnP: get data for PnP
				pts.clear(), t3D.clear();
				for (int pid = 0; pid < VCorpusInfo.n2DPointsPerView[KF2Process]; pid++)
				{
					int threeDId = VCorpusInfo.threeDIdAllViews2[KF2Process][pid];
					if (threeDId > -1 && IsValid3D(VCorpusInfo.xyz[threeDId]))
					{
						pts.push_back(VCorpusInfo.uvAllViews2[KF2Process][pid]), t3D.push_back(VCorpusInfo.xyz[threeDId]), cnt2++;
						//printf("%.2f %.2f %.3f %.3f %.3f\n", pts.back().x, pts.back().y, t3D.back().x, t3D.back().y, t3D.back().z);
					}
				}

				Inliers.clear();
				int ninliers = EstimatePoseAndInliers(VCorpusInfo.camera[KF2Process].K, VCorpusInfo.camera[KF2Process].distortion, VCorpusInfo.camera[KF2Process].LensModel, VCorpusInfo.camera[KF2Process].ShutterModel,
					VCorpusInfo.camera[KF2Process].R, VCorpusInfo.camera[KF2Process].T, VCorpusInfo.camera[KF2Process].wt, pts, t3D, Inliers, mySfMPara.reProjectionTrianguatlionThresh, mySfMPara.fixIntrinsic, mySfMPara.distortionCorrected, mySfMPara.minFRatio, mySfMPara.maxFratio, VCorpusInfo.camera[KF2Process].width, VCorpusInfo.camera[KF2Process].height, PnP::EPNP);
				if (ninliers > mySfMPara.nInliersThresh)
				{
					VCorpusInfo.camera[KF2Process].valid = true;
					GetrtFromRT(&VCorpusInfo.camera[KF2Process], 1);
					GetIntrinsicFromK(VCorpusInfo.camera[KF2Process]);
				}

				//reTri/BA
				if (!VCorpusInfo.camera[KF2Process].valid)
					nPassesPerFrame[KF2Process]++; //none of the PnP works
				else
				{
					nLocalizedFrames++, nAddedFrames++;
					vKF2Process[KF2Process] = 0;

					GetCfromT(VCorpusInfo.camera[KF2Process].R, VCorpusInfo.camera[KF2Process].T, VCorpusInfo.camera[KF2Process].camCenter);
					AssembleP(VCorpusInfo.camera[KF2Process]);

					printLOG("Triangulate frame %d", KF2Process);
					int new3Dcnt = sSfM_reTri(KF2Process, VCorpusInfo, mySfMPara);
					int nReconPoints = GetNumValid3Ds(VCorpusInfo.xyz);
					printLOG("...generating %d new 3D points (%d 3D points in total)\n", new3Dcnt, nReconPoints);
					globalLocal = GetGlobalAndLocalPointsStat(VCorpusInfo.viewIdAll3D, VCorpusInfo.GlobalAnchor3DId, VCorpusInfo.xyz);
					printLOG("global corpus: %d,  local corpus: %d\n", globalLocal.x, globalLocal.y);

					if (nAddedFrames > orgNviewPlus * 3 && mySfMPara.nViewsPlusBA != orgNviewPlus)
					{
						mySfMPara.nViewsPlusBA = orgNviewPlus;
						printLOG("\n******Having sufficient views for the requested NViewsPoints (%d views) ******\n", mySfMPara.nViewsPlusBA);
					}

					if (nLocalizedFrames > mySfMPara.ba_global_images_ratio*nFramesSinceLastBA || nReconPoints > mySfMPara.ba_global_images_ratio*nPointsSinceLastBA || nLocalizedFrames - nFramesSinceLastBA >= mySfMPara.globalBA_freq)
					{
						printLOG("\n\n******reTriangulate and BA******\n");
						printLOG("nLocalizedFrames: %d nReconPoints: %d nFramesSinceLastBA: %d\n", nLocalizedFrames, nReconPoints, nFramesSinceLastBA);

						printLOG("reTriangulation...");
						new3Dcnt = sSfM_reTri(VCorpusInfo, mySfMPara);
						printLOG("generates %d new 3D points  (%d 3D points in total)\n\n", new3Dcnt, GetNumValid3Ds(VCorpusInfo.xyz));
						globalLocal = GetGlobalAndLocalPointsStat(VCorpusInfo.viewIdAll3D, VCorpusInfo.GlobalAnchor3DId, VCorpusInfo.xyz);
						printLOG("global corpus: %d,  local corpus: %d\n\n", globalLocal.x, globalLocal.y);

						BA_Driver(Path, VCorpusInfo, mySfMPara);
						nPointsSinceLastBA = GetNumValid3Ds(VCorpusInfo.xyz);
						nFramesSinceLastBA = nLocalizedFrames;
					}

					if (nAddedFrames%mySfMPara.snapshot_images_freq == 0)
						sSfM_CleanInliers(VCorpusInfo, mySfMPara);
				}
			}
		}

		if (nLocalizedFrames != nFramesSinceLastBA)
		{
			printLOG("\n\n******reTriangulate and BA ******\n");
			printLOG("reTriangulation...");
			int new3Dcnt = sSfM_reTri(VCorpusInfo, mySfMPara);
			printLOG("generates %d new 3D points  (%d 3D points in total)\n\n", new3Dcnt, GetNumValid3Ds(VCorpusInfo.xyz));
			globalLocal = GetGlobalAndLocalPointsStat(VCorpusInfo.viewIdAll3D, VCorpusInfo.GlobalAnchor3DId, VCorpusInfo.xyz);
			printLOG("global corpus: %d,  local corpus: %d\n\n", globalLocal.x, globalLocal.y);

			nFramesSinceLastBA = nLocalizedFrames;
			BA_Driver(Path, VCorpusInfo, mySfMPara);
			sSfM_CleanInliers(VCorpusInfo, mySfMPara);
		}

		int cnt = 0;
		for (size_t KF2Process = 0; KF2Process < vrfid.size(); KF2Process++)
			if (VCorpusInfo.camera[KF2Process].valid)
				cnt++;
		if (cnt == VCorpusInfo.nCameras)
			break;
	}
	printLOG("\n******Done******\n");

	sprintf(Fname, "%s/aIntrinsic_%.4d.txt", Path, sCamId); fp = fopen(Fname, "w+");
	for (int ii = 0; ii < VCorpusInfo.nCameras; ii++)
	{
		CameraData *camI = VCorpusInfo.camera;
		if (!camI[ii].valid)
			continue;
		fprintf(fp, "%d %d %d %d %d ", vrfid[ii], camI[ii].LensModel, camI[ii].ShutterModel, camI[ii].width, camI[ii].height);
		for (int jj = 0; jj < 5; jj++)
			fprintf(fp, "%f ", camI[ii].intrinsic[jj]);
		if (camI[ii].LensModel == RADIAL_TANGENTIAL_PRISM)
			for (int jj = 0; jj < 7; jj++)
				fprintf(fp, "%f ", camI[ii].distortion[jj]);
		else
			for (int jj = 0; jj < 3; jj++)
				fprintf(fp, "%f ", camI[ii].distortion[jj]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/aCamPose_%.4d.txt", Path, sCamId); fp = fopen(Fname, "w+");
	for (int ii = 0; ii < VCorpusInfo.nCameras; ii++)
	{
		CameraData *camI = VCorpusInfo.camera;
		if (!camI[ii].valid)
			continue;
		fprintf(fp, "%d ", vrfid[ii]);
		for (int jj = 0; jj < 6; jj++)
			fprintf(fp, "%.16f ", camI[ii].rt[jj]);
		if (camI[ii].ShutterModel == 1)
			for (int jj = 0; jj < 6; jj++)
				fprintf(fp, "%.16f ", camI[ii].wt[jj]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/%d/Video3DCorpus.xyz", Path, sCamId); fp = fopen(Fname, "w+");
	for (size_t ii = 0; ii < VCorpusInfo.xyz.size(); ii++)
		if (IsValid3D(VCorpusInfo.xyz[ii]))
			fprintf(fp, "%d %d %f %f %f\n", ii, VCorpusInfo.GlobalAnchor3DId[ii], VCorpusInfo.xyz[ii].x, VCorpusInfo.xyz[ii].y, VCorpusInfo.xyz[ii].z);
	fclose(fp);

	return 0;
}

int convertPnP2KPnP(char *Path, int selectedCam, int startF, int stopF)
{
	char Fname[512];
	vector<int> queryFrames;
	sprintf(Fname, "%s/%d/querry.txt", Path, selectedCam); std::ifstream file(Fname);
	if (file.is_open())
	{
		std::string line;
		while (std::getline(file, line))
		{
			StringTrim(&line);
			if (line.empty())
				continue;
			std::size_t found = line.find(".");
			std::string NameOnly = line.substr(0, found);
			if (atoi(NameOnly.c_str()) >= startF && atoi(NameOnly.c_str()) <= stopF)
				queryFrames.push_back(atoi(NameOnly.c_str()));
		}
		file.close();
	}
	else
		return -1;

	for (int ii = 0; ii < queryFrames.size(); ii++)
	{
		sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, selectedCam, queryFrames[ii]);
		if (IsFileExist(Fname) == 1)
		{
			FILE *fp1 = fopen(Fname, "r");
			sprintf(Fname, "%s/%d/PnP/KF_Inliers_%.4d.txt", Path, selectedCam, queryFrames[ii]); 	FILE *fp2 = fopen(Fname, "w");
			int pid2D, pid3D; Point3d xyz; Point2f uv; float s;
			while (fscanf(fp1, "%d %lf %lf %lf %d %f %f %f", &pid3D, &xyz.x, &xyz.y, &xyz.z, &pid2D, &uv.x, &uv.y, &s) != EOF)
			{
				fprintf(fp2, "%d %d %.8e %.8e %.8e %d %.4f %.4f %.3f\n", pid3D, pid3D, xyz.x, xyz.y, xyz.z, pid2D, uv.x, uv.y, s);
			}
			fclose(fp1), fclose(fp2);
		}
	}

	return 0;
}
bool VideoKeyFrame2Corpus_CacheResults(char *Path, Corpus &VCorpusInfo, int selectedCamId, vector<int> &vrfid, int cacheID = 0)
{
	printLOG("Running cacheID %.2d\n", cacheID);
	char Fname[512];

	sprintf(Fname, "%s/cache/%d/Intrinsic_%.2d.txt", Path, selectedCamId, cacheID); FILE *fp = fopen(Fname, "w");
	for (int kk = 0; kk < VCorpusInfo.nCameras; kk++)
	{
		CameraData *camI = VCorpusInfo.camera;
		if (!camI[kk].valid)
			continue;
		fprintf(fp, "%d %d %d %d %d ", vrfid[kk], camI[kk].LensModel, camI[kk].ShutterModel, camI[kk].width, camI[kk].height);
		for (int jj = 0; jj < 5; jj++)
			fprintf(fp, "%f ", camI[kk].intrinsic[jj]);
		if (camI[kk].LensModel == RADIAL_TANGENTIAL_PRISM)
			for (int jj = 0; jj < 7; jj++)
				fprintf(fp, "%f ", camI[kk].distortion[jj]);
		else
			for (int jj = 0; jj < 3; jj++)
				fprintf(fp, "%f ", camI[kk].distortion[jj]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/cache/%d/CamPose_%.2d.txt", Path, selectedCamId, cacheID); fp = fopen(Fname, "w");
	for (int kk = 0; kk < VCorpusInfo.nCameras; kk++)
	{
		CameraData *camI = VCorpusInfo.camera;
		if (!camI[kk].valid)
			continue;
		fprintf(fp, "%d ", vrfid[kk]);
		for (int jj = 0; jj < 6; jj++)
			fprintf(fp, "%.16f ", camI[kk].rt[jj]);
		if (camI[kk].ShutterModel == 1)
			for (int jj = 0; jj < 6; jj++)
				fprintf(fp, "%.16f ", camI[kk].wt[jj]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	for (int ii = 0; ii < VCorpusInfo.nCameras; ii++)
	{
		CameraData *camI = VCorpusInfo.camera;
		if (!camI[ii].valid)
			continue;

		sprintf(Fname, "%s/cache/%d/PnP/KF_Inliers_%.2d_%.4d.txt", Path, selectedCamId, cacheID, vrfid[ii]); fp = fopen(Fname, "w+");
		for (int p2DId = 0; p2DId < VCorpusInfo.n2DPointsPerView[ii]; p2DId++)
		{
			int localCorpusP3DId = VCorpusInfo.threeDIdAllViews2[ii][p2DId];
			if (localCorpusP3DId > -1 && VCorpusInfo.InlierAllViews2[ii][p2DId] && IsValid3D(VCorpusInfo.xyz[localCorpusP3DId]))
			{
				int globalCorpusP3DId = VCorpusInfo.GlobalAnchor3DId[localCorpusP3DId];
				Point3d xyz = VCorpusInfo.xyz[localCorpusP3DId];
				Point2d uv = VCorpusInfo.uvAllViews2[ii][p2DId];
				fprintf(fp, "%d %d %f %f %f %d %.6f %.6f %.2f\n", globalCorpusP3DId, localCorpusP3DId, xyz.x, xyz.y, xyz.z, p2DId, uv.x, uv.y, VCorpusInfo.scaleAllViews2[ii][p2DId]);
			}
		}
		fclose(fp);
	}

	sprintf(Fname, "%s/cache/%d/Video3DCorpus_%.2d.xyz", Path, selectedCamId, cacheID); fp = fopen(Fname, "w+");
	for (size_t kk = 0; kk < VCorpusInfo.xyz.size(); kk++)
		if (IsValid3D(VCorpusInfo.xyz[kk]))
			fprintf(fp, "%d %d %f %f %f\n", kk, VCorpusInfo.GlobalAnchor3DId[kk], VCorpusInfo.xyz[kk].x, VCorpusInfo.xyz[kk].y, VCorpusInfo.xyz[kk].z);
	fclose(fp);

	sprintf(Fname, "%s/cache/%d/lastCache.txt", Path, selectedCamId); fp = fopen(Fname, "w"), fprintf(fp, "%d\n", cacheID); fclose(fp);

	return true;
}
bool VideoKeyFrame2Corpus_LoadCache(char *Path, Corpus &VCorpusInfo, int selectedCamId, vector<int> &vrfid, int cacheID)
{
	printLOG("Loading cacheID %.2d\n", cacheID);
	char Fname[512];

	CameraData *camI = VCorpusInfo.camera;

	int rfid, lfid, LensModel, ShutterModel, width, height;
	double intrinsic[5], distortion[7];
	sprintf(Fname, "%s/cache/%d/Intrinsic_%.2d.txt", Path, selectedCamId, cacheID); FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d %d %d %d ", &rfid, &LensModel, &ShutterModel, &width, &height) != EOF)
	{
		std::vector<int>::iterator it = find(vrfid.begin(), vrfid.end(), rfid);
		if (it != vrfid.end())
		{
			lfid = std::distance(vrfid.begin(), it);

			for (int jj = 0; jj < 5; jj++)
				fscanf(fp, "%lf ", &camI[lfid].intrinsic[jj]);
			if (camI[lfid].LensModel == RADIAL_TANGENTIAL_PRISM)
				for (int jj = 0; jj < 7; jj++)
					fscanf(fp, "%lf ", &camI[lfid].distortion[jj]);
			else
				for (int jj = 0; jj < 3; jj++)
					fscanf(fp, "%lf ", &camI[lfid].distortion[jj]);
		}
		else
		{
			for (int jj = 0; jj < 5; jj++)
				fscanf(fp, "%lf ", &intrinsic[jj]);
			if (camI[lfid].LensModel == RADIAL_TANGENTIAL_PRISM)
				for (int jj = 0; jj < 7; jj++)
					fscanf(fp, "%lf ", &distortion[jj]);
			else
				for (int jj = 0; jj < 3; jj++)
					fscanf(fp, "%lf ", &distortion[jj]);
		}
	}
	fclose(fp);

	double rt[6], wt[6];
	sprintf(Fname, "%s/cache/%d/CamPose_%.2d.txt", Path, selectedCamId, cacheID); fp = fopen(Fname, "r");
	while (fscanf(fp, "%d ", &rfid) != EOF)
	{
		std::vector<int>::iterator it = find(vrfid.begin(), vrfid.end(), rfid);
		if (it != vrfid.end())
		{
			lfid = std::distance(vrfid.begin(), it);

			for (int jj = 0; jj < 6; jj++)
				fscanf(fp, "%lf ", &camI[lfid].rt[jj]);
			if (camI[lfid].ShutterModel == 1)
				for (int jj = 0; jj < 6; jj++)
					fscanf(fp, "%lf ", &camI[lfid].wt[jj]);
			camI[lfid].valid = true;
		}
		else
		{
			for (int jj = 0; jj < 6; jj++)
				fscanf(fp, "%lf ", &rt[jj]);
			if (camI[0].ShutterModel == 1)
				for (int jj = 0; jj < 6; jj++)
					fscanf(fp, "%lf ", &wt[jj]);
		}
	}
	fclose(fp);

	/*vector<Point3d> globalCorpus3D;
	int dummy, nGlobalCorpus3D, useColor;
	sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
	if (IsFileExist(Fname) == 0)
	sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
	FILE *fp = fopen(Fname, "r");
	fscanf(fp, "%d %d %d", &dummy, &nGlobalCorpus3D, &useColor);
	globalCorpus3D.resize(nGlobalCorpus3D);
	if (useColor)
	{
	for (int jj = 0; jj < nGlobalCorpus3D; jj++)
	fscanf(fp, "%lf %lf %lf %d %d %d", &globalCorpus3D[jj].x, &globalCorpus3D[jj].y, &globalCorpus3D[jj].z, &dummy, &dummy, &dummy);
	}
	else
	{
	for (int jj = 0; jj < nGlobalCorpus3D; jj++)
	fscanf(fp, "%lf %lf %lf ", &globalCorpus3D[jj].x, &globalCorpus3D[jj].y, &globalCorpus3D[jj].z);
	}
	fclose(fp);*/

	for (int lfid = 0; lfid < VCorpusInfo.nCameras; lfid++)
	{
		CameraData *camI = VCorpusInfo.camera;
		if (!camI[lfid].valid)
			continue;

		Point3d xyz; Point2f uv; float s;
		int globalCorpusP3DId, localCorpusP3DId, p2DId;

		sprintf(Fname, "%s/cache/%d/PnP/KF_Inliers_%.2d_%.4d.txt", Path, selectedCamId, cacheID, vrfid[lfid]); fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %lf %lf %lf %d %f %f %f ", &globalCorpusP3DId, &localCorpusP3DId, &xyz.x, &xyz.y, &xyz.z, &p2DId, &uv.x, &uv.y, &s) != EOF)
		{
			VCorpusInfo.xyz[localCorpusP3DId] = xyz;
			VCorpusInfo.uvAllViews2[lfid][p2DId] = uv;
			VCorpusInfo.scaleAllViews2[lfid][p2DId] = s;
		}
		fclose(fp);
		/*float x, y, z, u, v, s;
		int global3DId, localP3DId, twoDid;
		vector<int>cidPer3D, pidPer3D;
		vector<Point2d> uvPer3D;
		vector<double>scalePer3D;

		sprintf(Fname, "%s/cache/%d/PnP/KF_Inliers_%.2d_%.4d.txt", Path, selectedCamId, cacheID, vrfid[lfid]); fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %f %f %f %d %f %f %f", &global3DId, &localP3DId, &x, &y, &z, &twoDid, &u, &v, &s) != EOF)
		{
		if (abs(x) + abs(y) + abs(z) > LIMIT3D && (abs(VCorpusInfo.uvAllViews2[lfid][twoDid].x - u) > 10 || abs(VCorpusInfo.uvAllViews2[lfid][twoDid].y - v) > 10))
		{
		printLOG("Inconsistency in %.4d.sift and Inlier_%.4d.txt", vrfid[lfid], vrfid[lfid]);
		exit(0);
		}

		int local3DId = VCorpusInfo.threeDIdAllViews2[lfid][twoDid];
		if (local3DId == -1) //not a point formed by local matching but show up in global corpus-->add it in
		{
		cidPer3D.clear(), pidPer3D.clear(), uvPer3D.clear(), scalePer3D.clear();

		cidPer3D.push_back(lfid), pidPer3D.push_back(twoDid);
		uvPer3D.push_back(Point2d(VCorpusInfo.uvAllViews2[lfid][twoDid].x, VCorpusInfo.uvAllViews2[lfid][twoDid].y)), scalePer3D.push_back(s);

		VCorpusInfo.viewIdAll3D.push_back(cidPer3D);
		VCorpusInfo.pointIdAll3D.push_back(pidPer3D);
		VCorpusInfo.uvAll3D.push_back(uvPer3D);
		VCorpusInfo.scaleAll3D.push_back(scalePer3D);

		VCorpusInfo.threeDIdAllViews2[lfid][twoDid] = VCorpusInfo.xyz.size();
		VCorpusInfo.GlobalAnchor3DId.push_back(global3DId);  //so that you can trace back. Belong to global corpus, use as anchor during local SfM
		VCorpusInfo.xyz.push_back(globalCorpus3D[global3DId]);
		}
		else //a point formed by local kf matching but also global corpus
		{
		VCorpusInfo.GlobalAnchor3DId[local3DId] = global3DId; //so that you can trace back. Belong to global corpus, use as anchor during local SfM
		VCorpusInfo.xyz[local3DId] = globalCorpus3D[global3DId];
		}
		}
		fclose(fp);*/
	}

	int pid, GlobalAnchor3DId, dummy;
	Point3d xyz;
	sprintf(Fname, "%s/cache/%d/Video3DCorpus_%.2d.xyz", Path, selectedCamId, cacheID); fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d %lf %lf %lf\n", &pid, &GlobalAnchor3DId, &xyz.x, &xyz.y, &xyz.z) != EOF)
	{
		VCorpusInfo.GlobalAnchor3DId[pid] = GlobalAnchor3DId;
		VCorpusInfo.xyz[pid] = xyz;
	}
	fclose(fp);

	return true;
}
int VideoKeyframe2Corpus_GenerateAllView_2D_And_Corres_Info(char *Path, int selectedCamId, Corpus &VCorpusInfo, vector<int> &vrfid, SfMPara mySfMPara)
{
	//ViewIDAll3D, UVAll3D, ScalleAll3D: some 3D points may not have any inliers
	//threeDIdAllViews2: each 2d point is assigned a 3D pointID, among which may not be active
	//XYZ: (0,0,0) means deactive points
	char Fname[512];
	vector<KeyPoint> keypoints;

	vector<Point3d> globalCorpus3D;
	int dummy, nGlobalCorpus3D, useColor;
	sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
	FILE *fp = fopen(Fname, "r");
	fscanf(fp, "%d %d %d", &dummy, &nGlobalCorpus3D, &useColor);
	globalCorpus3D.resize(nGlobalCorpus3D);
	if (useColor)
	{
		for (int jj = 0; jj < nGlobalCorpus3D; jj++)
			fscanf(fp, "%lf %lf %lf %d %d %d", &globalCorpus3D[jj].x, &globalCorpus3D[jj].y, &globalCorpus3D[jj].z, &dummy, &dummy, &dummy);
	}
	else
	{
		for (int jj = 0; jj < nGlobalCorpus3D; jj++)
			fscanf(fp, "%lf %lf %lf ", &globalCorpus3D[jj].x, &globalCorpus3D[jj].y, &globalCorpus3D[jj].z);
	}
	fclose(fp);

	printLOG("Reading 2d feature points\n");
	for (size_t lfid = 0; lfid < vrfid.size(); lfid++)
	{
		keypoints.clear();
		sprintf(Fname, "%s/%d/%.4d.sift", Path, selectedCamId, vrfid[lfid]);
		if (readVisualSFMSiftGPU(Fname, keypoints) == 1)
			return 1;

		size_t npoints = keypoints.size();
		Point2f *uvAllViews2 = new Point2f[npoints];
		float *scaleAllViews2 = new float[npoints];
		int *threeDIdAllViews2 = new int[npoints];
		bool *InlierAllViews2 = new bool[npoints];

		for (size_t jj = 0; jj < npoints; jj++)
		{
			uvAllViews2[jj] = keypoints[jj].pt;
			scaleAllViews2[jj] = keypoints[jj].size;
			threeDIdAllViews2[jj] = -1; //not available yet. Will be determined after reading corres matches
			InlierAllViews2[jj] = true; //to be cleaned later after BA loop
		}

		VCorpusInfo.n2DPointsPerView.push_back(npoints);
		VCorpusInfo.uvAllViews2.push_back(uvAllViews2);
		VCorpusInfo.scaleAllViews2.push_back(scaleAllViews2);
		VCorpusInfo.threeDIdAllViews2.push_back(threeDIdAllViews2);
		VCorpusInfo.InlierAllViews2.push_back(InlierAllViews2);
	}

	printLOG("Reading 2d feature matches and generate database\n");
	sprintf(Fname, "%s/%d/P3D_Cid_Pid.txt", Path, selectedCamId);
	if (IsFileExist(Fname) == 0)
	{
		char Fname1[512], Fname2[512];

		int id1, id2, nPairwiseMatches;

		//Generate Visbible Points Table
		int totalPts = 0;
		vector<int> *KeysBelongTo3DPoint = new vector <int>[vrfid.size()];
		for (int jj = 0; jj < vrfid.size(); jj++)
		{
			totalPts += VCorpusInfo.n2DPointsPerView[jj];
			KeysBelongTo3DPoint[jj].reserve(VCorpusInfo.n2DPointsPerView[jj]);
			for (int ii = 0; ii < VCorpusInfo.n2DPointsPerView[jj]; ii++)
				KeysBelongTo3DPoint[jj].push_back(-1);
		}

		int count3D = 0;
		vector<int>viewIDs;
		vector<Point2d> uvPer3D;
		vector<double>scalePer3D;

		double start = omp_get_wtime();
		sprintf(Fname, "%s/%d/instreamMatches.txt", Path, selectedCamId);
		if (IsFileExist(Fname) == 1)
		{
			vector<int>*ViewMatch = new vector<int>[totalPts]; //cotains all visible views of 1 3D point
			vector<int>*PointIDMatch = new vector<int>[totalPts];//cotains all keyID of the visible views of 1 3D point

			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%s %s %d ", &Fname1, Fname2, &nPairwiseMatches) != EOF)
			{
				Point2i *matches = new Point2i[nPairwiseMatches];
				for (int ii = 0; ii < nPairwiseMatches; ii++)
					fscanf(fp, "%d %d ", &matches[ii].x, &matches[ii].y);

				std::string str1(Fname1);
				std::size_t found1 = str1.find(".");
				int kf1 = atoi(str1.substr(0, found1).c_str());

				std::string str2(Fname2);
				std::size_t found2 = str2.find(".");
				int kf2 = atoi(str2.substr(0, found2).c_str());

				std::vector<int>::iterator it = find(vrfid.begin(), vrfid.end(), kf1);
				if (it != vrfid.end())
					kf1 = std::distance(vrfid.begin(), it);
				else
					continue;

				std::vector<int>::iterator it2 = find(vrfid.begin(), vrfid.end(), kf2);
				if (it2 != vrfid.end())
					kf2 = std::distance(vrfid.begin(), it2);
				else
					continue;
				//not needed
				//VCorpusInfo.nPairwiseMatches.push_back(nPairwiseMatches);
				//VCorpusInfo.matchedPairwiseCid.push_back(Point2i(kf1, kf2));
				//VCorpusInfo.matchedPairwiseCidPid.push_back(matches);

				for (int kk = 0; kk < nPairwiseMatches; kk++)
				{
					int id1 = matches[kk].x, id2 = matches[kk].y;
					int ID3D1 = KeysBelongTo3DPoint[kf1][id1], ID3D2 = KeysBelongTo3DPoint[kf2][id2];
					if (ID3D1 == -1 && ID3D2 == -1) //Both are never seeen before
					{
						ViewMatch[count3D].push_back(kf1), ViewMatch[count3D].push_back(kf2);
						PointIDMatch[count3D].push_back(id1), PointIDMatch[count3D].push_back(id2);
						KeysBelongTo3DPoint[kf1][id1] = count3D, KeysBelongTo3DPoint[kf2][id2] = count3D; //this pair of corres constitutes 3D point #count
						count3D++;
					}
					else if (ID3D1 == -1 && ID3D2 != -1)
					{
						ViewMatch[ID3D2].push_back(kf1);
						PointIDMatch[ID3D2].push_back(id1);
						KeysBelongTo3DPoint[kf1][id1] = ID3D2; //this point constitutes 3D point #ID3D2
					}
					else if (ID3D1 != -1 && ID3D2 == -1)
					{
						ViewMatch[ID3D1].push_back(kf2);
						PointIDMatch[ID3D1].push_back(id2);
						KeysBelongTo3DPoint[kf2][id2] = ID3D1; //this point constitutes 3D point #ID3D2
					}
					else if (ID3D1 != -1 && ID3D2 != -1 && ID3D1 != ID3D2)//Strange case where 1 point (usually not vey discrimitive or repeating points) is matched to multiple points in the same view pair --> Just concatanate the one with fewer points to largrer one and hope MultiTriangulationRansac can do sth.
					{
						if (ViewMatch[ID3D1].size() >= ViewMatch[ID3D2].size())
						{
							int nPairwiseMatcheses = (int)ViewMatch[ID3D2].size();
							for (int ll = 0; ll < nPairwiseMatcheses; ll++)
							{
								ViewMatch[ID3D1].push_back(ViewMatch[ID3D2].at(ll));
								PointIDMatch[ID3D1].push_back(PointIDMatch[ID3D2].at(ll));
							}
							ViewMatch[ID3D2].clear(), PointIDMatch[ID3D2].clear();
						}
						else
						{
							int nPairwiseMatcheses = (int)ViewMatch[ID3D1].size();
							for (int ll = 0; ll < nPairwiseMatcheses; ll++)
							{
								ViewMatch[ID3D2].push_back(ViewMatch[ID3D1].at(ll));
								PointIDMatch[ID3D2].push_back(PointIDMatch[ID3D1].at(ll));
							}
							ViewMatch[ID3D1].clear(), PointIDMatch[ID3D1].clear();
						}
					}
					else//(ID3D1 == ID3D2): cycle in the corres, i.e. a-b, a-c, and b-c
						continue;
				}
			}
			printLOG("Merged correspondences in %.2fs...", omp_get_wtime() - start, count3D);

			//generate uvAll3D and sAll3D, 3DIdAllViews, XYZ
			VCorpusInfo.xyz.reserve(count3D);
			VCorpusInfo.GlobalAnchor3DId.reserve(count3D);
			int cnt = 0;
			for (int jj = 0; jj < count3D; jj++)
			{
				uvPer3D.clear(), scalePer3D.clear();
				for (size_t ii = 0; ii < ViewMatch[jj].size(); ii++)
				{
					int vid = ViewMatch[jj][ii], pid = PointIDMatch[jj][ii];

					double s = (double)VCorpusInfo.scaleAllViews2[vid][pid];
					Point2d uv(VCorpusInfo.uvAllViews2[vid][pid].x, VCorpusInfo.uvAllViews2[vid][pid].y);

					uvPer3D.push_back(uv), scalePer3D.push_back(s);

					VCorpusInfo.threeDIdAllViews2[vid][pid] = cnt;  //assign 3D pid
				}
				VCorpusInfo.viewIdAll3D.push_back(ViewMatch[jj]); //cotains all visible views of 1 3D point
				VCorpusInfo.pointIdAll3D.push_back(PointIDMatch[jj]);//cotains all keyID of the visible views of 1 3D point
				VCorpusInfo.uvAll3D.push_back(uvPer3D);
				VCorpusInfo.scaleAll3D.push_back(scalePer3D);

				VCorpusInfo.xyz.push_back(Point3d(0, 0, 0));
				VCorpusInfo.GlobalAnchor3DId.push_back(-1);
				cnt++;
			}
			printLOG("Generating %d potential 3D points\n", VCorpusInfo.xyz.size());

			delete[]ViewMatch, delete[]PointIDMatch;
		}
		else
			printLOG("Cannot load %s.\nWill not do local sfm on keyframes\n", Fname);

		sprintf(Fname, "%s/%d/P3D_Cid_Pid.txt", Path, selectedCamId); fp = fopen(Fname, "w");
		fprintf(fp, "%d\n", VCorpusInfo.xyz.size());
		for (int jj = 0; jj < VCorpusInfo.xyz.size(); jj++)
		{
			fprintf(fp, "%d\n", VCorpusInfo.viewIdAll3D[jj].size());
			for (size_t ii = 0; ii < VCorpusInfo.viewIdAll3D[jj].size(); ii++)
				fprintf(fp, "%d %d ", VCorpusInfo.viewIdAll3D[jj][ii], VCorpusInfo.pointIdAll3D[jj][ii]);
			fprintf(fp, "\n");
		}
		fclose(fp);
	}
	else
	{
		int count3D = 0, nmatches, cid, pid;

		vector<int>cidPer3D, pidPer3D;
		vector<Point2d> uvPer3D;
		vector<double>scalePer3D;

		sprintf(Fname, "%s/%d/P3D_Cid_Pid.txt", Path, selectedCamId); FILE *fp = fopen(Fname, "r");
		fscanf(fp, "%d ", &count3D);
		for (int jj = 0; jj < count3D; jj++)
		{
			fscanf(fp, "%d", &nmatches);

			cidPer3D.clear(), pidPer3D.clear();
			for (size_t ii = 0; ii < nmatches; ii++)
			{
				fscanf(fp, "%d %d ", &cid, &pid);
				cidPer3D.push_back(cid), pidPer3D.push_back(pid);
			}

			VCorpusInfo.viewIdAll3D.push_back(cidPer3D);
			VCorpusInfo.pointIdAll3D.push_back(pidPer3D);
		}
		fclose(fp);

		//generate uvAll3D and sAll3D, 3DIdAllViews, XYZ
		VCorpusInfo.xyz.reserve(count3D);
		VCorpusInfo.GlobalAnchor3DId.reserve(count3D);
		for (int jj = 0; jj < VCorpusInfo.viewIdAll3D.size(); jj++)
		{
			uvPer3D.clear(), scalePer3D.clear();
			for (size_t ii = 0; ii < VCorpusInfo.viewIdAll3D[jj].size(); ii++)
			{
				int cid = VCorpusInfo.viewIdAll3D[jj][ii], pid = VCorpusInfo.pointIdAll3D[jj][ii];
				Point2d uv(VCorpusInfo.uvAllViews2[cid][pid].x, VCorpusInfo.uvAllViews2[cid][pid].y);
				double s = (double)VCorpusInfo.scaleAllViews2[cid][pid];

				uvPer3D.push_back(uv);
				scalePer3D.push_back(s);

				VCorpusInfo.threeDIdAllViews2[cid][pid] = jj; //assign 3D pid
			}
			VCorpusInfo.uvAll3D.push_back(uvPer3D);
			VCorpusInfo.scaleAll3D.push_back(scalePer3D);

			VCorpusInfo.xyz.push_back(Point3d(0, 0, 0));
			VCorpusInfo.GlobalAnchor3DId.push_back(-1);
		}
		printLOG("Generating %d potential 3D points\n", VCorpusInfo.xyz.size());
	}

	int cnt = 0, cnt2 = 0;
	vector<int>cidPer3D, pidPer3D;
	vector<Point2d> uvPer3D;
	vector<double>scalePer3D;
	printLOG("Reading PnP feature points from keyframes\n");
	for (size_t lfid = 0; lfid < vrfid.size(); lfid++)
	{
		double u, v, s, x, y, z;
		int twoDid, global3DId, //point in global corpus
			local3DId; //point in current camera corpus
		int cnt3 = 0, cnt4 = 0;

		sprintf(Fname, "%s/%d/PnP/KF_Inliers_%.4d.txt", Path, selectedCamId, vrfid[lfid]);
		if (IsFileExist(Fname) == 1)
		{
			float x, y, z, u, v, s;
			int global3DId, localP3DId, p2DId;
			vector<int> vglobalCorpusP3DId, vlocalCorpusP3DId;
			vector<float > vu, vv;
			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d %f %f %f %d %f %f %f", &global3DId, &localP3DId, &x, &y, &z, &twoDid, &u, &v, &s) != EOF)
			{
				if (abs(x) + abs(y) + abs(z) > LIMIT3D && (abs(VCorpusInfo.uvAllViews2[lfid][twoDid].x - u) > 10 || abs(VCorpusInfo.uvAllViews2[lfid][twoDid].y - v) > 10))
				{
					printLOG("Inconsistency in %.4d.sift and Inlier_%.4d.txt", vrfid[lfid], vrfid[lfid]);
					exit(0);
				}

				local3DId = VCorpusInfo.threeDIdAllViews2[lfid][twoDid];
				if (local3DId == -1) //not a point formed by local matching but show up in global corpus-->add it in
				{
					cidPer3D.clear(), pidPer3D.clear(), uvPer3D.clear(), scalePer3D.clear();

					cidPer3D.push_back(lfid), pidPer3D.push_back(twoDid);
					uvPer3D.push_back(Point2d(VCorpusInfo.uvAllViews2[lfid][twoDid].x, VCorpusInfo.uvAllViews2[lfid][twoDid].y)), scalePer3D.push_back(s);

					VCorpusInfo.viewIdAll3D.push_back(cidPer3D);
					VCorpusInfo.pointIdAll3D.push_back(pidPer3D);
					VCorpusInfo.uvAll3D.push_back(uvPer3D);
					VCorpusInfo.scaleAll3D.push_back(scalePer3D);

					VCorpusInfo.threeDIdAllViews2[lfid][twoDid] = VCorpusInfo.xyz.size();
					VCorpusInfo.GlobalAnchor3DId.push_back(global3DId);  //so that you can trace back. Belong to global corpus, use as anchor during local SfM
					VCorpusInfo.xyz.push_back(globalCorpus3D[global3DId]);

					cnt++;
				}
				else //a point formed by local kf matching but also global corpus
				{
					VCorpusInfo.GlobalAnchor3DId[local3DId] = global3DId; //so that you can trace back. Belong to global corpus, use as anchor during local SfM
					VCorpusInfo.xyz[local3DId] = globalCorpus3D[global3DId];

					cnt2++;
				}
			}
			fclose(fp);
			//printLOG("(%d %d %d)..", vrfid[lfid], cnt, cnt2);
		}
		else
		{
			sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, selectedCamId, vrfid[lfid]);
			if (IsFileExist(Fname))
			{
				FILE *fp = fopen(Fname, "r");
				while (fscanf(fp, "%d %lf %lf %lf %d %lf %lf %lf\n", &global3DId, &u, &v, &s, &twoDid, &u, &v, &s) != EOF)
				{
					if (global3DId< 0 || global3DId >nGlobalCorpus3D)
					{
						printLOG("Imposible global3DId in Inlier_%.4d.txt", vrfid[lfid]);
						exit(0);
					}
					if (abs(VCorpusInfo.uvAllViews2[lfid][twoDid].x - u) > 10 || abs(VCorpusInfo.uvAllViews2[lfid][twoDid].y - v) > 10)
					{
						printLOG("Inconsistency in %.4d.sift and Inlier_%.4d.txt", vrfid[lfid], vrfid[lfid]);
						exit(0);
					}

					local3DId = VCorpusInfo.threeDIdAllViews2[lfid][twoDid];
					if (local3DId == -1) //not a point formed by local matching but show up in global corpus-->add it in
					{
						cidPer3D.clear(), pidPer3D.clear(), uvPer3D.clear(), scalePer3D.clear();

						cidPer3D.push_back(lfid), pidPer3D.push_back(twoDid);
						uvPer3D.push_back(Point2d(VCorpusInfo.uvAllViews2[lfid][twoDid].x, VCorpusInfo.uvAllViews2[lfid][twoDid].y)), scalePer3D.push_back(s);

						VCorpusInfo.viewIdAll3D.push_back(cidPer3D);
						VCorpusInfo.pointIdAll3D.push_back(pidPer3D);
						VCorpusInfo.uvAll3D.push_back(uvPer3D);
						VCorpusInfo.scaleAll3D.push_back(scalePer3D);

						VCorpusInfo.threeDIdAllViews2[lfid][twoDid] = VCorpusInfo.xyz.size();
						VCorpusInfo.GlobalAnchor3DId.push_back(global3DId);  //so that you can trace back. Belong to global corpus, use as anchor during local SfM
						VCorpusInfo.xyz.push_back(globalCorpus3D[global3DId]);

						cnt++;
					}
					else //a point formed by local kf matching but also global corpus
					{
						VCorpusInfo.GlobalAnchor3DId[local3DId] = global3DId; //so that you can trace back. Belong to global corpus, use as anchor during local SfM
						VCorpusInfo.xyz[local3DId] = globalCorpus3D[global3DId];

						cnt2++;
					}
				}
				fclose(fp);
				//printLOG("(%d %d %d)..", vrfid[lfid], cnt, cnt2);
			}
		}
	}

	//start pruning < N+point nViewsPlusBA
	for (size_t pid = 0; pid < VCorpusInfo.xyz.size(); pid++)
	{
		if (VCorpusInfo.viewIdAll3D[pid].size() < mySfMPara.nViewsPlusBA && VCorpusInfo.GlobalAnchor3DId[pid] == -1) //not N+ and not anchor (anchor can be visible only once in that view)
		{
			for (size_t ii = 0; ii < VCorpusInfo.viewIdAll3D[pid].size(); ii++)
			{
				int fid = VCorpusInfo.viewIdAll3D[pid][ii], twoDid = VCorpusInfo.pointIdAll3D[pid][ii];
				VCorpusInfo.threeDIdAllViews2[fid][twoDid] = -1;
			}

			VCorpusInfo.viewIdAll3D[pid].clear();
			VCorpusInfo.pointIdAll3D[pid].clear();
			VCorpusInfo.uvAll3D[pid].clear();
			VCorpusInfo.scaleAll3D[pid].clear();
			VCorpusInfo.xyz[pid] = Point3d(0, 0, 0);
		}
	}

	cnt = 0, cnt2 = 0;
	for (size_t pid = 0; pid < VCorpusInfo.xyz.size(); pid++)
	{
		if (VCorpusInfo.viewIdAll3D[pid].size() > 0 && VCorpusInfo.GlobalAnchor3DId[pid] > -1)
			cnt++;
		else if (VCorpusInfo.viewIdAll3D[pid].size() > 0 && VCorpusInfo.GlobalAnchor3DId[pid] == -1)
			cnt2++;
	}
	printLOG("Global corpus: %d, potential local corpus: %d\n", cnt, cnt2);

	return 0;
}
int VideoKeyframe2Corpus_SFM(char *Path, int selectedCamId, SfMPara mySfMPara)
{
	//Useful if PnP does not find all matches but pairwise matching does. Essentially, this function uses partially localized frames as init for starting in iSfM.
	//make sure you initialize the intrinsic.
	char Fname[512], Fname1[512], Fname2[512];
	sprintf(Fname, "%s/cache", Path); makeDir(Fname);
	sprintf(Fname, "%s/cache/%d", Path, selectedCamId); makeDir(Fname);
	sprintf(Fname, "%s/cache/%d/PnP", Path, selectedCamId); makeDir(Fname);

	printLOG("\n\n************************\n******WORKING ON CAMERA %d******\n", selectedCamId);

	int startF = mySfMPara.startF, stopF = mySfMPara.stopF;

	CameraData InitIntrinsicCam;
	sprintf(Fname, "%s/AvgDevicesIntrinsics.txt", Path);
	if (IsFileExist(Fname))
	{
		int lensType, shutterType, width, height;
		double fx, fy, skew, u0, v0, r0, r1, r2, t0, t1, p0, p1, omega, DistCtrX, DistCtrY;

		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%s %d %d %d %d %lf %lf %lf %lf %lf ", Fname, &lensType, &shutterType, &width, &height, &fx, &fy, &skew, &u0, &v0) != EOF)
		{
			string  filename = string(Fname);

			std::size_t posDot = filename.find(".");
			filename.erase(posDot, 4);
			const char * str = filename.c_str();
			int id = atoi(str);

			if (id == selectedCamId)
			{
				InitIntrinsicCam.LensModel = lensType, InitIntrinsicCam.ShutterModel = shutterType, InitIntrinsicCam.width = width, InitIntrinsicCam.height = height;
				InitIntrinsicCam.K[0] = fx, InitIntrinsicCam.K[1] = skew, InitIntrinsicCam.K[2] = u0,
					InitIntrinsicCam.K[3] = 0.0, InitIntrinsicCam.K[4] = fy, InitIntrinsicCam.K[5] = v0,
					InitIntrinsicCam.K[6] = 0.0, InitIntrinsicCam.K[7] = 0.0, InitIntrinsicCam.K[8] = 1.0;
				GetIntrinsicFromK(InitIntrinsicCam);
				mat_invert(InitIntrinsicCam.K, InitIntrinsicCam.invK);
			}

			if (lensType == RADIAL_TANGENTIAL_PRISM)
			{
				fscanf(fp, " %lf %lf %lf %lf %lf %lf %lf ", &r0, &r1, &r2, &t0, &t1, &p0, &p1);
				if (id == selectedCamId)
				{
					InitIntrinsicCam.distortion[0] = r0, InitIntrinsicCam.distortion[1] = r1, InitIntrinsicCam.distortion[2] = r2;
					InitIntrinsicCam.distortion[3] = t0, InitIntrinsicCam.distortion[4] = t1;
					InitIntrinsicCam.distortion[5] = p0, InitIntrinsicCam.distortion[6] = p1;
				}
			}
			else
			{
				fscanf(fp, " %lf %lf %lf ", &omega, &DistCtrX, &DistCtrY);
				if (id == selectedCamId)
				{
					InitIntrinsicCam.distortion[0] = omega, InitIntrinsicCam.distortion[1] = DistCtrX, InitIntrinsicCam.distortion[2] = DistCtrY;
					InitIntrinsicCam.distortion[3] = 0, InitIntrinsicCam.distortion[4] = 0;
					InitIntrinsicCam.distortion[5] = 0, InitIntrinsicCam.distortion[6] = 0;
				}
			}
		}
		fclose(fp);
	}
	else
	{
		sprintf(Fname, "%s/InitDevicesIntrinsics.txt", Path); FILE *fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int width, height, id, lensType; double focal;
			while (fscanf(fp, "%d %d %d %d %lf", &id, &lensType, &width, &height, &focal) != EOF)
			{
				if (id == selectedCamId)
				{
					InitIntrinsicCam.width = width, InitIntrinsicCam.height = height;
					InitIntrinsicCam.intrinsic[0] = focal, InitIntrinsicCam.intrinsic[1] = focal;
					InitIntrinsicCam.intrinsic[3] = width / 2, InitIntrinsicCam.intrinsic[4] = height / 2;
					InitIntrinsicCam.LensModel = lensType;
				}

				if (lensType == RADIAL_TANGENTIAL_PRISM)
					for (int ii = 0; ii < 7; ii++)
						fscanf(fp, "%lf ", &InitIntrinsicCam.distortion[ii]);
				else
					fscanf(fp, "%lf %lf %lf ", &InitIntrinsicCam.distortion[0], &InitIntrinsicCam.intrinsic[3], &InitIntrinsicCam.intrinsic[4]);
			}
			fclose(fp);
		}
	}

	//identify keyframe
	int  dummy, rfid;
	vector<int> vrfid;
	sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, selectedCamId);
	if (IsFileExist(Fname, false) == 0)
		return 1;
	FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d %d %d ", &dummy, &dummy, &rfid, &dummy) != EOF)
		vrfid.push_back(rfid);
	fclose(fp);

	Corpus VCorpusInfo;
	VCorpusInfo.nCameras = (int)vrfid.size();
	VCorpusInfo.camera = new CameraData[vrfid.size()];
	for (int kflid = 0; kflid < (int)vrfid.size(); kflid++)
	{
		CopyCamereInfo(InitIntrinsicCam, VCorpusInfo.camera[kflid], false);
		VCorpusInfo.camera[kflid].frameID = vrfid[kflid], VCorpusInfo.camera[kflid].valid = false;
	}

	//in case the camera intrinsic is not initialized before PnP, this intrinsic file will not contain the distortion info.
	sprintf(Fname, "%s/Intrinsic_%.4d.txt", Path, selectedCamId); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int lfid, LensType, ShutterModel, width, height;
		double intrinsic[5], distortion[7];
		while (fscanf(fp, "%d %d %d %d %d %lf %lf %lf %lf %lf ", &rfid, &LensType, &ShutterModel, &width, &height, &intrinsic[0], &intrinsic[1], &intrinsic[2], &intrinsic[3], &intrinsic[4]) != EOF)
		{
			if (LensType == RADIAL_TANGENTIAL_PRISM)
				fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf ", &distortion[0], &distortion[1], &distortion[2], &distortion[3], &distortion[4], &distortion[5], &distortion[6]);
			else
				fscanf(fp, "%lf %lf %lf ", &distortion[0], &distortion[1], &distortion[2]);
			std::vector<int>::iterator iter = find(vrfid.begin(), vrfid.end(), rfid);
			if (iter != vrfid.end())
			{
				lfid = std::distance(vrfid.begin(), iter);
				VCorpusInfo.camera[lfid].LensModel = LensType, VCorpusInfo.camera[lfid].ShutterModel = ShutterModel;
				VCorpusInfo.camera[lfid].width = width, VCorpusInfo.camera[lfid].height = height;
				for (int jj = 0; jj < 5; jj++)
					VCorpusInfo.camera[lfid].intrinsic[jj] = intrinsic[jj];
				if (LensType == RADIAL_TANGENTIAL_PRISM)
					for (int jj = 0; jj < 7; jj++)
						VCorpusInfo.camera[lfid].distortion[jj] = distortion[jj];
				else
					for (int jj = 0; jj < 3; jj++)
						VCorpusInfo.camera[lfid].distortion[jj] = distortion[jj];

				GetKFromIntrinsic(VCorpusInfo.camera[lfid]);
			}
		}
	}
	sprintf(Fname, "%s/CamPose_%.4d.txt", Path, selectedCamId); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int lfid;  double rt[6], wt[6];
		while (fscanf(fp, "%d %lf %lf %lf %lf %lf %lf ", &rfid, &rt[0], &rt[1], &rt[2], &rt[3], &rt[4], &rt[5]) != EOF)
		{
			if (mySfMPara.ShutterModel == ROLLING_SHUTTER)
				fscanf(fp, "%lf %lf %lf %lf %lf %lf ", &wt[0], &wt[1], &wt[2], &wt[3], &wt[4], &wt[5]);

			std::vector<int>::iterator iter = find(vrfid.begin(), vrfid.end(), rfid);
			if (iter != vrfid.end())
			{
				lfid = std::distance(vrfid.begin(), iter);
				for (int jj = 0; jj < 6; jj++)
				{
					VCorpusInfo.camera[lfid].rt[jj] = rt[jj];
					if (mySfMPara.ShutterModel == ROLLING_SHUTTER)
						VCorpusInfo.camera[lfid].wt[jj] = wt[jj];
				}
				GetRTFromrt(VCorpusInfo.camera[lfid]);
				AssembleP(VCorpusInfo.camera[lfid]);

				VCorpusInfo.camera[lfid].valid = true;
			}
		}
	}

	printLOG("\n******Getting 2D features and correspondences info ******\n");
	if (VideoKeyframe2Corpus_GenerateAllView_2D_And_Corres_Info(Path, selectedCamId, VCorpusInfo, vrfid, mySfMPara))
	{
		printLOG("Problem reading features and correspondences\n");
		return 1;
	}

	printLOG("\n*****Start iSfM*****\n");

	Point2i globalLocal;
	vector<int> Inliers;
	vector<Point2d> pts;
	vector<Point3d> t3D;
	vector<int> sorted(vrfid.size()), order(vrfid.size());

	int orgNviewPlus = mySfMPara.nViewsPlusBA;
	if (mySfMPara.nViewsPlusBA != 2)
		mySfMPara.nViewsPlusBA = 2;

	//for every un-posed keyframe, determine its pair that has the largest PnP inliers for PnP and retriangulate. The list of keyframe with high number of inliers is updated
	int nReconPoints = 0, nLocalizedFrames = 0;
	vector<int> nPassesPerFrame(vrfid.size()), nPassesWoPnPPerFrame(vrfid.size()), vKF2Process(vrfid.size());
	for (size_t KF2Process = 0; KF2Process < vrfid.size(); KF2Process++)
	{
		if (VCorpusInfo.camera[KF2Process].valid)
		{
			nPassesPerFrame[KF2Process] = mySfMPara.maxPassesPerImage, vKF2Process[KF2Process] = 0, nLocalizedFrames++;
			GetRTFromrt(VCorpusInfo.camera[KF2Process]);
			GetCfromT(VCorpusInfo.camera[KF2Process]);
		}
		else
			nPassesPerFrame[KF2Process] = 0, vKF2Process[KF2Process] = 1;

		int cnt = 0;
		for (size_t pid = 0; pid < VCorpusInfo.n2DPointsPerView[KF2Process]; pid++)
			if (VCorpusInfo.threeDIdAllViews2[KF2Process][pid] > -1) // at least, has corres accross views
				cnt++;

		if (cnt < mySfMPara.nInliersThresh)
			nPassesPerFrame[KF2Process] = mySfMPara.maxPassesPerImage; //none of the PnP works
	}

	printLOG("\n******reTriangulate and BA ******\n");
	int new3Dcnt, nPointsSinceLastBA, nFramesSinceLastBA, nAddedFrames = 0;

	//Loading cache
	bool foundCache = false;
	int cacheID = 0;
	sprintf(Fname, "%s/cache/%d/lastCache.txt", Path, selectedCamId);
	if (IsFileExist(Fname) == 1)
	{
		fp = fopen(Fname, "r");
		fscanf(fp, "%d", &cacheID);
		fclose(fp);

		foundCache = true;
	}

	if (foundCache)
	{
		nLocalizedFrames = 0;
		VideoKeyFrame2Corpus_LoadCache(Path, VCorpusInfo, selectedCamId, vrfid, cacheID);
		for (size_t KF2Process = 0; KF2Process < vrfid.size(); KF2Process++)
		{
			if (VCorpusInfo.camera[KF2Process].valid)
			{
				vKF2Process[KF2Process] = 0, nLocalizedFrames++;
				GetRTFromrt(VCorpusInfo.camera[KF2Process]);
				GetCfromT(VCorpusInfo.camera[KF2Process]);
			}
			else
				vKF2Process[KF2Process] = 1;

			int cnt = 0;
			for (size_t pid = 0; pid < VCorpusInfo.n2DPointsPerView[KF2Process]; pid++)
				if (VCorpusInfo.threeDIdAllViews2[KF2Process][pid] > -1) // at least, has corres accross views
					cnt++;

			if (cnt < mySfMPara.nInliersThresh)
				nPassesPerFrame[KF2Process] = mySfMPara.maxPassesPerImage; //none of the PnP works
		}
	}
	else
	{
		printLOG("reTriangulation...");
		new3Dcnt = sSfM_reTri(VCorpusInfo, mySfMPara);

		printLOG("generates %d new 3D points  (%d 3D points in total)...", new3Dcnt, GetNumValid3Ds(VCorpusInfo.xyz));
		globalLocal = GetGlobalAndLocalPointsStat(VCorpusInfo.viewIdAll3D, VCorpusInfo.GlobalAnchor3DId, VCorpusInfo.xyz);
		printLOG("global corpus: %d,  local corpus: %d\n\n", globalLocal.x, globalLocal.y);

		/*sprintf(Fname, "%s/cache/%d/Video3DCorpus_%.2d.xyz", Path, selectedCamId, 0); fp = fopen(Fname, "w+");
		for (size_t kk = 0; kk < VCorpusInfo.xyz.size(); kk++)
		if (IsValid3D(VCorpusInfo.xyz[kk]))
		fprintf(fp, "%d %d %f %f %f\n", kk, VCorpusInfo.GlobalAnchor3DId[kk], VCorpusInfo.xyz[kk].x, VCorpusInfo.xyz[kk].y, VCorpusInfo.xyz[kk].z);
		fclose(fp);

		int pid, GlobalAnchor3DId, dummy;
		Point3d xyz;
		sprintf(Fname, "%s/cache/%d/Video3DCorpus.xyz", Path, selectedCamId); fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %lf %lf %lf\n", &pid, &GlobalAnchor3DId, &xyz.x, &xyz.y, &xyz.z) != EOF)
		{
		VCorpusInfo.GlobalAnchor3DId[pid] = GlobalAnchor3DId;
		VCorpusInfo.xyz[pid] = xyz;
		}
		fclose(fp);*/

		BA_Driver(Path, VCorpusInfo, mySfMPara);
		sSfM_CleanInliers(VCorpusInfo, mySfMPara);
		VideoKeyFrame2Corpus_CacheResults(Path, VCorpusInfo, selectedCamId, vrfid, nAddedFrames);
	}
	nFramesSinceLastBA = nLocalizedFrames;
	nPointsSinceLastBA = GetNumValid3Ds(VCorpusInfo.xyz);

	int nUnlocalizedFrames = 0;
	for (size_t KF2Process = 0; KF2Process < vrfid.size(); KF2Process++)
		if (VCorpusInfo.camera[KF2Process].valid == 0)
			vKF2Process[KF2Process] == 1, nUnlocalizedFrames++;

	for (int iter = 0; iter < mySfMPara.maxGlobalPass; iter++)
	{
		printLOG("\n******************\n");
		printLOG("\n******(global pass #%d) ******\n", iter);
		for (size_t KF2Process = 0; KF2Process < vrfid.size(); KF2Process++)
		{
			nPassesPerFrame[KF2Process] = 0, nPassesWoPnPPerFrame[KF2Process] = 0;
			if (VCorpusInfo.camera[KF2Process].valid == 0) //let's detect cameras left out by the BA
				vKF2Process[KF2Process] == 1;
		}

		while (true)
		{
			//determine uncalib/not exceeding max pass kf with highest number of avail3D
			int cnt = 0;
			for (size_t KF2Process = 0; KF2Process < vrfid.size(); KF2Process++)
			{
				if (vKF2Process[KF2Process] == 0 || nPassesPerFrame[KF2Process] > mySfMPara.maxPassesPerImage || nPassesWoPnPPerFrame[KF2Process] > mySfMPara.maxPassesPerImage * 10)
					continue;

				sorted[cnt] = 0;
				for (int pid = 0; pid < VCorpusInfo.n2DPointsPerView[KF2Process]; pid++)
				{
					int threeDId = VCorpusInfo.threeDIdAllViews2[KF2Process][pid];
					if (threeDId > -1 && IsValid3D(VCorpusInfo.xyz[threeDId]))
						sorted[cnt]--;
				}

				order[cnt] = KF2Process;
				cnt++;
			}
			if (cnt == 0) //may need to be retriangulate for more PnP corres or you cannot localize any further
				break;

			Quick_Sort_Int(&sorted[0], &order[0], 0, cnt - 1);

			for (int ii = 0; ii < cnt; ii++) //do PnP until #inlier drops below threshold or retriangulation/BA is called
			{
				if (-sorted[ii] < mySfMPara.nInliersThresh)
				{
					nPassesWoPnPPerFrame[order[ii]]++;
					break;
				}

				int KF2Process = order[ii], cnt2 = 0;
				printLOG("\n******Registering frame %d (%d) of camera %d (%d of %d localized)******\n", KF2Process, vrfid[KF2Process], selectedCamId, nAddedFrames + 1, nUnlocalizedFrames);

				//PnP: get data for PnP
				pts.clear(), t3D.clear();
				for (int pid = 0; pid < VCorpusInfo.n2DPointsPerView[KF2Process]; pid++)
				{
					int threeDId = VCorpusInfo.threeDIdAllViews2[KF2Process][pid];
					if (threeDId > -1 && IsValid3D(VCorpusInfo.xyz[threeDId]))
					{
						if (mySfMPara.distortionCorrected == 0) //EstimatePoseAndInliers only takes undistorted points
						{
							Point2d uv = VCorpusInfo.uvAllViews2[KF2Process][pid];
							if (VCorpusInfo.camera[KF2Process].LensModel == RADIAL_TANGENTIAL_PRISM)
								LensCorrectionPoint(&uv, VCorpusInfo.camera[KF2Process].K, VCorpusInfo.camera[KF2Process].distortion);
							else
								FishEyeCorrectionPoint(&uv, VCorpusInfo.camera[KF2Process].K, VCorpusInfo.camera[KF2Process].distortion[0]);
							pts.push_back(uv), t3D.push_back(VCorpusInfo.xyz[threeDId]), cnt2++;
						}
					}
				}

				Inliers.clear();
				int ninliers = EstimatePoseAndInliers(VCorpusInfo.camera[KF2Process].K, VCorpusInfo.camera[KF2Process].distortion, VCorpusInfo.camera[KF2Process].LensModel, VCorpusInfo.camera[KF2Process].ShutterModel,
					VCorpusInfo.camera[KF2Process].R, VCorpusInfo.camera[KF2Process].T, VCorpusInfo.camera[KF2Process].wt, pts, t3D, Inliers, mySfMPara.reProjectionTrianguatlionThresh, mySfMPara.fixIntrinsic, mySfMPara.distortionCorrected, mySfMPara.minFRatio, mySfMPara.maxFratio, VCorpusInfo.camera[KF2Process].width, VCorpusInfo.camera[KF2Process].height, PnP::EPNP);
				if (ninliers > mySfMPara.nInliersThresh)
				{
					VCorpusInfo.camera[KF2Process].valid = true;
					GetrtFromRT(&VCorpusInfo.camera[KF2Process], 1);
					GetIntrinsicFromK(VCorpusInfo.camera[KF2Process]);
				}

				//reTri/BA
				if (!VCorpusInfo.camera[KF2Process].valid)
					nPassesPerFrame[KF2Process]++; //none of the PnP works
				else
				{
					nLocalizedFrames++, nAddedFrames++;
					vKF2Process[KF2Process] = 0;

					GetCfromT(VCorpusInfo.camera[KF2Process].R, VCorpusInfo.camera[KF2Process].T, VCorpusInfo.camera[KF2Process].camCenter);
					AssembleP(VCorpusInfo.camera[KF2Process]);

					printLOG("Triangulate frame %d", KF2Process);
					new3Dcnt = sSfM_reTri(KF2Process, VCorpusInfo, mySfMPara);
					nReconPoints = GetNumValid3Ds(VCorpusInfo.xyz);
					printLOG("...generating %d new 3D points (%d 3D points in total)\n", new3Dcnt, nReconPoints);
					globalLocal = GetGlobalAndLocalPointsStat(VCorpusInfo.viewIdAll3D, VCorpusInfo.GlobalAnchor3DId, VCorpusInfo.xyz);
					printLOG("global corpus: %d,  local corpus: %d\n", globalLocal.x, globalLocal.y);

					if (nAddedFrames > orgNviewPlus * 3 && mySfMPara.nViewsPlusBA != orgNviewPlus)
					{
						mySfMPara.nViewsPlusBA = orgNviewPlus;
						printLOG("\n******Having sufficient views for the requested NViewsPoints (%d views) ******\n", mySfMPara.nViewsPlusBA);
					}

					if (nLocalizedFrames > mySfMPara.ba_global_images_ratio*nFramesSinceLastBA || nReconPoints > mySfMPara.ba_global_images_ratio*nPointsSinceLastBA || nLocalizedFrames - nFramesSinceLastBA >= mySfMPara.globalBA_freq)
					{
						printLOG("\n\n******reTriangulate and BA******\n");
						printLOG("nLocalizedFrames: %d nReconPoints: %d nFramesSinceLastBA: %d\n", nLocalizedFrames, nReconPoints, nFramesSinceLastBA);

						printLOG("reTriangulation...");
						new3Dcnt = sSfM_reTri(VCorpusInfo, mySfMPara);
						printLOG("generates %d new 3D points  (%d 3D points in total)\n\n", new3Dcnt, GetNumValid3Ds(VCorpusInfo.xyz));
						globalLocal = GetGlobalAndLocalPointsStat(VCorpusInfo.viewIdAll3D, VCorpusInfo.GlobalAnchor3DId, VCorpusInfo.xyz);
						printLOG("global corpus: %d,  local corpus: %d\n\n", globalLocal.x, globalLocal.y);

						BA_Driver(Path, VCorpusInfo, mySfMPara);
						nPointsSinceLastBA = GetNumValid3Ds(VCorpusInfo.xyz);
						nFramesSinceLastBA = nLocalizedFrames;
					}

					if (nAddedFrames%mySfMPara.snapshot_images_freq == 0)
					{
						sSfM_CleanInliers(VCorpusInfo, mySfMPara);
						VideoKeyFrame2Corpus_CacheResults(Path, VCorpusInfo, selectedCamId, vrfid, nAddedFrames);
					}
				}
			}
		}

		if (nLocalizedFrames != nFramesSinceLastBA)
		{
			printLOG("\n\n******reTriangulate and BA ******\n");
			printLOG("reTriangulation...");
			new3Dcnt = sSfM_reTri(VCorpusInfo, mySfMPara);
			printLOG("generates %d new 3D points  (%d 3D points in total)\n\n", new3Dcnt, GetNumValid3Ds(VCorpusInfo.xyz));
			globalLocal = GetGlobalAndLocalPointsStat(VCorpusInfo.viewIdAll3D, VCorpusInfo.GlobalAnchor3DId, VCorpusInfo.xyz);
			printLOG("global corpus: %d,  local corpus: %d\n\n", globalLocal.x, globalLocal.y);

			nFramesSinceLastBA = nLocalizedFrames;
			BA_Driver(Path, VCorpusInfo, mySfMPara);
			sSfM_CleanInliers(VCorpusInfo, mySfMPara);
			VideoKeyFrame2Corpus_CacheResults(Path, VCorpusInfo, selectedCamId, vrfid, nAddedFrames + 1);
		}

		int cnt = 0;
		for (size_t KF2Process = 0; KF2Process < vrfid.size(); KF2Process++)
			if (VCorpusInfo.camera[KF2Process].valid)
				cnt++;
		if (cnt == VCorpusInfo.nCameras)
			break;
	}
	printLOG("\n******Done******\n");

	double residuals[2], miniX, maxiX, avgX, stdX, miniY, maxiY, avgY, stdY;
	vector<double> ReProjectionErrorX, ReProjectionErrorY, ReProjectionErrorAX, ReProjectionErrorAY;
	sprintf(Fname, "%s/%d/KF_Inliers_Stat.txt", Path, selectedCamId); FILE *fp1 = fopen(Fname, "w+");
	fprintf(fp1, "Fid #A \t min_x min_y \t max_x max_y \t mean_x mean_y \t std_x std_y\t #L \t min_x min_y \t max_x max_y \t mean_x mean_y \t std_x std_y\n");
	for (int ii = 0; ii < VCorpusInfo.nCameras; ii++)
	{
		CameraData *camI = VCorpusInfo.camera;
		if (!camI[ii].valid)
		{
			fprintf(fp1, "%d %d %d \n", vrfid[ii], 0, 0);
			continue;
		}
		ReProjectionErrorAX.clear(), ReProjectionErrorAY.clear(), ReProjectionErrorX.clear(), ReProjectionErrorY.clear();

		sprintf(Fname, "%s/%d/PnP/KF_Inliers_%.4d.txt", Path, selectedCamId, vrfid[ii]); fp = fopen(Fname, "w+");
		for (int p2DId = 0; p2DId < VCorpusInfo.n2DPointsPerView[ii]; p2DId++)
		{
			int localCorpusP3DId = VCorpusInfo.threeDIdAllViews2[ii][p2DId];
			if (localCorpusP3DId > -1 && VCorpusInfo.InlierAllViews2[ii][p2DId] && IsValid3D(VCorpusInfo.xyz[localCorpusP3DId]))
			{
				int globalCorpusP3DId = VCorpusInfo.GlobalAnchor3DId[localCorpusP3DId];
				Point3d xyz = VCorpusInfo.xyz[localCorpusP3DId];
				Point2d uv = VCorpusInfo.uvAllViews2[ii][p2DId];
				fprintf(fp, "%d %d %f %f %f %d %.6f %.6f %.2f\n", globalCorpusP3DId, localCorpusP3DId, xyz.x, xyz.y, xyz.z, p2DId, uv.x, uv.y, VCorpusInfo.scaleAllViews2[ii][p2DId]);

				if (mySfMPara.distortionCorrected == 0)
				{
					if (camI[ii].ShutterModel == GLOBAL_SHUTTER)
					{
						if (camI[ii].LensModel == RADIAL_TANGENTIAL_PRISM)
							PinholeDistortionReprojectionDebug(camI[ii].intrinsic, camI[ii].distortion, camI[ii].rt, uv, xyz, residuals);
						else
							FOVReprojectionDistortion2Debug(camI[ii].intrinsic, camI[ii].distortion, camI[ii].rt, uv, xyz, residuals);
					}
					else
					{
						if (camI[ii].LensModel == RADIAL_TANGENTIAL_PRISM)
							CayleyDistortionReprojectionDebug(camI[ii].intrinsic, camI[ii].distortion, camI[ii].rt, camI[ii].wt, uv, xyz, camI[ii].width, camI[ii].height, residuals);
						else
							CayleyFOVReprojection2Debug(camI[ii].intrinsic, camI[ii].distortion, camI[ii].rt, camI[ii].wt, uv, xyz, camI[ii].width, camI[ii].height, residuals);
					}
				}
				else
				{
					if (camI[ii].ShutterModel == GLOBAL_SHUTTER)
						PinholeReprojectionDebug(camI[ii].intrinsic, camI[ii].rt, uv, xyz, residuals);
					else
						CayleyReprojectionDebug(camI[ii].intrinsic, camI[ii].rt, camI[ii].wt, uv, xyz, camI[ii].width, camI[ii].height, residuals);
				}

				if (globalCorpusP3DId > -1)
					ReProjectionErrorAX.push_back(residuals[0]), ReProjectionErrorAY.push_back(residuals[1]);
				else
					ReProjectionErrorX.push_back(residuals[0]), ReProjectionErrorY.push_back(residuals[1]);
			}
		}
		fclose(fp);

		fprintf(fp1, "%d \t ", vrfid[ii]);
		if (ReProjectionErrorAX.size() > 0)
		{
			miniX = *min_element(ReProjectionErrorAX.begin(), ReProjectionErrorAX.end());
			maxiX = *max_element(ReProjectionErrorAX.begin(), ReProjectionErrorAX.end());
			avgX = MeanArray(ReProjectionErrorAX);
			stdX = sqrt(VarianceArray(ReProjectionErrorAX, avgX));
			miniY = *min_element(ReProjectionErrorAY.begin(), ReProjectionErrorAY.end());
			maxiY = *max_element(ReProjectionErrorAY.begin(), ReProjectionErrorAY.end());
			avgY = MeanArray(ReProjectionErrorAY);
			stdY = sqrt(VarianceArray(ReProjectionErrorAY, avgY));
		}

		fprintf(fp1, "%d \t %.2f %.2f\t %.2f %.2f \t %.2f %.2f \t %.2f %.2f \t", ReProjectionErrorAY.size(), miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);

		if (ReProjectionErrorX.size() > 0)
		{
			miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
			maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
			avgX = MeanArray(ReProjectionErrorX);
			stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
			miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
			maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
			avgY = MeanArray(ReProjectionErrorY);
			stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
		}
		fprintf(fp1, "%d \t %.2f %.2f\t %.2f %.2f \t %.2f %.2f \t %.2f %.2f \n", ReProjectionErrorY.size(), miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);

		if (ReProjectionErrorAX.size() + ReProjectionErrorX.size() < mySfMPara.nInliersThresh)
		{
			camI[ii].valid = false;
			sprintf(Fname, "%s/%d/PnP/KF_Inliers_%.4d.txt", Path, selectedCamId, vrfid[ii]); remove(Fname);
		}
	}
	fclose(fp1);

	sprintf(Fname, "%s/Intrinsic_%.4d.txt", Path, selectedCamId); fp = fopen(Fname, "w+");
	for (int ii = 0; ii < VCorpusInfo.nCameras; ii++)
	{
		CameraData *camI = VCorpusInfo.camera;
		if (!camI[ii].valid)
			continue;
		fprintf(fp, "%d %d %d %d %d ", vrfid[ii], camI[ii].LensModel, camI[ii].ShutterModel, camI[ii].width, camI[ii].height);
		for (int jj = 0; jj < 5; jj++)
			fprintf(fp, "%f ", camI[ii].intrinsic[jj]);
		if (camI[ii].LensModel == RADIAL_TANGENTIAL_PRISM)
			for (int jj = 0; jj < 7; jj++)
				fprintf(fp, "%f ", camI[ii].distortion[jj]);
		else
			for (int jj = 0; jj < 3; jj++)
				fprintf(fp, "%f ", camI[ii].distortion[jj]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/CamPose_%.4d.txt", Path, selectedCamId); fp = fopen(Fname, "w+");
	for (int ii = 0; ii < VCorpusInfo.nCameras; ii++)
	{
		CameraData *camI = VCorpusInfo.camera;
		if (!camI[ii].valid)
			continue;
		fprintf(fp, "%d ", vrfid[ii]);
		for (int jj = 0; jj < 6; jj++)
			fprintf(fp, "%.16f ", camI[ii].rt[jj]);
		if (camI[ii].ShutterModel == 1)
			for (int jj = 0; jj < 6; jj++)
				fprintf(fp, "%.16f ", camI[ii].wt[jj]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/%d/Video3DCorpus.xyz", Path, selectedCamId); fp = fopen(Fname, "w+");
	for (size_t ii = 0; ii < VCorpusInfo.xyz.size(); ii++)
		if (IsValid3D(VCorpusInfo.xyz[ii]))
			fprintf(fp, "%d %d %f %f %f\n", ii, VCorpusInfo.GlobalAnchor3DId[ii], VCorpusInfo.xyz[ii].x, VCorpusInfo.xyz[ii].y, VCorpusInfo.xyz[ii].z);
	fclose(fp);

	//vector<int> vCams; vCams.push_back(selectedCamId);
	//visualizationDriver(Path, vCams, startF, stopF, 1, true, false, false, false, false, startF, mySfMPara.ShutterModel);

	return 0;
}

int BuildCorpus(char *Path, int distortionCorrected, int ShutterModel, int fixIntrinsic, int fixDistortion, int fixPose, int fix3D, int fixSkew, int fixPrism, int nViewsPlus, int LossType)
{
	printLOG("Reading Corpus and camera info");
	char Fname[512];

	Corpus CorpusInfo;
	sprintf(Fname, "%s/BA_Camera_AllParams_after.txt", Path);
	if (!readBundleAdjustedNVMResults(Fname, CorpusInfo))
		return 1;

	int nviews = CorpusInfo.nCameras;
	for (int ii = 0; ii < nviews; ii++)
	{
		CorpusInfo.camera[ii].threshold = 5.0, CorpusInfo.camera[ii].nInlierThresh = 50, CorpusInfo.camera[ii];
		GetrtFromRT(CorpusInfo.camera[ii].rt, CorpusInfo.camera[ii].R, CorpusInfo.camera[ii].T);
		GetIntrinsicFromK(CorpusInfo.camera[ii]);
		AssembleP(CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].R, CorpusInfo.camera[ii].T, CorpusInfo.camera[ii].P);
		if (distortionCorrected == 1)
			for (int jj = 0; jj < 7; jj++)
				CorpusInfo.camera[ii].distortion[jj] = 0.0;
	}
	printLOG("...Done\n");

	vector<int>SharedCameraToBuildCorpus, SharedIntrinsicCameras;
	sprintf(Fname, "%s/CamerasWithFixedIntrinsic.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int camID;
		while (fscanf(fp, "%d ", &camID) != EOF)
			SharedIntrinsicCameras.push_back(camID);
		fclose(fp);
	}

	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
		SharedCameraToBuildCorpus.push_back(-1); //first visible camera is the reference camera to build the corpus

	int nDevices = 0;
	if (SharedIntrinsicCameras.size() > 0) //some shares
	{
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int camID, deviceID;
			while (fscanf(fp, "%d %d", &camID, &deviceID) != EOF)
			{
				nDevices = max(nDevices, deviceID);
				bool shared = false;
				for (size_t ii = 0; ii < SharedIntrinsicCameras.size() && !shared; ii++)
					if (SharedIntrinsicCameras[ii] == deviceID)
						shared = true;
				if (shared)
					SharedCameraToBuildCorpus[camID] = deviceID;
			}
			fclose(fp);
		}
	}

	//Setup lens and shutter Model
	int LensModel = RADIAL_TANGENTIAL_PRISM;
	vector<Point2i> CameraLensModel;
	sprintf(Fname, "%s/CameraLensModel.txt", Path); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int CameraGroup;
		while (fscanf(fp, "%d %d ", &CameraGroup, &LensModel) != EOF)
			CameraLensModel.push_back(Point2i(CameraGroup, LensModel));
		fclose(fp);
	}

	bool hasFishEyeLens = false;
	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
		CorpusInfo.camera[ii].LensModel = RADIAL_TANGENTIAL_PRISM;
	if (CameraLensModel.size() > 0)
	{
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int CorpusCamID, CameraGroup;
			while (fscanf(fp, "%d %d", &CorpusCamID, &CameraGroup) != EOF)
			{
				for (size_t ii = 0; ii < CameraLensModel.size(); ii++)
				{
					if (CameraLensModel[ii].x == CameraGroup)
					{
						CorpusInfo.camera[CorpusCamID].LensModel = CameraLensModel[ii].y;
						if (CorpusInfo.camera[CorpusCamID].LensModel == FISHEYE)
							hasFishEyeLens = true,
							CorpusInfo.camera[CorpusCamID].distortion[0] = 0.001, CorpusInfo.camera[CorpusCamID].distortion[1] = CorpusInfo.camera[CorpusCamID].width / 2, CorpusInfo.camera[CorpusCamID].distortion[2] = CorpusInfo.camera[CorpusCamID].height / 2;
						break;
					}
				}
			}
			fclose(fp);
		}
	}

	sprintf(Fname, "%s/InitDevicesIntrinsics.txt", Path); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int width, height, cid, lensType; double focal;
		vector<CameraData> InitDevicesIntrinsics(nDevices + 1);
		while (fscanf(fp, "%d %d %d %d %lf", &cid, &lensType, &width, &height, &focal) != EOF)
		{
			InitDevicesIntrinsics[cid].width = width, InitDevicesIntrinsics[cid].height = height;
			InitDevicesIntrinsics[cid].intrinsic[0] = focal, InitDevicesIntrinsics[cid].intrinsic[1] = focal;
			InitDevicesIntrinsics[cid].intrinsic[3] = width / 2, InitDevicesIntrinsics[cid].intrinsic[4] = height / 2;

			InitDevicesIntrinsics[cid].LensModel = lensType;
			if (lensType == RADIAL_TANGENTIAL_PRISM)
				for (int ii = 0; ii < 7; ii++)
					fscanf(fp, "%lf ", &InitDevicesIntrinsics[cid].distortion[ii]);
			else
				fscanf(fp, "%lf %lf %lf ", &InitDevicesIntrinsics[cid].distortion[0], &InitDevicesIntrinsics[cid].intrinsic[3], &InitDevicesIntrinsics[cid].intrinsic[4]);
		}
		fclose(fp);

		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int CorpusCamID, deviceID;
			while (fscanf(fp, "%d %d", &CorpusCamID, &deviceID) != EOF)
			{
				for (size_t ii = 0; ii < CameraLensModel.size(); ii++)
				{
					if (CameraLensModel[ii].x == deviceID)
					{
						if (CorpusInfo.camera[CorpusCamID].LensModel == RADIAL_TANGENTIAL_PRISM)
							for (int jj = 0; jj < 7; jj++)
								CorpusInfo.camera[CorpusCamID].distortion[jj] = InitDevicesIntrinsics[deviceID].distortion[jj];
						else
							for (int jj = 0; jj < 3; jj++)
								CorpusInfo.camera[CorpusCamID].distortion[jj] = InitDevicesIntrinsics[deviceID].distortion[jj];
					}
				}
			}
			fclose(fp);
		}
	}

	sprintf(Fname, "%s/ViewPM.txt", Path); fp = fopen(Fname, "r");
	int nviewsi, viewi, n3D = 0;
	while (fscanf(fp, "%d ", &nviewsi) != EOF)
	{
		for (int ii = 0; ii < nviewsi; ii++)
			fscanf(fp, "%d ", &viewi);
		n3D++;
	}
	fclose(fp);

	vector<int> cumulativePts;
	ReadCumulativePoints(Path, nviews, -1, cumulativePts);
	int totalPts = cumulativePts[nviews];

	vector<int>*PViewIdAll3D = new vector<int>[n3D];
	vector<int>*PuvIdAll3D = new vector<int>[n3D];

	printLOG("Reading Matching table....");
	sprintf(Fname, "%s/ViewPM.txt", Path); fp = fopen(Fname, "r");
	n3D = 0;
	while (fscanf(fp, "%d ", &nviewsi) != EOF)
	{
		PViewIdAll3D[n3D].reserve(nviewsi);
		for (int ii = 0; ii < nviewsi; ii++)
		{
			fscanf(fp, "%d ", &viewi);
			PViewIdAll3D[n3D].push_back(viewi);
		}
		n3D++;
	}
	fclose(fp);

	sprintf(Fname, "%s/IDPM.txt", Path); fp = fopen(Fname, "r");
	int np, pi;
	n3D = 0;
	while (fscanf(fp, "%d ", &np) != EOF)
	{
		PuvIdAll3D[n3D].reserve(np);
		for (int ii = 0; ii < np; ii++)
		{
			fscanf(fp, "%d ", &pi);
			PuvIdAll3D[n3D].push_back(pi);
		}
		n3D++;
	}
	fclose(fp);
	printLOG("...Done\n");

	//Read all sift points
	printLOG("Reading SIFT keys....");
	vector<SiftKeypoint> *AllKeys = new vector < SiftKeypoint >[nviews];
	vector<Point3i> *AllRGB = new vector < Point3i >[nviews];
	for (int ii = 0; ii < nviews; ii++)
	{
		sprintf(Fname, "%s/%.4d.kpts", Path, ii); ReadKPointsBinarySIFT(Fname, AllKeys[ii]);
		sprintf(Fname, "%s/%.4d.rgb", Path, ii); ReadRGBBinarySIFT(Fname, AllRGB[ii]);
	}
	printLOG("...Done\n");

	//Correct for distortion if needed
	if (distortionCorrected == 0)
	{
		distortionCorrected = 1;
		Point2d pt;
		for (int ii = 0; ii < nviews; ii++)
		{
			int npts = (int)AllKeys[ii].size();
			if (CorpusInfo.camera[ii].LensModel == RADIAL_TANGENTIAL_PRISM)
			{
				for (int jj = 0; jj < npts; jj++)
				{
					pt.x = AllKeys[ii][jj].x, pt.y = AllKeys[ii][jj].y;
					LensCorrectionPoint(&pt, CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].distortion);
					AllKeys[ii][jj].x = pt.x, AllKeys[ii][jj].y = pt.y;
				}
			}
			else
			{
				for (int jj = 0; jj < npts; jj++)
				{
					pt.x = AllKeys[ii][jj].x, pt.y = AllKeys[ii][jj].y;
					//FishEyeCorrectionPoint(&pt, CorpusInfo.camera[ii].distortion[0], CorpusInfo.camera[ii].distortion[1], CorpusInfo.camera[ii].distortion[2]);
					FishEyeCorrectionPoint(&pt, CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].distortion[0]);
					AllKeys[ii][jj].x = pt.x, AllKeys[ii][jj].y = pt.y;
				}
			}
		}
	}

	//Triangulate points from estimated camera poses
	printLOG("Triangulating the Corpus...");
	Point3d xyz;
	double *A = new double[6 * nviews * 2];
	double *B = new double[2 * nviews * 2];
	double *tPs = new double[12 * nviews * 2];
	bool *passed = new bool[nviews * 2];
	double *Ps = new double[12 * nviews * 2];

	vector<int>Inliers[1];  Inliers[0].reserve(nviews * 2);
	Point2d *match2Dpts = new Point2d[nviews * 2];
	double *matchScales = new double[nviews * 2];

	CorpusInfo.xyz.reserve(n3D);
	CorpusInfo.rgb.reserve(n3D);
	CorpusInfo.viewIdAll3D.reserve(n3D);
	CorpusInfo.pointIdAll3D.reserve(n3D);

	vector<int>viewIDs, pointIDs, orgId, threeDid;
	vector<Point2d> uvPer3D, uvperView;
	vector<double>scalePer3D, scalePerView;

	for (int ii = 0; ii < n3D; ii++)
	{
		CorpusInfo.viewIdAll3D.push_back(viewIDs), CorpusInfo.viewIdAll3D[ii].reserve(nviews);
		CorpusInfo.pointIdAll3D.push_back(pointIDs), CorpusInfo.pointIdAll3D[ii].reserve(nviews);
		CorpusInfo.uvAll3D.push_back(uvPer3D), CorpusInfo.uvAll3D[ii].reserve(nviews);
		CorpusInfo.scaleAll3D.push_back(scalePer3D), CorpusInfo.scaleAll3D[ii].reserve(nviews);
	}

	printLOG("Start: \n");
	double ProThresh = 0.99, PercentInlier = 0.25;
	int goodNDplus = 0, iterMax = (int)(log(1.0 - ProThresh) / log(1.0 - pow(PercentInlier, 2)) + 0.5); //log(1-eps) / log(1 - (inlier%)^min_pts_requires)
	bool printout = 0;
	double start = omp_get_wtime();
	for (int jj = 0; jj < n3D; jj++)
	{
		if (jj % 1000 == 0)
			printLOG("@\r# %.2f%% (%.2fs) Triangualating corpus..", 100.0*jj / n3D, omp_get_wtime() - start);
		int nviewsi = (int)PViewIdAll3D[jj].size();
		if (nviewsi >= nViewsPlus)
		{
			Inliers[0].clear();
			for (int ii = 0; ii < nviewsi; ii++)
			{
				viewi = PViewIdAll3D[jj][ii], pi = PuvIdAll3D[jj][ii];
				if (ShutterModel == 0)
				{
					for (int kk = 0; kk < 12; kk++)
						Ps[12 * ii + kk] = CorpusInfo.camera[viewi].P[kk];
				}
				else
				{
					Point2d pt = Point2d(AllKeys[viewi][pi].x, AllKeys[viewi][pi].y);
					AssembleP_RS(pt, CorpusInfo.camera[viewi], Ps + 12 * ii);
				}

				match2Dpts[ii].x = AllKeys[viewi][pi].x, match2Dpts[ii].y = AllKeys[viewi][pi].y;
				matchScales[ii] = AllKeys[viewi][pi].s;
			}
		}
		else
			continue;
		/*if (printout)
		{
		FILE *fp = fopen("C:/temp/corres.txt", "w+");
		for (int ii = 0; ii < nviewsi; ii++)
		fprintf(fp, "%.1f %.1f\n", match2Dpts[ii].x, match2Dpts[ii].y);
		for (int ii = 0; ii < nviewsi; ii++)
		{
		for (int jj = 0; jj < 12; jj++)
		fprintf(fp, "%.4f ", Ps[jj + ii * 12]);
		fprintf(fp, "\n");
		}
		fclose(fp);
		}*/

		NviewTriangulationRANSAC(match2Dpts, Ps, &xyz, passed, Inliers, nviewsi, 1, 2, iterMax, PercentInlier, CorpusInfo.camera[0].threshold, A, B, tPs);
		if (passed[0])
		{
			int ninlier = 0;
			for (int ii = 0; ii < Inliers[0].size(); ii++)
				if (Inliers[0][ii])
					ninlier++;
			if (ninlier < nViewsPlus)
				continue; //Corpus needs nViewsPlus+ points!
			CorpusInfo.xyz.push_back(xyz);

			for (int ii = 0; ii < nviewsi; ii++)
			{
				if (Inliers[0][ii])
				{
					viewi = PViewIdAll3D[jj][ii], pi = PuvIdAll3D[jj][ii];

					CorpusInfo.viewIdAll3D[goodNDplus].push_back(viewi);
					CorpusInfo.pointIdAll3D[goodNDplus].push_back(pi);
					CorpusInfo.uvAll3D[goodNDplus].push_back((match2Dpts[ii]));//store corrected 2d points into corpus
					CorpusInfo.scaleAll3D[goodNDplus].push_back((matchScales[ii]));//store corrected 2d points into corpus
				}
			}
			goodNDplus++;
		}
	}
	printLOG("@\r# %.2f%% (%.2fs) \n", 100.0, omp_get_wtime() - start);
	printLOG("Found %d (%d+) points.\n\n", goodNDplus, nViewsPlus);

	printLOG("Runing BA on the triangulated points...");
	//Let's reoptimize verything
	int fix1stCamPose = 1;
	if (fixIntrinsic == 0 || fixDistortion == 0)
	{
		distortionCorrected = 0;
		for (int jj = 0; jj < (int)CorpusInfo.xyz.size(); jj++)
		{
			for (int ii = 0; ii < (int)CorpusInfo.uvAll3D[jj].size(); ii++)
			{
				int viewID = CorpusInfo.viewIdAll3D[jj][ii];
				LensDistortionPoint(&CorpusInfo.uvAll3D[jj][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
			}
		}
	}

	GenericBundleAdjustment(Path, CorpusInfo.camera, CorpusInfo.xyz, CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D, SharedCameraToBuildCorpus, nviews,
		fixIntrinsic, fixDistortion, fixPose, fix1stCamPose, false, fix3D, fixSkew, fixPrism, distortionCorrected, nViewsPlus, LossType, false, false, true);

	//Now, can undistort points again
	if (fixIntrinsic == 0 || fixDistortion == 0)
	{
		distortionCorrected = 1;
		for (int jj = 0; jj < (int)CorpusInfo.xyz.size(); jj++)
		{
			for (int ii = 0; ii < (int)CorpusInfo.uvAll3D[jj].size(); ii++)
			{
				int viewID = CorpusInfo.viewIdAll3D[jj][ii];
				LensCorrectionPoint(&CorpusInfo.uvAll3D[jj][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
			}
		}
	}
	printLOG("\n");

	SaveAvgIntrinsicResults(Path, CorpusInfo.camera, SharedCameraToBuildCorpus);

	sprintf(Fname, "%s/BA_Camera_AllParams_after.txt", Path);
	ReSaveBundleAdjustedNVMResults(Fname, CorpusInfo);

	//Get the color info
	Point3i rgb;
	CorpusInfo.rgb.reserve(goodNDplus);
	for (int kk = 0; kk < goodNDplus; kk++)
	{
		viewi = CorpusInfo.viewIdAll3D[kk][0];
		pi = CorpusInfo.pointIdAll3D[kk][0];
		rgb = AllRGB[viewi][pi];
		CorpusInfo.rgb.push_back(rgb);
	}
	vector<int> AvailViews; AvailViews.reserve(nviews);
	for (int ii = 0; ii < nviews; ii++)
		AvailViews.push_back(ii);
	SaveCurrentSfmGL(Path, CorpusInfo.camera, AvailViews, CorpusInfo.xyz, CorpusInfo.rgb); // OK for visualization

																						   //Prune corpus for bad points
	printLOG("Remove not good points ...");
	vector<int> *notGood = new vector<int>[goodNDplus];
	sprintf(Fname, "%s/Good.txt", Path);	fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		for (int jj = 0; jj < goodNDplus; jj++)
		{
			int pid, ii;
			fscanf(fp, "%d %d", &pid, &ii);
			while (ii != -1)
			{
				notGood[jj].push_back(ii);
				fscanf(fp, "%d ", &ii);
			}
		}
		fclose(fp);
	}

	for (int jj = 0; jj < goodNDplus; jj++)
	{
		for (int ii = (int)notGood[jj].size() - 1; ii >= 0; ii--)//start from last to first when deleting vector stack of data
		{
			int viewID = notGood[jj][ii];
			if (viewID > CorpusInfo.viewIdAll3D[jj].size() - 1)
				printLOG("%d\n", jj);
			else
			{
				CorpusInfo.viewIdAll3D[jj].erase(CorpusInfo.viewIdAll3D[jj].begin() + viewID);
				CorpusInfo.pointIdAll3D[jj].erase(CorpusInfo.pointIdAll3D[jj].begin() + viewID);
				CorpusInfo.uvAll3D[jj].erase(CorpusInfo.uvAll3D[jj].begin() + viewID);
				CorpusInfo.scaleAll3D[jj].erase(CorpusInfo.scaleAll3D[jj].begin() + viewID);
			}
		}
	}
	delete[]notGood;
	printLOG("Done!\n");


	//And generate 3D id, uv, sift id for all views
	printLOG("and generate Corpus visibility info....");
	vector<int> *twoDIdAllViews = new vector<int>[nviews];
	CorpusInfo.threeDIdAllViews = new vector<int>[nviews];
	CorpusInfo.uvAllViews = new vector<Point2d>[nviews];
	CorpusInfo.scaleAllViews = new vector<double>[nviews];

	for (int ii = 0; ii < nviews; ii++)
	{
		CorpusInfo.threeDIdAllViews[ii].reserve(10000);
		CorpusInfo.uvAllViews[ii].reserve(10000);
		CorpusInfo.scaleAllViews[ii].reserve(10000);
		twoDIdAllViews[ii].reserve(10000);
	}

	double scale;
	Point2d uv;
	for (int jj = 0; jj < goodNDplus; jj++)
	{
		for (int ii = 0; ii < (int)CorpusInfo.viewIdAll3D[jj].size(); ii++)
		{
			viewi = CorpusInfo.viewIdAll3D[jj][ii], pi = CorpusInfo.pointIdAll3D[jj][ii], uv = CorpusInfo.uvAll3D[jj][ii], scale = CorpusInfo.scaleAll3D[jj][ii];

			CorpusInfo.threeDIdAllViews[viewi].push_back(jj);
			CorpusInfo.uvAllViews[viewi].push_back(uv);
			CorpusInfo.scaleAllViews[viewi].push_back(scale);
			twoDIdAllViews[viewi].push_back(pi);
		}
	}
	printLOG("Done!\n");

	//Get sift matrix for all views
	printLOG("Prune SIFT descriptors for only Corpus points....");
	int nSift, totalSift = 0, maxSift = 0;
	CorpusInfo.IDCumView.reserve(nviews + 1);
	for (int ii = 0; ii < nviews; ii++)
	{
		CorpusInfo.IDCumView.push_back(totalSift);
		nSift = (int)twoDIdAllViews[ii].size();
		if (nSift > maxSift)
			maxSift = nSift;
		totalSift += nSift;
	}
	CorpusInfo.IDCumView.push_back(totalSift);

	/*CorpusInfo.SiftDesc.create(totalSift, SIFTBINS, CV_32F);
	vector<float> desc; desc.reserve(maxSift*SIFTBINS);
	for (int ii = 0; ii < nviews; ii++)
	{
	desc.clear();
	sprintf(Fname, "%s%.4d.desc", Path, ii), ReadDescriptorBinarySIFT(Fname, desc);

	int curPid = CorpusInfo.IDCumView[ii], nSift = twoDIdAllViews[ii].size();
	for (int j = 0; j < nSift; ++j)
	{
	int pid = twoDIdAllViews[ii][j];
	for (int i = 0; i < SIFTBINS; i++)
	CorpusInfo.SiftDesc.at<float>(curPid + j, i) = desc[pid*SIFTBINS + i];
	}
	}*/

	FeatureDesc desci;
	vector<KeyPoint> keys;
	//vector<float> desc; desc.reserve(maxSift*SIFTBINS);
	CorpusInfo.DescAllViews = new vector<FeatureDesc>[nviews];
	for (int ii = 0; ii < nviews; ii++)
	{
		int nSift = (int)CorpusInfo.uvAllViews[ii].size();

		//desc.clear();
		//sprintf(Fname, "%s%.4d.desc", Path, ii), ReadDescriptorBinarySIFT(Fname, desc);

		keys.clear();  cv::Mat desc;
		sprintf(Fname, "%s%.4d.sift", Path, ii), readVisualSFMSiftGPU(Fname, keys, desc);
		for (int j = 0; j < nSift; ++j)
		{
			int pid = twoDIdAllViews[ii][j];
			//for (int i = 0; i < SIFTBINS; i++)
			//desci.desc[ii] = desc[pid*SIFTBINS + i];
			uchar *ptr = desc.ptr<uchar>(j);
			for (int i = 0; i < SIFTBINS; i++)
				desci.desc[ii] = ptr[i];

			CorpusInfo.DescAllViews[ii].push_back(desci);
		}
	}

	printLOG("...Done\n\n");

	///****NOTE: 2d points in Corpus are corrected***///
	SaveCorpusInfo(Path, CorpusInfo);

	delete[]PViewIdAll3D, delete[]PuvIdAll3D, delete[]AllKeys, delete[]twoDIdAllViews;
	delete[]A, delete[]B, delete[]tPs, delete[]passed, delete[]Ps, delete[]match2Dpts, delete[]matchScales;
	return 0;
}
int BuildCorpusVisualSfm(char *Path, int distortionCorrected, int ShutterModel, int fixSkew, int  fixPrism, int nViewsPlus, int LossType)
{
	printLOG("Reading Corpus and camera info");
	char Fname[512];

	Corpus CorpusInfo;
	sprintf(Fname, "%s/BA_Camera_AllParams_after.txt", Path);
	if (!readBundleAdjustedNVMResults(Fname, CorpusInfo))
		return 1;

	CorpusInfo.camera[1060];
	int nviews = CorpusInfo.nCameras;
	for (int ii = 0; ii < nviews; ii++)
	{
		CorpusInfo.camera[ii].viewID = ii;
		CorpusInfo.camera[ii].threshold = 5.0, CorpusInfo.camera[ii].nInlierThresh = 50, CorpusInfo.camera[ii];
		GetrtFromRT(CorpusInfo.camera[ii].rt, CorpusInfo.camera[ii].R, CorpusInfo.camera[ii].T);
		GetIntrinsicFromK(CorpusInfo.camera[ii]);
		AssembleP(CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].R, CorpusInfo.camera[ii].T, CorpusInfo.camera[ii].P);
		if (distortionCorrected == 1)
			for (int jj = 0; jj < 7; jj++)
				CorpusInfo.camera[ii].distortion[jj] = 0.0;
	}

	vector<int>SharedCameraToBuildCorpus, SharedIntrinsicCameras;
	sprintf(Fname, "%s/CamerasWithFixedIntrinsic.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int camID;
		while (fscanf(fp, "%d ", &camID) != EOF)
			SharedIntrinsicCameras.push_back(camID);
		fclose(fp);
	}

	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
		SharedCameraToBuildCorpus.push_back(-1); //first visible camera is the reference camera to build the corpus

	int nDevices = 0;
	if (SharedIntrinsicCameras.size() > 0) //some shares
	{
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int camID, deviceID;
			while (fscanf(fp, "%d %d", &camID, &deviceID) != EOF)
			{
				nDevices = max(nDevices, deviceID);
				bool shared = false;
				for (size_t ii = 0; ii < SharedIntrinsicCameras.size() && !shared; ii++)
					if (SharedIntrinsicCameras[ii] == deviceID)
						shared = true;
				if (shared)
					SharedCameraToBuildCorpus[camID] = deviceID;
			}
			fclose(fp);
		}
	}

	//Setup lens and shutter Model
	int LensModel = RADIAL_TANGENTIAL_PRISM;
	vector<Point2i> CameraLensModel;
	sprintf(Fname, "%s/CameraLensModel.txt", Path); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int CameraGroup;
		while (fscanf(fp, "%d %d ", &CameraGroup, &LensModel) != EOF)
			CameraLensModel.push_back(Point2i(CameraGroup, LensModel));
		fclose(fp);
	}

	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
		CorpusInfo.camera[ii].LensModel = RADIAL_TANGENTIAL_PRISM;
	if (CameraLensModel.size() > 0)
	{
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int CorpusCamID, CameraGroup;
			while (fscanf(fp, "%d %d", &CorpusCamID, &CameraGroup) != EOF)
			{
				for (size_t ii = 0; ii < CameraLensModel.size(); ii++)
				{
					if (CameraLensModel[ii].x == CameraGroup)
					{
						CorpusInfo.camera[CorpusCamID].LensModel = CameraLensModel[ii].y;
						if (CorpusInfo.camera[CorpusCamID].LensModel == FISHEYE)
							CorpusInfo.camera[CorpusCamID].distortion[0] = 0.001, CorpusInfo.camera[CorpusCamID].distortion[1] = CorpusInfo.camera[CorpusCamID].width / 2, CorpusInfo.camera[CorpusCamID].distortion[2] = CorpusInfo.camera[CorpusCamID].height / 2;
						break;
					}
				}
			}
			fclose(fp);
		}
	}

	bool obtainedInitialIntrinisc = false;
	int cid, lensType, shutterType, width, height;
	double fx, fy, skew, u0, v0, r0, r1, r2, t0, t1, p0, p1, omega, DistCtrX, DistCtrY;
	vector<CameraData> InitDevicesIntrinsics(nDevices + 1);

	sprintf(Fname, "%s/AvgDevicesIntrinsics.txt", Path);
	if (IsFileExist(Fname))
	{
		fp = fopen(Fname, "r");
		while (fscanf(fp, "%s %d %d %d %d %lf %lf %lf %lf %lf ", Fname, &lensType, &shutterType, &width, &height, &fx, &fy, &skew, &u0, &v0) != EOF)
		{
			string  filename = string(Fname);

			std::size_t posDot = filename.find(".");
			filename.erase(posDot, 4);
			const char * str = filename.c_str();
			int id = atoi(str);

			InitDevicesIntrinsics[id].LensModel = lensType, InitDevicesIntrinsics[id].ShutterModel = shutterType, InitDevicesIntrinsics[id].width = width, InitDevicesIntrinsics[id].height = height;
			InitDevicesIntrinsics[id].K[0] = fx, InitDevicesIntrinsics[id].K[1] = skew, InitDevicesIntrinsics[id].K[2] = u0,
				InitDevicesIntrinsics[id].K[3] = 0.0, InitDevicesIntrinsics[id].K[4] = fy, InitDevicesIntrinsics[id].K[5] = v0,
				InitDevicesIntrinsics[id].K[6] = 0.0, InitDevicesIntrinsics[id].K[7] = 0.0, InitDevicesIntrinsics[id].K[8] = 1.0;

			GetIntrinsicFromK(InitDevicesIntrinsics[id]);
			mat_invert(InitDevicesIntrinsics[id].K, InitDevicesIntrinsics[id].invK);
			if (lensType == RADIAL_TANGENTIAL_PRISM)
			{
				fscanf(fp, " %lf %lf %lf %lf %lf %lf %lf ", &r0, &r1, &r2, &t0, &t1, &p0, &p1);
				InitDevicesIntrinsics[id].distortion[0] = r0, InitDevicesIntrinsics[id].distortion[1] = r1, InitDevicesIntrinsics[id].distortion[2] = r2;
				InitDevicesIntrinsics[id].distortion[3] = t0, InitDevicesIntrinsics[id].distortion[4] = t1;
				InitDevicesIntrinsics[id].distortion[5] = p0, InitDevicesIntrinsics[id].distortion[6] = p1;
			}
			else
			{
				fscanf(fp, " %lf %lf %lf ", &omega, &DistCtrX, &DistCtrY);
				InitDevicesIntrinsics[id].distortion[0] = omega, InitDevicesIntrinsics[id].distortion[1] = DistCtrX, InitDevicesIntrinsics[id].distortion[2] = DistCtrY;
				InitDevicesIntrinsics[id].distortion[3] = 0, InitDevicesIntrinsics[id].distortion[4] = 0;
				InitDevicesIntrinsics[id].distortion[5] = 0, InitDevicesIntrinsics[id].distortion[6] = 0;
			}
		}
		fclose(fp);
		obtainedInitialIntrinisc = true;
	}
	else
	{
		sprintf(Fname, "%s/InitDevicesIntrinsics.txt", Path);	fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int width, height, cid, lensType; double focal;
			vector<CameraData> InitDevicesIntrinsics(nDevices + 1);
			while (fscanf(fp, "%d %d %d %d %lf", &cid, &lensType, &width, &height, &focal) != EOF)
			{
				InitDevicesIntrinsics[cid].width = width, InitDevicesIntrinsics[cid].height = height;
				InitDevicesIntrinsics[cid].intrinsic[0] = focal, InitDevicesIntrinsics[cid].intrinsic[1] = focal;
				InitDevicesIntrinsics[cid].intrinsic[3] = width / 2, InitDevicesIntrinsics[cid].intrinsic[4] = height / 2;

				InitDevicesIntrinsics[cid].LensModel = lensType;
				if (lensType == RADIAL_TANGENTIAL_PRISM)
					for (int ii = 0; ii < 7; ii++)
						fscanf(fp, "%lf ", &InitDevicesIntrinsics[cid].distortion[ii]);
				else
					fscanf(fp, "%lf %lf %lf ", &InitDevicesIntrinsics[cid].distortion[0], &InitDevicesIntrinsics[cid].intrinsic[3], &InitDevicesIntrinsics[cid].intrinsic[4]);
			}
			fclose(fp);

			obtainedInitialIntrinisc = true;
		}
	}

	if (obtainedInitialIntrinisc)
	{
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int CorpusCamID, deviceID;
			while (fscanf(fp, "%d %d", &CorpusCamID, &deviceID) != EOF)
			{
				for (size_t ii = 0; ii < CameraLensModel.size(); ii++)
				{
					if (CameraLensModel[ii].x == deviceID)
					{
						if (CorpusInfo.camera[CorpusCamID].LensModel == RADIAL_TANGENTIAL_PRISM)
							for (int jj = 0; jj < 7; jj++)
								CorpusInfo.camera[CorpusCamID].distortion[jj] = InitDevicesIntrinsics[deviceID].distortion[jj];
						else
							for (int jj = 0; jj < 3; jj++)
								CorpusInfo.camera[CorpusCamID].distortion[jj] = InitDevicesIntrinsics[deviceID].distortion[jj];
					}
				}
			}
			fclose(fp);
		}
	}

	sprintf(Fname, "%s/ViewPM.txt", Path); fp = fopen(Fname, "r");
	int nviewsi, viewi, np, pi, n3D = 0;
	while (fscanf(fp, "%d ", &nviewsi) != EOF)
	{
		for (int ii = 0; ii < nviewsi; ii++)
			fscanf(fp, "%d ", &viewi);
		n3D++;
	}
	fclose(fp);

	vector<int> cumulativePts;
	ReadCumulativePointsVisualSfm(Path, nviews, cumulativePts);
	int totalPts = cumulativePts[nviews];

	vector<int>*PViewIdAll3D = new vector<int>[n3D];
	vector<int>*PuvIdAll3D = new vector<int>[n3D];

	printLOG("\nReading Matching table....");
	sprintf(Fname, "%s/View_ID_PM.txt", Path); fp = fopen(Fname, "r");
	n3D = 0;
	while (fscanf(fp, "%d ", &nviewsi) != EOF)
	{
		PViewIdAll3D[n3D].reserve(nviewsi);
		PuvIdAll3D[n3D].reserve(nviewsi);
		for (int ii = 0; ii < nviewsi; ii++)
		{
			fscanf(fp, "%d %d ", &viewi, &pi);
			PViewIdAll3D[n3D].push_back(viewi);
			PuvIdAll3D[n3D].push_back(pi);
		}
		n3D++;
	}
	fclose(fp);
	printLOG("...Done\n");

	//Read all sift points
	printLOG("Reading SIFT keys....");
	vector<SiftKeypoint> *AllKeys = new vector < SiftKeypoint >[nviews];
	Mat *AllDesc = new Mat[nviews];
	vector<Point3i> *AllRGB = new vector < Point3i >[nviews];
	Mat cvImg;
	for (int ii = 0; ii < nviews; ii++)
	{
		sprintf(Fname, "%s/%.4d.sift", Path, ii); readVisualSFMSiftGPU(Fname, AllKeys[ii], AllDesc[ii]);// ReadKPointsBinarySIFT(Fname, AllKeys[ii]);

		sprintf(Fname, "%s/%.4d.rgb", Path, ii);
		if (!ReadRGBBinarySIFT(Fname, AllRGB[ii]))
		{
			sprintf(Fname, "%s/%.4d.jpg", Path, ii);
			if (IsFileExist(Fname) == 0)
				sprintf(Fname, "%s/%.4d.png", Path, ii);
			cvImg = imread(Fname, IMREAD_COLOR);

			int nkeys = (int)AllKeys[ii].size();
			AllRGB[ii].reserve(nkeys);
			for (int kk = 0; kk < nkeys; kk++)
			{
				int x = (int)AllKeys[ii][kk].x, y = (int)AllKeys[ii][kk].y;
				int id = x + y * cvImg.cols;
				Point3i rgb;
				rgb.z = cvImg.data[3 * id + 0];//b
				rgb.y = cvImg.data[3 * id + 1];//g
				rgb.x = cvImg.data[3 * id + 2];//r
				AllRGB[ii].push_back(rgb);
			}

			sprintf(Fname, "%s/%.4d.rgb", Path, ii); WriteRGBBinarySIFT(Fname, AllRGB[ii]);
		}
	}
	printLOG("...Done\n");

	//Correct for distortion if needed
	if (distortionCorrected == 0)
	{
		distortionCorrected = 1;
		Point2d pt;
		for (int ii = 0; ii < nviews; ii++)
		{
			int npts = (int)AllKeys[ii].size();
			if (CorpusInfo.camera[ii].LensModel == RADIAL_TANGENTIAL_PRISM)
			{
				for (int jj = 0; jj < npts; jj++)
				{
					pt.x = AllKeys[ii][jj].x, pt.y = AllKeys[ii][jj].y;
					LensCorrectionPoint(&pt, CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].distortion);
					AllKeys[ii][jj].x = pt.x, AllKeys[ii][jj].y = pt.y;
				}
			}
			else
			{
				for (int jj = 0; jj < npts; jj++)
				{
					pt.x = AllKeys[ii][jj].x, pt.y = AllKeys[ii][jj].y;
					//FishEyeCorrectionPoint(&pt, CorpusInfo.camera[ii].distortion[0], CorpusInfo.camera[ii].distortion[1], CorpusInfo.camera[ii].distortion[2]);
					FishEyeCorrectionPoint(&pt, CorpusInfo.camera[ii].K, CorpusInfo.camera[ii].distortion[0]);
					AllKeys[ii][jj].x = pt.x, AllKeys[ii][jj].y = pt.y;
				}
			}
		}
	}

	//Triangulate points from estimated camera poses
	printLOG("Triangulating the Corpus...");
	Point3d xyz;
	double *A = new double[6 * nviews * 2];
	double *B = new double[2 * nviews * 2];
	double *tPs = new double[12 * nviews * 2];
	bool *passed = new bool[nviews * 2];
	double *Ps = new double[12 * nviews * 2];

	vector<int>Inliers[1];  Inliers[0].reserve(nviews * 2);
	Point2d *match2Dpts = new Point2d[nviews * 2];
	double *matchScales = new double[nviews * 2];

	CorpusInfo.xyz.reserve(n3D);
	CorpusInfo.rgb.reserve(n3D);
	CorpusInfo.viewIdAll3D.reserve(n3D);
	CorpusInfo.pointIdAll3D.reserve(n3D);

	vector<int>viewIDs, pointIDs, orgId, threeDid;
	vector<Point2d> uvPer3D, uvperView;
	vector<double>scalePer3D, scalePerView;

	for (int ii = 0; ii < n3D; ii++)
	{
		CorpusInfo.viewIdAll3D.push_back(viewIDs), CorpusInfo.viewIdAll3D[ii].reserve(nviews);
		CorpusInfo.pointIdAll3D.push_back(pointIDs), CorpusInfo.pointIdAll3D[ii].reserve(nviews);
		CorpusInfo.uvAll3D.push_back(uvPer3D), CorpusInfo.uvAll3D[ii].reserve(nviews);
		CorpusInfo.scaleAll3D.push_back(scalePer3D), CorpusInfo.scaleAll3D[ii].reserve(nviews);
	}

	printLOG("Start: \n");
	double ProThresh = 0.99, PercentInlier = 0.5;
	int goodNDplus = 0, iterMax = (int)(log(1.0 - ProThresh) / log(1.0 - pow(PercentInlier, 2)) + 0.5); //log(1-eps) / log(1 - (inlier%)^min_pts_requires)
	bool printout = 0;
	double start = omp_get_wtime();
	for (int jj = 0; jj < n3D; jj++)
	{
		if (jj % 1000 == 0)
			printLOG("@\r# %.2f%% (%.2fs) Triangualating corpus..", 100.0*jj / n3D, omp_get_wtime() - start);
		int nviewsi = (int)PViewIdAll3D[jj].size();
		if (nviewsi >= nViewsPlus)
		{
			Inliers[0].clear();
			for (int ii = 0; ii < nviewsi; ii++)
			{
				viewi = PViewIdAll3D[jj][ii]; pi = PuvIdAll3D[jj][ii];
				if (ShutterModel == 0)
					for (int kk = 0; kk < 12; kk++)
						Ps[12 * ii + kk] = CorpusInfo.camera[viewi].P[kk];
				else
				{
					double *wt = CorpusInfo.camera[viewi].wt;
					double *intrinsic = CorpusInfo.camera[viewi].intrinsic;
					double *R_global = CorpusInfo.camera[viewi].R;
					double *T_global = CorpusInfo.camera[viewi].T;
					double ycn = (AllKeys[viewi][pi].y - intrinsic[4]) / intrinsic[1];

					double wx = ycn * wt[0], wy = ycn * wt[1], wz = ycn * wt[2];
					double wx2 = wx * wx, wy2 = wy * wy, wz2 = wz * wz, wxz = wx * wz, wxy = wx * wy, wyz = wy * wz;
					double denum = 1.0 + wx2 + wy2 + wz2;

					double Rw[9] = { 1.0 + wx2 - wy2 - wz2, 2.0 * wxy - 2.0 * wz, 2.0 * wy + 2.0 * wxz,
						2.0 * wz + 2.0 * wxy, 1.0 - wx2 + wy2 - wz2, 2.0 * wyz - 2.0 * wx,
						2.0 * wxz - 2.0 * wy, 2.0 * wx + 2.0 * wyz, 1.0 - wx2 - wy2 + wz2 };

					for (int jj = 0; jj < 9; jj++)
						Rw[jj] = Rw[jj] / denum;

					double R[9];  mat_mul(Rw, R_global, R, 3, 3, 3);
					double T[3] = { T_global[0] + ycn * wt[3], T_global[1] + ycn * wt[4], T_global[2] + ycn * wt[5] };

					AssembleP(CorpusInfo.camera[viewi].K, R, T, Ps + 12 * ii);
				}

				match2Dpts[ii].x = AllKeys[viewi][pi].x, match2Dpts[ii].y = AllKeys[viewi][pi].y;
				matchScales[ii] = AllKeys[viewi][pi].s;
			}
		}
		else
			continue;

		/*if (printout)
		{
		FILE *fp = fopen("C:/temp/corres.txt", "w+");
		for (int ii = 0; ii < nviewsi; ii++)
		fprintf(fp, "%.1f %.1f\n", match2Dpts[ii].x, match2Dpts[ii].y);
		for (int ii = 0; ii < nviewsi; ii++)
		{
		for (int jj = 0; jj < 12; jj++)
		fprintf(fp, "%.4f ", Ps[jj + ii * 12]);
		fprintf(fp, "\n");
		}
		fclose(fp);
		}*/

		NviewTriangulationRANSAC(match2Dpts, Ps, &xyz, passed, Inliers, nviewsi, 1, 2, iterMax, PercentInlier, CorpusInfo.camera[0].threshold / 2.0, A, B, tPs);

		bool breakflag = false;
		if (passed[0])
		{
			int ninlier = 0;
			for (int ii = 0; ii < Inliers[0].size(); ii++)
				if (Inliers[0][ii])
					ninlier++;
			if (ninlier < nViewsPlus)
				continue; //Corpus needs nViewsPlus+ points!
			CorpusInfo.xyz.push_back(xyz);

			for (int ii = 0; ii < nviewsi; ii++)
			{
				if (Inliers[0][ii])
				{
					viewi = PViewIdAll3D[jj][ii], pi = PuvIdAll3D[jj][ii];

					CorpusInfo.viewIdAll3D[goodNDplus].push_back(viewi);
					CorpusInfo.pointIdAll3D[goodNDplus].push_back(pi);
					CorpusInfo.uvAll3D[goodNDplus].push_back((match2Dpts[ii]));//store corrected 2d points into corpus
					CorpusInfo.scaleAll3D[goodNDplus].push_back((matchScales[ii]));//store corrected 2d points into corpus
				}
			}
			goodNDplus++;
		}
	}
	printLOG("@\r# %.2f%% (%.2fs) \n", 100.0, omp_get_wtime() - start);
	printLOG("Found %d (%d+) points.\n\n", goodNDplus, nViewsPlus);

	//SaveCorpusInfo(Path, CorpusInfo, false, false);//caching:
	//ReadCorpusInfo(Path, CorpusInfo, false, true);
	//for (int ii = 0; ii < nviews; ii++)
	//CorpusInfo.camera[ii].valid = true, CorpusInfo.camera[ii].threshold = 5.0;

	//Let's reoptimize verything
	printLOG("Runing BA on the triangulated points...");
	int fixIntrinsic = 0, fixDistortion = 0, fixPose = 0, fix1stCamPose = 1, fix3D = 0;
	if (fixIntrinsic == 0 || fixDistortion == 0) //Get back the distorted points so that the BA can correctly restart
	{
		distortionCorrected = 0;
		for (int jj = 0; jj < (int)CorpusInfo.xyz.size(); jj++)
		{
			for (int ii = 0; ii < (int)CorpusInfo.uvAll3D[jj].size(); ii++)
			{
				int viewID = CorpusInfo.viewIdAll3D[jj][ii];
				LensDistortionPoint(&CorpusInfo.uvAll3D[jj][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
			}
		}
	}

	GenericBundleAdjustment(Path, CorpusInfo.camera, CorpusInfo.xyz, CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D,
		SharedCameraToBuildCorpus, nviews, fixIntrinsic, fixDistortion, fixPose, fix1stCamPose, false, fix3D, fixSkew, fixPrism, distortionCorrected, nViewsPlus, LossType, false, false, false);

	//Now, can undistort points again
	if (fixIntrinsic == 0 || fixDistortion == 0)
	{
		distortionCorrected = 1;
		for (int jj = 0; jj < (int)CorpusInfo.xyz.size(); jj++)
		{
			for (int ii = 0; ii < (int)CorpusInfo.uvAll3D[jj].size(); ii++)
			{
				int viewID = CorpusInfo.viewIdAll3D[jj][ii];
				GetKFromIntrinsic(CorpusInfo.camera[viewID]);
				LensCorrectionPoint(&CorpusInfo.uvAll3D[jj][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
			}
		}

		for (int viewID = 0; viewID < CorpusInfo.nCameras; viewID++)
		{
			for (int ii = 0; ii < (int)CorpusInfo.uvAllViews[viewID].size(); ii++)
			{
				GetKFromIntrinsic(CorpusInfo.camera[viewID]);
				if (CorpusInfo.camera[viewID].LensModel == FISHEYE)
					FishEyeCorrectionPoint(&CorpusInfo.uvAllViews[viewID][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion[0]);
				else
					LensCorrectionPoint(&CorpusInfo.uvAllViews[viewID][ii], CorpusInfo.camera[viewID].K, CorpusInfo.camera[viewID].distortion);
			}
		}
	}
	printLOG("\n");

	if (SharedCameraToBuildCorpus.size() > 0)
	{
		SharedCameraToBuildCorpus.clear();
		for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
			SharedCameraToBuildCorpus.push_back(-1); //first visible camera is the reference camera to build the corpus
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); FILE *fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int camID, group;
			while (fscanf(fp, "%d %d", &camID, &group) != EOF)
				SharedCameraToBuildCorpus[camID] = group;
			fclose(fp);
		}
		SaveAvgIntrinsicResults(Path, CorpusInfo.camera, SharedCameraToBuildCorpus);
	}

	sprintf(Fname, "%s/BA_Camera_AllParams_after.txt", Path);
	ReSaveBundleAdjustedNVMResults(Fname, CorpusInfo);

	//Get the color info
	Point3i rgb;
	CorpusInfo.rgb.reserve(goodNDplus);
	for (int kk = 0; kk < goodNDplus; kk++)
	{
		viewi = CorpusInfo.viewIdAll3D[kk][0];
		pi = CorpusInfo.pointIdAll3D[kk][0];
		rgb = AllRGB[viewi][pi];
		CorpusInfo.rgb.push_back(rgb);
	}
	vector<int> AvailViews; AvailViews.reserve(nviews);
	for (int ii = 0; ii < nviews; ii++)
		AvailViews.push_back(ii);
	SaveCurrentSfmGL(Path, CorpusInfo.camera, AvailViews, CorpusInfo.xyz, CorpusInfo.rgb); // OK for visualization

																						   //Prune corpus for bad points
	printLOG("Remove not good points ...");
	vector<int> *notGood = new vector<int>[goodNDplus];
	sprintf(Fname, "%s/Good.txt", Path);	fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		for (int jj = 0; jj < goodNDplus; jj++)
		{
			int pid, ii;
			fscanf(fp, "%d %d", &pid, &ii);
			while (ii != -1)
			{
				notGood[jj].push_back(ii);
				fscanf(fp, "%d ", &ii);
			}
		}
		fclose(fp);
	}

	for (int jj = 0; jj < goodNDplus; jj++)
	{
		for (int ii = (int)notGood[jj].size() - 1; ii >= 0; ii--)//start from last to first when deleting vector stack of data
		{
			int viewID = notGood[jj][ii];
			if (viewID > CorpusInfo.viewIdAll3D[jj].size() - 1)
				printLOG("%d\n", jj);
			else
			{
				CorpusInfo.viewIdAll3D[jj].erase(CorpusInfo.viewIdAll3D[jj].begin() + viewID);
				CorpusInfo.pointIdAll3D[jj].erase(CorpusInfo.pointIdAll3D[jj].begin() + viewID);
				CorpusInfo.uvAll3D[jj].erase(CorpusInfo.uvAll3D[jj].begin() + viewID);
				CorpusInfo.scaleAll3D[jj].erase(CorpusInfo.scaleAll3D[jj].begin() + viewID);
			}
		}
	}
	delete[]notGood;
	sprintf(Fname, "%s/Good.txt", Path);  remove(Fname);


	//And generate 3D id, uv, sift id for all views
	printLOG("and generate Corpus visibility info....");
	vector<int> *twoDiDAllViews = new vector<int>[nviews];
	CorpusInfo.threeDIdAllViews = new vector<int>[nviews];
	CorpusInfo.uvAllViews = new vector<Point2d>[nviews];
	CorpusInfo.scaleAllViews = new vector<double>[nviews];
	CorpusInfo.DescAllViews = new vector<FeatureDesc>[nviews];

	for (int ii = 0; ii < nviews; ii++)
	{
		twoDiDAllViews[ii].reserve(10000);
		CorpusInfo.threeDIdAllViews[ii].reserve(10000);
		CorpusInfo.uvAllViews[ii].reserve(10000);
		CorpusInfo.scaleAllViews[ii].reserve(10000);
		CorpusInfo.DescAllViews[ii].reserve(10000);
	}

	double scale;
	Point2d uv;
	for (int jj = 0; jj < goodNDplus; jj++)
	{
		for (int ii = 0; ii < (int)CorpusInfo.viewIdAll3D[jj].size(); ii++)
		{
			viewi = CorpusInfo.viewIdAll3D[jj][ii], pi = CorpusInfo.pointIdAll3D[jj][ii], uv = CorpusInfo.uvAll3D[jj][ii], scale = CorpusInfo.scaleAll3D[jj][ii];

			twoDiDAllViews[viewi].push_back(pi);
			CorpusInfo.threeDIdAllViews[viewi].push_back(jj);
			CorpusInfo.uvAllViews[viewi].push_back(uv);
			CorpusInfo.scaleAllViews[viewi].push_back(scale);
		}
	}
	printLOG("Done!\n");

	//Get sift desc for all views
	printLOG("Prune SIFT descriptors for only Corpus points....");
	int nSift, totalSift = 0, maxSift = 0;
	CorpusInfo.IDCumView.reserve(nviews + 1);
	for (int ii = 0; ii < nviews; ii++)
	{
		CorpusInfo.IDCumView.push_back(totalSift);
		nSift = (int)twoDiDAllViews[ii].size();
		if (nSift > maxSift)
			maxSift = nSift;
		totalSift += nSift;
	}
	CorpusInfo.IDCumView.push_back(totalSift);

	FeatureDesc desci;
	for (int ii = 0; ii < nviews; ii++)
	{
		int nSift = (int)CorpusInfo.uvAllViews[ii].size();
		for (int j = 0; j < nSift; ++j)
		{
			int pid = twoDiDAllViews[ii][j];
			for (int i = 0; i < SIFTBINS; i++)
				desci.desc[i] = AllDesc[ii].at<float>(pid, i);
			CorpusInfo.DescAllViews[ii].push_back(desci);
		}
	}

	printLOG("... Done!\nSaving corpus info\n");
	printLOG("****NOTE: 2d points in Corpus are corrected***\n");
	SaveCorpusInfo(Path, CorpusInfo);

	printLOG("... Done\n\n");

	//delete[]PViewIdAll3D, delete[]PuvIdAll3D, delete[]AllKeys, delete[]AllDesc, delete[]twoDiDAllViews;
	//delete[]A, delete[]B, delete[]tPs, delete[]passed, delete[]Ps, delete[]match2Dpts, delete[]matchScales;

	return 0;
}
int Build3DFromSyncedImages(char *Path, int nviews, int startF, int stopF, int timeStep, int LensType, int distortionCorrected, int nViewsPlus, double Reprojectionthreshold, double DepthThresh, int *frameTimeStamp, bool SaveToDenseColMap, bool Save2DCorres, bool Gen3DPatchFile, double Patch_World_Unit, bool useRANSAC)
{
	int nFrames = max(MaxnFrames, stopF);
	if (frameTimeStamp == NULL)
	{
		frameTimeStamp = new int[nviews];
		for (int ii = 0; ii < nviews; ii++)
			frameTimeStamp[ii] = 0;
	}
	int maxframeTimeStamp = 0;
	for (int ii = 0; ii < nviews; ii++)
		maxframeTimeStamp = max(maxframeTimeStamp, abs(frameTimeStamp[ii]));

	char Fname[512];
	VideoData *VideoI = new VideoData[nviews];
	for (int ii = 0; ii < nviews; ii++)
		ReadVideoDataI(Path, VideoI[ii], ii, -1, -1);

	int totalPts, MAXPTS = 0;
	for (int timeID = startF; timeID <= stopF; timeID += timeStep)
	{
		sprintf(Fname, "%s/Dynamic/%.4d/ViewPM.txt", Path, timeID); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		int nviewsi, viewi, n3D = 0;
		while (fscanf(fp, "%d ", &nviewsi) != EOF)
		{
			for (int ii = 0; ii < nviewsi; ii++)
				fscanf(fp, "%d ", &viewi);
			n3D++;
		}
		fclose(fp);
		if (n3D > MAXPTS)
			MAXPTS = n3D;
	}

	vector<int> cumulativePts; cumulativePts.reserve(nviews);
	vector<int>*PViewIdAll3D = new vector<int>[MAXPTS];
	vector<int>*PuvIdAll3D = new vector<int>[MAXPTS];
	vector<KeyPoint> *AllKeys = new vector < KeyPoint >[nviews];
	vector<Point3i> *RGB = new vector < Point3i >[nviews];
	vector<Point3d> AllXYZ; AllXYZ.reserve(1000);
	vector<Point3i> AllRGB; AllRGB.reserve(1000);

	double *A = new double[6 * nviews * 2];
	double *B = new double[2 * nviews * 2];
	double *tPs = new double[12 * nviews * 2];
	bool passed;
	double *Ps = new double[12 * nviews * 2];
	Point2d *match2Dpts = new Point2d[nviews * 2], *match2Dpts_BK = new Point2d[nviews * 2];
	Point3i *matchRGB = new Point3i[nviews * 2];

	FILE *fp1 = 0, *fp2 = 0, *fp3 = 0;
	for (int timeID = startF; timeID <= stopF; timeID += timeStep)
	{
		printLOG("Working on time %d ...\n", timeID);
		cumulativePts.clear(); AllXYZ.clear(), AllRGB.clear();
		if (ReadCumulativePoints(Path, nviews, timeID, cumulativePts) == 1)
			continue;
		totalPts = cumulativePts.at(nviews);

		sprintf(Fname, "%s/Dynamic/%.4d/ViewPM.txt", Path, timeID); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		int nviewsi, viewi, n3D = 0;
		while (fscanf(fp, "%d ", &nviewsi) != EOF)
		{
			PViewIdAll3D[n3D].clear(), PViewIdAll3D[n3D].reserve(nviewsi);
			for (int ii = 0; ii < nviewsi; ii++)
			{
				fscanf(fp, "%d ", &viewi);
				PViewIdAll3D[n3D].push_back(viewi);
			}
			n3D++;
		}
		fclose(fp);

		sprintf(Fname, "%s/Dynamic/%.4d/IDPM.txt", Path, timeID); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		int np, pi;
		n3D = 0;
		while (fscanf(fp, "%d ", &np) != EOF)
		{
			PuvIdAll3D[n3D].clear(), PuvIdAll3D[n3D].reserve(np);
			for (int ii = 0; ii < np; ii++)
			{
				fscanf(fp, "%d ", &pi);
				PuvIdAll3D[n3D].push_back(pi);
			}
			n3D++;
		}
		fclose(fp);

		//Read all sift points
		for (int ii = 0; ii < nviews; ii++)
		{
			AllKeys[ii].clear(); RGB[ii].clear();
			sprintf(Fname, "%s/%d/%.4d.sift", Path, ii, timeID - frameTimeStamp[ii]); readVisualSFMSiftGPU(Fname, AllKeys[ii]);
			//sprintf(Fname, "%s/%d/%.4d.rgb", Path, ii, timeID - frameTimeStamp[ii]); ReadRGBBinarySIFT(Fname, RGB[ii]);
		}

		//Triangulate points from estimated camera poses
		Point3d xyz;
		vector<int>Inliers[1];  Inliers[0].reserve(nviews * 2);
		vector<int>viewIDs, pointIDs, orgId, threeDid;
		vector<Point2d> uvPer3D, uvperView;
		Point3d PatchExpansionArrow[2];
		vector<KeyPoint> inlierPts;
		vector<CameraData> inlierViewsInfo;

		sprintf(Fname, "%s/Dynamic/%.4d/3dGL.xyz", Path, timeID); fp1 = fopen(Fname, "w+");
		if (Save2DCorres)
			sprintf(Fname, "%s/Dynamic/2DCorres_%.4d.txt", Path, timeID), fp2 = fopen(Fname, "w+");
		if (Gen3DPatchFile)
			sprintf(Fname, "%s/Dynamic/3DMem_%.4d.txt", Path, timeID), fp3 = fopen(Fname, "w+");

		double ProThresh = 0.99, PercentInlier = 0.25;
		int ninlier, inlierID, goodNDplus = 0, iterMax = (int)(log(1.0 - ProThresh) / log(1.0 - pow(PercentInlier, 2)) + 0.5); //log(1-eps) / log(1 - (inlier%)^min_pts_requires)
		double start = omp_get_wtime();

		Corpus CorpusInfo;
		CorpusInfo.nCameras = nviews;
		CorpusInfo.twoDIdAllViews = new vector<int>[nviews];
		CorpusInfo.threeDIdAllViews = new vector<int>[nviews];
		CorpusInfo.uvAllViews = new vector<Point2d>[nviews];

		for (int jj = 0; jj < n3D; jj++)
		{
			int nviewsi = (int)PViewIdAll3D[jj].size();
			if (nviewsi >= nViewsPlus)
			{
				//check for duplication
				bool duplicated = false;
				for (int ii = 1; ii < nviewsi; ii++)
					if (PViewIdAll3D[jj].at(ii - 1) == PViewIdAll3D[jj][ii])
						duplicated = true;
				if (duplicated)
					continue;

				Inliers[0].clear();
				int count = 0;
				for (int ii = 0; ii < nviewsi; ii++)
				{
					viewi = PViewIdAll3D[jj][ii];
					int fid = timeID - frameTimeStamp[viewi];
					CameraData *camI = VideoI[viewi].VideoInfo;
					if (!camI[fid].valid)
						continue;

					pi = PuvIdAll3D[jj][ii];
					match2Dpts[count] = Point2d(AllKeys[viewi][pi].pt.x, AllKeys[viewi][pi].pt.y);
					//matchRGB[count] = Point3i(RGB[viewi][pi].x, RGB[viewi][pi].y, RGB[viewi][pi].z);

					if (distortionCorrected == 0 && camI[fid].LensModel == RADIAL_TANGENTIAL_PRISM)
						LensCorrectionPoint(&match2Dpts[count], camI[fid].K, camI[0].distortion);
					else if (distortionCorrected == 0 && camI[fid].LensModel == FISHEYE)
						//FishEyeCorrectionPoint(&match2Dpts[count], camI[0].distortion[0], camI[0].distortion[1], camI[0].distortion[2]);
						FishEyeCorrectionPoint(&match2Dpts[count], camI[fid].K, camI[fid].distortion[0]);

					if (camI->ShutterModel == 0)
						for (int kk = 0; kk < 12; kk++)
							Ps[12 * count + kk] = camI[0].P[kk];
					else
						AssembleP_RS(match2Dpts[count], camI[0], Ps + 12 * count);

					count++;
				}
				if (count < nViewsPlus)
					continue;

				if (useRANSAC)
					NviewTriangulationRANSAC(match2Dpts, Ps, &xyz, &passed, Inliers, count, 1, 2, nviewsi == 2 ? 1 : iterMax, PercentInlier, Reprojectionthreshold, A, B, tPs);
				else
				{
					NviewTriangulation(match2Dpts, Ps, &xyz, count, 1, NULL, A, B);
					ProjectandDistort(xyz, match2Dpts_BK, Ps, NULL, NULL, count);

					double finalerror = 0.0;
					for (int ii = 0; ii < count; ii++)
						finalerror += pow(match2Dpts_BK[ii].x - match2Dpts[ii].x, 2) + pow(match2Dpts_BK[ii].y - match2Dpts[ii].y, 2);
					finalerror = sqrt(finalerror / count);
					if (finalerror < Reprojectionthreshold)
						passed = true;
					else
						passed = false;
				}

				if (passed)
				{
					inlierPts.clear();
					inlierViewsInfo.clear();

					if (useRANSAC)
					{
						ninlier = 0;
						for (int ii = 0; ii < Inliers[0].size(); ii++)
						{
							if (Inliers[0][ii])
							{
								inlierID = ii, ninlier++;
								if (Gen3DPatchFile)
								{
									viewi = PViewIdAll3D[jj][ii];
									pi = PuvIdAll3D[jj][ii];
									inlierPts.push_back(AllKeys[viewi][pi]);
									inlierViewsInfo.push_back(VideoI[viewi].VideoInfo[timeID - frameTimeStamp[viewi]]);
								}
							}
						}
						if (ninlier < nViewsPlus)
							continue; //Corpus needs nViewsPlus+ points!
					}
					else
						inlierID = 0;

					AllXYZ.push_back(xyz);
					//AllRGB.push_back(matchRGB[inlierID]);
					if (IsValid3D(xyz))
					{
						//threshold by depth
						double *Center, Dist, minPointCamDistance = 9e9;
						for (int ii = 0; ii < nviews; ii++)
						{
							Center = VideoI[ii].VideoInfo[timeID - frameTimeStamp[ii]].camCenter;
							Dist = Distance3D(Point3d(Center[0], Center[1], Center[2]), xyz);
							if (Dist < minPointCamDistance)
								minPointCamDistance = Dist;
						}
						if (minPointCamDistance > DepthThresh)
							continue;

						//fprintf(fp1, "%.4f %.4f %.4f %d %d %d\n", xyz.x, xyz.y, xyz.z, matchRGB[inlierID].x, matchRGB[inlierID].y, matchRGB[inlierID].z);
						fprintf(fp1, "%.4f %.4f %.4f\n", xyz.x, xyz.y, xyz.z);

						//For colmap output
						if (SaveToDenseColMap)
						{
							CorpusInfo.xyz.emplace_back(xyz);
							CorpusInfo.rgb.emplace_back(0, 0, 0);
							vector<int> viewIdAll3D, pointIdAll3D;

							if (useRANSAC)
							{
								for (int ii = 0; ii < Inliers[0].size(); ii++)
								{
									if (Inliers[0][ii])
									{
										int viewid = PViewIdAll3D[jj][ii], pid = PuvIdAll3D[jj][ii];
										viewIdAll3D.emplace_back(viewid), pointIdAll3D.emplace_back(pid);

									}
								}
							}
							else
							{
								for (int ii = 0; ii < nviewsi; ii++)
								{
									viewi = PViewIdAll3D[jj][ii], pi = PuvIdAll3D[jj][ii];
									viewIdAll3D.emplace_back(viewi), pointIdAll3D.emplace_back(pi);
								}
							}
							CorpusInfo.viewIdAll3D.emplace_back(viewIdAll3D);
							CorpusInfo.pointIdAll3D.emplace_back(pointIdAll3D);
						}

						if (Save2DCorres)
						{
							fprintf(fp2, "%d ", ninlier);
							for (int ii = 0; ii < Inliers[0].size(); ii++)
							{
								if (Inliers[0][ii])
								{
									int viewid = PViewIdAll3D[jj][ii];
									LensDistortionPoint(&match2Dpts[ii], VideoI[viewid].VideoInfo[timeID - frameTimeStamp[viewid]].K, VideoI[viewid].VideoInfo[timeID - frameTimeStamp[viewid]].distortion);
									fprintf(fp2, "%d %f %f ", viewid, match2Dpts[ii].x, match2Dpts[ii].y);
								}
							}
							fprintf(fp2, "\n");
						}

						if (Gen3DPatchFile)
						{
							double scale3D;
							SelectRefCam_InitPatchFixedScale(PatchExpansionArrow, scale3D, xyz, inlierPts, inlierViewsInfo, Patch_World_Unit);
							//fprintf(fp3, "Pt3D %d %.4f %.4f %.4f %.4f %.4f %.4f %f %f %f %f %f %f %f\n", goodNDplus, xyz.x, xyz.y, xyz.z, 1.0*matchRGB[inlierID].x / 255.0, 1.0*matchRGB[inlierID].y / 255.0, 1.0*matchRGB[inlierID].z / 255.0,
							fprintf(fp3, "Pt3D %d %.4f %.4f %.4f %f %f %f %f %f %f %f\n", goodNDplus, xyz.x, xyz.y, xyz.z,
								scale3D, PatchExpansionArrow[0].x, PatchExpansionArrow[0].y, PatchExpansionArrow[0].z,
								PatchExpansionArrow[1].x, PatchExpansionArrow[1].y, PatchExpansionArrow[1].z);
							fprintf(fp3, "%d ", ninlier);
							for (int ii = 0; ii < Inliers[0].size(); ii++)
							{
								if (Inliers[0][ii])
									fprintf(fp3, "%d %f %f ", PViewIdAll3D[jj][ii], match2Dpts[ii].x, match2Dpts[ii].y);
							}
							fprintf(fp3, "\n");
						}
					}

					goodNDplus++;
				}
			}
		}

		fclose(fp1);
		if (Save2DCorres)
			fclose(fp2);
		if (Gen3DPatchFile)
			fclose(fp3);

		if (SaveToDenseColMap)
		{
			for (int ii = 0; ii < CorpusInfo.viewIdAll3D.size(); ii++)
			{
				for (int jj = 0; jj < CorpusInfo.viewIdAll3D[ii].size(); jj++)
				{
					int viewId = CorpusInfo.viewIdAll3D[ii][jj],
						pid = CorpusInfo.pointIdAll3D[ii][jj];
					CorpusInfo.twoDIdAllViews[viewId].emplace_back(pid);
					CorpusInfo.threeDIdAllViews[viewId].emplace_back(ii);

					int fid = timeID - frameTimeStamp[viewi];
					CameraData *camI = VideoI[viewi].VideoInfo;

					Point2d uv = Point2d(AllKeys[viewi][pi].pt.x, AllKeys[viewi][pi].pt.y);
					if (distortionCorrected == 0 && camI[fid].LensModel == RADIAL_TANGENTIAL_PRISM)
						LensCorrectionPoint(&uv, camI[fid].K, camI[fid].distortion);
					else if (distortionCorrected == 0 && camI[fid].LensModel == FISHEYE)
						//FishEyeCorrectionPoint(&match2Dpts[count], camI[0].distortion[0], camI[0].distortion[1], camI[0].distortion[2]);
						FishEyeCorrectionPoint(&uv, camI[fid].K, camI[fid].distortion[0]);

					CorpusInfo.uvAllViews[viewId].emplace_back(uv);
				}
			}

			/*printLOG("Writing 3D points cloud info\n");
			sprintf(Fname, "%s/dense/sparse/points3D.txt", Path);
			fp = fopen(Fname, "w");
			fprintf(fp, "# 3D point list with one line of data per point:\n");
			fprintf(fp, "	#   POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as(IMAGE_ID, POINT2D_IDX)\n");
			fprintf(fp, "	# Number of points : %d, mean track length : 10.0\n", CorpusInfo.n3dPoints);
			for (int pid = 0; pid < CorpusInfo.n3dPoints; pid++)
			{
				fprintf(fp, "%d %.6f %.6f %.6f %d %d %d 0.0 ", pid, CorpusInfo.xyz[pid].x, CorpusInfo.xyz[pid].y, CorpusInfo.xyz[pid].z,
					CorpusInfo.rgb[pid].x, CorpusInfo.rgb[pid].y, CorpusInfo.rgb[pid].z);
				for (size_t ii = 0; ii < CorpusInfo.pointIdAll3D[pid].size(); ii++)
					fprintf(fp, "%d %d ", CorpusInfo.viewIdAll3D[pid][ii] + 1, CorpusInfo.pointIdAll3D[pid][ii]);
				fprintf(fp, "\n");
			}


			sprintf(Fname, "%s/dense/sparse/images.txt", Path);
			fp = fopen(Fname, "w");
			fprintf(fp, "# Image list with two lines of data per image:\n");
			fprintf(fp, "#   IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\n");
			fprintf(fp, "#   POINTS2D[] as(X, Y, POINT3D_ID)\n");
			fprintf(fp, "# Number of images : %d, mean observations per image : 1000\n", CorpusInfo.nCameras);
			for (int cid = 0; cid < CorpusInfo.nCameras; cid++)
			{
				if (CorpusInfo.twoDIdAllViews[cid].size() == 0)
					continue;

				CameraData *camI = CorpusInfo.camera;
				GetRTFromrt(camI[cid]);
				ceres::AngleAxisToQuaternion(camI[cid].rt, camI[cid].Quat);

				fprintf(fp, "%d %.8f %.8f %.8f %.8f %.8f %.8f %.8f %d %.4d.jpg\n", cid + 1, camI[cid].Quat[0], camI[cid].Quat[1], camI[cid].Quat[2], camI[cid].Quat[3],
					camI[cid].T[0], camI[cid].T[1], camI[cid].T[2], cid + 1, cid);

				int maxSiftId = *max_element(CorpusInfo.twoDIdAllViews[cid].begin(), CorpusInfo.twoDIdAllViews[cid].end()) + 1;
				for (int pid = 0; pid < maxSiftId; pid++)
				{
					std::vector<int>::iterator iter = find(CorpusInfo.twoDIdAllViews[cid].begin(), CorpusInfo.twoDIdAllViews[cid].end(), pid);
					if (iter != CorpusInfo.twoDIdAllViews[cid].end())
					{
						int lpid = std::distance(CorpusInfo.twoDIdAllViews[cid].begin(), iter);
						Point2d ImgPt = CorpusInfo.uvAllViews[cid][lpid]; //coprus should be correctd
						fprintf(fp, "%.3f %.3f %d ", ImgPt.x, ImgPt.y, CorpusInfo.threeDIdAllViews[cid][lpid]);
					}
					else
						fprintf(fp, "1.0 1.0 -1 ");
				}
				fprintf(fp, "\n");
			}
			fclose(fp);*/

			CorpusInfo.camera = new CameraData[nviews];
			for (int ii = 0; ii < nviews; ii++)
			{
				int fid = timeID - frameTimeStamp[ii];
				CorpusInfo.vTrueFrameId.push_back(fid);
				CopyCamereInfo(VideoI[ii].VideoInfo[fid], CorpusInfo.camera[ii], true);
			}
			CorpusInfo.n3dPoints = (int)CorpusInfo.xyz.size();
			writeColMap4DenseStereo(Path, CorpusInfo, -1, timeID); //need twoDIdAllViews
		}
	}

	delete[]PViewIdAll3D, delete[]PuvIdAll3D, delete[]AllKeys;
	delete[]A, delete[]B, delete[]tPs, delete[]Ps, delete[]match2Dpts, delete[]match2Dpts_BK;
	return 0;
}
int BuildCorpusAndLocalizeCameraBatch(char *Path, SfMPara mySfMPara, int module)
{
	char Fname[4096], buffer[4096];
	myGetCurDir(4096, buffer);

	int nCams = mySfMPara.nCams, startF = mySfMPara.startF, stopF = mySfMPara.stopF, increF = mySfMPara.increF,
		extractedFrames = mySfMPara.extractedFrames, interpAlgo = mySfMPara.interpAlgo, UseJpg = mySfMPara.useRanSac;
	double imgRescale = mySfMPara.imgRescale;

	int ExternalCorpus = mySfMPara.ExternalCorpus, IncreMatchingFrame = mySfMPara.IncreMatchingFrame, fromKeyFrameTracking = mySfMPara.fromKeyFrameTracking;

	//Key frames extraction
	bool highQualityTracking = mySfMPara.highQualityTracking;
	int minKFinterval = mySfMPara.minKFinterval, maxKFinterval = mySfMPara.maxKFinterval, minFeaturesToTrack = mySfMPara.minFeaturesToTrack;
	double kfFlowThresh = mySfMPara.kfFlowThresh, kfSuccessConsecutiveTrackingRatio = mySfMPara.kfSuccessConsecutiveTrackingRatio, kfSuccessRefTrackingRatio = mySfMPara.kfSuccessRefTrackingRatio;

	//For BA
	int nViewsPlus = mySfMPara.nViewsPlusBA, nViewsPlus2 = mySfMPara.nViewsPlusBA2, LossType = mySfMPara.LossType, doubleRefinement = mySfMPara.BARefinementIter;
	int ShutterModel = mySfMPara.ShutterModel, ShutterModel2 = mySfMPara.ShutterModel2;
	int fixIntrinsic = mySfMPara.fixIntrinsic, fixDistortion = mySfMPara.fixDistortion, fixPose = mySfMPara.fixPose, fix3D = mySfMPara.fix3D, fixLocal3D = mySfMPara.fixLocal3D, fixSkew = mySfMPara.fixSkew, fixPrism = mySfMPara.fixPrism;
	int distortionCorrected = mySfMPara.distortionCorrected;
	int snapshot_images_freq = mySfMPara.snapshot_images_freq;
	double threshold = mySfMPara.reProjectionBAThresh, nInlierThresh = mySfMPara.nInliersThresh, nInlierThresh2 = mySfMPara.nInliersThresh2;
	double ba_global_images_ratio = mySfMPara.ba_global_images_ratio, ba_global_points_ratio = mySfMPara.ba_global_points_ratio, ba_global_tri_min_angle = mySfMPara.ba_global_tri_min_angle;

	//Vocal matching
	int MatchingMode = mySfMPara.MatchingMode, SeqMatchingForcedNearbyImageRange = mySfMPara.SeqMatchingForcedNearbyImageRange, VocMatchingkNN = mySfMPara.VocMatchingkNN;
	char VocabTreePath[512]; sprintf(VocabTreePath, "%s", mySfMPara.VocabTreePath);

	//For Pnp
	int ec2BatchSize = mySfMPara.ec2BatchSize, PnPMatchingForcedNearbyKeyFrameRange = mySfMPara.PnPMatchingForcedNearbyKeyFrameRange;


	sprintf(Fname, "%s/CamerasWithFixedIntrinsic.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		char Fname2[512]; sprintf(Fname, "%s/CamerasWithFixedIntrinsic.txt", Path);
		sprintf(Fname2, "%s/Corpus/CamerasWithFixedIntrinsic.txt", Path);
		MyCopyFile(Fname, Fname2);
	}
	else
	{
		printLOG("Cannot find %s.\nPlease take a moment to sepecify the shared intrinsic in CamerasWithFixedIntrinsic.txt. Format: camID\n", Fname);
		return 0;
	}

	vector<int> CameraLensModel; CameraLensModel.resize(nCams);
	sprintf(Fname, "%s/CameraLensModel.txt", Path); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int CameraGroup, LensModel;
		while (fscanf(fp, "%d %d ", &CameraGroup, &LensModel) != EOF)
			CameraLensModel[CameraGroup] = LensModel;
		fclose(fp);

		char Fname2[512]; sprintf(Fname, "%s/CameraLensModel.txt", Path);
		sprintf(Fname2, "%s/Corpus/CameraLensModel.txt", Path);
		MyCopyFile(Fname, Fname2);
	}
	else
	{
		printLOG("Cannot find %s.\nPlease take a moment to sepecify the camera lens type in CameraLensModel.txt. Format: camID lensType\n", Fname);
		return 0;
	}

	vector<int> CameraWithFishEyeLens;
	for (int ii = 0; ii < nCams; ii++)
		if (CameraLensModel[ii] == FISHEYE)
			CameraWithFishEyeLens.push_back(ii);

	vector<CameraData> InitDevicesIntrinsics(nCams);
	sprintf(Fname, "%s/InitDevicesIntrinsics.txt", Path); fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		if (CameraWithFishEyeLens.size() > 0)
			printLOG("\nWarning: Fisheye lens used.\nPlease take a moment to initialze the camera intrinsic for fisheye lens camera in InitDevicesIntrinsics.txt.\nFormat: camID lensType focal (r0 r1 r2 t0 t1 p0 p1) (omega cenX cenY)\n\n");
	}
	else
	{
		int cid, lensType, width, height;
		double focal;
		while (fscanf(fp, "%d %d %d %d %lf", &cid, &lensType, &width, &height, &focal) != EOF)
		{
			InitDevicesIntrinsics[cid].width = width, InitDevicesIntrinsics[cid].height = height;
			InitDevicesIntrinsics[cid].intrinsic[0] = focal, InitDevicesIntrinsics[cid].intrinsic[1] = focal;
			InitDevicesIntrinsics[cid].intrinsic[3] = width / 2, InitDevicesIntrinsics[cid].intrinsic[4] = height / 2;

			InitDevicesIntrinsics[cid].LensModel = lensType;
			if (lensType == RADIAL_TANGENTIAL_PRISM)
				for (int ii = 0; ii < 7; ii++)
					fscanf(fp, "%lf ", &InitDevicesIntrinsics[cid].distortion[ii]);
			else
				fscanf(fp, "%lf %lf %lf ", &InitDevicesIntrinsics[cid].distortion[0], &InitDevicesIntrinsics[cid].intrinsic[3], &InitDevicesIntrinsics[cid].intrinsic[4]);
		}
		fclose(fp);

		char Fname2[512]; sprintf(Fname, "%s/InitDevicesIntrinsics.txt", Path);
		sprintf(Fname2, "%s/Corpus/InitDevicesIntrinsics.txt", Path);
		MyCopyFile(Fname, Fname2);
	}

	std::string DataName(Path);
	while (true)
	{
		std::size_t pos = DataName.find("/");
		if (pos != std::string::npos)
			DataName.erase(0, pos + 1);
		else
			break;
	}

	int bestSum = 0, nCorpusImg = 0;
	vector<int> njobs, vcamID;

	Point3d *CamTimeInfo = new Point3d[nCams];
	for (int ii = 0; ii < nCams; ii++)
		CamTimeInfo[ii].x = 1.0, CamTimeInfo[ii].y = 0.0;
	sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		double fps; int selected, offset;
		while (fscanf(fp, "%d %lf %d ", &selected, &fps, &offset) != EOF)
		{
			if (selected > nCams - 1)
				continue;
			CamTimeInfo[selected].x = 1.0 / fps;
			CamTimeInfo[selected].y = offset;
			CamTimeInfo[selected].z = 1.0;
		}
		fclose(fp);
	}
	else
		printLOG("Cannot load time stamp info. Assume no frame offsets!");


	sprintf(Fname, "%s/Logs/realStopFrame.txt", Path);
	if (IsFileExist(Fname))
	{
		FILE *fp = fopen(Fname, "r");
		fscanf(fp, "%d", &stopF);
		fclose(fp);
		printLOG("\n\nNew stopFrame: %d\n\n", stopF);
	}

	//0. Image extraction
	vector<Point2i> rotateImage;
	sprintf(Fname, "%s/RotationInfo.txt", Path); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int cid, code;
		while (fscanf(fp, "%d %d", &cid, &code) != EOF)
			rotateImage.push_back(Point2i(cid, code));
		fclose(fp);
	}
	if (module == 0 || module < 0)
	{
		printLOG("Extracting images for each camera ...\n");
#ifdef SCHEDULER
		for (int cid = 0; cid < nCams; cid++)
		{
			int code = 0;
			for (int ii = 0; ii < (int)rotateImage.size() && code == 0; ii++)
				if (rotateImage[ii].x == cid)
					code = rotateImage[ii].y;

#ifdef _WINDOWS
			sprintf(Fname, "%s/EnRecon.exe %s 12 %d %d %d %d %d %.2f %d", buffer, Path, cid, startF, stopF, increF, code, imgRescale, UseJpg);
#elif EC2
			sprintf(Fname, "qsub -b y -cwd -pe orte 1 ./EnRecon %s 12 %d %d %d %d %d %.2f %d", Path, cid, startF, stopF, increF, code, imgRescale, UseJpg);
#else
			sprintf(Fname, "./EnRecon %s 12 %d %d %d %d %d %.2f %d", Path, cid, startF, stopF, increF, code, imgRescale, UseJpg);
#endif

			printLOG(Fname); printLOG("\n");
			system(Fname);
			njobs.push_back(0);
		}
		while (true)//wait for it to finish
		{
			mySleep(30e3);
			int count = 0;
			for (int cid = 0; cid < nCams; cid++)
			{
				sprintf(Fname, "%s/Logs/ImgExtraction_%d_%d_%.4d.txt", Path, cid, startF, stopF); fp = fopen(Fname, "r");
				if (fp != NULL)
				{
					njobs[count] = 1;
					fclose(fp);
				}
				count++;
			}
			int sumRes = 0;
			for (int ii = 0; ii < (int)njobs.size(); ii++)
				sumRes += njobs[ii];

			if (sumRes == (int)njobs.size())
				break;
			if (bestSum < sumRes)
			{
				bestSum = sumRes;
				printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
			}
		}
		for (int cid = 0; cid < nCams; cid++)
			sprintf(Fname, "%s/Logs/ImgExtraction_%d_%d_%.4d.txt", Path, cid, startF, stopF), remove(Fname);
#else
#pragma omp parallel for schedule(dynamic,1)
		for (int cid = 0; cid < nCams; cid++)
		{
			int code = 0;
			for (int ii = 0; ii < (int)rotateImage.size() && code == 0; ii++)
			{
				if (rotateImage[ii].x == cid)
					code = rotateImage[ii].y;
			}
			ExtractVideoFrames(Path, cid, startF, stopF, increF, code, 1.0, 3, UseJpg, CamTimeInfo[cid].y);
		}
#endif
		printLOG("done\n");
}

	//1. Copy images to corpus
	if (module == 1 || module < 0)
	{
		printLOG("Create corpus images ...\n");
#ifdef SCHEDULER
		printLOG("Extracting non-blur images\n");
		njobs.clear();
		for (int cid = 0; cid < nCams; cid++)
		{
#ifdef _WINDOWS
			sprintf(Fname, "%s/EnRecon.exe %s 22 %d %d %d %d", buffer, Path, cid, startF, stopF, extractedFrames);
#elif EC2
			sprintf(Fname, "qsub -b y -cwd -pe orte 1 ./EnRecon %s 22 %d %d %d %d", Path, cid, startF, stopF, extractedFrames);
#else
			sprintf(Fname, "./EnRecon %s 22 %d %d %d %d", Path, cid, startF, stopF, extractedFrames);
#endif
			printLOG(Fname); printLOG("\n");
			system(Fname);
			njobs.push_back(0);
		}

		while (true)//wait for it to finish
		{
			mySleep(30e3);
			int count = 0;
			for (int cid = 0; cid < nCams; cid++)
			{
				sprintf(Fname, "%s/Logs/ImgBlurDetection_%d_%d_%d.txt", Path, cid, startF, stopF); fp = fopen(Fname, "r");
				if (fp != NULL)
				{
					njobs[count] = 1;
					fclose(fp);
				}
				count++;
			}
			int sumRes = 0;
			for (int ii = 0; ii < (int)njobs.size(); ii++)
				sumRes += njobs[ii];

			if (sumRes == (int)njobs.size())
				break;
			if (bestSum < sumRes)
			{
				bestSum = sumRes;
				printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
			}
		}
		for (int cid = 0; cid < nCams; cid++)
			sprintf(Fname, "%s/Logs/ImgBlurDetection_%d_%d_%d.txt", Path, cid, startF, stopF), remove(Fname);

		printLOG("Extracting keyframe\n");
		njobs.clear();
		for (int cid = 0; cid < nCams; cid++)
		{
			int code = 0;
			for (int ii = 0; ii < (int)rotateImage.size() && code == 0; ii++)
				if (rotateImage[ii].x == cid)
					code = rotateImage[ii].y;

#ifdef _WINDOWS
			sprintf(Fname, "%s/EnRecon.exe %s 23 %d %d %d %f %f %f %d %d %d %d %d  %d", buffer, Path, cid, startF, stopF, kfSuccessConsecutiveTrackingRatio, kfSuccessRefTrackingRatio, kfFlowThresh,
				minFeaturesToTrack, minKFinterval, maxKFinterval, highQualityTracking, extractedFrames, dedicatedCorpus);
#elif EC2
			sprintf(Fname, "qsub -b y -cwd -pe orte 8 ./EnRecon %s 23%d %d %d %f %f %f %d %d %d %d %d %d", buffer, Path, cid, startF, stopF, kfSuccessConsecutiveTrackingRatio, kfSuccessRefTrackingRatio, kfFlowThresh,
				minFeaturesToTrack, minKFinterval, maxKFinterval, highQualityTracking, extractedFrames, dedicatedCorpus);
#else
			sprintf(Fname, "./EnRecon %s 23 %d %d %d %f %f %f %d %d %d %d %d %d", buffer, Path, cid, startF, stopF, kfSuccessConsecutiveTrackingRatio, kfSuccessRefTrackingRatio, kfFlowThresh,
				minFeaturesToTrack, minKFinterval, maxKFinterval, highQualityTracking, extractedFrames, dedicatedCorpus);
#endif

			printLOG(Fname); printLOG("\n");
			system(Fname);
			njobs.push_back(0);
		}

		while (true)//wait for it to finish
		{
			mySleep(30e3);
			int count = 0;
			for (int cid = 0; cid < nCams; cid++)
			{
				sprintf(Fname, "%s/Logs/ImKeyFramesExtraction_%d_%d_%d.txt", Path, cid, startF, stopF); fp = fopen(Fname, "r");
				if (fp != NULL)
				{
					njobs[count] = 1;
					fclose(fp);
				}
				count++;
			}
			int sumRes = 0;
			for (int ii = 0; ii < (int)njobs.size(); ii++)
				sumRes += njobs[ii];

			if (sumRes == (int)njobs.size())
				break;
			if (bestSum < sumRes)
			{
				bestSum = sumRes;
				printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
			}
		}
		for (int cid = 0; cid < nCams; cid++)
			sprintf(Fname, "%s/Logs/ImKeyFramesExtraction_%d_%d_%d.txt", Path, cid, startF, stopF), remove(Fname);
#else

		int EvenlySample = 100;
		omp_set_num_threads(omp_get_max_threads());

#pragma omp parallel for schedule(dynamic,1)
		for (int cid = 0; cid < nCams; cid++)
		{
			bool staticCam = false;
			sprintf(Fname, "%s/staticCamList.txt", Path);
			if (IsFileExist(Fname))
			{
				int scid;
				FILE *fp = fopen(Fname, "r");
				while (fscanf(fp, "%d ", &scid) != EOF)
				{
					if (cid == scid)
						staticCam = true;
				}
				fclose(fp);
			}

			if (staticCam && EvenlySample > 0)
				continue;
			else
			{
#pragma omp critical
				printLOG("Extracting non-blurry frame for %d\n", cid);

				vector<int> goodFrames;
				char Fname[512];
				sprintf(Fname, "%s/%d", Path, cid); makeDir(Fname);
				sprintf(Fname, "%s/%d/goodFrames_%d_%d.txt", Path, cid, startF, stopF);
				if (IsFileExist(Fname) == 0)
				{
					if (extractedFrames)
						VideoBasedBlurDetection2(Path, cid, startF, stopF, goodFrames);
					else
						VideoBasedBlurDetection(Path, cid, startF, stopF, goodFrames);
				}
			}
		}

		sprintf(Fname, "%s/Logs/realStopFrame.txt", Path);
		if (IsFileExist(Fname))
		{
			FILE *fp = fopen(Fname, "r");
			fscanf(fp, "%d", &stopF);
			fclose(fp);
			printLOG("\n\nNew stopFrame: %d\n\n", stopF);
		}

#pragma omp parallel for schedule(dynamic,1)
		for (int cid = 0; cid < nCams; cid++)
		{
			bool staticCam = false;
			sprintf(Fname, "%s/staticCamList.txt", Path);
			if (IsFileExist(Fname))
			{
				int scid;
				FILE *fp = fopen(Fname, "r");
				while (fscanf(fp, "%d ", &scid) != EOF)
				{
					if (cid == scid)
						staticCam = true;
				}
				fclose(fp);
			}

			if (staticCam && EvenlySample > 0)
			{
#pragma omp critical
				printLOG("Static keyframe for camera %d\n", cid);
				vector<Point2i> vCidFid;
				sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, cid); FILE *fp = fopen(Fname, "w+");
				for (int fid = startF, nkf = 0; fid <= stopF; fid += EvenlySample, nkf++)
				{
					char Fname[512];  sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid);
					if (IsFileExist(Fname))
					{
						fprintf(fp, "%d %d %d 1\n", cid, nkf, fid);
						vCidFid.emplace_back(cid, fid);
					}
				}
				fclose(fp);
				ExtractSiftCPUFromImageListDriver(Path, vCidFid);
			}
			else
			{
#pragma omp critical
				printLOG("Dynamic keyframe for camera %d\n", cid);

				sprintf(Fname, "%s/Logs/ImKeyFramesExtraction_%d_%d_%d.txt", Path, cid, startF, stopF);
				if (IsFileExist(Fname) == 1)
					continue;

				int fid;
				vector<int> goodFrames;
				char Fname[512];  sprintf(Fname, "%s/%d/goodFrames_%d_%d.txt", Path, cid, startF, stopF);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s. Skip camera %d\n", Fname, cid);
					continue;
				}
				FILE *fp = fopen(Fname, "r");
				while (fscanf(fp, "%d ", &fid) != EOF)
					goodFrames.push_back(fid);
				fclose(fp);

				int code = 0;
				for (int ii = 0; ii < (int)rotateImage.size() && code == 0; ii++)
				{
					if (rotateImage[ii].x == cid)
						code = rotateImage[ii].y;
				}

#ifdef _WINDOWS
				KeyFramesViaOpticalFlow_HQ(Path, cid, startF, stopF, extractedFrames, code, goodFrames, kfSuccessConsecutiveTrackingRatio, kfSuccessRefTrackingRatio, kfFlowThresh, minFeaturesToTrack, minKFinterval, maxKFinterval, 1.0, -1, highQualityTracking, omp_get_max_threads(), 1, true, ExternalCorpus > -1);
#else
				KeyFramesViaOpticalFlow_HQ(Path, cid, startF, stopF, extractedFrames, code, goodFrames, kfSuccessConsecutiveTrackingRatio, kfSuccessRefTrackingRatio, kfFlowThresh, minFeaturesToTrack, minKFinterval, maxKFinterval, 1.0, -1, highQualityTracking, omp_get_max_threads(), 0, true, ExternalCorpus > -1);
#endif	
			}
			sprintf(Fname, "%s/Logs/ImKeyFramesExtraction_%d_%d_%d.txt", Path, cid, startF, stopF); fp = fopen(Fname, "w"); fclose(fp);
		}
#endif

		for (int cid = 0; cid < nCams; cid++)
		{
			sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, cid);
			if (IsFileExist(Fname, false) == 1)
			{
				vector<int> vrfid;
				int dummy, rfid;
				FILE *fp = fopen(Fname, "r");
				while (fscanf(fp, "%d %d %d %d ", &dummy, &dummy, &rfid, &dummy) != EOF)
					vrfid.push_back(rfid);
				fclose(fp);

				sprintf(Fname, "%s/%d/querry.txt", Path, cid); fp = fopen(Fname, "w");
				for (auto fid : vrfid)
					fprintf(fp, "%.4d.jpg\n", fid);
				fclose(fp);
			}
		}

		printLOG("Reorganizing frames...\n");
		vector<Point2i> dummy;
		if (ExternalCorpus == -1)
			for (int ii = 0; ii < nCams; ii++)
				vcamID.push_back(ii);
		else
			vcamID.push_back(ExternalCorpus);
		nCorpusImg = GenCorpusImgsFromKeyFrames(Path, vcamID, extractedFrames == 0 ? rotateImage : dummy, InitDevicesIntrinsics, mySfMPara.KFSample4Corpus);//this will also generate list.txt file for vocab matching
																																							//GenMaskedCorpusFromKeyFrames(Path, nCams);
																																							//GenCorpusImgsFromCachedText(Path, nCams);
		printLOG("Done\n");
	}

	//2. Extract feature from videos --> Not needed anymore @Minh: 04/13/20
	if (module == 2 || module < 0)
	{
		printLOG("Extract feature for images from each camera\n");
		for (int cid = 0; cid < nCams; cid++)
		{
#ifdef SCHEDULER
			sprintf(Fname, "qsub -b y -cwd -pe orte %d ./EnRecon %s 4 2 %d %d %d %d %d 0 2", min(8, omp_get_max_threads()), Path, cid, nCams, startF, stopF, IncreMatchingFrame);
#elif _WINDOWS
			sprintf(Fname, "%s/EnRecon.exe %s 4 %d %d %d %d %d %d 0", buffer, Path, 4 - extractedFrames, cid, nCams, startF, stopF, IncreMatchingFrame);
#else
			sprintf(Fname, "./EnRecon %s 4 2 %d %d %d %d %d 0 2", Path, cid, nCams, startF, stopF, IncreMatchingFrame);
#endif
			printLOG(Fname); printLOG("\n");
			system(Fname); //somehow, siftgpu does not work well for many images. Do vlfeat sift instead.
	}
		printLOG("Done\n");
}

	//3.Run visualsfm to build corpus +  Refine corpus and retriangulate
	if (module == 3 || module < 0)
	{
		sprintf(Fname, "%s/Logs/OrganizeKF2Corpus.txt", Path);
		if (IsFileExist(Fname) == 0)
		{
			printLOG("Reorganizing frames...\n");
			vector<Point2i> dummy;
			if (ExternalCorpus == -1)
				for (int ii = 0; ii < nCams; ii++)
					vcamID.push_back(ii);
			else
				vcamID.push_back(ExternalCorpus);
			nCorpusImg = GenCorpusImgsFromKeyFrames(Path, vcamID, extractedFrames == 0 ? rotateImage : dummy, InitDevicesIntrinsics, mySfMPara.KFSample4Corpus);//this will also generate list.txt file for vocab matching
																																								//GenMaskedCorpusFromKeyFrames(Path, nCams);
																																								//GenCorpusImgsFromCachedText(Path, nCams);
		}
		if (nCorpusImg == 0)
		{
			while (true)
			{
				sprintf(Fname, "%s/Corpus/%.4d.jpg", Path, nCorpusImg);
				char Fname2[512];  sprintf(Fname2, "%s/Corpus/%.4d.png", Path, nCorpusImg);
				if (IsFileExist(Fname) == 1 || IsFileExist(Fname2) == 1)
					nCorpusImg++;
				else
					break;
			}
		}

		sprintf(Fname, "%s/Corpus/Corpus.db", Path);
		if (IsFileExist(Fname) == 0)
		{
#ifdef _WINDOWS
			sprintf(Fname, "%s/feature_importer.exe --database_path %s/Corpus/Corpus.db --image_path %s/Corpus --import_path %s/Corpus/ --image_list %s/Corpus/ImageList.txt", buffer, Path, Path, Path, Path);
#else
			sprintf(Fname, "./feature_importer --database_path %s/Corpus/Corpus.db --image_path %s/Corpus --import_path %s/Corpus/ --image_list %s/Corpus/ImageList.txt", Path, Path, Path, Path);
#endif
			printLOG("%s\n", Fname); system(Fname);
		}

		if (MatchingMode == 1 || MatchingMode == 3)
		{
			if (IsFileExist(VocabTreePath) == 0)
			{
				printLOG("VocabTree could not be found. Please input its Path: ");
				cin >> VocabTreePath;
				if (IsFileExist(VocabTreePath) == 0)
				{
					printLOG("VocabTree could not be found. Do exhaustive matching.\n");
					MatchingMode = 0;
				}
			}
		}
		else if (MatchingMode == 2 || MatchingMode == 4)
		{
			sprintf(Fname, "%s/Corpus/vocabTree.db", Path);
			if (IsFileExist(Fname) == 0)
			{
#ifdef _WINDOWS
				sprintf(Fname, "%s/vocab_tree_builder.exe --database_path %s/Corpus/Corpus.db --vocab_tree_path %s/Corpus/vocabTree.db", buffer, Path, Path);
#else
				sprintf(Fname, "./vocab_tree_builder --database_path %s/Corpus/Corpus.db --vocab_tree_path %s/Corpus/vocabTree.db", Path, Path);
#endif
				printLOG(Fname), printLOG("\n"), system(Fname);
			}
		}

		sprintf(Fname, "%s/Logs/Colmap_mapper.txt", Path);
		if (!IsFileExist(Fname))
		{
			if (MatchingMode == 0)
			{
#ifdef _WINDOWS
				sprintf(Fname, "%s/exhaustive_matcher.exe  --database_path %s/Corpus/Corpus.db", buffer, Path);
#else
				sprintf(Fname, "./exhaustive_matcher  --database_path %s/Corpus/Corpus.db", Path);
#endif
				printLOG("%s\n", Fname); system(Fname);

#ifdef _WINDOWS
				sprintf(Fname, "%s/mapper.exe --database_path %s/Corpus/Corpus.db --image_path %s/Corpus --export_path %s/Corpus --Mapper.ba_global_use_pba 0 --Mapper.ba_global_max_num_iterations 7 --Mapper.ba_global_images_ratio %.2f  --Mapper.ba_global_points_ratio %.1f --Mapper.tri_min_angle %.1f --Mapper.snapshot_path %s/Corpus --Mapper.snapshot_images_freq %d",
					buffer, Path, Path, Path, ba_global_images_ratio, ba_global_points_ratio, ba_global_tri_min_angle, Path, snapshot_images_freq);
#else
				sprintf(Fname, "./mapper --database_path %s/Corpus/Corpus.db --image_path %s/Corpus --export_path %s/Corpus --Mapper.ba_global_use_pba 0 --Mapper.ba_global_max_num_iterations 7 --Mapper.ba_global_images_ratio %.2f  --Mapper.ba_global_points_ratio %.1f --Mapper.tri_min_angle %.1f --Mapper.snapshot_path %s/Corpus --Mapper.snapshot_images_freq %d",
					Path, Path, Path, ba_global_images_ratio, ba_global_points_ratio, ba_global_tri_min_angle, Path, snapshot_images_freq);
#endif
				printLOG("%s\n", Fname); system(Fname);
			}
			else if (MatchingMode == 1 || MatchingMode == 2) //sequential with vocab loop closure
			{
				sprintf(Fname, "%s/Corpus/ColMapPairs.txt", Path);
				if (IsFileExist(Fname) == 0)
				{
					sprintf(Fname, "%s/Corpus/matches.txt", Path);
					if (IsFileExist(Fname) == 0)
					{
#ifdef _WINDOWS
						if (MatchingMode == 1)
							sprintf(Fname, "%s/vocab_tree_retriever.exe 0 --database_path %s/Corpus/Corpus.db --vocab_tree_path %s --database_image_list_path %s/Corpus/ImageList.txt --query_image_path %s/Corpus --query_image_list_path %s/Corpus/ImageList.txt --queried_output_file %s/Corpus/matches.txt --kNN %d",
								buffer, Path, VocabTreePath, Path, Path, Path, Path, VocMatchingkNN);
						else
							sprintf(Fname, "%s/vocab_tree_retriever.exe 0 --database_path %s/Corpus/Corpus.db --vocab_tree_path %s/Corpus/vocabTree.db --database_image_list_path %s/Corpus/ImageList.txt --query_image_path %s/Corpus --query_image_list_path %s/Corpus/ImageList.txt --queried_output_file %s/Corpus/matches.txt --kNN %d",
								buffer, Path, Path, Path, Path, Path, Path, VocMatchingkNN);

#else
						if (MatchingMode == 1)
							sprintf(Fname, "./vocab_tree_retriever 0 --database_path %s/Corpus/Corpus.db --vocab_tree_path %s --database_image_list_path %s/Corpus/ImageList.txt --query_image_path %s/Corpus --query_image_list_path %s/Corpus/ImageList.txt --queried_output_file %s/Corpus/matches.txt --kNN %d",
								Path, VocabTreePath, Path, Path, Path, Path, VocMatchingkNN);
						else
							sprintf(Fname, "./vocab_tree_retriever 0 --database_path %s/Corpus/Corpus.db --vocab_tree_path %s/Corpus/vocabTree.db --database_image_list_path %s/Corpus/ImageList.txt --query_image_path %s/Corpus --query_image_list_path %s/Corpus/ImageList.txt --queried_output_file %s/Corpus/matches.txt --kNN %d",
								Path, Path, Path, Path, Path, Path, VocMatchingkNN);
#endif
						printLOG(Fname); printLOG("\n"), system(Fname);
					}

					//Make sure nearby images are in the list
					if (ExternalCorpus == -1)
					{
						sprintf(Fname, "%s/Corpus/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
						int maxF = 0, fid, old_cid = -1, cid; Point2i startF_stopF(-1, -1);  vector<Point2i> cid_startF_stopF;
						while (fscanf(fp, "%d %d ", &fid, &cid) != EOF)
						{
							if (cid != old_cid)
							{
								if (startF_stopF.x == -1)
									startF_stopF.x = fid;
								else
								{
									startF_stopF.y = fid - 1;
									cid_startF_stopF.push_back(startF_stopF);
									maxF = max(maxF, startF_stopF.y - startF_stopF.x + 1);
									startF_stopF = Point2i(fid, -1);
								}
								old_cid = cid;
							}
						}
						startF_stopF.y = fid;
						maxF = max(maxF, startF_stopF.y - startF_stopF.x + 1) + 1;
						cid_startF_stopF.push_back(startF_stopF);
						fclose(fp);

						sprintf(Fname, "%s/Corpus/matches.txt", Path); fp = fopen(Fname, "a");
						for (int ii = 0; ii < cid_startF_stopF.size(); ii++)
						{
							int startF = cid_startF_stopF[ii].x, stopF = cid_startF_stopF[ii].y;
							for (int fid = startF; fid <= stopF; fid++)
							{
								for (int jj = -SeqMatchingForcedNearbyImageRange / 2; jj <= SeqMatchingForcedNearbyImageRange / 2; jj++)
								{
									if (fid + jj <  startF || fid + jj > stopF || jj == 0)
										continue;
									fprintf(fp, "%d %d 1.0\n", fid, fid + jj);
								}
							}
						}
						fclose(fp);
					}
					else
					{
						sprintf(Fname, "%s/Corpus/matches.txt", Path); fp = fopen(Fname, "a");
						for (int ii = 0; ii < nCorpusImg; ii++)
						{
							for (int jj = -SeqMatchingForcedNearbyImageRange / 2; jj <= SeqMatchingForcedNearbyImageRange / 2; jj++)
							{
								if (ii + jj <  0 || ii + jj > nCorpusImg - 1 || jj == 0)
									continue;
								fprintf(fp, "%d %d 1.0\n", ii, ii + jj);
							}
						}
						fclose(fp);
					}
					GenerateUnduplicatedCorpusMatchesList(Path, VocMatchingkNN);
				}

#ifdef _WINDOWS
				sprintf(Fname, "%s/matches_importer.exe --database_path %s/Corpus/Corpus.db --match_list_path %s/Corpus/ColMapPairs.txt --SiftMatching.gpu_index=0", buffer, Path, Path);
#else
				sprintf(Fname, "./matches_importer --database_path %s/Corpus/Corpus.db --match_list_path %s/Corpus/ColMapPairs.txt --SiftMatching.gpu_index=0,1,2,3", Path, Path);
#endif
				printLOG("%s\n", Fname); system(Fname);

#ifdef _WINDOWS
				sprintf(Fname, "%s/mapper.exe --database_path %s/Corpus/Corpus.db --image_path %s/Corpus --export_path %s/Corpus --Mapper.ba_global_use_pba 0 --Mapper.ba_global_max_num_iterations 7 --Mapper.ba_global_images_ratio %.2f  --Mapper.ba_global_points_ratio %.1f --Mapper.tri_min_angle %.1f --Mapper.snapshot_path %s/Corpus --Mapper.snapshot_images_freq %d",
					buffer, Path, Path, Path, ba_global_images_ratio, ba_global_points_ratio, ba_global_tri_min_angle, Path, snapshot_images_freq);
#else
				sprintf(Fname, "./mapper --database_path %s/Corpus/Corpus.db --image_path %s/Corpus --export_path %s/Corpus --Mapper.ba_global_use_pba 0 --Mapper.ba_global_max_num_iterations 7 --Mapper.ba_global_images_ratio %.2f  --Mapper.ba_global_points_ratio %.1f --Mapper.tri_min_angle %.1f --Mapper.snapshot_path %s/Corpus --Mapper.snapshot_images_freq %d",
					Path, Path, Path, ba_global_images_ratio, ba_global_points_ratio, ba_global_tri_min_angle, Path, snapshot_images_freq);
#endif
				printLOG("%s\n", Fname); system(Fname);
			}
			else if (MatchingMode == 3 || MatchingMode == 4)
			{
				sprintf(Fname, "%s/Corpus/ColMapPairs.txt", Path);
				if (IsFileExist(Fname) == 0)
				{
#ifdef _WINDOWS
					if (MatchingMode == 3)
						sprintf(Fname, "%s/vocab_tree_matcher.exe --database_path %s/Corpus/Corpus.db --SiftMatching.gpu_index=0 --VocabTreeMatching.num_images %d --VocabTreeMatching.vocab_tree_path %s --VocabTreeMatching.match_list_path %s/Corpus/ImageList.txt",
							buffer, Path, VocMatchingkNN, VocabTreePath, Path);
					else
						sprintf(Fname, "%s/vocab_tree_matcher.exe --database_path %s/Corpus/Corpus.db --SiftMatching.gpu_index=0 --VocabTreeMatching.num_images %d --VocabTreeMatching.vocab_tree_path %s/Corpus/vocabTree.db --VocabTreeMatching.match_list_path %s/Corpus/ImageList.txt",
							buffer, Path, VocMatchingkNN, Path, Path);
#else
					if (MatchingMode == 3)
						sprintf(Fname, "./vocab_tree_matcher --database_path %s/Corpus/Corpus.db --SiftMatching.gpu_index=0,1,2,3 --VocabTreeMatching.num_images %d --VocabTreeMatching.vocab_tree_path %s --VocabTreeMatching.match_list_path %s/Corpus/ImageList.txt",
							Path, VocMatchingkNN, VocabTreePath, Path);
					else
						sprintf(Fname, "./vocab_tree_matcher --database_path %s/Corpus/Corpus.db --SiftMatching.gpu_index=0,1,2,3 --VocabTreeMatching.num_images %d --VocabTreeMatching.vocab_tree_path %s/Corpus/vocabTree.db --VocabTreeMatching.match_list_path %s/Corpus/ImageList.txt",
							Path, VocMatchingkNN, Path, Path);
#endif
					printLOG("%s\n", Fname); system(Fname);
				}

#ifdef _WINDOWS
				sprintf(Fname, "%s/mapper.exe --database_path %s/Corpus/Corpus.db --image_path %s/Corpus --export_path %s/Corpus --Mapper.ba_global_use_pba 0 --Mapper.ba_global_max_num_iterations 7 --Mapper.ba_global_images_ratio %.2f  --Mapper.ba_global_points_ratio %.1f --Mapper.tri_min_angle %.1f --Mapper.snapshot_path %s/Corpus --Mapper.snapshot_images_freq %d",
					buffer, Path, Path, Path, ba_global_images_ratio, ba_global_points_ratio, ba_global_tri_min_angle, Path, snapshot_images_freq);
#else
				sprintf(Fname, "./mapper --database_path %s/Corpus/Corpus.db --image_path %s/Corpus --export_path %s/Corpus --Mapper.ba_global_use_pba 0 --Mapper.ba_global_max_num_iterations 7  --Mapper.ba_global_images_ratio %.2f  --Mapper.ba_global_points_ratio %.1f --Mapper.tri_min_angle %.1f --Mapper.snapshot_path %s/Corpus --Mapper.snapshot_images_freq %d",
					Path, Path, Path, ba_global_images_ratio, ba_global_points_ratio, ba_global_tri_min_angle, Path, snapshot_images_freq);
#endif
				printLOG("%s\n", Fname); system(Fname);
			}
			sprintf(Fname, "%s/Logs/Colmap_mapper.txt", Path);
			fp = fopen(Fname, "w"); fclose(fp);
		}

		sprintf(Fname, "%s/Logs/RefineVisualSfMAndCreateCorpus.txt", Path);
		if (IsFileExist(Fname) == 0)
		{
			printLOG("Refine SFM corpus ... with %d images\n", nCorpusImg);
			sprintf(Fname, "%s/Corpus", Path);
			RefineVisualSfMAndCreateCorpus(Fname, nCorpusImg, ShutterModel, threshold, fixIntrinsic, fixDistortion, fixPose, 1, fixSkew, fixPrism, distortionCorrected, nViewsPlus, LossType, doubleRefinement);
			printLOG("Done with BA\n");

			sprintf(Fname, "%s/Logs/RefineVisualSfMAndCreateCorpus.txt", Path);
			fp = fopen(Fname, "w"); fclose(fp);
		}

		if (ExternalCorpus == -1)
		{
			printLOG("Distribute to SFM corpus ...\n", nCorpusImg);
			DistributeCorpusCalibToAllCamKeyFrames(Path, nCams, distortionCorrected);
		}

		char Fname1[2000], Fname2[512];
		sprintf(Fname1, "%s/Corpus/AvgDevicesIntrinsics.txt", Path);
		sprintf(Fname2, "%s/AvgDevicesIntrinsics.txt", Path);
		if (!MyCopyFile(Fname1, Fname2))
		{
			printLOG("Cannot copy AvgDevicesIntrinsics.txt.\n");
			return 1;
		}
		printLOG("Rebuilding/Refining Corpus: Done\n");
	}

	//4. Localize camera to corpus
	omp_set_num_threads(omp_get_max_threads());
#ifdef SCHEDULER
	double startWaitTime, appMeanTime, appStopTime;
	int stepSize, nstep, alreadyComputed, once;

	//Find matches
	if (module == 4)
	{
		printLOG("Find matches with the corpus\n");

		if (useVocabForPnP)
		{
#ifdef _WINDOWS
			char buffer[512];  myGetCurDir(512, buffer);
			sprintf(Fname, "%s/vocab_tree_builder.exe --database_path %s/Corpus.db --vocab_tree_path %s/vocabTree.db", buffer, Path, Path);
			printLOG(Fname); printLOG("\n"), system(Fname);
			sprintf(Fname, "%s/vocab_tree_retriever.exe --dataPath %s --database_path %s/Corpus.db --vocab_tree_path %s/vocabTree.db --CamID_start %d --CamID_stop %d --database_image_list_path %s/Corpus/ImageList.txt -kNN", buffer, Path, Path, Path, 0, nCams, Path, SeqMatchingForcedNearbyImageRange * 2);
			printLOG(Fname); printLOG("\n"), system(Fname);
#elif EC2
			sprintf(Fname, "qsub -b y -cwd -pe orte %d ./vocab_tree_builder --database_path %s/Corpus.db --vocab_tree_path %s/vocabTree.db", omp_get_max_threads(), Path, Path);
			printLOG(Fname); printLOG("\n"), system(Fname);

			int increC = 5;
			for (int cid = 0; cid < nCams; cid += increC)
			{
				sprintf(Fname, "qsub -b y -cwd -pe orte %d ./vocab_tree_retriever --dataPath %s --database_path %s/Corpus.db --vocab_tree_path %s/vocabTree.db --CamID_start %d --CamID_stop %d --database_image_list_path %s/Corpus/ImageList.txt -kNN",
					min(4, omp_get_max_threads()), Path, Path, Path, cid, cid + increC - 1, Path, SeqMatchingForcedNearbyImageRange * 2);
				printLOG(Fname); printLOG("\n"), system(Fname);
			}
#else
			sprintf(Fname, "./vocab_tree_builder --database_path %s/Corpus.db --vocab_tree_path %s/vocabTree.db", buffer, Path, Path);
			printLOG(Fname); printLOG("\n"), system(Fname);
			sprintf(Fname, "./vocab_tree_retriever --dataPath %s --database_path %s/Corpus.db --vocab_tree_path %s/vocabTree.db --CamID_start %d --CamID_stop %d --database_image_list_path %s/Corpus/ImageList.txt -kNN", Path, Path, Path, 0, nCams, Path, SeqMatchingForcedNearbyImageRange * 2);
			printLOG(Fname); printLOG("\n"), system(Fname);
#endif
		}

		if (ExternalCorpus == -1)
		{
			for (int cid = 0; cid < nCams; cid++)
			{
				sprintf(Fname, "%s/%d/ToMatch2.txt", Path, cid);
				if (IsFileExist(Fname) == 1)
					continue;

				if (useVocabForPnP)
				{
					sprintf(Fname, "%s/%d/VocabMatches.txt", Path, cid);
					startWaitTime = omp_get_wtime(); appStopTime = 9e9;
					while (omp_get_wtime() - startWaitTime < appStopTime)//wait for it to finish
						if (IsFileExist(Fname))
							break;
				}

				GenerateCameraIMatchList(Path, cid, startF, stopF, IncreMatchingFrame, SeqMatchingForcedNearbyImageRange * 2, PnPMatchingForcedNearbyKeyFrameRange);
			}
		}

		/*printLOG("Converting sift features\n");
		#pragma omp parallel for schedule(dynamic,1)
		for (int cid = 0; cid < nCams; cid++)
		{
		char Fname[512];
		for (int fid = startF; fid <= stopF; fid += IncreMatchingFrame)
		sprintf(Fname, "%s/%d/%.4d", Path, cid, fid), convertVisualSFMSiftGPU2KPointsDesc(Fname);
		}*/

		printLOG("Start PnP process\n");
		stepSize = ec2BatchSize * IncreMatchingFrame, nstep = (stopF - startF + 1) / stepSize, alreadyComputed = 0;
		if (nstep == 0)
			nstep = 1, stepSize = stopF + IncreMatchingFrame;
		for (int cid = 0; cid < nCams; cid++)
		{
			sprintf(Fname, "%s/%d/PnP", Path, cid); makeDir(Fname);
			for (int ID = 0; ID < nstep; ID++)
			{
				sprintf(Fname, "%s/Logs/CamLocalizeMatch_%d_%d_%.4d.txt", Path, cid, startF + stepSize * ID, startF + stepSize * (ID + 1) - IncreMatchingFrame);
				if (IsFileExist(Fname) == 0)
				{
#ifdef  _WINDOWS
					sprintf(Fname, "EnRecon.exe %s %d %d %d %d %d %d %d %d %d %d", Path, 5, startF + stepSize * ID, startF + stepSize * (ID + 1) - IncreMatchingFrame, IncreMatchingFrame, cid, nCams, 0, distortionCorrected, CameraLensModel[cid], UsePnPFilterForMatching);
					printLOG(Fname); printLOG("\n");	system(Fname);
#elif EC2
					//sprintf(Fname, "qsub -b y -cwd -pe orte 1 ./EnRecon %s %d %d %d %d %d %d %d %d %d %d", Path, 5, startF + stepSize*ID, startF + stepSize*(ID + 1) - IncreMatchingFrame, IncreMatchingFrame, cid, nCams, 0, distortionCorrected, CameraLensModel[cid], UsePnPFilterForMatching);
					//printLOG(Fname); printLOG("\n");	system(Fname);
#else
					sprintf(Fname, "./EnRecon %s %d %d %d %d %d %d %d %d %d %d", Path, 5, startF + stepSize * ID, startF + stepSize * (ID + 1) - IncreMatchingFrame, IncreMatchingFrame, cid, nCams, 0, distortionCorrected, CameraLensModel[cid], UsePnPFilterForMatching);
					printLOG(Fname); printLOG("\n");	system(Fname);
#endif
				}
				else
					alreadyComputed++;
				njobs.push_back(0);
			}
		}
		bestSum = 0, once = 1;
		startWaitTime = omp_get_wtime(); appStopTime = 9e9;  appMeanTime = 9e9;
		while (omp_get_wtime() - startWaitTime < appStopTime)//wait for it to finish
		{
			mySleep(10e3);
			int count = 0;
			for (int cid = 0; cid < nCams; cid++)
			{
				for (int ID = 0; ID < nstep; ID++)
				{
					sprintf(Fname, "%s/Logs/CamLocalizeMatch_%d_%d_%.4d.txt", Path, cid, startF + stepSize * ID, startF + stepSize * (ID + 1) - IncreMatchingFrame);
					if (IsFileExist(Fname) == 1)
					{
						appMeanTime = omp_get_wtime() - startWaitTime;
						njobs[count] = 1;
					}
					count++;
				}
			}
			int sumRes = 0;
			for (int ii = 0; ii < (int)njobs.size(); ii++)
				sumRes += njobs[ii];

			if (sumRes - alreadyComputed > ((int)njobs.size() - alreadyComputed) / 2 && once == 1)
			{
				once = 2;
				appStopTime = appMeanTime * 3;
				printLOG("\nSet max waiting time: %.2fs\n", appStopTime);
			}

			if (sumRes == (int)njobs.size())
				break;
			if (bestSum < sumRes)
			{
				bestSum = sumRes;
				printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
			}
		}
		//for (int cid = 0; cid < nCams; cid++)
		//for (int ID = 0; ID < nstep; ID++)
		// sprintf(Fname, "%s/Logs/CamLocalizeMatch_%d_%d_%.4d.txt", Path, cid, startF + stepSize*ID, startF + stepSize*(ID + 1) - IncreMatchingFrame), remove(Fname);
	}

	//Do Pnp: the distortion flag will be taken from corpus BA results. So, unless the intriniscs are time-varying, this flag is not important here
	if (module == 5)
	{
		printLOG("Do PnP to the corpus\n");
		njobs.clear();
		stepSize = ec2BatchSize * IncreMatchingFrame, nstep = (stopF - startF + 1) / stepSize, alreadyComputed = 0;
		if (nstep == 0)
			nstep = 1, stepSize = stopF + IncreMatchingFrame;

		//sprintf(Fname, "job.txt"); FILE *fp = fopen(Fname, "w");
		//for (int cid = 0; cid < nCams; cid++)
		//	for (int ID = 0; ID < nstep; ID++)
		//		fprintf(fp, "./EnRecon %s %d %d %d %d %d %d %d %d %d %d\n", Path, 5, startF + stepSize*ID, startF + stepSize*(ID + 1) - IncreMatchingFrame, IncreMatchingFrame, cid, nCams, 1,  distortionCorrected == 0 ? 1 : 2, CameraLensModel[cid], UsePnPFilter);
		//fclose(fp);

		for (int cid = 0; cid < nCams; cid++)
		{
			for (int ID = 0; ID < nstep; ID++)
			{
				sprintf(Fname, "%s/Logs/CamLocalizePnP_%d_%d_%.4d.txt", Path, cid, startF + stepSize * ID, startF + stepSize * (ID + 1) - IncreMatchingFrame);
				if (IsFileExist(Fname) == 0)
				{
#ifdef  _WINDOWS
					sprintf(Fname, "EnRecon.exe %s %d %d %d %d %d %d %d %d %d %d", Path, 5, startF + stepSize * ID, startF + stepSize * (ID + 1) - IncreMatchingFrame, IncreMatchingFrame, cid, nCams, 1, distortionCorrected == 0 ? 1 : 2, CameraLensModel[cid], UsePnPFilter);
					printLOG(Fname); printLOG("\n");	system(Fname);
#elif EC2
					sprintf(Fname, "qsub -b y -cwd -pe orte 1 ./EnRecon %s %d %d %d %d %d %d %d %d %d %d", Path, 5, startF + stepSize * ID, startF + stepSize * (ID + 1) - IncreMatchingFrame, IncreMatchingFrame, cid, nCams, 1, distortionCorrected == 0 ? 1 : 2, CameraLensModel[cid], UsePnPFilter);
					printLOG(Fname); printLOG("\n");	system(Fname);
#else
					sprintf(Fname, "./EnRecon %s %d %d %d %d %d %d %d %d %d %d", Path, 5, startF + stepSize * ID, startF + stepSize * (ID + 1) - IncreMatchingFrame, IncreMatchingFrame, cid, nCams, 1, distortionCorrected == 0 ? 1 : 2, CameraLensModel[cid], UsePnPFilter);
					printLOG(Fname); printLOG("\n");	system(Fname);
#endif

				}
				else
					alreadyComputed++;
				njobs.push_back(0);
			}
		}
		bestSum = 0, once = 1;
		startWaitTime = omp_get_wtime(); appStopTime = 9e9;  appMeanTime = 9e9;
		while (omp_get_wtime() - startWaitTime < appStopTime)//wait for it to finish
		{
			mySleep(10e3);
			int count = 0;
			for (int cid = 0; cid < nCams; cid++)
			{
				for (int ID = 0; ID < nstep; ID++)
				{
					sprintf(Fname, "%s/Logs/CamLocalizePnP_%d_%d_%.4d.txt", Path, cid, startF + stepSize * ID, startF + stepSize * (ID + 1) - IncreMatchingFrame);
					if (IsFileExist(Fname) == 1)
					{
						appMeanTime = omp_get_wtime() - startWaitTime;
						njobs[count] = 1;
					}
					else
						printLOG("Cannot load %s\n", Fname);
					count++;
				}
			}
			int sumRes = 0;
			for (int ii = 0; ii < (int)njobs.size(); ii++)
				sumRes += njobs[ii];

			if (sumRes - alreadyComputed > ((int)njobs.size() - alreadyComputed) / 2 && once == 1)
			{
				once = 2;
				appStopTime = appMeanTime * 3;
				printLOG("\nSet max waiting time: %.2fs\n", appStopTime);
			}

			if (sumRes == (int)njobs.size())
				break;
			if (bestSum < sumRes)
			{
				bestSum = sumRes;
				printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
			}
		}
		//	for (int cid = 0; cid < nCams; cid++)
		//for (int ID = 0; ID < nstep; ID++)
		//sprintf(Fname, "%s/Logs/CamLocalizePnP_%d_%d_%.4d.txt", Path, cid, startF + stepSize*ID, startF + stepSize*(ID + 1) - IncreMatchingFrame), remove(Fname);
	}

	if (module == 6)
	{
		nstep = 4, alreadyComputed = 0;
		//if (TrackCorpusPoints == 1)
		{
			//Propagate corpus points
			printLOG("Track corpus points \n");
			njobs.clear();
			/*for (int cid = 0; cid < nCams; cid++)
			{
			sprintf(Fname, "job_%d.txt", cid); FILE *fp = fopen(Fname, "w");
			for (int fid = startF; fid <= stopF; fid += increF*IncreMatchingFrame*nstep)
			{
			fprintf(fp, "./EnRecon %s 9 %d %d %d %d %d %d %d %d %d %.2f %d\n", Path,
			cid, fid, fid + increF*IncreMatchingFrame*(nstep - 1), increF, IncreMatchingFrame, CorpusTrackRange, nWins, WinStep, cvPyrLevel, meanSSGThresh,  distortionCorrected == 0 ? 1 : 2); //assign 1 cores suffers from memory problem
			}
			fclose(fp);
			}*/

			for (int cid = 0; cid < nCams; cid++)
			{
				int CameraNotCalibrated = 0;
				sprintf(Fname, "%s/AvgDevicesIntrinsics.txt", Path); FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
					CameraNotCalibrated = 1;
				else
				{
					CameraNotCalibrated = 1;
					int dummyi; double dummyf;
					while (fscanf(fp, "%s %d %d %d %d %lf %lf %lf %lf %lf ", Fname, &dummyi, &dummyi, &dummyi, &dummyi, &dummyf, &dummyf, &dummyf, &dummyf, &dummyf) != EOF)
					{
						string filename = string(Fname);
						std::size_t posDot = filename.find(".");
						filename.erase(posDot, 4);
						if (atoi(filename.c_str()) == cid)
						{
							CameraNotCalibrated = 0;
							break;
						}
					}
				}

				for (int fid = startF; fid <= stopF; fid += increF * IncreMatchingFrame*nstep)
				{
					sprintf(Fname, "%s/Logs/TrackCorpus_%d_%d_%.4d.txt", Path, cid, fid, fid + increF * IncreMatchingFrame*(nstep - 1));
					if (IsFileExist(Fname) == 0)
					{
#ifdef _WINDOWS
						sprintf(Fname, "EnRecon.exe %s 9 %d %d %d %d %d %d %d %d %d %.2f %d %d %d ", Path,
							cid, fid, fid + increF * IncreMatchingFrame*(nstep - 1), increF, IncreMatchingFrame, CorpusTrackRange, nWins, WinStep, cvPyrLevel, meanSSGThresh, CameraNotCalibrated, distortionCorrected == 0 ? 1 : 2, interpAlgo);
						printLOG(Fname); printLOG("\n");	system(Fname);
#elif EC2
						sprintf(Fname, "qsub -b y -cwd -pe orte 2 ./EnRecon %s 9 %d %d %d %d %d %d %d %d %d %.2f %d %d %d", Path,
							cid, fid, fid + increF * IncreMatchingFrame*(nstep - 1), increF, IncreMatchingFrame, CorpusTrackRange, nWins, WinStep, cvPyrLevel, meanSSGThresh, CameraNotCalibrated, distortionCorrected == 0 ? 1 : 2, interpAlgo); //assign 1 cores suffers from memory problem
						printLOG(Fname); printLOG("\n");	system(Fname);
#else
						sprintf(Fname, "./EnRecon %s 9 %d %d %d %d %d %d %d %d %d %.2f %d %d %d", Path,
							cid, fid, fid + increF * IncreMatchingFrame*(nstep - 1), increF, IncreMatchingFrame, CorpusTrackRange, nWins, WinStep, cvPyrLevel, meanSSGThresh, CameraNotCalibrated, distortionCorrected == 0 ? 1 : 2, interpAlgo); //assign 1 cores suffers from memory problem
						printLOG(Fname); printLOG("\n");	system(Fname);
#endif
					}
					else
						alreadyComputed++;
					njobs.push_back(0);
				}
			}
			bestSum = 0, once = 1;
			printLOG("Track corpus points \n");
			startWaitTime = omp_get_wtime(); appStopTime = 9e9;  appMeanTime = 9e9;
			while (omp_get_wtime() - startWaitTime < appStopTime)//wait for it to finish
			{
				mySleep(10e3);
				int count = 0;
				for (int cid = 0; cid < nCams; cid++)
				{
					for (int fid = startF; fid <= stopF; fid += increF * IncreMatchingFrame*nstep)
					{
						sprintf(Fname, "%s/Logs/TrackCorpus_%d_%d_%.4d.txt", Path, cid, fid, fid + increF * IncreMatchingFrame*(nstep - 1));
						if (IsFileExist(Fname) == 1)
						{
							appMeanTime = omp_get_wtime() - startWaitTime;
							njobs[count] = 1;
						}
						count++;
					}
				}
				int sumRes = 0;
				for (int ii = 0; ii < (int)njobs.size(); ii++)
					sumRes += njobs[ii];

				if (sumRes - alreadyComputed > ((int)njobs.size() - alreadyComputed) / 2 && once == 1)
				{
					once = 2;
					appStopTime = appMeanTime * 3;
					printLOG("\nSet max waiting time: %.2fs\n", appStopTime);
				}

				if (sumRes == (int)njobs.size())
					break;
				if (bestSum < sumRes)
				{
					bestSum = sumRes;
					printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
				}
			}
			//for (int cid = 0; cid < nCams; cid++)
			//for (int fid = startF; fid <= stopF; fid += increF*IncreMatchingFrame)
			//sprintf(Fname, "%s/Logs/TrackCorpus_%d_%d_%.4d.txt", Path, cid, fid, fid + increF*IncreMatchingFrame*(nstep-1)), remove(Fname);
			printLOG("Done\n");

			//Merge track
			printLOG("Merging  tracked corpus points\n");
			for (int cid = 0; cid < nCams; cid++)
				MergeTrackedCorpusPoints(Path, cid, startF, stopF, increF);
			printLOG("Done\n");

			//compute pose again in case un-localized cameras' correspondences got propagated
			printLOG("Re-localize camera to corpus\n");
			njobs.clear();
			for (int cid = 0; cid < nCams; cid++)
			{
				sprintf(Fname, "%s/ForcePnP_%d_%d_%.4d.txt", Path, cid, startF, stopF);
				if (IsFileExist(Fname) == 0)
				{
#ifdef _WINDOWS
					sprintf(Fname, "EnRecon.exe %s %d %d %d %d %d %d %d %d %d %d", Path,
						5, startF, stopF, increF, cid, nCams, 2, distortionCorrected == 0 ? 1 : 2, CameraLensModel[cid], ShutterModel);
#elif EC2
					sprintf(Fname, "qsub -b y -cwd -pe orte 2 ./EnRecon %s %d %d %d %d %d %d %d %d %d %d", Path,
						5, startF, stopF, increF, cid, nCams, 2, distortionCorrected == 0 ? 1 : 2, CameraLensModel[cid], ShutterModel);
#else
					sprintf(Fname, "./EnRecon %s %d %d %d %d %d %d %d %d %d %d", Path,
						5, startF, stopF, increF, cid, nCams, 2, distortionCorrected == 0 ? 1 : 2, CameraLensModel[cid], ShutterModel);
#endif
					printLOG(Fname); printLOG("\n");
					system(Fname);
				}
				else
					alreadyComputed++;
				njobs.push_back(0);
			}
			bestSum = 0, once = 1;
			startWaitTime = omp_get_wtime(); appStopTime = 9e9;  appMeanTime = 9e9;
			while (omp_get_wtime() - startWaitTime < appStopTime)//wait for it to finish
			{
				mySleep(10e3);
				int count = 0;
				for (int cid = 0; cid < nCams; cid++)
				{
					sprintf(Fname, "%s/ForcePnP_%d_%d_%.4d.txt", Path, cid, startF, stopF);
					if (IsFileExist(Fname) == 1)
					{
						appMeanTime = omp_get_wtime() - startWaitTime;
						njobs[count] = 1;
					}
					//else
					//printLOG("Cannot load %s\n", Fname);
					count++;
				}
				int sumRes = 0;
				for (int ii = 0; ii < (int)njobs.size(); ii++)
					sumRes += njobs[ii];

				if (sumRes - alreadyComputed > ((int)njobs.size() - alreadyComputed) / 2 && once == 1)
				{
					once = 2;
					appStopTime = appMeanTime * 3;
					printLOG("\nSet max waiting time: %.2fs\n", appStopTime);
				}

				if (sumRes == (int)njobs.size())
					break;
				if (bestSum < sumRes)
				{
					bestSum = sumRes;
					printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
				}
			}
			printLOG("Done\n");
		}
	}

	if (module == 7)
	{
		printLOG("Video refinement\n");
		njobs.clear(); alreadyComputed = 0;
		int nthreadsAvail = omp_get_max_threads();
		int fix3D = 1; //do not change 3D corpus points since this does not optimize over all cameras
		for (int cid = 0; cid < nCams; cid++)
		{
			sprintf(Fname, "%s/Logs/PerCamBA_%d_%d_%.4d.txt", Path, cid, startF, stopF);
			if (IsFileExist(Fname) == 0)
			{
				if (ShutterModel == 0)
				{
#ifdef _WINDOWS
					sprintf(Fname, "EnRecon.exe %s %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %.2f", Path,
						5, startF, stopF, increF, cid, nCams, 3, fixIntrinsic, fixDistortion, fix3D, fixSkew, fixPrism, distortionCorrected == 0 ? 1 : 2, nViewsPlus2, LossType, threshold);
#elif EC2
					sprintf(Fname, "qsub -b y -cwd -pe orte %d ./EnRecon %s %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %.2f, Path",
						min(8, nthreadsAvail), 5, startF, stopF, increF, cid, nCams, 3, fixIntrinsic, fixDistortion, fix3D, fixSkew, fixPrism, distortionCorrected == 0 ? 1 : 2, nViewsPlus2, LossType, threshold);
#else
					sprintf(Fname, " ./EnRecon %s %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %.2f", Path,
						5, startF, stopF, increF, cid, nCams, 3, fixIntrinsic, fixDistortion, fix3D, fixSkew, fixPrism, distortionCorrected == 0 ? 1 : 2, nViewsPlus2, LossType, threshold);
#endif
				}
				else
				{
#ifdef _WINDOWS
					sprintf(Fname, "EnRecon.exe %s %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %.2f", Path,
						5, startF, stopF, increF, cid, nCams, 4, fixIntrinsic, fixDistortion, 0, fix3D, fixSkew, fixPrism, distortionCorrected == 0 ? 1 : 2, nViewsPlus2, LossType, threshold);
#elif EC2
					sprintf(Fname, "qsub -b y -cwd -pe orte %d ./EnRecon %s %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %.2f", Path,
						min(8, nthreadsAvail), 5, startF, stopF, increF, cid, nCams, 4, fixIntrinsic, fixDistortion, 0, fix3D, fixSkew, fixPrism, distortionCorrected == 0 ? 1 : 2, nViewsPlus2, LossType, threshold);
#else
					sprintf(Fname, "./EnRecon %s %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %.2f", Path,
						5, startF, stopF, increF, cid, nCams, 4, fixIntrinsic, fixDistortion, 0, fix3D, fixSkew, fixPrism, distortionCorrected == 0 ? 1 : 2, nViewsPlus2, LossType, threshold);
#endif
				}
				printLOG(Fname); printLOG("\n");
				system(Fname);
			}
			else
				alreadyComputed++;
			njobs.push_back(0);
		}
		bestSum = 0, once = 1;
		startWaitTime = omp_get_wtime(); appStopTime = 9e9;  appMeanTime = 9e9;
		while (omp_get_wtime() - startWaitTime < appStopTime)//wait for it to finish
		{
			mySleep(30e3);
			int count = 0;
			for (int cid = 0; cid < nCams; cid++)
			{
				sprintf(Fname, "%s/Logs/PerCamBA_%d_%d_%.4d.txt", Path, cid, startF, stopF);
				if (IsFileExist(Fname) == 1)
				{
					njobs[count] = 1;
					appMeanTime = omp_get_wtime() - startWaitTime;
				}
				count++;
			}
			int sumRes = 0;
			for (int ii = 0; ii < (int)njobs.size(); ii++)
				sumRes += njobs[ii];
			if (sumRes - alreadyComputed > ((int)njobs.size() - alreadyComputed) / 2 && once == 1)
			{
				once = 2;
				appStopTime = appMeanTime * 3;
				printLOG("\nSet max waiting time: %.2fs\n", appStopTime);
			}
			if (sumRes == (int)njobs.size())
				break;
			if (bestSum < sumRes)
			{
				bestSum = sumRes;
				printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
			}
		}
		printLOG("Done\n");
	}
#else
	vector<int> vCams;
	for (int ii = 0; ii < mySfMPara.nCams; ii++)
		vCams.push_back(ii);

	if (module == 4)
	{
		printLOG("Retrieve NNs of per-camera's keyframe to Corpus\n");
		sprintf(Fname, "%s/vCamIDquery.txt", Path);
		fp = fopen(Fname, "w");
		for (int ii = 0; ii < vCams.size(); ii++)
			fprintf(fp, "%d ", vCams[ii]);
		fclose(fp);

		//more efficient to generate VocabMatches.txt but assume all cameras will be used since the retrival pool is indexed only once(cannot distingush corpus dedicated camera)
#ifdef _WINDOWS
		if (MatchingMode == 0 || MatchingMode == 1 || MatchingMode == 3)//use pretrained vocabDB
			sprintf(Fname, "%s/vocab_tree_retriever.exe 1 --dataPath %s --database_path %s/Corpus/Corpus.db --vocab_tree_path %s --vCamIDList vCamIDquery.txt --database_image_list_path %s/Corpus/ImageList.txt --kNN %d", buffer, Path, Path, VocabTreePath, Path, SeqMatchingForcedNearbyImageRange * 2);
		else//use scene specific vocabDB
			sprintf(Fname, "%s/vocab_tree_retriever.exe 1 --dataPath %s --database_path %s/Corpus/Corpus.db --vocab_tree_path %s/Corpus/vocabTree.db --vCamIDList vCamIDquery.txt --database_image_list_path %s/Corpus/ImageList.txt --kNN %d", buffer, Path, Path, Path, Path, SeqMatchingForcedNearbyImageRange * 2);
		printLOG(Fname); printLOG("\n"), system(Fname);
#else
		if (MatchingMode == 0 || MatchingMode == 1 || MatchingMode == 3)//use pretrained vocabDB
			sprintf(Fname, "./vocab_tree_retriever 1 --dataPath %s --database_path %s/Corpus/Corpus.db --vocab_tree_path %s --vCamIDList vCamIDquery.txt --database_image_list_path %s/Corpus/ImageList.txt --kNN %d", Path, Path, VocabTreePath, Path, SeqMatchingForcedNearbyImageRange * 2);
		else//use scene specific vocabDB
			sprintf(Fname, "./vocab_tree_retriever 1 --dataPath %s --database_path %s/Corpus/Corpus.db --vocab_tree_path %s/Corpus/vocabTree.db --vCamIDList vCamIDquery.txt --database_image_list_path %s/Corpus/ImageList.txt --kNN %d", Path, Path, Path, Path, SeqMatchingForcedNearbyImageRange * 2);
		printLOG(Fname); printLOG("\n"), system(Fname);
#endif

#pragma omp parallel for schedule(dynamic,1)
		for (int ii = 0; ii < vCams.size(); ii++)
		{
			int cid = vCams[ii];
			sprintf(Fname, "%s/%d/VocabMatches.txt", Path, cid);
			if (IsFileExist(Fname) == 1)
				GenerateCameraIMatchList(Path, cid, startF, stopF, 1, SeqMatchingForcedNearbyImageRange * 2, PnPMatchingForcedNearbyKeyFrameRange); //ensure that close-by kfs should match to the same corpus frame
		}

		printf("Done with module %d\n", module);
	}
	if (module == 5)
	{
		printLOG("\n*******Find Match to Corpus for PnP*******\n");
		for (auto cid : vCams)
		{
			sprintf(Fname, "%s/Logs/CamLocalizeMatch_%d_%d_%.4d.txt", Path, cid, startF, stopF);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "./EnRecon %s 5 0 %d %d %d %d %d %d\n", Path, startF, stopF, increF, cid, distortionCorrected, CameraLensModel[cid]);
				printLOG(Fname);

				LocalizeCameraToCorpusDriver(Path, startF, stopF, increF, 0, cid, distortionCorrected, nInlierThresh, 0);
				sprintf(Fname, "%s/Logs/CamLocalizeMatch_%d_%d_%.4d.txt", Path, cid, startF, stopF); FILE*fp = fopen(Fname, "w"); fclose(fp);
			}
		}
	}
	if (module == 6)
	{
		printLOG("\n*******PnP to Corpus*******\n");
		for (int cid = 0; cid < nCams; cid++)
		{
			sprintf(Fname, "%s/Logs/CamLocalizePnP_%d_%d_%.4d.txt", Path, cid, startF, stopF);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "./EnRecon %s 5 1 %d %d %d %d %d %d\n", Path, startF, stopF, increF, cid, distortionCorrected, CameraLensModel[cid]);
				printLOG(Fname);

				LocalizeCameraToCorpusDriver(Path, startF, stopF, increF, 1, cid, distortionCorrected, nInlierThresh, 0);
				sprintf(Fname, "%s/Logs/CamLocalizePnP_%d_%d_%.4d.txt", Path, cid, startF, stopF); FILE*fp = fopen(Fname, "w"); fclose(fp);
			}
		}
	}
	if (module == 7) //generate kf matches within video. If the kf of these videos are registered to the global corpus, the matched info can constrain the global corpus--kf registration
	{
		for (int ii = 0; ii < vCams.size(); ii++)
		{
			int cid = vCams[ii];
			if (cid == ExternalCorpus)
				continue;

			sprintf(Fname, "%s/%d/V.db", Path, cid);
			//if (IsFileExist(Fname) == 0)
			{
#ifdef _WINDOWS
				sprintf(Fname, "%s/feature_importer.exe --database_path %s/%d/V.db --image_path %s/%d --import_path %s/%d/ --image_list %s/%d/querry.txt", buffer, Path, cid, Path, cid, Path, cid, Path, cid);
				printLOG("%s\n", Fname); system(Fname);
#else
				sprintf(Fname, "./feature_importer --database_path %s/%d/V.db --image_path %s/%d --import_path %s/%d/ --image_list %s/%d/querry.txt", Path, cid, Path, cid, Path, cid, Path, cid);
				printLOG("%s\n", Fname); system(Fname);
#endif
			}

			sprintf(Fname, "%s/%d/instreamMatches.txt", Path, cid);
			//if (IsFileExist(Fname) == 0)
			{
#ifdef _WINDOWS
				if (MatchingMode == 0 || MatchingMode == 1 || MatchingMode == 3)//use pretrained vocabDB
					sprintf(Fname, "%s/vocab_tree_matcher.exe --database_path %s/%d/V.db --SiftMatching.gpu_index=0 --VocabTreeMatching.num_images 80 --VocabTreeMatching.vocab_tree_path %s --VocabTreeMatching.match_list_path %s/%d/querry.txt", buffer, Path, cid, mySfMPara.VocabTreePath, Path, cid);
				else//use scene specific vocabDB
					sprintf(Fname, "%s/vocab_tree_matcher.exe --database_path %s/%d/V.db --SiftMatching.gpu_index=0 --VocabTreeMatching.num_images 80 --VocabTreeMatching.vocab_tree_path %s/Corpus/vocabTree.db --VocabTreeMatching.match_list_path %s/%d/querry.txt", buffer, Path, cid, Path, Path, cid);
				printLOG("%s\n", Fname); system(Fname);
#else
				if (MatchingMode == 0 || MatchingMode == 1 || MatchingMode == 3)//use pretrained vocabDB
					sprintf(Fname, "./vocab_tree_matcher --database_path %s/%d/V.db --SiftMatching.gpu_index=0 --VocabTreeMatching.num_images 80 --VocabTreeMatching.vocab_tree_path %s --VocabTreeMatching.match_list_path %s/%d/querry.txt", Path, cid, mySfMPara.VocabTreePath, Path, cid);
				else//use scene specific vocabDB
					sprintf(Fname, "./vocab_tree_matcher --database_path %s/%d/V.db --SiftMatching.gpu_index=0 --VocabTreeMatching.num_images 80 --VocabTreeMatching.vocab_tree_path %s/Corpus/vocabTree.db --VocabTreeMatching.match_list_path %s/%d/querry.txt", Path, cid, Path, Path, cid);
				printLOG("%s\n", Fname); system(Fname);
#endif

#ifdef _WINDOWS
				sprintf(Fname, "python %s/export_inlier_matches.py --database_path %s/%d/V.db --output_path %s/%d/instreamMatches.txt --min_num_matches %d", buffer, Path, cid, Path, cid, 30);
#else
				sprintf(Fname, "python export_inlier_matches.py --database_path %s/%d/V.db --output_path %s/%d/instreamMatches.txt --min_num_matches %d", Path, cid, Path, cid, 30);
#endif
				printLOG("%s\n", Fname); system(Fname);
			}
		}
	}
	if (module == 8)  //Redo registration to corpus via local video BA for kf with anchored global Corpus
	{
		sprintf(Fname, "%s/kfPose", Path), makeDir(Fname);

		for (int cid = 0; cid < nCams; cid++)
		{
			if (cid == ExternalCorpus)
				continue;

			sprintf(Fname, "%s/Logs/VideoKeyframe2Corpus_SFM_%d_%d_%.4d.txt", Path, cid, startF, stopF);
			if (IsFileExist(Fname) == 0)
			{
				VideoKeyframe2Corpus_SFM(Path, cid, mySfMPara);

				char Fname1[512], Fname2[512];
				sprintf(Fname1, "%s/Intrinsic_%.4d.txt", Path, cid);
				sprintf(Fname2, "%s/kfPose/Intrinsic_%.4d.txt", Path, cid);
				MyCopyFile(Fname1, Fname2);
				sprintf(Fname1, "%s/CamPose_%.4d.txt", Path, cid);
				sprintf(Fname2, "%s/kfPose/CamPose_%.4d.txt", Path, cid);
				MyCopyFile(Fname1, Fname2);

				sprintf(Fname, "%s/Logs/VideoKeyframe2Corpus_SFM_%d_%d_%.4d.txt", Path, cid, startF, stopF);
				FILE*fp = fopen(Fname, "w"); fclose(fp);
			}
		}
	}

	if (module == 9)
	{
		printLOG("\n*******Track Global Corpus Points for all Keyframes*******\n");
		int nstep = 4;

		for (int cid = 0; cid < nCams; cid++)
		{
			if (ExternalCorpus == cid)
				continue;

			bool staticCam = false;
			sprintf(Fname, "%s/staticCamList.txt", Path);
			if (IsFileExist(Fname))
			{
				int scid;
				FILE *fp = fopen(Fname, "r");
				while (fscanf(fp, "%d ", &scid) != EOF)
				{
					if (cid == scid)
						staticCam = true;
				}
				fclose(fp);
			}

			if (staticCam)
				continue;

			sprintf(Fname, "%s/Logs/TrackCorpusPointsFromKeyFrames_%d_%d_%.4d.txt", Path, cid, startF, stopF);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/PnPf", Path, cid), makeDir(Fname);
				sprintf(Fname, "%s/%d/PnPTc", Path, cid), makeDir(Fname);
				sprintf(Fname, "%s/%d/PnPmTc", Path, cid), makeDir(Fname);

				//identify keyframe
				int  dummy, rfid;
				vector<int> KeyFrameID2LocalFrameID;
				sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, cid);
				if (!IsFileExist(Fname))
					continue;
				FILE *fp = fopen(Fname, "r");
				while (fscanf(fp, "%d %d %d %d ", &dummy, &dummy, &rfid, &dummy) != EOF)
					KeyFrameID2LocalFrameID.push_back(rfid);
				fclose(fp);

				VideoData VideoI;
				if (ReadVideoDataI(Path, VideoI, cid, mySfMPara.startF, mySfMPara.stopF) == 1)
					return 1;

				if (ExternalCorpus == -1)
					convertPnP2KPnP(Path, cid, mySfMPara.startF, mySfMPara.stopF);

				vector<int> ValidKeyFrames;  ValidKeyFrames.reserve(KeyFrameID2LocalFrameID.size());
				for (size_t keyFrameID = 0; keyFrameID < KeyFrameID2LocalFrameID.size(); keyFrameID++)
				{
					sprintf(Fname, "%s/%d/PnP/KF_Inliers_%.4d.txt", Path, cid, KeyFrameID2LocalFrameID[keyFrameID]);
					if (IsFileExist(Fname) == 1 && VideoI.VideoInfo[KeyFrameID2LocalFrameID[keyFrameID]].valid == 1)
						ValidKeyFrames.push_back(1);
					else
						ValidKeyFrames.push_back(0);
				}

				for (size_t keyFrameID = 0; keyFrameID < KeyFrameID2LocalFrameID.size(); keyFrameID++)
				{
					int winDim = mySfMPara.trackingWinSize, cvPyrLevel = mySfMPara.cvPyrLevel, trackRange;
					int reffid = KeyFrameID2LocalFrameID[keyFrameID];

					if (keyFrameID == 0)
					{
						int nextValidFrame = keyFrameID + 2;
						for (int ii = nextValidFrame; ii < KeyFrameID2LocalFrameID.size(); ii++)
						{
							if (ValidKeyFrames[ii] == 1)
							{
								nextValidFrame = ii;
								break;
							}
						}
						trackRange = (KeyFrameID2LocalFrameID[nextValidFrame] - KeyFrameID2LocalFrameID[keyFrameID]);
					}
					else if (keyFrameID == KeyFrameID2LocalFrameID.size() - 1)
					{
						int nextValidFrame = keyFrameID - 2;
						for (int ii = nextValidFrame; ii >= 0; ii--)
						{
							if (ValidKeyFrames[ii] == 1)
							{
								nextValidFrame = ii;
								break;
							}
						}
						trackRange = (KeyFrameID2LocalFrameID[keyFrameID] - KeyFrameID2LocalFrameID[nextValidFrame]);
					}
					else if (keyFrameID > 1 && keyFrameID < KeyFrameID2LocalFrameID.size() - 2)
					{
						int nextValidFrame1 = keyFrameID + 2;
						for (int ii = nextValidFrame1; ii < KeyFrameID2LocalFrameID.size(); ii++)
						{
							if (ValidKeyFrames[ii] == 1)
							{
								nextValidFrame1 = ii;
								break;
							}
						}
						int nextValidFrame2 = keyFrameID - 2;
						for (int ii = nextValidFrame2; ii >= 0; ii--)
						{
							if (ValidKeyFrames[ii] == 1)
							{
								nextValidFrame2 = ii;
								break;
							}
						}
						trackRange = max(KeyFrameID2LocalFrameID[nextValidFrame1] - KeyFrameID2LocalFrameID[keyFrameID], KeyFrameID2LocalFrameID[keyFrameID] - KeyFrameID2LocalFrameID[nextValidFrame2]);
					}
					else if (keyFrameID > 0 && keyFrameID < KeyFrameID2LocalFrameID.size() - 1)
					{
						int nextValidFrame1 = keyFrameID + 1;
						for (int ii = nextValidFrame1; ii < KeyFrameID2LocalFrameID.size(); ii++)
						{
							if (ValidKeyFrames[ii] == 1)
							{
								nextValidFrame1 = ii;
								break;
							}
						}
						int nextValidFrame2 = keyFrameID - 1;
						for (int ii = nextValidFrame2; ii >= 0; ii--)
						{
							if (ValidKeyFrames[ii] == 1)
							{
								nextValidFrame2 = ii;
								break;
							}
						}
						trackRange = 2 * max(KeyFrameID2LocalFrameID[nextValidFrame1] - KeyFrameID2LocalFrameID[keyFrameID], KeyFrameID2LocalFrameID[keyFrameID] - KeyFrameID2LocalFrameID[nextValidFrame2]);
					}
					//this function produces raw, distorted features
					double startTime = omp_get_wtime();
					printLOG("Keyframe #%d-->(%d, %d) [%d] ", keyFrameID, cid, reffid, trackRange);
					TrackGlocalLocalCorpusFeatureToNonKeyFrames(Path, cid, keyFrameID, reffid, trackRange, winDim, cvPyrLevel, 1.0, kfSuccessConsecutiveTrackingRatio*0.5, kfSuccessRefTrackingRatio*0.5, 300, -1, highQualityTracking, omp_get_max_threads(), 0);
					printLOG("%.2fs\n", omp_get_wtime() - startTime);
				}

				MergeTrackedCorpusFeaturetoNonKeyframe2(Path, cid, KeyFrameID2LocalFrameID, startF, stopF, increF);
				ForceLocalizeCameraToCorpusDriver(Path, startF, stopF, increF, cid, distortionCorrected, nInlierThresh2, fromKeyFrameTracking);

				sprintf(Fname, "%s/Logs/TrackCorpusPointsFromKeyFrames_%d_%d_%.4d.txt", Path, cid, startF, stopF); fp = fopen(Fname, "w"); fclose(fp);
			}
		}
	}
	if (module == 10)
	{
		int fix3D = 1, fixLocal3D = 0, fixIntrinsic = 0; //do not change 3D corpus points since this does not optimize over all cameras
		vector<int> sCams;
		for (int cid = 0; cid < nCams; cid++)
		{
			if (ExternalCorpus == cid)
				continue;

			bool staticCam = false;
			sprintf(Fname, "%s/staticCamList.txt", Path);
			if (IsFileExist(Fname))
			{
				int scid;
				FILE *fp = fopen(Fname, "r");
				while (fscanf(fp, "%d ", &scid) != EOF)
				{
					if (cid == scid)
						staticCam = true;
				}
				fclose(fp);
			}

			if (staticCam)
				continue;

			printLOG("\n*******Working on camera: %d *******\n", cid);

			sprintf(Fname, "./EnRecon %s %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %d %.2f", Path,
				5, startF, stopF, increF, cid, nCams, 4, fixIntrinsic, fixDistortion, 0, fix3D, fixSkew, fixPrism, distortionCorrected, nViewsPlus2, LossType, threshold);

			sprintf(Fname, "%s/Logs/PerCamBA_%d_%d_%.4d.txt", Path, cid, startF, stopF);
			if (IsFileExist(Fname) == 0)
			{
				int orgIncreFrame = increF, orgfixed3D = fix3D;
				//increF *= 3;
				PerVideo_BA(Path, cid, startF, stopF, increF, fixIntrinsic, fixDistortion, fix3D, fixLocal3D, fixPose, fixSkew, fixPrism, distortionCorrected, nViewsPlus2, ShutterModel2, LossType, doubleRefinement, threshold);

				//fix3D = 1, fixLocal3D = 1;
				//PerVideo_BA(Path, cid, startF + 1, stopF, increF, fixIntrinsic, fixDistortion, fix3D, fixLocal3D, fixPose, fixSkew, fixPrism, distortionCorrected, nViewsPlus2, ShutterModel2, LossType, doubleRefinement, threshold);
				//PerVideo_BA(Path, cid, startF + 2, stopF, increF, fixIntrinsic, fixDistortion, fix3D, fixLocal3D, fixPose, fixSkew, fixPrism, distortionCorrected, nViewsPlus2, ShutterModel2, LossType, doubleRefinement, threshold);

				fix3D = orgfixed3D, increF = orgIncreFrame;

				sprintf(Fname, "%s/Logs/PerCamBA_%d_%d_%.4d.txt", Path, cid, startF, stopF); FILE*fp = fopen(Fname, "w"); fclose(fp);
			}
		}
	}
#endif

	//All video refinement
	if (module == 11)
	{
		printLOG("\n*******Refine all cameras joinly*******\n");
		fixIntrinsic = 0;
		increF = 2;
		AllVideo_BA(Path, nCams, startF, stopF, increF, fixIntrinsic, fixDistortion, fixPose, 0, fix3D, fixSkew, fixPrism, distortionCorrected == 0 ? 1 : 2, nViewsPlus2, ShutterModel, LossType, doubleRefinement, threshold);

		fix3D = 1;
		AllVideo_BA(Path, nCams, startF, stopF, increF, fixIntrinsic, fixDistortion, fixPose, 0, fix3D, fixSkew, fixPrism, distortionCorrected == 0 ? 1 : 2, nViewsPlus2, ShutterModel, LossType, doubleRefinement, threshold);
		increF = 1;
	}

	if (module == 12)
	{
		for (int cid = 0; cid < nCams; cid++)
			Virtual3D_RS_BA_Driver(Path, cid, startF, stopF, increF, 1);

		int id;  double rp;
		sprintf(Fname, "%s/CamTimingPara.txt", Path); FILE *fp = fopen(Fname, "w+");
		for (int cid = 0; cid < 7; cid++)
		{
			sprintf(Fname, "%s/RP_%.4d.txt", Path, cid); FILE *fpi = fopen(Fname, "r");
			if (fpi != NULL)
			{
				fscanf(fpi, "%d %lf ", &id, &rp);
				fclose(fpi);
			}

			fprintf(fp, "%d 59.94 %.8f\n", id, rp);
		}
		fclose(fp);

		for (int cid = 0; cid < 7; cid++)
			sprintf(Fname, "%s/RP_%.4d.txt", Path, cid), remove(Fname);
	}

	if (module == 13)
	{
		vector<int> vCams;
		for (int ii = 0; ii < nCams; ii++)
			vCams.push_back(ii);
		visualizationDriver(Path, vCams, startF, stopF, increF, true, false, false, false, false, 18, startF, true, ShutterModel);
	}

	return 0;

	}

int TestKSfM(char *Path, int selectedCamId, int distortionCorrected, int nInliersThresh)
{
	char Fname[512];

	int  dummy, rfid;
	vector<int> vrfid;
	sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, selectedCamId);
	if (IsFileExist(Fname, false) == 0)
		return 1;
	FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %d %d %d ", &dummy, &dummy, &rfid, &dummy) != EOF)
		vrfid.push_back(rfid);
	fclose(fp);

	VideoData VideoI;
	ReadVideoDataI(Path, VideoI, selectedCamId);

	Corpus CorpusInfo;
	Point3d xyz;
	int lpid, gpid;
	sprintf(Fname, "%s/%d/Video3DCorpus.xyz", Path, selectedCamId); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		while (fscanf(fp, "%d %d %lf %lf %lf ", &lpid, &gpid, &xyz.x, &xyz.y, &xyz.z) != EOF)
		{
			if (lpid > CorpusInfo.xyz.size())
			{
				dummy = CorpusInfo.xyz.size();
				for (int ii = dummy; ii < lpid; ii++)
					CorpusInfo.xyz.push_back(Point3d(0, 0, 0));
			}
			CorpusInfo.xyz.push_back(xyz);
		}
		fclose(fp);

		CorpusInfo.n3dPoints = CorpusInfo.xyz.size();
	}
	else
	{
		sprintf(Fname, "%s/Corpus/nHCorpus_3D.txt", Path);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
			if (IsFileExist(Fname) == 0)
				sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
		}
		fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		Point3i rgb;
		int nCameras, nPoints, useColor;
		fscanf(fp, "%d %d %d", &nCameras, &nPoints, &useColor);
		CorpusInfo.nCameras = nCameras;
		CorpusInfo.n3dPoints = nPoints;
		CorpusInfo.xyz.reserve(nPoints);
		if (useColor)
		{
			CorpusInfo.rgb.reserve(nPoints);
			for (int jj = 0; jj < nPoints; jj++)
			{
				fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
				CorpusInfo.xyz.push_back(xyz);
			}
		}
		else
		{
			CorpusInfo.rgb.reserve(nPoints);
			for (int jj = 0; jj < nPoints; jj++)
			{
				fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
				CorpusInfo.xyz.push_back(xyz);
			}
		}
		fclose(fp);
	}

	double residuals[2];
	float x, y, z, u, v, s;
	int globalCorpusP3DId, localCorpusP3DId, p2DId;
	double miniX, maxiX, avgX, stdX, miniY, maxiY, avgY, stdY;

	vector<float > vu, vv;
	vector<int> vglobalCorpusP3DId, vlocalCorpusP3DId;
	vector<double> ReProjectionErrorX, ReProjectionErrorY, ReProjectionErrorAX, ReProjectionErrorAY;

	sprintf(Fname, "%s/%d/KF_Inliers_Stat.txt", Path, selectedCamId); FILE *fp1 = fopen(Fname, "w+");
	fprintf(fp1, "Fid #A \t min_x min_y \t max_x max_y \t mean_x mean_y \t std_x std_y\t #L \t min_x min_y \t max_x max_y \t mean_x mean_y \t std_x std_y\n");
	for (auto fid : vrfid)
	{
		vu.clear(), vv.clear(), vglobalCorpusP3DId.clear(), vlocalCorpusP3DId.clear();
		sprintf(Fname, "%s/%d/PnP/KF_Inliers_%.4d.txt", Path, selectedCamId, fid);
		if (!VideoI.VideoInfo[fid].valid || IsFileExist(Fname) == 0)
			continue;

		fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %f %f %f %d %f %f %f", &globalCorpusP3DId, &localCorpusP3DId, &x, &y, &z, &p2DId, &u, &v, &s) != EOF)
		{
			vglobalCorpusP3DId.push_back(globalCorpusP3DId);
			vlocalCorpusP3DId.push_back(localCorpusP3DId);
			vu.push_back(u), vv.push_back(v);
		}
		fclose(fp);

		fprintf(fp1, "%d \t ", fid);
		ReProjectionErrorAX.clear(), ReProjectionErrorAY.clear(), ReProjectionErrorX.clear(), ReProjectionErrorY.clear();
		for (size_t ii = 0; ii < vu.size(); ii++)
		{
			localCorpusP3DId = vlocalCorpusP3DId[ii];

			Point2d uv(vu[ii], vv[ii]);
			Point3d xyz = CorpusInfo.xyz[localCorpusP3DId];
			if (distortionCorrected == 0)
			{
				if (VideoI.VideoInfo[fid].ShutterModel == GLOBAL_SHUTTER)
				{
					if (VideoI.VideoInfo[fid].LensModel == RADIAL_TANGENTIAL_PRISM)
						PinholeDistortionReprojectionDebug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].distortion, VideoI.VideoInfo[fid].rt, uv, xyz, residuals);
					else
						FOVReprojectionDistortion2Debug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].distortion, VideoI.VideoInfo[fid].rt, uv, xyz, residuals);
				}
				else
				{
					if (VideoI.VideoInfo[fid].LensModel == RADIAL_TANGENTIAL_PRISM)
						CayleyDistortionReprojectionDebug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].distortion, VideoI.VideoInfo[fid].rt, VideoI.VideoInfo[fid].wt, uv, xyz, VideoI.VideoInfo[fid].width, VideoI.VideoInfo[fid].height, residuals);
					else
						CayleyFOVReprojection2Debug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].distortion, VideoI.VideoInfo[fid].rt, VideoI.VideoInfo[fid].wt, uv, xyz, VideoI.VideoInfo[fid].width, VideoI.VideoInfo[fid].height, residuals);
					;// CayleyFOVReprojection2Debug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].distortion, VideoI.VideoInfo[fid].rt, VideoI.VideoInfo[fid].wt, uv, xyz, VideoI.VideoInfo[fid].width, VideoI.VideoInfo[fid].height, residuals);
				}
			}
			else
			{
				if (VideoI.VideoInfo[fid].ShutterModel == GLOBAL_SHUTTER)
					PinholeReprojectionDebug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].rt, uv, xyz, residuals);
				else
					CayleyReprojectionDebug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].rt, VideoI.VideoInfo[fid].wt, uv, xyz, VideoI.VideoInfo[fid].width, VideoI.VideoInfo[fid].height, residuals);
			}

			if (vglobalCorpusP3DId[ii] > -1)
				ReProjectionErrorAX.push_back(residuals[0]), ReProjectionErrorAY.push_back(residuals[1]);
			else
				ReProjectionErrorX.push_back(residuals[0]), ReProjectionErrorY.push_back(residuals[1]);
		}

		printLOG("**********\nFrame %d/%.4d:\n", selectedCamId, fid);
		miniX = 0, miniY = 0, maxiX = 0, maxiY = 0, avgX = 0, avgY = 0, stdX = 0, stdY = 0;
		if (ReProjectionErrorAX.size() > 1)
		{
			miniX = *min_element(ReProjectionErrorAX.begin(), ReProjectionErrorAX.end());
			maxiX = *max_element(ReProjectionErrorAX.begin(), ReProjectionErrorAX.end());
			avgX = MeanArray(ReProjectionErrorAX);
			stdX = sqrt(VarianceArray(ReProjectionErrorAX, avgX));
			miniY = *min_element(ReProjectionErrorAY.begin(), ReProjectionErrorAY.end());
			maxiY = *max_element(ReProjectionErrorAY.begin(), ReProjectionErrorAY.end());
			avgY = MeanArray(ReProjectionErrorAY);
			stdY = sqrt(VarianceArray(ReProjectionErrorAY, avgY));
			printLOG("%d Anchor points with reprojection error: Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", ReProjectionErrorAY.size(), miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
		}
		fprintf(fp1, "%d \t %.2f %.2f\t %.2f %.2f \t %.2f %.2f \t %.2f %.2f \t", ReProjectionErrorAY.size(), miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);

		miniX = 0, miniY = 0, maxiX = 0, maxiY = 0, avgX = 0, avgY = 0, stdX = 0, stdY = 0;
		if (ReProjectionErrorX.size() > 1)
		{
			miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
			maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
			avgX = MeanArray(ReProjectionErrorX);
			stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
			miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
			maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
			avgY = MeanArray(ReProjectionErrorY);
			stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
			printLOG("%d local points with reprojection error: Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n\n", ReProjectionErrorX.size(), miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
		}
		fprintf(fp1, "%d \t %.2f %.2f\t %.2f %.2f \t %.2f %.2f \t %.2f %.2f \n", ReProjectionErrorY.size(), miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);

		if (ReProjectionErrorAX.size() + ReProjectionErrorX.size() < nInliersThresh)
		{
			VideoI.VideoInfo[fid].valid = false;
			sprintf(Fname, "%s/%d/PnP/KF_Inliers_%.4d.txt", Path, selectedCamId, fid); remove(Fname);
		}
	}
	fclose(fp1);

	WriteVideoDataI(Path, VideoI, selectedCamId, vrfid[0], vrfid.back(), 2);

	return 0;
}
int TestPnPf(char *Path, int selectedCamId, int startF, int stopF, int distortionCorrected, int nInliersThresh)
{
	char Fname[512];
	printLOG("\n******************Working on %d******************\nCleaning frames with insufficient #inliers: ", selectedCamId);

	VideoData VideoI;
	ReadVideoDataI(Path, VideoI, selectedCamId);

	Corpus CorpusInfo;
	Point3d xyz;
	int lpid, gpid, dummy;
	sprintf(Fname, "%s/%d/Video3DCorpus.xyz", Path, selectedCamId);
	if (IsFileExist(Fname) == 1)
	{
		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %lf %lf %lf ", &lpid, &gpid, &xyz.x, &xyz.y, &xyz.z) != EOF)
		{
			if (lpid > CorpusInfo.xyz.size())
			{
				dummy = CorpusInfo.xyz.size();
				for (int ii = dummy; ii < lpid; ii++)
					CorpusInfo.xyz.push_back(Point3d(0, 0, 0));
			}
			CorpusInfo.xyz.push_back(xyz);
		}
		fclose(fp);

		CorpusInfo.n3dPoints = CorpusInfo.xyz.size();
	}
	else
	{
		sprintf(Fname, "%s/Corpus/nHCorpus_3D.txt", Path);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n", Fname);
					return 1;
				}
			}
			Point3i rgb;
			int nCameras, nPoints, useColor;
			FILE *fp = fopen(Fname, "r");
			fscanf(fp, "%d %d %d", &nCameras, &nPoints, &useColor);
			CorpusInfo.nCameras = nCameras;
			CorpusInfo.n3dPoints = nPoints;
			CorpusInfo.xyz.reserve(nPoints);
			if (useColor)
			{
				CorpusInfo.rgb.reserve(nPoints);
				for (int jj = 0; jj < nPoints; jj++)
				{
					fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
					CorpusInfo.xyz.push_back(xyz);
				}
			}
			else
			{
				CorpusInfo.rgb.reserve(nPoints);
				for (int jj = 0; jj < nPoints; jj++)
				{
					fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
					CorpusInfo.xyz.push_back(xyz);
				}
			}
			fclose(fp);
		}
	}

	double residuals[2];
	float x, y, z, u, v, s;
	int globalCorpusP3DId, localCorpusP3DId, p2DId;
	double miniX, maxiX, avgX, stdX, miniY, maxiY, avgY, stdY;

	vector<float > vu, vv;
	vector<int> vglobalCorpusP3DId, vlocalCorpusP3DId;
	vector<double> ReProjectionErrorX, ReProjectionErrorY, ReProjectionErrorAX, ReProjectionErrorAY;

	sprintf(Fname, "%s/%d/InliersF_Stat.txt", Path, selectedCamId); FILE *fp1 = fopen(Fname, "w+");
	fprintf(fp1, "Fid #A \t min_x min_y \t max_x max_y \t mean_x mean_y \t std_x std_y\t #L \t min_x min_y \t max_x max_y \t mean_x mean_y \t std_x std_y\n");
	for (int fid = startF; fid <= stopF; fid++)
	{
		vu.clear(), vv.clear(), vglobalCorpusP3DId.clear(), vlocalCorpusP3DId.clear();
		sprintf(Fname, "%s/%d/PnPf/Inliers_%.4d.txt", Path, selectedCamId, fid);
		if (!VideoI.VideoInfo[fid].valid || IsFileExist(Fname) == 0)
			continue;

		FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %f %f %f %f %f %f", &globalCorpusP3DId, &localCorpusP3DId, &x, &y, &z, &u, &v, &s) != EOF)
		{
			vglobalCorpusP3DId.push_back(globalCorpusP3DId);
			vlocalCorpusP3DId.push_back(localCorpusP3DId);
			vu.push_back(u), vv.push_back(v);
		}
		fclose(fp);

		fprintf(fp1, "%d \t ", fid);
		ReProjectionErrorAX.clear(), ReProjectionErrorAY.clear(), ReProjectionErrorX.clear(), ReProjectionErrorY.clear();
		for (size_t ii = 0; ii < vu.size(); ii++)
		{
			localCorpusP3DId = vlocalCorpusP3DId[ii];

			Point2d uv(vu[ii], vv[ii]);
			Point3d xyz = CorpusInfo.xyz[localCorpusP3DId];
			if (distortionCorrected == 0)
			{
				if (VideoI.VideoInfo[fid].ShutterModel == GLOBAL_SHUTTER)
				{
					if (VideoI.VideoInfo[fid].LensModel == RADIAL_TANGENTIAL_PRISM)
						PinholeDistortionReprojectionDebug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].distortion, VideoI.VideoInfo[fid].rt, uv, xyz, residuals);
					else
						FOVReprojectionDistortion2Debug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].distortion, VideoI.VideoInfo[fid].rt, uv, xyz, residuals);
				}
				else
				{
					if (VideoI.VideoInfo[fid].LensModel == RADIAL_TANGENTIAL_PRISM)
						CayleyDistortionReprojectionDebug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].distortion, VideoI.VideoInfo[fid].rt, VideoI.VideoInfo[fid].wt, uv, xyz, VideoI.VideoInfo[fid].width, VideoI.VideoInfo[fid].height, residuals);
					else
						CayleyFOVReprojection2Debug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].distortion, VideoI.VideoInfo[fid].rt, VideoI.VideoInfo[fid].wt, uv, xyz, VideoI.VideoInfo[fid].width, VideoI.VideoInfo[fid].height, residuals);
				}
			}
			else
			{
				if (VideoI.VideoInfo[fid].ShutterModel == GLOBAL_SHUTTER)
					PinholeReprojectionDebug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].rt, uv, xyz, residuals);
				else
					CayleyReprojectionDebug(VideoI.VideoInfo[fid].intrinsic, VideoI.VideoInfo[fid].rt, VideoI.VideoInfo[fid].wt, uv, xyz, VideoI.VideoInfo[fid].width, VideoI.VideoInfo[fid].height, residuals);
			}

			if (vglobalCorpusP3DId[ii] > -1)
				ReProjectionErrorAX.push_back(residuals[0]), ReProjectionErrorAY.push_back(residuals[1]);
			else
				ReProjectionErrorX.push_back(residuals[0]), ReProjectionErrorY.push_back(residuals[1]);
		}

		printLOG("**********\nFrame %d/%.4d:\n", selectedCamId, fid);
		miniX = 0, miniY = 0, maxiX = 0, maxiY = 0, avgX = 0, avgY = 0, stdX = 0, stdY = 0;
		if (ReProjectionErrorAX.size() > 1)
		{
			miniX = *min_element(ReProjectionErrorAX.begin(), ReProjectionErrorAX.end());
			maxiX = *max_element(ReProjectionErrorAX.begin(), ReProjectionErrorAX.end());
			avgX = MeanArray(ReProjectionErrorAX);
			stdX = sqrt(VarianceArray(ReProjectionErrorAX, avgX));
			miniY = *min_element(ReProjectionErrorAY.begin(), ReProjectionErrorAY.end());
			maxiY = *max_element(ReProjectionErrorAY.begin(), ReProjectionErrorAY.end());
			avgY = MeanArray(ReProjectionErrorAY);
			stdY = sqrt(VarianceArray(ReProjectionErrorAY, avgY));
			printLOG("%d Anchor points with reprojection error: Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", ReProjectionErrorAY.size(), miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
		}
		fprintf(fp1, "%d \t %.2f %.2f\t %.2f %.2f \t %.2f %.2f \t %.2f %.2f \t", ReProjectionErrorAY.size(), miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);

		miniX = 0, miniY = 0, maxiX = 0, maxiY = 0, avgX = 0, avgY = 0, stdX = 0, stdY = 0;
		if (ReProjectionErrorX.size() > 1)
		{
			miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
			maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
			avgX = MeanArray(ReProjectionErrorX);
			stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
			miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
			maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
			avgY = MeanArray(ReProjectionErrorY);
			stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
			printLOG("%d local points with reprojection error: Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n\n", ReProjectionErrorX.size(), miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);
		}
		fprintf(fp1, "%d \t %.2f %.2f\t %.2f %.2f \t %.2f %.2f \t %.2f %.2f \n", ReProjectionErrorY.size(), miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);

		if (ReProjectionErrorAX.size() + ReProjectionErrorX.size() < nInliersThresh)
		{
			VideoI.VideoInfo[fid].valid = false;
			sprintf(Fname, "%s/%d/PnPf/Inliers_%.4d.txt", Path, selectedCamId, fid); remove(Fname);
			printLOG("%d...", fid);
		}
	}
	fclose(fp1);

	printLOG("\n\n");

	WriteVideoDataI(Path, VideoI, selectedCamId, startF, stopF, 2);

	return 0;
}

//Spatialtemporal calibration
int ConvertTrajectoryToPointCloudTime(char *Path, int npts)
{
	char Fname[512];

	double x, y, z, t;
	vector<double> timeStamp;
	std::vector<int>::iterator it;

	//Read all the time possible
	for (int pid = 0; pid < npts; pid++)
	{
		sprintf(Fname, "%s/_ATrack_%d_0.txt", Path, pid);  FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%lf %lf %lf %lf", &x, &y, &z, &t) != EOF)
		{
			bool found = false;
			for (int ii = 0; ii < timeStamp.size(); ii++)
			{
				if (abs(timeStamp[ii] - t) < 0.01)
				{
					found = true;
					break;
				}
			}

			if (!found)
				timeStamp.push_back(t);
		}
		fclose(fp);
	}
	sort(timeStamp.begin(), timeStamp.end());

	int ntimes = (int)timeStamp.size();
	vector<int> *PoindID = new vector<int>[ntimes];
	vector<Point3d> *PointCloudTime = new vector<Point3d>[ntimes];
	for (int pid = 0; pid < npts; pid++)
	{
		sprintf(Fname, "%s/_ATrack_%d_0.txt", Path, pid);  FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%lf %lf %lf %lf", &x, &y, &z, &t) != EOF)
		{
			for (int ii = 0; ii < timeStamp.size(); ii++)
			{
				if (abs(timeStamp[ii] - t) < 0.01)
				{
					PoindID[ii].push_back(pid);
					PointCloudTime[ii].push_back(Point3d(x, y, z));
					break;
				}
			}
		}
		fclose(fp);
	}

	for (int ii = 0; ii < ntimes; ii++)
	{
		sprintf(Fname, "%s/Dynamic/HP3D_%.4d.xyz", Path, ii);  FILE *fp = fopen(Fname, "w+");
		for (int jj = 0; jj < PointCloudTime[ii].size(); jj++)
			fprintf(fp, "%d %.4f %.4f %.4f\n", PoindID[ii][jj], PointCloudTime[ii][jj].x, PointCloudTime[ii][jj].y, PointCloudTime[ii][jj].z);
		fclose(fp);
	}

	return 0;
}
int ResamplingOf3DTrajectorySplineDriver(char *Path, vector<int> &SelectedCams, vector<double> &OffsetInfo, int startF, int stopF, int ntracks, double lamda)
{
	char Fname[512]; FILE *fp = 0;
	//double Tscale = 1000.0, fps = 30.0, ialpha = 1.0 / fps;
	double Tscale = 1000.0, fps = 10.0, ialpha = 1.0 / fps, eps = 1.0e-6;

	//Read calib info
	int nCams = (int)SelectedCams.size();
	VideoData *VideoInfo = new VideoData[nCams];
	for (int camID = 0; camID < nCams; camID++)
		if (ReadVideoDataI(Path, VideoInfo[camID], SelectedCams[camID], startF, stopF) == 1)
			return 1;

	int frameID, id, nf;
	int nframes = max(MaxnFrames, stopF);

	double u, v, s;
	vector<int>VectorCamID, VectorFrameID;
	vector<double> AllError2D;
	ImgPtEle ptEle;
	vector<ImgPtEle> *PerCam_UV = new vector<ImgPtEle>[nCams*ntracks];

	printLOG("Get 2D ...");
	for (int camID = 0; camID < nCams; camID++)
	{
		for (int trackID = 0; trackID < ntracks; trackID++)
			PerCam_UV[camID*ntracks + trackID].reserve(stopF - startF + 1);

		sprintf(Fname, "%s/Track2D/Ultimate_%.4d.txt", Path, SelectedCams[camID]); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		fscanf(fp, "%d ", &ntracks);
		while (fscanf(fp, "%d %d ", &id, &nf) != EOF)
		{
			//if (id != trackID)
			//	printLOG("Problem at Point %d of Cam %d", id, camID);
			for (int pid = 0; pid < nf; pid++)
			{
				fscanf(fp, "%d %lf %lf %lf ", &frameID, &u, &v, &s);
				if (frameID < 0)
					continue;
				if (!VideoInfo[camID].VideoInfo[frameID].valid)
					continue; //camera not localized

				fps = VideoInfo[camID].VideoInfo[frameID].fps, ialpha = 1.0 / fps;
				if (u > 0 && v > 0)
				{
					ptEle.pt2D.x = u, ptEle.pt2D.y = v, ptEle.scale = s, ptEle.frameID = frameID, ptEle.imWidth = VideoInfo[camID].VideoInfo[frameID].width, ptEle.imHeight = VideoInfo[camID].VideoInfo[frameID].height;
					LensCorrectionPoint(&ptEle.pt2D, VideoInfo[camID].VideoInfo[frameID].K, VideoInfo[camID].VideoInfo[frameID].distortion);
					PerCam_UV[camID*ntracks + id].push_back(ptEle);
				}
			}
		}
		fclose(fp);
	}

	printLOG("Get rays info ....");
	double P[12], AA[6], bb[2], ccT[3], dd[1];
	for (int trackID = 0; trackID < ntracks; trackID++)
	{
		int count = 0;
		for (int camID = 0; camID < nCams; camID++)
		{
			for (int frameID = 0; frameID < PerCam_UV[camID*ntracks + trackID].size(); frameID++)
			{
				int RealFrameID = PerCam_UV[camID*ntracks + trackID][frameID].frameID;

				if (VideoInfo[camID].VideoInfo[RealFrameID].ShutterModel == 0)
				{
					for (int kk = 0; kk < 12; kk++)
						P[kk] = VideoInfo[camID].VideoInfo[RealFrameID].P[kk];

					for (int kk = 0; kk < 9; kk++)
						PerCam_UV[camID*ntracks + trackID][frameID].R[kk] = VideoInfo[camID].VideoInfo[RealFrameID].R[kk];
				}
				else if (VideoInfo[camID].VideoInfo[RealFrameID].ShutterModel == 1)
					AssembleP_RS(PerCam_UV[camID*ntracks + trackID][frameID].pt2D, VideoInfo[camID].VideoInfo[RealFrameID], P);
				else
					printLOG("Not supported model for motion prior sync\n");

				fps = VideoInfo[camID].VideoInfo[RealFrameID].fps, ialpha = 1.0 / fps;
				for (int kk = 0; kk < 12; kk++)
					PerCam_UV[camID*ntracks + trackID][frameID].P[kk] = P[kk];
				for (int kk = 0; kk < 9; kk++)
					PerCam_UV[camID*ntracks + trackID][frameID].K[kk] = VideoInfo[camID].VideoInfo[RealFrameID].K[kk];

				AA[0] = P[0], AA[1] = P[1], AA[2] = P[2], bb[0] = P[3];
				AA[3] = P[4], AA[4] = P[5], AA[5] = P[6], bb[1] = P[7];
				ccT[0] = P[8], ccT[1] = P[9], ccT[2] = P[10], dd[0] = P[11];

				PerCam_UV[camID*ntracks + trackID][frameID].Q[0] = AA[0] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.x*ccT[0],
					PerCam_UV[camID*ntracks + trackID][frameID].Q[1] = AA[1] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.x*ccT[1],
					PerCam_UV[camID*ntracks + trackID][frameID].Q[2] = AA[2] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.x*ccT[2];
				PerCam_UV[camID*ntracks + trackID][frameID].Q[3] = AA[3] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.y*ccT[0],
					PerCam_UV[camID*ntracks + trackID][frameID].Q[4] = AA[4] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.y*ccT[1],
					PerCam_UV[camID*ntracks + trackID][frameID].Q[5] = AA[5] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.y*ccT[2];
				PerCam_UV[camID*ntracks + trackID][frameID].u[0] = dd[0] * PerCam_UV[camID*ntracks + trackID][frameID].pt2D.x - bb[0],
					PerCam_UV[camID*ntracks + trackID][frameID].u[1] = dd[0] * PerCam_UV[camID*ntracks + trackID][frameID].pt2D.y - bb[1];

				PerCam_UV[camID*ntracks + trackID][frameID].pt3D = Point3d(count, count, count);//Interestingly, Ceres does not work if all the input are the same
				count++;
			}
		}
	}

	//Initialize data for optim
	vector<int> PointsPerTrack;
	vector<int *> PerTrackFrameID(ntracks);
	vector<double*> All3D(ntracks);
	int ntimeinstances, maxntimeinstances = 0;
	for (int trackID = 0; trackID < ntracks; trackID++)
	{
		ntimeinstances = 0;
		for (int camID = 0; camID < nCams; camID++)
			ntimeinstances += (int)PerCam_UV[camID*ntracks + trackID].size();

		if (maxntimeinstances < ntimeinstances)
			maxntimeinstances = ntimeinstances;

		PerTrackFrameID[trackID] = new int[ntimeinstances];
		All3D[trackID] = new double[3 * ntimeinstances];
	}

	vector<int> VisCamID, VisLocalFrameID;
	vector<double> TimeStamp;
	vector<Point3d> T3D;
	vector<ImgPtEle> *Traj3D = new vector<ImgPtEle>[ntracks];
	int cID, fID;
	double x, y, z, t;
	int dummy[10000];
	double ts[10000];
	ImgPtEle iele;

	printLOG("Get 3D data:\n");
	for (int trackID = 0; trackID < ntracks; trackID++)
	{
		TimeStamp.clear(), T3D.clear(), VisCamID.clear(), VisLocalFrameID.clear();

		sprintf(Fname, "%s/Track3D/OptimizedRaw_Track_%.4d.txt", Path, trackID); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		while (fscanf(fp, "%lf %lf %lf %lf %d %d", &x, &y, &z, &t, &cID, &fID) != EOF)
		{
			TimeStamp.push_back(t), VisCamID.push_back(cID), VisLocalFrameID.push_back(fID);
			T3D.push_back(Point3d(x, y, z));
		}
		fclose(fp);

		for (int ii = 0; ii < (int)TimeStamp.size(); ii++)
			ts[ii] = TimeStamp[ii], dummy[ii] = ii;
		Quick_Sort_Double(ts, dummy, 0, (int)TimeStamp.size() - 1);

		for (int ii = 0; ii < (int)TimeStamp.size(); ii++)
		{
			int id = dummy[ii], camID = VisCamID[id], frameID = VisLocalFrameID[id];
			iele.viewID = camID, iele.frameID = frameID, iele.timeStamp = TimeStamp[id];

			iele.pt3D = T3D[id];
			for (int fid = 0; fid < (int)PerCam_UV[camID*ntracks + trackID].size(); fid++)
			{
				if (PerCam_UV[camID*ntracks + trackID][fid].frameID == frameID)
				{
					iele.pt2D = PerCam_UV[camID*ntracks + trackID][fid].pt2D;
					for (int jj = 0; jj < 12; jj++)
						iele.P[jj] = PerCam_UV[camID*ntracks + trackID][fid].P[jj];
					break;
				}
			}
			Traj3D[trackID].push_back(iele);
		}
	}

	printLOG("Cubic Bspline resampling:\n");
	sprintf(Fname, "%s/Track3D", Path); makeDir(Fname);

	omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic,1)
	for (int trackID = 0; trackID < ntracks; trackID++)
	{
#pragma omp critical
		printLOG("%d: ", trackID);

		if (Traj3D[trackID].size() == 0)
			continue;
		ResamplingOf3DTrajectorySpline(Traj3D[trackID], true, ialpha *Tscale, ialpha *Tscale / nCams, lamda);

#pragma omp critical
		{
			sprintf(Fname, "%s/Track3D/SplineResampled_Track_%.4d.txt", Path, trackID); remove(Fname);
			fp = fopen(Fname, "w+");
			for (int ii = 0; ii < (int)Traj3D[trackID].size(); ii++)
				fprintf(fp, "%.4f %.4f %.4f %.4f %d %d\n", Traj3D[trackID][ii].pt3D.x, Traj3D[trackID][ii].pt3D.y, Traj3D[trackID][ii].pt3D.z, Traj3D[trackID][ii].timeStamp, Traj3D[trackID][ii].viewID, Traj3D[trackID][ii].frameID);
			fclose(fp);
		}
	}
	printLOG("Done!\n\n");

	delete[]VideoInfo;
	delete[]PerCam_UV;
	delete[]Traj3D;

	return 0;
}
int ResamplingOf3DTrajectoryDCTDriver(char *Path, vector<int> &SelectedCams, vector<double> &OffsetInfo, int PriorOrder, int startF, int stopF, int ntracks, double lamda_Data, double lamda_Reg)
{
	char Fname[512]; FILE *fp = 0;

	//Read calib info
	int nCams = (int)SelectedCams.size();
	VideoData *VideoInfo = new VideoData[nCams];
	for (int camID = 0; camID < nCams; camID++)
		if (ReadVideoDataI(Path, VideoInfo[camID], SelectedCams[camID], startF, stopF) == 1)
			return 1;

	int frameID, id, nf;
	int nframes = max(MaxnFrames, stopF);

	double u, v, s;
	vector<int>VectorCamID, VectorFrameID;
	vector<double> AllError2D;
	ImgPtEle ptEle;
	vector<ImgPtEle> *PerCam_UV = new vector<ImgPtEle>[nCams*ntracks];

	printLOG("Get 2D ...");
	for (int camID = 0; camID < nCams; camID++)
	{
		for (int trackID = 0; trackID < ntracks; trackID++)
			PerCam_UV[camID*ntracks + trackID].reserve(stopF - startF + 1);

		sprintf(Fname, "%s/Track2D/Ultimate_%.4d.txt", Path, SelectedCams[camID]); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		fscanf(fp, "%d ", &ntracks);
		while (fscanf(fp, "%d %d ", &id, &nf) != EOF)
		{
			for (int fid = 0; fid < nf; fid++)
			{
				fscanf(fp, "%d %lf %lf %lf ", &frameID, &u, &v, &s);
				if (frameID < 0)
					continue;
				if (!VideoInfo[camID].VideoInfo[frameID].valid)
					continue; //camera not localized

				if (u > 0 && v > 0)
				{
					ptEle.pt2D.x = u, ptEle.pt2D.y = v, ptEle.scale = s, ptEle.frameID = frameID, ptEle.imWidth = VideoInfo[camID].VideoInfo[frameID].width, ptEle.imHeight = VideoInfo[camID].VideoInfo[frameID].height;
					LensCorrectionPoint(&ptEle.pt2D, VideoInfo[camID].VideoInfo[frameID].K, VideoInfo[camID].VideoInfo[frameID].distortion);
					PerCam_UV[camID*ntracks + id].push_back(ptEle);
				}
			}
		}
		fclose(fp);
	}

	printLOG("Get rays info ....");
	double P[12], AA[6], bb[2], ccT[3], dd[1];
	for (int trackID = 0; trackID < ntracks; trackID++)
	{
		int count = 0;
		for (int camID = 0; camID < nCams; camID++)
		{
			for (int frameID = 0; frameID < PerCam_UV[camID*ntracks + trackID].size(); frameID++)
			{
				int RealFrameID = PerCam_UV[camID*ntracks + trackID][frameID].frameID;

				if (VideoInfo[camID].VideoInfo[RealFrameID].ShutterModel == 0)
				{
					for (int kk = 0; kk < 12; kk++)
						P[kk] = VideoInfo[camID].VideoInfo[RealFrameID].P[kk];

					for (int kk = 0; kk < 9; kk++)
						PerCam_UV[camID*ntracks + trackID][frameID].R[kk] = VideoInfo[camID].VideoInfo[RealFrameID].R[kk];
				}
				else if (VideoInfo[camID].VideoInfo[RealFrameID].ShutterModel == 1)
					AssembleP_RS(PerCam_UV[camID*ntracks + trackID][frameID].pt2D, VideoInfo[camID].VideoInfo[RealFrameID], P);
				else
					printLOG("Not supported model for motion prior sync\n");

				for (int kk = 0; kk < 12; kk++)
					PerCam_UV[camID*ntracks + trackID][frameID].P[kk] = P[kk];
				for (int kk = 0; kk < 9; kk++)
					PerCam_UV[camID*ntracks + trackID][frameID].K[kk] = VideoInfo[camID].VideoInfo[RealFrameID].K[kk];

				AA[0] = P[0], AA[1] = P[1], AA[2] = P[2], bb[0] = P[3];
				AA[3] = P[4], AA[4] = P[5], AA[5] = P[6], bb[1] = P[7];
				ccT[0] = P[8], ccT[1] = P[9], ccT[2] = P[10], dd[0] = P[11];

				PerCam_UV[camID*ntracks + trackID][frameID].Q[0] = AA[0] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.x*ccT[0],
					PerCam_UV[camID*ntracks + trackID][frameID].Q[1] = AA[1] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.x*ccT[1],
					PerCam_UV[camID*ntracks + trackID][frameID].Q[2] = AA[2] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.x*ccT[2];
				PerCam_UV[camID*ntracks + trackID][frameID].Q[3] = AA[3] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.y*ccT[0],
					PerCam_UV[camID*ntracks + trackID][frameID].Q[4] = AA[4] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.y*ccT[1],
					PerCam_UV[camID*ntracks + trackID][frameID].Q[5] = AA[5] - PerCam_UV[camID*ntracks + trackID][frameID].pt2D.y*ccT[2];
				PerCam_UV[camID*ntracks + trackID][frameID].u[0] = dd[0] * PerCam_UV[camID*ntracks + trackID][frameID].pt2D.x - bb[0],
					PerCam_UV[camID*ntracks + trackID][frameID].u[1] = dd[0] * PerCam_UV[camID*ntracks + trackID][frameID].pt2D.y - bb[1];

				PerCam_UV[camID*ntracks + trackID][frameID].pt3D = Point3d(count, count, count);//Interestingly, Ceres does not work if all the input are the same
				count++;
			}
		}
	}

	//Initialize data for optim
	vector<int> PointsPerTrack;
	vector<int *> PerTrackFrameID(ntracks);
	vector<double*> All3D(ntracks);
	int ntimeinstances, maxntimeinstances = 0;
	for (int trackID = 0; trackID < ntracks; trackID++)
	{
		ntimeinstances = 0;
		for (int camID = 0; camID < nCams; camID++)
			ntimeinstances += (int)PerCam_UV[camID*ntracks + trackID].size();

		if (maxntimeinstances < ntimeinstances)
			maxntimeinstances = ntimeinstances;

		PerTrackFrameID[trackID] = new int[ntimeinstances];
		All3D[trackID] = new double[3 * ntimeinstances];
	}

	vector<int> VisCamID, VisLocalFrameID;
	vector<double> TimeStamp;
	vector<Point3d> T3D;
	vector<ImgPtEle> *Traj3D = new vector<ImgPtEle>[ntracks];
	int cID, fID;
	double x, y, z, t;
	int dummy[10000];
	double ts[10000];
	ImgPtEle iele;

	printLOG("Get 3D data:\n");
	for (int trackID = 0; trackID < ntracks; trackID++)
	{
		TimeStamp.clear(), T3D.clear(), VisCamID.clear(), VisLocalFrameID.clear();

		sprintf(Fname, "%s/Track3D/OptimizedRaw_Track_%.4d.txt", Path, trackID); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		while (fscanf(fp, "%lf %lf %lf %lf %d %d", &x, &y, &z, &t, &cID, &fID) != EOF)
		{
			TimeStamp.push_back(t), VisCamID.push_back(cID), VisLocalFrameID.push_back(fID);
			T3D.push_back(Point3d(x, y, z));
		}
		fclose(fp);

		for (int ii = 0; ii < (int)TimeStamp.size(); ii++)
			ts[ii] = TimeStamp[ii], dummy[ii] = ii;
		Quick_Sort_Double(ts, dummy, 0, (int)TimeStamp.size() - 1);

		for (int ii = 0; ii < (int)TimeStamp.size(); ii++)
		{
			int id = dummy[ii], camID = VisCamID[id], frameID = VisLocalFrameID[id];
			iele.viewID = camID, iele.frameID = frameID, iele.timeStamp = TimeStamp[id];

			iele.pt3D = T3D[id];
			for (int fid = 0; fid < (int)PerCam_UV[camID*ntracks + trackID].size(); fid++)
			{
				if (PerCam_UV[camID*ntracks + trackID][fid].frameID == frameID)
				{
					iele.pt2D = PerCam_UV[camID*ntracks + trackID][fid].pt2D;
					for (int jj = 0; jj < 12; jj++)
						iele.P[jj] = PerCam_UV[camID*ntracks + trackID][fid].P[jj];
					break;
				}
			}
			Traj3D[trackID].push_back(iele);
		}
	}

	printLOG("DCT-based resampling:\n");
	sprintf(Fname, "%s/Track3D", Path); makeDir(Fname);

	omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic,1)
	for (int trackID = 0; trackID < ntracks; trackID++)
	{
		if (Traj3D[trackID].size() == 0)
			continue;

#pragma omp critical
		printLOG("%d: ", trackID);

		double earliest = Traj3D[trackID][0].timeStamp, latest = Traj3D[trackID].back().timeStamp;
		int nData = (int)Traj3D[trackID].size();
		double resamplingStep = (latest - earliest) / nData;

		double lamda_Reg_ = lamda_Reg * resamplingStep;
		ResamplingOf3DTrajectoryDCT(Traj3D[trackID], PriorOrder, true, resamplingStep, lamda_Data, lamda_Reg_, true);

#pragma omp critical
		{
			sprintf(Fname, "%s/Track3D/DCTResampled_Track_%.4d.txt", Path, trackID); remove(Fname);
			fp = fopen(Fname, "w+");
			for (int ii = 0; ii < (int)Traj3D[trackID].size(); ii++)
				fprintf(fp, "%.4f %.4f %.4f %.4f %d %d\n", Traj3D[trackID][ii].pt3D.x, Traj3D[trackID][ii].pt3D.y, Traj3D[trackID][ii].pt3D.z, Traj3D[trackID][ii].timeStamp, Traj3D[trackID][ii].viewID, Traj3D[trackID][ii].frameID);
			fclose(fp);
		}
	}
	printLOG("Done!\n\n");

	delete[]VideoInfo;
	delete[]PerCam_UV;
	delete[]Traj3D;

	return 0;
}
int ResamplingOf3DTrajectoryDCTDriverParallel(char *Path, vector<int> &SelectedCams, vector<double> &OffsetInfo, int TargetTrackID, int PriorOrder, int startF, int stopF, int ntracks, double lamda1, double lamda2)
{
	char Fname[512]; FILE *fp = 0;

	//Read calib info
	int nCams = (int)SelectedCams.size();
	VideoData *VideoInfo = new VideoData[nCams];
	for (int camID = 0; camID < nCams; camID++)
		if (ReadVideoDataI(Path, VideoInfo[camID], SelectedCams[camID], startF, stopF) == 1)
			return 1;

	int frameID, id, npts;
	int nframes = max(MaxnFrames, stopF);

	double u, v, s;
	vector<int>VectorCamID, VectorFrameID;
	vector<double> AllError2D;
	ImgPtEle ptEle;
	vector<ImgPtEle> *PerCam_UV = new vector<ImgPtEle>[nCams];

	printLOG("Get 2D ...");
	for (int camID = 0; camID < nCams; camID++)
	{
		PerCam_UV[camID].reserve(stopF - startF + 1);

		sprintf(Fname, "%s/Track2D/Ultimate_%.4d.txt", Path, SelectedCams[camID]); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		fscanf(fp, "%d ", &ntracks);
		while (fscanf(fp, "%d %d ", &id, &npts) != EOF)
		{
			//if (id != trackID)
			//	continue;
			for (int pid = 0; pid < npts; pid++)
			{
				fscanf(fp, "%d %lf %lf %lf ", &frameID, &u, &v, &s);
				if (frameID < 0)
					continue;
				if (!VideoInfo[camID].VideoInfo[frameID].valid)
					continue; //camera not localized

				if (u > 0 && v > 0)
				{
					ptEle.pt2D.x = u, ptEle.pt2D.y = v, ptEle.scale = s, ptEle.frameID = frameID, ptEle.imWidth = VideoInfo[camID].VideoInfo[frameID].width, ptEle.imHeight = VideoInfo[camID].VideoInfo[frameID].height;
					LensCorrectionPoint(&ptEle.pt2D, VideoInfo[camID].VideoInfo[frameID].K, VideoInfo[camID].VideoInfo[frameID].distortion);
					PerCam_UV[camID].push_back(ptEle);
				}
			}
		}
		fclose(fp);
	}

	printLOG("Get rays info ....");
	double P[12], AA[6], bb[2], ccT[3], dd[1];
	int count = 0;
	for (int camID = 0; camID < nCams; camID++)
	{
		for (int frameID = 0; frameID < PerCam_UV[camID].size(); frameID++)
		{
			int RealFrameID = PerCam_UV[camID][frameID].frameID;

			for (int kk = 0; kk < 12; kk++)
			{
				P[kk] = VideoInfo[camID].VideoInfo[RealFrameID].P[kk];
				PerCam_UV[camID][frameID].P[kk] = P[kk];
			}

			for (int kk = 0; kk < 9; kk++)
				PerCam_UV[camID][frameID].K[kk] = VideoInfo[camID].VideoInfo[RealFrameID].K[kk],

				AA[0] = P[0], AA[1] = P[1], AA[2] = P[2], bb[0] = P[3];
			AA[3] = P[4], AA[4] = P[5], AA[5] = P[6], bb[1] = P[7];
			ccT[0] = P[8], ccT[1] = P[9], ccT[2] = P[10], dd[0] = P[11];

			PerCam_UV[camID][frameID].Q[0] = AA[0] - PerCam_UV[camID][frameID].pt2D.x*ccT[0],
				PerCam_UV[camID][frameID].Q[1] = AA[1] - PerCam_UV[camID][frameID].pt2D.x*ccT[1],
				PerCam_UV[camID][frameID].Q[2] = AA[2] - PerCam_UV[camID][frameID].pt2D.x*ccT[2];
			PerCam_UV[camID][frameID].Q[3] = AA[3] - PerCam_UV[camID][frameID].pt2D.y*ccT[0],
				PerCam_UV[camID][frameID].Q[4] = AA[4] - PerCam_UV[camID][frameID].pt2D.y*ccT[1],
				PerCam_UV[camID][frameID].Q[5] = AA[5] - PerCam_UV[camID][frameID].pt2D.y*ccT[2];
			PerCam_UV[camID][frameID].u[0] = dd[0] * PerCam_UV[camID][frameID].pt2D.x - bb[0],
				PerCam_UV[camID][frameID].u[1] = dd[0] * PerCam_UV[camID][frameID].pt2D.y - bb[1];

			PerCam_UV[camID][frameID].pt3D = Point3d(count, count, count);//Interestingly, Ceres does not work if all the input are the same
			count++;
		}
	}

	//Initialize data for optim
	vector<int> PointsPerTrack;
	int ntimeinstances = 0;
	for (int camID = 0; camID < nCams; camID++)
		ntimeinstances += (int)PerCam_UV[camID].size();
	int * PerTrackFrameID = new int[ntimeinstances];
	double*All3D = new double[3 * ntimeinstances];

	int cID, fID;
	double x, y, z, t;
	int dummy[10000];
	double ts[10000];
	ImgPtEle iele;

	printLOG("Get 3D data:\n");
	vector<Point3d> T3D;
	vector<int> VisCamID, VisLocalFrameID;
	vector<double> TimeStamp;
	sprintf(Fname, "%s/Track3D/OptimizedRaw_Track_%.4d.txt", Path, TargetTrackID); fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	while (fscanf(fp, "%lf %lf %lf %lf %d %d", &x, &y, &z, &t, &cID, &fID) != EOF)
	{
		TimeStamp.push_back(t), VisCamID.push_back(cID), VisLocalFrameID.push_back(fID);
		T3D.push_back(Point3d(x, y, z));
	}
	fclose(fp);

	for (int ii = 0; ii < (int)TimeStamp.size(); ii++)
		ts[ii] = TimeStamp[ii], dummy[ii] = ii;
	Quick_Sort_Double(ts, dummy, 0, (int)TimeStamp.size() - 1);

	vector<ImgPtEle> Traj3D;
	for (int ii = 0; ii < (int)TimeStamp.size(); ii++)
	{
		int id = dummy[ii], camID = VisCamID[id], frameID = VisLocalFrameID[id];
		iele.viewID = camID, iele.frameID = frameID, iele.timeStamp = TimeStamp[id];

		iele.pt3D = T3D[id];
		for (int fid = 0; fid < (int)PerCam_UV[camID].size(); fid++)
		{
			if (PerCam_UV[camID][fid].frameID == frameID)
			{
				iele.pt2D = PerCam_UV[camID][fid].pt2D;
				for (int jj = 0; jj < 12; jj++)
					iele.P[jj] = PerCam_UV[camID][fid].P[jj];
				break;
			}
		}
		Traj3D.push_back(iele);
	}

	printLOG("DCT-based resampling:\n");
	omp_set_num_threads(omp_get_max_threads());
	printLOG("%d: ", TargetTrackID);

	if (Traj3D.size() == 0)
		return 0;

	double earliest = Traj3D[0].timeStamp, latest = Traj3D.back().timeStamp;
	int nData = (int)Traj3D.size();
	double resamplingStep = (latest - earliest) / nData;

	double lamda2_ = lamda2 * resamplingStep;
	ResamplingOf3DTrajectoryDCT(Traj3D, PriorOrder, true, resamplingStep, lamda1, lamda2_, true);

	sprintf(Fname, "%s/Track3D", Path); makeDir(Fname);
#pragma omp critical
	{
		sprintf(Fname, "%s/Track3D/DCTResampled_Track_%.4d.txt", Path, TargetTrackID); remove(Fname);
		fp = fopen(Fname, "w+");
		for (int ii = 0; ii < (int)Traj3D.size(); ii++)
			fprintf(fp, "%.4f %.4f %.4f %.4f %d %d\n", Traj3D[ii].pt3D.x, Traj3D[ii].pt3D.y, Traj3D[ii].pt3D.z, Traj3D[ii].timeStamp, Traj3D[ii].viewID, Traj3D[ii].frameID);
		fclose(fp);
	}

	delete[]VideoInfo;
	delete[]PerCam_UV;

	return 0;
}

int MotionPriorSTReconstructionDriver(char *Path, int nCams, int startF, int stopF, int npts, double RealOverSfm, double lamdaData, int SearchRange, double SearchStep, int module)
{
	const int PriorOrder = 1, motionPriorPower = 2;
	double lamdaPrior = 1.0 - lamdaData;
	double CeresCost;
	FILE *fp = 0;

	if (module == 1)
	{
		char Fname[512]; 	sprintf(Fname, "%s/Parameter.txt", Path); fp = fopen(Fname, "w+");
		fprintf(fp, "%d %d %d %d %.2f %d %.2f %.16f\n", nCams, startF, stopF, npts, lamdaData, SearchRange, SearchStep, RealOverSfm);
		fclose(fp);

		double *FrameLevelOffsetInfo = new double[nCams];
		sprintf(Fname, "%s/FGeoSync.txt", Path);  fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			exit(1);
		}
		for (int ii = 0; ii < nCams; ii++)
		{
			int cid; double foffset;
			fscanf(fp, "%d %lf ", &cid, &foffset);
			FrameLevelOffsetInfo[cid] = foffset;
		}
		fclose(fp);

		sprintf(Fname, "%s/Timing.txt", Path);	FILE *fp2 = fopen(Fname, "w+");

		double startTime = omp_get_wtime();
#ifdef EC2
		sprintf(Fname, "%s/PairwiseCost.txt", Path);
		if (IsFileExist(Fname) == 0)
		{
			vector<int> njobs;
			printLOG("EC2 Motion prior sync:\n");
			double nstartTime = omp_get_wtime();
			for (int ii = 0; ii < nCams - 1; ii++)
			{
				for (int jj = ii + 1; jj < nCams; jj++)
				{
					sprintf(Fname, "%s/PairwiseCost_%d_%.4d.txt", Path, ii, jj);
					if (IsFileExist(Fname) == 0)
					{
#ifdef _WINDOWS
						sprintf(Fname, "EnRecon.exe %s 7 1 1 %d %d", Path, ii, jj);
#else
#ifdef  EC2
						sprintf(Fname, "qsub -b y -cwd -pe orte 4 ./EnRecon %s 7 1 1 %d %d", Path, ii, jj);
#else
						sprintf(Fname, "./EnRecon %s 7 1 1 %d %d", Path, ii, jj);
#endif
#endif
						printLOG("%s\n", Fname);
						system(Fname);
					}
					njobs.push_back(0);
				}
			}
			printLOG("Start waiting ...\n");
			int bestSum = 0;
			while (true)
			{
				mySleep(1e3);
				int count = 0;
				for (int ii = 0; ii < nCams - 1; ii++)
				{
					for (int jj = ii + 1; jj < nCams; jj++)
					{
						sprintf(Fname, "%s/PairwiseCost_%d_%.4d.txt", Path, ii, jj); FILE *fp3 = fopen(Fname, "r");
						if (fp3 != NULL)
						{
							njobs[count] = 1;
							fclose(fp3);
						}
						//else
						//	printLOG("Have not seen %s yet. Found %d\n", Fname, count);
						count++;
					}
				}
				int sumRes = 0;
				for (int ii = 0; ii < (int)njobs.size(); ii++)
					sumRes += njobs[ii];

				if (sumRes == (int)njobs.size())
					break;
				if (bestSum < sumRes)
				{
					bestSum = sumRes;
					printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
				}
			}
			printLOG("ETime: %.4fs\n", omp_get_wtime() - nstartTime);

			//Generate PairwiseCost.txt
			sprintf(Fname, "%s/PairwiseCost.txt", Path);  fp = fopen(Fname, "w+");
			for (int ii = 0; ii < nCams - 1; ii++)
			{
				for (int jj = ii + 1; jj < nCams; jj++)
				{
					int v1, v2, nvalidPts; double baseline, TrajCost, offset;
					sprintf(Fname, "%s/PairwiseCost_%d_%.4d.txt", Path, ii, jj); FILE *fp3 = fopen(Fname, "r");
					fscanf(fp3, "%d %d %d %lf %lf %lf ", &v1, &v2, &nvalidPts, &baseline, &TrajCost, &offset); fclose(fp3);

					fprintf(fp, "%d %d %d %.3e %.8e %.3f\n", v1, v2, nvalidPts, baseline, TrajCost, offset);
				}
			}
			fclose(fp);
	}
#else
		sprintf(Fname, "%s/PairwiseCost.txt", Path);
		if (IsFileExist(Fname) == 0)
			EvaluateAllPairSTCost(Path, nCams, npts, startF, stopF, SearchRange, SearchStep, lamdaData, RealOverSfm, 2, FrameLevelOffsetInfo);
#endif
		fprintf(fp2, "Evaluated all pair: %.2fs\n", omp_get_wtime() - startTime);

		vector<int>cameraOrdering;
		vector<double> InitTimeStampInfoVector;
		DetermineCameraOrderingForGreedyDynamicSTBA(Path, "PairwiseCost", nCams, cameraOrdering, InitTimeStampInfoVector);
		vector<int> SelectedCamera;
		vector<double>TimeStampInfoVector;
		for (int ii = 0; ii < 3; ii++)
			SelectedCamera.push_back(cameraOrdering[ii]), TimeStampInfoVector.push_back(InitTimeStampInfoVector[ii]);// + FrameLevelOffsetInfo[ii]);

		startTime = omp_get_wtime();
		printLOG("\nCoarse ST estimation for 3 cameras (%d, %d, %d):\n", SelectedCamera[0], SelectedCamera[1], SelectedCamera[2]);
		MotionPriorSyncBruteForce2DTriplet(Path, SelectedCamera, 0, stopF, npts, TimeStampInfoVector, -SearchRange / 2, SearchRange / 2, SearchStep, lamdaData, RealOverSfm, motionPriorPower);
		printLOG("Coarse ST estimation for 3 cameras (%d, %d, %d): %.6f %.6f %.6f \n\n", SelectedCamera[0], SelectedCamera[1], SelectedCamera[2], TimeStampInfoVector[0], TimeStampInfoVector[1], TimeStampInfoVector[2]);
		fprintf(fp2, "Triplet bruteforce: %.2fs\n", omp_get_wtime() - startTime);

		//IncrementalMotionPriorSyncDiscreteContinous2D(Path, SelectedCamera, startF, stopF, npts, TimeStampInfoVector, 0, 0, 0, lamdaData, RealOverSfm, CeresCost, false);

		sprintf(Fname, "%s/MotionPriorSyncProgress.txt", Path);	fp = fopen(Fname, "w+");
		fprintf(fp, "%d %d %d %d %.6f %.6f %.6f \n", 3, SelectedCamera[0], SelectedCamera[1], SelectedCamera[2], TimeStampInfoVector[0], TimeStampInfoVector[1], TimeStampInfoVector[2]);

		int orderingChangeTrials = 0;
		for (int currentCamID = 3; currentCamID < nCams; currentCamID++)
		{
			startTime = omp_get_wtime();

			SelectedCamera.push_back(cameraOrdering[currentCamID]);
			TimeStampInfoVector.push_back(InitTimeStampInfoVector[currentCamID]);
			int NotSuccess = IncrementalMotionPriorSyncDiscreteContinous2D(Path, SelectedCamera, startF, stopF, npts, TimeStampInfoVector, -(int)(SearchStep* SearchRange / 2), (int)(SearchStep* SearchRange / 2), 0.0, lamdaData, RealOverSfm, CeresCost);

			//Push the current ordering ID to the end of the stack
			if (NotSuccess == 1)
			{
				SelectedCamera.erase(SelectedCamera.end() - 1);
				TimeStampInfoVector.erase(TimeStampInfoVector.end() - 1);

				//Nothing can be done with this last camera
				if (currentCamID == nCams - 1)
					break;

				std::vector<int>::iterator it1;
				it1 = cameraOrdering.end();
				cameraOrdering.insert(it1, cameraOrdering[currentCamID]);
				cameraOrdering.erase(cameraOrdering.begin() + currentCamID);

				std::vector<double>::iterator it2;
				it2 = InitTimeStampInfoVector.end();
				InitTimeStampInfoVector.insert(it2, InitTimeStampInfoVector[currentCamID]);
				InitTimeStampInfoVector.erase(InitTimeStampInfoVector.begin() + currentCamID);

				currentCamID--;

				orderingChangeTrials++;
				if (orderingChangeTrials == nCams - 3) //Already tried other ordering options but failed
					break;
			}
			else
			{
				fprintf(fp, "%d ", (int)SelectedCamera.size());
				for (int ii = 0; ii < (int)SelectedCamera.size(); ii++)
					fprintf(fp, "%d ", SelectedCamera[ii]);
				for (int ii = 0; ii < (int)SelectedCamera.size(); ii++)
					fprintf(fp, "%.6f ", TimeStampInfoVector[ii]);
				fprintf(fp, "\n");
			}

			fprintf(fp2, "Incre-Camera: %d %.2fs\n", (int)SelectedCamera.size(), omp_get_wtime() - startTime);
		}
		fclose(fp); fclose(fp2);

		//Final refinement using ML weight
		int NotSuccess = IncrementalMotionPriorSyncDiscreteContinous2D(Path, SelectedCamera, startF, stopF, npts, TimeStampInfoVector, 0, 0, 0, lamdaData, RealOverSfm, CeresCost, false);
		if (NotSuccess == 0)
		{
			double earliest = 9e9;
			vector<int> SortedSelectedCamera;
			vector<double> SortedTimeStampInfoVector;
			SortedSelectedCamera = SelectedCamera;
			sort(SortedSelectedCamera.begin(), SortedSelectedCamera.end());
			for (int ii = 0; ii < (int)SelectedCamera.size(); ii++)
			{
				for (int jj = 0; jj < (int)SelectedCamera.size(); jj++)
				{
					if (SortedSelectedCamera[ii] == SelectedCamera[jj])
					{
						SortedTimeStampInfoVector.push_back(TimeStampInfoVector[jj]);
						if (earliest > TimeStampInfoVector[jj])
							earliest = TimeStampInfoVector[jj];
						break;
					}
				}
			}
			for (int ii = (int)SortedSelectedCamera.size() - 1; ii >= 0; ii--)
				SortedTimeStampInfoVector[ii] -= earliest;

			sprintf(Fname, "%s/FMotionPriorSync.txt", Path);	fp = fopen(Fname, "w+");
			for (int ii = 0; ii < (int)SortedSelectedCamera.size(); ii++)
				fprintf(fp, "%d 1.0 %.6f\n", SortedSelectedCamera[ii], SortedTimeStampInfoVector[ii]);
			fclose(fp);
		}
		delete[]FrameLevelOffsetInfo;
}
	else if (module > 1)
	{
		vector<int> SelectedCamera;
		vector<double> TimeStampInfoVector;
		char Fname[512]; sprintf(Fname, "%s/FMotionPriorSync.txt", Path);	FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n. Abort!", Fname);
			return 1;
		}
		int selected; double offsetValue;
		while (fscanf(fp, "%d 1.0 %lf ", &selected, &offsetValue) != EOF)
			SelectedCamera.push_back(selected), TimeStampInfoVector.push_back(offsetValue);
		fclose(fp);

		if (module == 2)
		{
			TrajectoryTriangulation(Path, SelectedCamera, TimeStampInfoVector, npts, startF, stopF, lamdaData, RealOverSfm, motionPriorPower);

			/*printLOG("Initial offsets: ");
			for (int ii = 0; ii < (int)SelectedCamera.size(); ii++)
			printLOG("%.6f ", TimeStampInfoVector[ii]);
			printLOG("\n");

			double CeresCost;
			IncrementalMotionPriorSyncDiscreteContinous2D(Path, SelectedCamera, startF, stopF, npts, TimeStampInfoVector, 0, 0, 0, lamdaData, RealOverSfm, CeresCost, false);

			printLOG("Final offsets: ");
			for (int ii = 0; ii < (int)SelectedCamera.size(); ii++)
			printLOG("%.6f ", TimeStampInfoVector[ii]);
			printLOG("\n");

			sprintf(Fname, "%s/FMotionPriorSync2.txt", Path);	fp = fopen(Fname, "w+");
			for (int ii = 0; ii < (int)SelectedCamera.size(); ii++)
			fprintf(fp, "%d 1.0 %.6f\n", SelectedCamera[ii], TimeStampInfoVector[ii] - TimeStampInfoVector[5]);
			fclose(fp);*/
		}
		else if (module == 3)
			ResamplingOf3DTrajectorySplineDriver(Path, SelectedCamera, TimeStampInfoVector, startF, stopF, npts, lamdaData);
		else if (module == 4)
		{
#ifdef EC2
			for (int pid = 0; pid < npts; pid++)
				ResamplingOf3DTrajectoryDCTDriverParallel(Path, SelectedCamera, TimeStampInfoVector, pid, PriorOrder, startF, stopF, npts, lamdaData, lamdaPrior);
#else
			ResamplingOf3DTrajectoryDCTDriver(Path, SelectedCamera, TimeStampInfoVector, PriorOrder, startF, stopF, npts, lamdaData, lamdaPrior);
#endif
	}
	}
	return 0;
}

int TriangulationSyncRobustBruteForce2DStereoAllInstances(char *Path, int *SelectedCams, int groupId, vector<int> &TrackingInst, int TrajRange, int startF, int stopF, int increImgFrames, int allNpts, int *frameTimeStamp, int LowBound, int UpBound, vector<ImgPtEle> *PerCam_UV, double TriangThresh, bool silent)
{
	//The goad is to accumulate all info from all instances for sync. This function only looks at points where there is a valley in the cost(offset) to sync and filter points
	char Fname[512]; FILE *fp = 0;
	const int nCams = 2;
	int minStamp = min(frameTimeStamp[0], frameTimeStamp[1]), maxStamp = max(frameTimeStamp[0], frameTimeStamp[1]);

	//Read calib info
	VideoData VideoInfo[2];
	if (ReadVideoDataI(Path, VideoInfo[0], SelectedCams[0], startF - maxStamp - TrajRange, stopF - minStamp + TrajRange) == 1)
		return 1;
	if (ReadVideoDataI(Path, VideoInfo[1], SelectedCams[1], startF - maxStamp - TrajRange, stopF - minStamp + TrajRange) == 1)
		return 1;

	ImgPtEle ptEle;
	bool createdMem = false;
	if (PerCam_UV == NULL)
	{
		createdMem = true;
		PerCam_UV = new vector<ImgPtEle>[nCams*allNpts];
		for (int camID = 0; camID < nCams; camID++)
			for (int pid = 0; pid < allNpts; pid++)
				PerCam_UV[camID*allNpts + pid].reserve(TrajRange + 1);
	}
	else
	{
		for (int camID = 0; camID < nCams; camID++)
			for (int trackID = 0; trackID < allNpts; trackID++)
				PerCam_UV[camID*allNpts + trackID].clear();
	}

	//Get 2D info
	for (int camID = 0; camID < nCams; camID++)
	{
		float u, v, s, a, w0, w1, w2, w3;
		int pid, fid, nf, nptsSeed, nptsCum = 0, nseeds = (int)TrackingInst.size();
		for (int seedID = 0; seedID < nseeds; seedID++)
		{
			sprintf(Fname, "%s/Track2D/CC_%d_%.4d.txt", Path, SelectedCams[camID], TrackingInst[seedID]);
			if (IsFileExist(Fname) == 0)
			{
				printLOG("Cannot load %s\n", Fname);
				continue;
			}
			FILE *fp = fopen(Fname, "r");
			fscanf(fp, "%d ", &nptsSeed);
			while (fscanf(fp, "%d %d", &pid, &nf) != EOF)
			{
				for (int ii = 0; ii < nf; ii++)
				{
					fscanf(fp, "%d %f %f %f %f %f %f %f %f ", &fid, &u, &v, &s, &a, &w0, &w1, &w2, &w3);
					if (!VideoInfo[camID].VideoInfo[fid].valid)
						continue; //camera not localized

					ptEle.pt2D.x = u, ptEle.pt2D.y = v, ptEle.scale = s, ptEle.frameID = fid;
					LensCorrectionPoint(&ptEle.pt2D, VideoInfo[camID].VideoInfo[fid].K, VideoInfo[camID].VideoInfo[fid].distortion);
					PerCam_UV[camID*allNpts + pid + nptsCum].push_back(ptEle);
				}
			}
			fclose(fp);

			nptsCum += nptsSeed; //nptsCum == allNpts in the end
		}
	}

	//Filter outliers again
	int ngoodPoint = 0;
	int *aOffset = new int[UpBound - LowBound + 1], *badPoints = new int[allNpts];
	double *aError = new double[UpBound - LowBound + 1], *saError = new double[UpBound - LowBound + 1];
	vector<double> vaError; vaError.resize(UpBound - LowBound + 1);
	double A[12], B[4], P[24]; Point2d pts[2], ppts[2]; Point3d P3d;
	for (int pid = 0; pid < allNpts; pid++)
	{
		int count = 0, bestoff, bestnPointUsed;
		double maxError = 0, minError = 9e9;
		for (int off = LowBound * increImgFrames; off <= UpBound * increImgFrames; off += increImgFrames)
		{
			double cumError = 0.0, usedPointsCount = 0;
			for (int fid1 = 0; fid1 < PerCam_UV[pid].size(); fid1++)
			{
				double error = 0.0;
				int ref1 = PerCam_UV[pid][fid1].frameID; //the point has been tracked at the offset frame already
				for (int fid2 = 0; fid2 < PerCam_UV[allNpts + pid].size(); fid2++)
				{
					int ref2 = PerCam_UV[allNpts + pid][fid2].frameID; //the point has been tracked at the offset frame already
					if (ref1 + frameTimeStamp[0] == ref2 + frameTimeStamp[1] + off) //see if the corresponding frame in the other camera has point. Use addition to fake the refframe:
					{
						if (VideoInfo[0].VideoInfo[ref1].valid == 0 || VideoInfo[1].VideoInfo[ref2].valid == 0)
							continue;

						pts[0] = PerCam_UV[pid][fid1].pt2D, pts[1] = PerCam_UV[allNpts + pid][fid2].pt2D;

						if (VideoInfo[0].VideoInfo[ref1].ShutterModel == 0)
							AssembleP(VideoInfo[0].VideoInfo[ref1].K, VideoInfo[0].VideoInfo[ref1].R, VideoInfo[0].VideoInfo[ref1].T, P);
						else
							AssembleP_RS(pts[0], VideoInfo[0].VideoInfo[ref1], P);

						if (VideoInfo[1].VideoInfo[ref2].ShutterModel == 0)
							AssembleP(VideoInfo[1].VideoInfo[ref2].K, VideoInfo[1].VideoInfo[ref2].R, VideoInfo[1].VideoInfo[ref2].T, P);
						else
							AssembleP_RS(pts[1], VideoInfo[1].VideoInfo[ref2], P + 12);

						NviewTriangulation(pts, P, &P3d, 2, 1, NULL, A, B);
						ProjectandDistort(P3d, ppts, P, NULL, NULL, 2);

						error = 0.0;
						for (int ll = 0; ll < 2; ll++)
							error += pow(ppts[ll].x - pts[ll].x, 2) + pow(ppts[ll].y - pts[ll].y, 2);
						error = sqrt(error / 2);

						usedPointsCount++;
						break;
					}
				}
				cumError += error;
			}
			aError[count] = cumError / (0.0000001 + usedPointsCount);
			vaError[count] = cumError / (0.0000001 + usedPointsCount);
			if (usedPointsCount > 10) //sufficient overlapping between 2 streams at the current frame offset
			{
				if (maxError < aError[count])
					maxError = aError[count];
				if (minError > aError[count])
				{
					bestoff = off, bestnPointUsed = usedPointsCount;
					minError = aError[count];
				}
			}
			count++;
		}

		/*bool OK = false;
		if (OK)
		{
		FILE *fp = fopen("C:/temp/cost.txt", "w+");
		for (int ii = 0; ii<241; ii++)
		fprintf(fp, "%.4f\n", vaError[ii]);
		fclose(fp);
		}*/
		if (minError / maxError > 0.25 || minError == 0 || minError > TriangThresh) //there is a valley in the cost function -->almost always corredponding trajectory
			badPoints[pid] = 1;
		else
		{
			badPoints[pid] = 0;
			ngoodPoint++;
			if (!silent)
				printLOG("%d ...", pid);
		}
	}
	printLOG("\nFound %d good points\n", ngoodPoint);
	if (ngoodPoint < 10)
	{
		if (createdMem)
			delete[]PerCam_UV;
		delete[]aOffset, delete[]aError, delete[]saError, delete[]badPoints;
		return 1;
	}

	//Start sliding
	int count = 0, BestOffset = 9e9;
	double minError = 9e9;
	for (int off = LowBound * increImgFrames; off <= UpBound * increImgFrames; off += increImgFrames)
	{
		double cumError = 0.0, usedPointsCount = 0;
		for (int pid = 0; pid < allNpts; pid++)
		{
			if (badPoints[pid] == 1)
				continue;
			for (int fid1 = 0; fid1 < PerCam_UV[pid].size(); fid1++)
			{
				double error = 0.0;
				int ref1 = PerCam_UV[pid][fid1].frameID; //the point has been tracked at the offset frame already
				for (int fid2 = 0; fid2 < PerCam_UV[allNpts + pid].size(); fid2++)
				{
					int ref2 = PerCam_UV[allNpts + pid][fid2].frameID; //the point has been tracked at the offset frame already
					if (ref1 + frameTimeStamp[0] == ref2 + frameTimeStamp[1] + off) //see if the corresponding frame in the other camera has point. Use addition to fake the refframe:
					{
						if (VideoInfo[0].VideoInfo[ref1].valid == 0 || VideoInfo[1].VideoInfo[ref2].valid == 0)
							continue;

						pts[0] = PerCam_UV[pid][fid1].pt2D, pts[1] = PerCam_UV[allNpts + pid][fid2].pt2D;
						if (VideoInfo[0].VideoInfo[ref1].ShutterModel == 0)
							AssembleP(VideoInfo[0].VideoInfo[ref1].K, VideoInfo[0].VideoInfo[ref1].R, VideoInfo[0].VideoInfo[ref1].T, P);
						else
							AssembleP_RS(pts[0], VideoInfo[0].VideoInfo[ref1], P);

						if (VideoInfo[1].VideoInfo[ref2].ShutterModel == 0)
							AssembleP(VideoInfo[1].VideoInfo[ref2].K, VideoInfo[1].VideoInfo[ref2].R, VideoInfo[1].VideoInfo[ref2].T, P);
						else
							AssembleP_RS(pts[1], VideoInfo[1].VideoInfo[ref2], P + 12);

						NviewTriangulation(pts, P, &P3d, 2, 1, NULL, A, B);
						ProjectandDistort(P3d, ppts, P, NULL, NULL, 2);

						error = 0.0;
						for (int ll = 0; ll < 2; ll++)
							error += pow(ppts[ll].x - pts[ll].x, 2) + pow(ppts[ll].y - pts[ll].y, 2);
						error = sqrt(error / 2);
						usedPointsCount++;

						break;
					}
				}
				cumError += error;
			}
		}

		if (usedPointsCount == 0)
			cumError = 9e9;
		cumError = cumError / (0.0000001 + usedPointsCount);
		if (cumError < minError)
			minError = cumError, BestOffset = off;

		aError[count] = cumError;
		aOffset[count] = off;
		printLOG("@off %d (id: %d): %.5e -- Best offset: %d\n", off, count, cumError, BestOffset);
		count++;
	}
	Quick_Sort_Double(aError, aOffset, 0, count - 1);
	printLOG("Pair (%d, %d): %d: %.3e  ... %d: %.3e \n", SelectedCams[0], SelectedCams[1], aOffset[0], aError[0], aOffset[1], aError[1]);

	sprintf(Fname, "%s/GeoSyncDebug_%d.txt", Path, groupId);	fp = fopen(Fname, "a+");
	fprintf(fp, "%d %d %d %d %.3e %d %.3e %d %.3e\n", SelectedCams[0], SelectedCams[1], ngoodPoint, aOffset[0], aError[0], aOffset[1], aError[1], aOffset[count - 1], aError[count - 1]);
	fclose(fp);

	frameTimeStamp[1] = frameTimeStamp[1] + BestOffset;

	for (int cid = 0; cid < nCams; cid++)
	{
		sprintf(Fname, "%s/Track2D/UltimateID_%d_%.4d.txt", Path, groupId, SelectedCams[cid]);	FILE *fp = fopen(Fname, "a+");
		for (int pid = 0; pid < allNpts; pid++)
		{
			if (badPoints[pid] != 0)
				continue;
			fprintf(fp, "%d ", pid);
		}
		fprintf(fp, "\n");
		fclose(fp);
	}

	if (createdMem)
		delete[]PerCam_UV;
	delete[]aOffset, delete[]aError, delete[]saError, delete[]badPoints;

	return 0;
}
int GeometricSyncAllInstancesDriver(char *Path, vector<int> vCams, int groupdId, int npts, vector<int> &TrackingInstance, int TrajRange, int startF, int stopF, int increImgFrames, int SearchRange, double TriangThresh, double *TimeStampOffset, bool HasInitOffset)
{
	char Fname[512];
	int nCams = (int)vCams.size();

	if (TimeStampOffset == NULL)
	{
		TimeStampOffset = new double[nCams];
		for (int ii = 0; ii < nCams; ii++)
			TimeStampOffset[ii] = 0;
	}
	if (!HasInitOffset)
		for (int ii = 0; ii < nCams; ii++)
			TimeStampOffset[ii] = 0;

	vector<ImgPtEle> *PerCam_UV = new vector<ImgPtEle>[2 * npts];
	for (int camID = 0; camID < 2; camID++)
		for (int pid = 0; pid < npts; pid++)
			PerCam_UV[camID*npts + pid].reserve(2 * TrajRange + 1);

	printLOG("Geometric sync:\n");
	for (int ii = 0; ii < nCams; ii++)
	{
		sprintf(Fname, "%s/Track2D/UltimateID_%d_%.4d.txt", Path, groupdId, vCams[ii]);
		FILE *fp = fopen(Fname, "w+"); fclose(fp);
	}

	sprintf(Fname, "%s/GeoSyncDebug_%d.txt", Path, groupdId);	FILE *fp = fopen(Fname, "w+"); fclose(fp);
	sprintf(Fname, "%s/GeoSync_%d.txt", Path, groupdId); fp = fopen(Fname, "w+");
	for (int jj = 0; jj < nCams - 1; jj++)
	{
		for (int ii = jj + 1; ii < nCams; ii++)
		{
			int SelectedCams[2] = { vCams[jj], vCams[ii] }, Offset[] = { TimeStampOffset[vCams[jj]], TimeStampOffset[vCams[ii]] };
			//FmatSyncBruteForce2DStereoAllInstances(Path, SelectedCams, TrackingInstance, TrajRange, startF, stopF, increImgFrames, npts, Offset, -SearchRange, SearchRange, GivenF, PerCam_UV, true);
			//FmatSyncRobustBruteForce2DStereoAllInstances(Path, SelectedCams, TrackingInstance, TrajRange, startF, stopF, increImgFrames, npts, Offset, -SearchRange, SearchRange, PerCam_UV, false);
			if (TriangulationSyncRobustBruteForce2DStereoAllInstances(Path, SelectedCams, groupdId, TrackingInstance, TrajRange, startF, stopF, increImgFrames, npts, Offset, -SearchRange, SearchRange, PerCam_UV, TriangThresh, true) == 1)
				continue;
			printLOG("%d %d %d\n", vCams[jj], vCams[ii], Offset[1] - TimeStampOffset[vCams[ii]]);
			fprintf(fp, "%d %d %d\n", vCams[jj], vCams[ii], Offset[1] - TimeStampOffset[vCams[ii]]);
		}
	}
	fclose(fp);
	delete[]PerCam_UV;

	sprintf(Fname, "GeoSync_%d", groupdId); PrismMST(Path, Fname, nCams);
	AssignOffsetFromMST(Path, Fname, nCams, TimeStampOffset);

	printLOG("Done.\n\n***NOTE: FGeoSync is in time stamp format (f = f_ref - offset) ***\n");



	return 0;
}
int SpatialTemporalCalibInTheWildDriver(char *Path, int nCams, int RefStartF, int RefStopF, int RefIncreF, int TrackInstanceStartF, int TrackInstanceStopF, int TrackInstanceStepF, int fps, int TrackTime, int module)
{
	omp_set_num_threads(omp_get_max_threads());

	int debug = 0;
	int interpAlgo = -1, useSIFTGPU = 1;

	char Fname[512];
	vector<int> TrackingInstances;
	for (int ii = TrackInstanceStartF; ii <= TrackInstanceStopF; ii += TrackInstanceStepF)
		TrackingInstances.push_back(ii);
	int nInstances = (int)TrackingInstances.size();

	//0. Obtain spatial calibration info for each cameras

	//1. Audio sync or very rough manual sync
	//int *frameTimeStamp = new int[nCams];
	int c, f, frameTimeStamp[100]; double dummy;
	sprintf(Fname, "%s/InitSync.txt", Path);
	if (IsFileExist(Fname) == 0)
		printLOG("Cannot load %s. Please initalize sync\n", Fname);
	else
		printLOG("Load %s. Make sure that it is in timestamp format (f = f_ref - timestamp)\n", Fname);
	FILE *fp = fopen(Fname, "r");
	while (fscanf(fp, "%d %lf %d ", &c, &dummy, &f) != EOF)
		frameTimeStamp[c] = f;
	fclose(fp);

	//int frameTimeStamp[] = { -96, -124, -70, 0, -118, -98, -106, -76, -138, -122 }; //in time stamp: f = f_ref - offset  (for dance seq)
	//int frameTimeStamp[] = { 0, -6, -51, -6, -44, -10, -12, -2 };//for jump rough
	//int frameTimeStamp[] = { 0, -11, -72, -18, -43, -27, -25, -8 };//for jump fine
	//int frameTimeStamp[] = { 0, -4, -18, -4, -11, -7, -6, -2 };//for jump fine @30
	//int frameTimeStamp[] = { 0, 0, 0, 0, 0, 0, 0 };//for checker2

	//2. Detect and match feature points
	int HistogrameEqual = 0, distortionCorrected = 0, OulierRemoveTestMethod = 2, ninlierThesh = 40, //fmat test
		nViewsPlus = 2, LensType = RADIAL_TANGENTIAL_PRISM;
	double ratioThresh = 0.6, minScale = 1.5, maxScale = 7.5; //too small features are likely to be noise, too large features are likely to be very unstable

	//3. Track all the features
	bool BroxInit = false;
	int nWins = 2, WinStep = 3, PyrLevel = 4;
	double MeanSSGThresh = 200.0;

	//4+5+6: triangulation + sync
	int maxnPts, GeoSearchRange = 120;
	double TriangThresh = 5.0, stationaryThresh = 50, scaleReal2Sfm = 300.0 / 1.14;
	double lamdaData = 0.99, MotionPriorSearchStep = 0.1; int MotionPriorSearchRange = 20;

	vector<int> SelectedCams;
	for (int ii = 0; ii < nCams; ii++)
		SelectedCams.push_back(ii);

	double *dframeTimeStamp = new double[nCams];
	for (int ii = 0; ii < nCams; ii++)
		dframeTimeStamp[ii] = frameTimeStamp[ii];

	//2. Detect and match feature points
	if (module == 2 || module == -1)
	{
#ifndef EC2
		for (int ii = 0; ii < (int)TrackingInstances.size(); ii++)
		{
			int fid = TrackingInstances[ii];
			sprintf(Fname, "%s/Dynamic/%.4d/IDPM.txt", Path, fid);
			if (IsFileExist(Fname) == 1)
			{
				printLOG("%s computed\n", Fname);
				if (debug == 1)
					VisualizeSiftMatchAllPairs(Path, nCams, fid, frameTimeStamp);
			}
			else
			{
				if (useSIFTGPU == 0)
					GeneratePointsCorrespondenceMatrix_CPU(Path, nCams, fid, HistogrameEqual, ratioThresh, frameTimeStamp, 2); //internal parallization
				else
					GeneratePointsCorrespondenceMatrix_SiftGPU(Path, nCams, fid, HistogrameEqual, ratioThresh, frameTimeStamp, true, debug);
				if (debug)
					VisualizeSiftMatchAllPairs(Path, nCams, fid, frameTimeStamp);
				GenerateMatchingTable(Path, nCams, fid);
			}
		}
#else
		vector<int>njobs;
		int alreadyComputed = 0, step = 5;
		int increRecon = TrackingInstances[1] - TrackingInstances[0];

		for (int ii = TrackInstanceStartF; ii <= TrackInstanceStopF; ii += TrackInstanceStepF * step)
		{
			int fidEnd = min(TrackInstanceStopF, ii + TrackInstanceStepF * step);
			sprintf(Fname, "%s/CorrespondenceMatrix_CPU_%d_%d_%.4d.txt", Path, ii, fidEnd, TrackInstanceStepF);
			if (IsFileExist(Fname) == 0)
			{
#ifdef _WINDOWS
				char buffer[512];  myGetCurDir(512, buffer);
				sprintf(Fname, "%s/EnRecon.exe %s 18 %d %d %d %d %.2f", buffer, Path, nCams, ii, fidEnd, TrackInstanceStepF, ratioThresh);
#else
#ifdef EC2
				sprintf(Fname, "qsub -b y -cwd -pe orte %d ./EnRecon %s 18 %d %d %d %d %.2f", min(omp_get_max_threads(), 2), Path, nCams, ii, fidEnd, TrackInstanceStepF, ratioThresh);
#else
				sprintf(Fname, "./EnRecon %s 18 %d %d %d %d %.2f", Path, nCams, ii, fidEnd, TrackInstanceStepF, ratioThresh);
#endif
#endif
				printLOG(Fname); printLOG("\n");
				system(Fname);
			}
			else
				alreadyComputed++;
			njobs.push_back(0);
		}
		int count, sumRes, bestSum = 0, once = 1;
		double startWaitTime = omp_get_wtime(), appStopTime = 9e9, appMeanTime = 9e9;
		while (omp_get_wtime() - startWaitTime < appStopTime)//wait for it to finish
		{
			count = 0;
			for (int ii = TrackInstanceStartF; ii <= TrackInstanceStopF; ii += TrackInstanceStepF * step)
			{
				int fidEnd = min(TrackInstanceStopF, ii + TrackInstanceStepF * step);
				sprintf(Fname, "%s/CorrespondenceMatrix_CPU_%d_%d_%.4d.txt", Path, ii, fidEnd, TrackInstanceStepF);
				if (IsFileExist(Fname) == 1)
				{
					njobs[count] = 1;
					appMeanTime = omp_get_wtime() - startWaitTime;
				}
				count++;
			}

			sumRes = 0;
			for (int ii = 0; ii < (int)njobs.size(); ii++)
				sumRes += njobs[ii];
			if (sumRes - alreadyComputed > ((int)njobs.size() - alreadyComputed) / 2 && once == 1)
			{
				once = 2;
				appStopTime = appMeanTime * 3;
				printLOG("\nSet max waiting time: %.2fs\n", appStopTime);
			}
			if (sumRes == (int)njobs.size())
				break;
			if (bestSum < sumRes)
			{
				bestSum = sumRes;
				printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
			}
			mySleep(10e3);
			}
#endif
		printLOG("Get puative matches for each view\n");
		GetPutativeMatchesForEachView(Path, nCams, TrackingInstances, Point2d(minScale, maxScale), nViewsPlus, frameTimeStamp);

		printLOG("Remove duplicated matches\n");
		for (int ii = 0; ii < (int)TrackingInstances.size(); ii++)
			RemoveDuplicatedMatches(Path, nCams, TrackingInstances[ii]);

		sprintf(Fname, "%s/ClassColor.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			printLOG("Remove matches of not interesting classes\n");
			vector<Point3i> DynamicClassColor;
			Point3i Color;
			while (fscanf(fp, "%d %d %d ", &Color.x, &Color.y, &Color.z) != EOF)
				DynamicClassColor.push_back(Color);
			fclose(fp);

			for (int ii = 0; ii < (int)TrackingInstances.size(); ii++)
				RemoveMatchesOfDifferentClass(Path, nCams, TrackingInstances[ii], frameTimeStamp, DynamicClassColor);
		}

		printLOG("Refine matches\n");
		omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic,1)
		for (int ii = 0; ii < (int)TrackingInstances.size(); ii++)
			RefineInitialDynamicPointsAppearance(Path, TrackingInstances[ii], nCams, nViewsPlus, 1.0);

		printLOG("Finalize matches\n");
		vector<int> VstartF, Vnpts;
		for (int inst = 0; inst < (int)TrackingInstances.size(); inst++)
		{
			int npts, TrackingStartF = TrackingInstances[inst];
			sprintf(Fname, "%s/Dynamic/nMatches_%.4d.txt", Path, TrackingStartF); 	FILE *fp = fopen(Fname, "r");
			fscanf(fp, "%d %d\n", &RefStartF, &npts); fclose(fp);

			VstartF.push_back(RefStartF), Vnpts.push_back(npts);
		}

		sprintf(Fname, "%s/Dynamic/nMatches.txt", Path); 	FILE *fp = fopen(Fname, "w+");
		for (int ii = 0; ii < (int)VstartF.size(); ii++)
			fprintf(fp, "%d %d\n", VstartF[ii], Vnpts[ii]);
		fclose(fp);
		}

	//3. Track all the features:
	int noTemplateUpdate = 0;
	if (module == 3 || module == -1)
	{
#ifndef EC2
		omp_set_num_threads(omp_get_max_threads());
		for (int cid = 0; cid < nCams; cid++)
		{
#pragma omp parallel for schedule(dynamic,1)
			for (int fid = 0; fid < (int)TrackingInstances.size(); fid++)
			{
				char Fname[512]; sprintf(Fname, "%s/Logs/PMatchTracking_%d_%.4d_%.4d.txt", Path, cid, fid, fid);
				if (IsFileExist(Fname) == 0)
				{
					TrackAllPointsWithRefTemplateDriver(Path, cid, TrackingInstances[fid], RefIncreF, fps, TrackTime, nWins, WinStep, PyrLevel, MeanSSGThresh, interpAlgo);
					FILE *fp = fopen(Fname, "w+"); fclose(fp);
				}
				if (debug == 1)
					VisualizeTracking(Path, cid, TrackingInstances[fid], 1, fps, TrackTime, 0);
			}
		}
		if (BroxInit)
		{
#pragma omp parallel for schedule(dynamic,1)
			for (int cid = 0; cid < nCams; cid++)
				for (int fid = 0; fid < (int)TrackingInstances.size(); fid++)
					TrackAllPointsWithRefTemplate_DenseFlowDriven_Driver(Path, cid, TrackingInstances[fid], RefIncreF, fps, TrackTime, nWins, WinStep, MeanSSGThresh, noTemplateUpdate, interpAlgo);
		}
#else
		vector<int>njobs;
		int alreadyComputed = 0;
		int increRecon = TrackingInstances[1] - TrackingInstances[0];

		for (int cid = 0; cid < nCams; cid++)
		{
			for (int fid = TrackingInstances[0]; fid <= TrackingInstances.back(); fid += increRecon)
			{
				char Fname[512]; sprintf(Fname, "%s/Logs/PMatchTracking_%d_%.4d_%.4d.txt", Path, cid, fid, fid);
				if (IsFileExist(Fname) == 0)
				{
#ifdef _WINDOWS
					sprintf(Fname, "EnRecon.exe %s 10 %d %d %d %d %d %d %d %d %d %d %.2f %d %d", Path, cid, fid, fid, increRecon, RefIncreF, fps, TrackTime, nWins, WinStep, PyrLevel, MeanSSGThresh, noTemplateUpdate, interpAlgo);
#elif EC2
					sprintf(Fname, "qsub -b y -cwd -pe orte 2 ./EnRecon %s 10 %d %d %d %d %d %d %d %d %d %d %.2f %d %d", Path, cid, fid, fid, increRecon, RefIncreF, fps, TrackTime, nWins, WinStep, PyrLevel, MeanSSGThresh, noTemplateUpdate, interpAlgo); //assign 1 cores suffers from memory problem
#else
					sprintf(Fname, "./EnRecon %s 10 %d %d %d %d %d %d %d %d %d %d %.2f %d %d", Path, cid, fid, fid, increRecon, RefIncreF, fps, TrackTime, nWins, WinStep, PyrLevel, MeanSSGThresh, noTemplateUpdate, interpAlgo); //assign 1 cores suffers from memory problem
#endif
					printLOG(Fname); printLOG("\n");
					system(Fname);
				}
				else
				{
					printLOG("Found %s\n", Fname);
					alreadyComputed++;
				}
				njobs.push_back(0);
			}
		}
		int count, sumRes, bestSum = 0, once = 1;
		double startWaitTime = omp_get_wtime(), appStopTime = 9e9, appMeanTime = 9e9;
		while (omp_get_wtime() - startWaitTime < appStopTime)//wait for it to finish
		{
			count = 0;
			for (int cid = 0; cid < nCams; cid++)
			{
				for (int fid = TrackingInstances[0]; fid <= TrackingInstances.back(); fid += increRecon)
				{
					sprintf(Fname, "%s/Logs/PMatchTracking_%d_%.4d_%.4d.txt", Path, cid, fid, fid);
					if (IsFileExist(Fname) == 1)
					{
						njobs[count] = 1;
						appMeanTime = omp_get_wtime() - startWaitTime;
					}
					count++;
				}
			}

			sumRes = 0;
			for (int ii = 0; ii < (int)njobs.size(); ii++)
				sumRes += njobs[ii];
			if (sumRes - alreadyComputed > ((int)njobs.size() - alreadyComputed) / 2 && once == 1)
			{
				once = 2;
				appStopTime = appMeanTime * 3;
				printLOG("\nSet max waiting time: %.2fs\n", appStopTime);
			}
			if (sumRes == (int)njobs.size())
				break;
			if (bestSum < sumRes)
			{
				bestSum = sumRes;
				printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
			}
			mySleep(10e3);
		}

		//Try dense flow-driven tracker
		if (BroxInit)
		{
			for (int cid = 0; cid < nCams; cid++)
			{
				for (int fid = TrackingInstances[0]; fid <= TrackingInstances.back(); fid += increRecon)
				{
					sprintf(Fname, "%s/Logs/PMatchTrackingD_%d_%d_%.4d.txt", Path, cid, fid, fid);
					if (IsFileExist(Fname) == 0)
					{
#ifdef _WINDOWS
						sprintf(Fname, "EnRecon.exe %s 14 %d %d %d %d %d %d %d %d %d %.2f %d", Path, cid, fid, fid, increRecon, RefIncreF, fps, TrackTime, nWins, WinStep, MeanSSGThresh, interpAlgo);
#else
#ifdef EC2
						sprintf(Fname, "qsub -b y -cwd -pe orte 1 ./EnRecon %s 14 %d %d %d %d %d %d %d %d %d %.2f %d", Path, cid, fid, fid, increRecon, RefIncreF, fps, TrackTime, nWins, WinStep, MeanSSGThresh, interpAlgo);
#else
						sprintf(Fname, "./EnRecon %s 14 %d %d %d %d %d %d %d %d %d %.2f %d", Path, cid, fid, fid, increRecon, RefIncreF, fps, TrackTime, nWins, WinStep, MeanSSGThresh, interpAlgo);
#endif
#endif
						printLOG(Fname); printLOG("\n");
						system(Fname);
					}
					else
						alreadyComputed++;
					njobs.push_back(0);
				}
			}
			bestSum = 0, once = 1;
			startWaitTime = omp_get_wtime(), appStopTime = 9e9, appMeanTime = 9e9;
			while (omp_get_wtime() - startWaitTime < appStopTime)//wait for it to finish
			{
				count = 0;
				for (int cid = 0; cid < nCams; cid++)
				{
					for (int fid = TrackingInstances[0]; fid <= TrackingInstances.back(); fid += increRecon)
					{
						sprintf(Fname, "%s/Logs/PMatchTrackingD_%d_%d_%.4d.txt", Path, cid, fid, fid);
						if (IsFileExist(Fname) == 1)
						{
							njobs[count] = 1;
							appMeanTime = omp_get_wtime() - startWaitTime;
						}
						count++;
					}
				}

				sumRes = 0;
				for (int ii = 0; ii < (int)njobs.size(); ii++)
					sumRes += njobs[ii];
				if (sumRes - alreadyComputed > ((int)njobs.size() - alreadyComputed) / 2 && once == 1)
				{
					once = 2;
					appStopTime = appMeanTime * 3;
					printLOG("\nSet max waiting time: %.2fs\n", appStopTime);
				}
				if (sumRes == (int)njobs.size())
					break;
				if (bestSum < sumRes)
				{
					bestSum = sumRes;
					printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
				}
		}
	}
#endif

		//get Track2D/C_**
		printLOG("Start removing spurious flow by gradient inconsistency...\n");
#pragma omp parallel for schedule(dynamic,1)
		for (int ii = 0; ii < (int)TrackingInstances.size(); ii++)
		{
			CleanUp2DTrackingByGradientConsistency(Path, nCams, TrackingInstances[ii], RefIncreF, TrackTime*fps, frameTimeStamp);
			if (BroxInit)
				CleanUp2DTrackingByGradientConsistency(Path, nCams, TrackingInstances[ii], RefIncreF, TrackTime*fps, frameTimeStamp, 1);
		}

		if (BroxInit)
		{
			printLOG("Start to combine flow\n");
			int dummy, maxnMatches = 0;
			sprintf(Fname, "%s/Dynamic/nMatches.txt", Path); 	FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d ", &dummy, &dummy) != EOF)
				maxnMatches = max(maxnMatches, dummy);
			fclose(fp);

			for (int ii = 0; ii < (int)TrackingInstances.size(); ii++)
				CombineFlow_PLK_B(Path, nCams, TrackingInstances[ii], TrackTime*fps, maxnMatches);
		}
		printLOG("\nDone\n");
	}

	//4. Remove sure stationary features via triangulation and 3D statistic
	if (module == 4 || module == -1)
	{
		int fid, nm;
		vector<Point2i> matches;
		sprintf(Fname, "%s/Dynamic/nMatches.txt", Path); 	FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d ", &fid, &nm) != EOF)
			matches.push_back(Point2i(fid, nm));
		fclose(fp);

		vector<int> vframeTimeStamp(nCams);
		for (int ii = 0; ii < nCams; ii++)
			vframeTimeStamp[ii] = frameTimeStamp[ii];

		for (int ii = 0; ii < (int)TrackingInstances.size(); ii++)
		{
			int fid = TrackingInstances[ii];
			for (int jj = 0; jj < (int)matches.size(); jj++)
			{
				if (fid == matches[jj].x)
				{
					ClassifyPointsFromTriangulation(Path, SelectedCams, matches[jj].y, vframeTimeStamp, fid - TrackTime * fps*RefIncreF, fid + TrackTime * fps*RefIncreF, fid, 3, TriangThresh, stationaryThresh / scaleReal2Sfm); //get CC_%d_%d
																																																							   //ClassifyPointsFromTriangulation(Path, vCam0, matches[jj].y, vframeTimeStamp, fid - TrackTime*fps*RefIncreF, fid + TrackTime*fps*RefIncreF, fid, 3, TriangThresh, stationaryThresh / scaleReal2Sfm); //get CC_%d_%d
																																																							   //ClassifyPointsFromTriangulation(Path, vCam1, matches[jj].y, vframeTimeStamp, fid - TrackTime*fps*RefIncreF, fid + TrackTime*fps*RefIncreF, fid, 3, TriangThresh, stationaryThresh / scaleReal2Sfm); //get CC_%d_%d
																																																							   //ClassifyPointsFromTriangulation(Path, vCam2, matches[jj].y, vframeTimeStamp, fid - TrackTime*fps*RefIncreF, fid + TrackTime*fps*RefIncreF, fid, 3, TriangThresh, stationaryThresh / scaleReal2Sfm); //get CC_%d_%d
																																																							   //ClassifyPointsFromTriangulation(Path, vCam3, matches[jj].y, vframeTimeStamp, fid - TrackTime*fps*RefIncreF, fid + TrackTime*fps*RefIncreF, fid, 3, TriangThresh, stationaryThresh / scaleReal2Sfm); //get CC_%d_%d
				}
			}
		}
		printLOG("Reordered tracjectories CC **\n");
		maxnPts = Reorder2DTrajectories(Path, nCams, TrackingInstances); //reorder CC_%d_%d
	}

	//5. Refine sync using geometric constraint
	if (module == 5 || module == -1)
	{
		int maxnPts = 0, npts = 0;
		for (int inst = 0; inst < (int)TrackingInstances.size(); inst++)
		{
			sprintf(Fname, "%s/Track2D/CC_0_%.4d.txt", Path, TrackingInstances[inst]);
			FILE *fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				fscanf(fp, "%d ", &npts); fclose(fp);
				maxnPts += npts;
			}
		}

		GeometricSyncAllInstancesDriver(Path, SelectedCams, 0, maxnPts, TrackingInstances, TrackTime*fps*RefIncreF, RefStartF, RefStopF, RefIncreF, GeoSearchRange, TriangThresh, dframeTimeStamp, true);

		printLOG("Final frame sync:\n");
		for (int ii = 0; ii < nCams; ii++)
			printLOG("%.1f ", dframeTimeStamp[ii]);
	}

	//6. Obtain initial 3D through point-triangulation
	if (module == 6 || module == -1)
	{
		printLOG("Frame-sync trianguation\n");
		int cid; float stamp;
		vector<int>dummy, vframeTimeStamp(nCams);
		sprintf(Fname, "%s/FGeoSync.txt", Path); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %f ", &cid, &stamp) != EOF)
		{
			for (int ii = 0; ii < (int)SelectedCams.size(); ii++)
			{
				if (SelectedCams[ii] == cid)
				{
					vframeTimeStamp[ii] = stamp;
					break;
				}
			}
		}
		fclose(fp);

		/*printLOG("Assemble u-trajectories ...\n");
		ReAssembleUltimateTrajectories(Path, nCams, TrackingInstances); //get Ultimate_%d

		printLOG("Clean inconsistent appearance trajectories ...\n");
		for (int cid = 0; cid < nCams; cid++)
		Clean2DTrajStartEndAppearance(Path, cid, RefStopF); //do not omp. Memory requirement is large for ~1000 frames seq

		maxnPts = Reorder2DTrajectories(Path, nCams, dummy); //reorder Ultimate_%d
		RemoveLargelyDisconnectedPointsInTraj(Path, nCams, 3);*/

		printLOG("Triangulation ...\n");
		scaleReal2Sfm = 300.0 / 1.14;//NEA1
		TriangulateFrameSync2DTrajectories2(Path, SelectedCams, vframeTimeStamp, -1, RefStartF, RefStopF, nViewsPlus, TriangThresh, stationaryThresh / scaleReal2Sfm, 140.0e3 / scaleReal2Sfm, 200.0e3 / scaleReal2Sfm, 0); //Clean Ultimate_%d
																																																							//Reorder2DTrajectories(Path, nCams, dummy);
																																																							//TriangulateFrameSync2DTrajectories2(Path, vCam0, vframeTimeStamp, -1, RefStartF, RefStopF, nViewsPlus, TriangThresh, stationaryThresh / scaleReal2Sfm, 140.0e3 / scaleReal2Sfm, 200.0e3 / scaleReal2Sfm, 0); //Clean Ultimate_%d
																																																							//TriangulateFrameSync2DTrajectories2(Path, vCam1, vframeTimeStamp, -1, RefStartF, RefStopF, nViewsPlus, TriangThresh, stationaryThresh / scaleReal2Sfm, 140.0e3 / scaleReal2Sfm, 200.0e3 / scaleReal2Sfm, 0); //Clean Ultimate_%d
																																																							//TriangulateFrameSync2DTrajectories2(Path, vCam2, vframeTimeStamp, -1, RefStartF, RefStopF, nViewsPlus, TriangThresh, stationaryThresh / scaleReal2Sfm, 140.0e3 / scaleReal2Sfm, 200.0e3 / scaleReal2Sfm, 0); //Clean Ultimate_%d
																																																							//TriangulateFrameSync2DTrajectories2(Path, vCam3, vframeTimeStamp, -1, RefStartF, RefStopF, nViewsPlus, TriangThresh, stationaryThresh / scaleReal2Sfm, 140.0e3 / scaleReal2Sfm, 200.0e3 / scaleReal2Sfm, 0); //Clean Ultimate_%d

																																																							/*printLOG("Remove weak trajectories ...\n");
																																																							RemoveWeakOverlappingTrajectories2(Path, nCams, RefStartF - 100, RefStopF + 100, frameTimeStamp, 20, 3);
																																																							maxnPts = Reorder2DTrajectories(Path, nCams, dummy);
																																																							GenerateTrackingVisibilityImage(Path, nCams, RefStartF - 100, RefStopF + 100, -1, frameTimeStamp, fps*TrackTime * 2, 2, maxnPts);
																																																							printLOG("\n... Done\n");*/
	}

	//7. Motion prior sync and 3d recon
	if (module == 7 || module == -1)
	{
		sprintf(Fname, "%s/Track2D/Ultimate_0000.txt", Path); FILE *fp = fopen(Fname, "r");
		int npts;  fscanf(fp, "%d ", &npts); fclose(fp);

		MotionPriorSearchRange = 10, MotionPriorSearchStep = 0.15;
		//MotionPriorSTReconstructionDriver(Path, nCams, RefStartF, RefStopF, npts, scaleReal2Sfm, lamdaData, MotionPriorSearchRange, MotionPriorSearchStep, 1);
		MotionPriorSTReconstructionDriver(Path, nCams, RefStartF, RefStopF, npts, scaleReal2Sfm, lamdaData, MotionPriorSearchRange, MotionPriorSearchStep, 2);
	}

	return 0;
}

int StaticDynamicSpatialTemporalBundleAdjustment(char *Path, VideoData *videoCam, int nCams, int startF, int stopF, vector<int> &sharedIntrinsicCamID, double *OffsetInfo,
	vector<Point3d> &Static3D, vector <vector<int> > &StaticViewIdAll3D, vector<vector<Point2d> > &StaticUvAll3D, vector<vector<double> > &StaticScaleAll3D, vector<ImgPtEle> *PerCamDynaFeatureTracks, int nDynaPts,
	int fixIntrinsic, int fixDistortion, int  fixPose, int fixLocalPose, int fix3D, int fixSkew, int fixPrism, int distortionCorrected,
	int LossType, double threshold, int nViewsPlus, double Tscale, double eps, double lamdaStatic, double lamdaDynaData, double RealOverSfm, int weightByDistance, bool non_monotonicDescent, bool silent)
{
	//sharedIntrinsicCamID: -2: no share, -1: want to share but master cam not determined yet, >=0: master camera set to id
	FILE *fp = 0;

	int *fixSkewView = new int[stopF*nCams], *fixPrismView = new int[stopF*nCams];
	for (int ii = 0; ii < stopF*nCams; ii++)
		fixSkewView[ii] = 0, fixPrismView[ii] = 0;
	if (fixSkew == 1)
	{
		printLOG("Fix skew.\n");
		for (int cid = 0; cid < nCams; cid++)
			for (int fid = startF; fid <= stopF; fid++)
				videoCam[cid].VideoInfo[fid].intrinsic[2] = 0.0;
	}
	if (fixPrism)
	{
		printLOG("Fix prsim.\n");
		for (int cid = 0; cid < nCams; cid++)
			for (int fid = startF; fid <= stopF; fid++)
				videoCam[cid].VideoInfo[fid].distortion[5] = 0.0, videoCam[cid].VideoInfo[fid].distortion[6] = 0.0;
	}
	if (fix3D == 1)
		printLOG("Fixed 3D.\n");

	int nStatPts = (int)Static3D.size();
	double *DStatic3D = new double[nStatPts * 3];
	for (int ii = 0; ii < nStatPts; ii++)
		DStatic3D[3 * ii] = Static3D[ii].x, DStatic3D[3 * ii + 1] = Static3D[ii].y, DStatic3D[3 * ii + 2] = Static3D[ii].z;

	int nvalidframes = 0;
	for (int cid = 0; cid < nCams; cid++)
		for (int fid = startF; fid <= stopF; fid++)
			if (videoCam[cid].VideoInfo[fid].valid == true)
				GetCfromT(videoCam[cid].VideoInfo[fid]), nvalidframes++;

	printLOG("set up Cayley RS-BA (%d views) ...\n", nvalidframes);
	ceres::Problem problem;

	ceres::LossFunction *loss_funcion = 0;
	if (LossType == 1) //Huber
		loss_funcion = new ceres::HuberLoss(5.0);

	//Static features
	printLOG("Working on stationary feature ...\n");

	double residuals[2], maxOutlierX = 0.0, maxOutlierY = 0.0;
	vector<double> ReProjectionErrorX; ReProjectionErrorX.reserve(nStatPts);
	vector<double> ReProjectionErrorY; ReProjectionErrorY.reserve(nStatPts);

	bool *discard3Dpoint = new bool[nStatPts];
	vector<bool> *Good = new vector<bool>[nStatPts];
	for (int ii = 0; ii < nStatPts; ii++)
		discard3Dpoint[ii] = false, Good[ii].reserve(StaticViewIdAll3D[ii].size());

	int nBadCounts = 0, goodCount = 0;
	int refCam = -1, nProjections = 0, nPossibleProjections = 0;
	vector<int>validCamID; validCamID.reserve(stopF*nCams);
	for (int pid = 0; pid < nStatPts; pid++)
	{
		if (abs(DStatic3D[3 * pid]) + abs(DStatic3D[3 * pid + 1]) + abs(DStatic3D[3 * pid + 2]) < LIMIT3D)
			continue;
		for (int ii = 0; ii < (int)StaticViewIdAll3D[pid].size(); ii++)
		{
			int cid = StaticViewIdAll3D[pid][ii] / (stopF + 1);
			int fid = StaticViewIdAll3D[pid][ii] - cid * (stopF + 1);

			Point2d uvuv = StaticUvAll3D[pid][ii];
			Point3d XYZ = Point3d(DStatic3D[3 * pid], DStatic3D[3 * pid + 1], DStatic3D[3 * pid + 2]);
			if (!videoCam[cid].VideoInfo[fid].valid)
				Good[pid].push_back(false);
			else
			{
				bool found = false;
				for (int kk = 0; kk < (int)validCamID.size() && !found; kk++)
					if (StaticViewIdAll3D[pid][ii] == validCamID[kk])
						found = true;
				if (!found)
					validCamID.push_back(StaticViewIdAll3D[pid][ii]);

				if (videoCam[cid].VideoInfo[fid].ShutterModel == 0)
				{
					if (distortionCorrected == 0)
						PinholeDistortionReprojectionDebug(videoCam[cid].VideoInfo[fid].intrinsic, videoCam[cid].VideoInfo[fid].distortion, videoCam[cid].VideoInfo[fid].rt, StaticUvAll3D[pid][ii], XYZ, residuals);
					else
						PinholeReprojectionDebug(videoCam[cid].VideoInfo[fid].intrinsic, videoCam[cid].VideoInfo[fid].rt, StaticUvAll3D[pid][ii], XYZ, residuals);
				}
				else
				{
					if (distortionCorrected == 0)
						CayleyDistortionReprojectionDebug(videoCam[cid].VideoInfo[fid].intrinsic, videoCam[cid].VideoInfo[fid].distortion, videoCam[cid].VideoInfo[fid].rt, videoCam[cid].VideoInfo[fid].wt,
							StaticUvAll3D[pid][ii], XYZ, videoCam[cid].VideoInfo[fid].width, videoCam[cid].VideoInfo[fid].height, residuals);
					else
						CayleyReprojectionDebug(videoCam[cid].VideoInfo[fid].intrinsic, videoCam[cid].VideoInfo[fid].rt, videoCam[cid].VideoInfo[fid].wt,
							StaticUvAll3D[pid][ii], XYZ, videoCam[cid].VideoInfo[fid].width, videoCam[cid].VideoInfo[fid].height, residuals);
				}

				if (abs(residuals[0]) > threshold || abs(residuals[1]) > threshold)
				{
					Good[pid].push_back(false);
					if (abs(residuals[0]) > maxOutlierX)
						maxOutlierX = residuals[0];
					if (abs(residuals[1]) > maxOutlierY)
						maxOutlierY = residuals[1];
					nBadCounts++;
				}
				else
				{
					Good[pid].push_back(true);
					goodCount++;
				}
			}
		}

		//Discard point
		int count = 0;
		for (int ii = 0; ii < StaticViewIdAll3D[pid].size(); ii++)
			if (Good[pid][ii] == true)
				count++;
		discard3Dpoint[pid] = false;
		if (count < nViewsPlus)
		{
			discard3Dpoint[pid] = true;
			continue;
		}

		//add 3D point and its 2D projections to Ceres
		bool once = true;
		int validViewcount = 0;
		double pointErrX = 0.0, pointErrY = 0.0;
		for (int ii = 0; ii < StaticViewIdAll3D[pid].size(); ii++)
		{
			if (!Good[pid][ii])
				continue;

			nPossibleProjections++;
			int cid = StaticViewIdAll3D[pid][ii] / (stopF + 1);
			int fid = StaticViewIdAll3D[pid][ii] - cid * (stopF + 1);
			int width = videoCam[cid].VideoInfo[fid].width, height = videoCam[cid].VideoInfo[fid].height;
			Point2d uv = StaticUvAll3D[pid][ii];
			Point3d XYZ = Point3d(DStatic3D[3 * pid], DStatic3D[3 * pid + 1], DStatic3D[3 * pid + 2]);
			CameraData *camI = &videoCam[cid].VideoInfo[fid];
			if (sharedIntrinsicCamID.size() > 0)
			{
				int refFid = sharedIntrinsicCamID[cid];
				if (refFid == -2) //not interested in sharing
					refFid = fid;
				else if (refFid == -1) //master has not been found
				{
					refFid = fid, sharedIntrinsicCamID[cid] = fid;
					printLOG("Set group %d's master camera to %d\n", cid, sharedIntrinsicCamID[cid]);
				}

				double std2d = StaticScaleAll3D[pid][ii];
				if (weightByDistance == 1)
				{
					double dist = (Distance3D(&DStatic3D[3 * pid], camI[0].camCenter));
					std2d *= sqrt(dist);
				}

				CameraData *Mcam = &videoCam[cid].VideoInfo[refFid];
				if (distortionCorrected == 0)
				{
					if (videoCam[cid].VideoInfo[fid].ShutterModel == 0)
					{
						ceres::CostFunction*cost_function = PinholeDistortionReprojectionError::Create(uv.x, uv.y, std2d / sqrt(lamdaStatic));
						problem.AddResidualBlock(cost_function, loss_funcion, Mcam[0].intrinsic, Mcam[0].distortion, camI[0].rt, &DStatic3D[3 * pid]);
						PinholeDistortionReprojectionDebug(Mcam[0].intrinsic, Mcam[0].distortion, camI[0].rt, uv, XYZ, residuals);
					}
					else
					{
						ceres::CostFunction*cost_function = CayleyDistortionReprojectionError::Create(uv.x, uv.y, std2d / sqrt(lamdaStatic), width, height);
						problem.AddResidualBlock(cost_function, loss_funcion, Mcam[0].intrinsic, Mcam[0].distortion, camI[0].rt, camI[0].wt, &DStatic3D[3 * pid]);
						CayleyDistortionReprojectionDebug(Mcam[0].intrinsic, Mcam[0].distortion, camI[0].rt, camI[0].wt, uv, XYZ, width, height, residuals);
					}

					if (fixIntrinsic)
						problem.SetParameterBlockConstant(Mcam[0].intrinsic);
					if (fixDistortion)
						problem.SetParameterBlockConstant(Mcam[0].distortion);
					if (fixSkew)
					{
						if (fixSkewView[cid*stopF + fid] == 0)
						{
							std::vector<int> constant_parameters; constant_parameters.push_back(2);
							problem.SetParameterization(Mcam[0].intrinsic, new ceres::SubsetParameterization(5, constant_parameters));
							fixSkewView[cid*stopF + fid] = 1;
						}
					}
					if (!fixDistortion && fixPrism && Mcam[0].LensModel == RADIAL_TANGENTIAL_PRISM)
					{
						if (fixPrismView[cid*stopF + fid] == 0)
						{
							std::vector<int> constant_parameters; constant_parameters.push_back(5), constant_parameters.push_back(6);
							problem.SetParameterization(Mcam[0].distortion, new ceres::SubsetParameterization(7, constant_parameters));
							fixPrismView[cid*stopF + fid] = 1;
						}
					}
				}
				else
				{
					if (videoCam[cid].VideoInfo[fid].ShutterModel == 0)
					{
						ceres::CostFunction* cost_function = PinholeReprojectionError::Create(uv.x, uv.y, std2d / sqrt(lamdaStatic));
						problem.AddResidualBlock(cost_function, loss_funcion, Mcam[0].intrinsic, camI[0].rt, &DStatic3D[3 * pid]);
						problem.SetParameterBlockConstant(Mcam[0].intrinsic);

						PinholeReprojectionDebug(Mcam[0].intrinsic, camI[0].rt, uv, XYZ, residuals);
					}
					else
					{
						ceres::CostFunction* cost_function = CayleyReprojectionError::Create(Mcam[0].intrinsic, uv.x, uv.y, std2d / sqrt(lamdaStatic), width, height);
						problem.AddResidualBlock(cost_function, loss_funcion, camI[0].rt, camI[0].wt, &DStatic3D[3 * pid]);

						CayleyReprojectionDebug(Mcam[0].intrinsic, camI[0].rt, camI[0].wt, uv, XYZ, width, height, residuals);
					}
				}

				if (fixPose)
					problem.SetParameterBlockConstant(camI[0].rt);
				if (videoCam[cid].VideoInfo[fid].ShutterModel == 1 && fixLocalPose)
					problem.SetParameterBlockConstant(camI[0].wt);
				if (fix3D)
					problem.SetParameterBlockConstant(&DStatic3D[3 * pid]);
			}
			else
			{
				double std2d = StaticScaleAll3D[pid][ii];
				if (weightByDistance == 1)
				{
					double dist = (Distance3D(&DStatic3D[3 * pid], camI[0].camCenter));
					std2d *= sqrt(dist);
				}

				if (distortionCorrected == 0)
				{
					if (camI[0].ShutterModel == 0)
					{
						ceres::CostFunction* cost_function = PinholeDistortionReprojectionError::Create(uv.x, uv.y, std2d / sqrt(lamdaStatic));
						problem.AddResidualBlock(cost_function, loss_funcion, camI[0].intrinsic, camI[0].distortion, camI[0].rt, &DStatic3D[3 * pid]);
						PinholeDistortionReprojectionDebug(camI[0].intrinsic, camI[0].distortion, camI[0].rt, uv, Static3D[pid], residuals);
					}
					else
					{
						ceres::CostFunction* cost_function = CayleyDistortionReprojectionError::Create(uv.x, uv.y, std2d / sqrt(lamdaStatic), width, height);
						problem.AddResidualBlock(cost_function, loss_funcion, camI[0].intrinsic, camI[0].distortion, camI[0].rt, camI[0].wt, &DStatic3D[3 * pid]);
						CayleyDistortionReprojectionDebug(camI[0].intrinsic, camI[0].distortion, camI[0].rt, camI[0].wt, uv, Static3D[pid], width, height, residuals);
					}

					if (fixIntrinsic)
						problem.SetParameterBlockConstant(camI[0].intrinsic);
					if (fixDistortion)
						problem.SetParameterBlockConstant(camI[0].distortion);
					if (fixSkew)
					{
						if (fixSkewView[cid*stopF + fid] == 0)
						{
							std::vector<int> constant_parameters; constant_parameters.push_back(2);
							problem.SetParameterization(camI[0].intrinsic, new ceres::SubsetParameterization(5, constant_parameters));
							fixSkewView[cid*stopF + fid] = 1;
						}
					}
					if (!fixDistortion &&fixPrism &&camI[0].LensModel == RADIAL_TANGENTIAL_PRISM)
					{
						if (fixPrismView[cid*stopF + fid] == 0)
						{
							std::vector<int> constant_parameters; constant_parameters.push_back(5), constant_parameters.push_back(6);
							problem.SetParameterization(camI[0].distortion, new ceres::SubsetParameterization(7, constant_parameters));
							fixPrismView[cid*stopF + fid] = 1;
						}
					}
				}
				else
				{
					if (camI[0].ShutterModel == 0)
					{
						ceres::CostFunction* cost_function = PinholeReprojectionError::Create(uv.x, uv.y, std2d / sqrt(lamdaStatic));
						problem.AddResidualBlock(cost_function, loss_funcion, camI[0].intrinsic, camI[0].rt, &DStatic3D[3 * pid]);
						problem.SetParameterBlockConstant(camI[0].intrinsic);

						PinholeReprojectionDebug(camI[0].intrinsic, camI[0].rt, uv, Static3D[pid], residuals);
					}
					else
					{
						ceres::CostFunction* cost_function = CayleyReprojectionError::Create(camI[0].intrinsic, uv.x, uv.y, std2d / sqrt(lamdaStatic), width, height);
						problem.AddResidualBlock(cost_function, loss_funcion, camI[0].rt, camI[0].wt, &DStatic3D[3 * pid]);

						CayleyReprojectionDebug(camI[0].intrinsic, camI[0].rt, camI[0].wt, uv, Static3D[pid], width, height, residuals);
					}
				}

				if (fixPose)
					problem.SetParameterBlockConstant(camI[0].rt);
				if (camI[0].ShutterModel == 1 && fixLocalPose)
					problem.SetParameterBlockConstant(camI[0].wt);
				if (fix3D)
					problem.SetParameterBlockConstant(&DStatic3D[3 * pid]);
			}

			validViewcount++;
			pointErrX += pow(residuals[0], 2), pointErrY += pow(residuals[1], 2);
		}
		if (validViewcount >= nViewsPlus)
		{
			ReProjectionErrorX.push_back(sqrt(pointErrX / validViewcount));
			ReProjectionErrorY.push_back(sqrt(pointErrY / validViewcount));
		}
	}

	double miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
	double maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
	double avgX = MeanArray(ReProjectionErrorX);
	double stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
	double miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
	double maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
	double avgY = MeanArray(ReProjectionErrorY);
	double stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
	printLOG("(%d/%d) bad points with maximum reprojection error of (%.2f %.2f) \n", nBadCounts, goodCount + nBadCounts, maxOutlierX, maxOutlierY);
	printLOG("Reprojection error before BA:\nMin: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);

	//Dynamic features
	printLOG("Working on dynamic features ...\n");
	ImgPtEle ptEle;
	vector<double> VectorTime;
	int *currentFrame = new int[nCams], *PerCam_nf = new int[nCams], *currentPID_InTrack = new int[nCams];
	vector<int> *VectorCamID = new vector<int>[nDynaPts], *VectorFrameID = new vector<int>[nDynaPts];
	vector<ImgPtEle> *DynaTrajAll = new vector<ImgPtEle>[nDynaPts];

	double MotionPriorCost = 0.0, ProjCost = 0.0, costi;
	double earliestTime, currentTime, RollingShutterOffset;
	int earliestCamFrameID, frameID, nfinishedCams, earliestcid;
	int nMP = 0, nIP = 0;

	for (int cid = 0; cid < nCams; cid++)
	{
		for (int pid = 0; pid < nDynaPts; pid++)
		{
			for (int fid = 0; fid < (int)PerCamDynaFeatureTracks[cid*nDynaPts + pid].size(); fid++)
			{
				int fid_ = PerCamDynaFeatureTracks[cid*nDynaPts + pid][fid].frameID;
				for (int ii = 0; ii < 9; ii++)
					PerCamDynaFeatureTracks[cid*nDynaPts + pid][fid].K[ii] = videoCam[cid].VideoInfo[fid_].K[ii];
				GetCfromT(videoCam[cid].VideoInfo[fid_].R, videoCam[cid].VideoInfo[fid_].T, PerCamDynaFeatureTracks[cid*nDynaPts + pid][fid].camcenter); //do not consider rolling shutter (should be fine for the weight)
			}
		}
	}
	MotionPrior_ML_Weighting(PerCamDynaFeatureTracks, nDynaPts, nCams);
	for (int pid = 0; pid < nDynaPts; pid++)
	{
		int nValidViews = 0;
		for (int cid = 0; cid < nCams; cid++)
		{
			PerCam_nf[cid] = (int)PerCamDynaFeatureTracks[cid*nDynaPts + pid].size();
			if (PerCam_nf[cid] > 0)
				nValidViews++;
		}
		if (nValidViews < nViewsPlus)
			continue;

		//Assemble trajactory and time from all Cameras
		VectorTime.clear();
		for (int jj = 0; jj < nCams; jj++)
			currentPID_InTrack[jj] = 0;

		while (true)
		{
			//Determine the next camera
			nfinishedCams = 0, earliestcid, earliestTime = 9e9;
			for (int cid = 0; cid < nCams; cid++)
			{
				int cPid_InTrack = currentPID_InTrack[cid];
				if (cPid_InTrack == PerCam_nf[cid])
				{
					nfinishedCams++;
					continue;
				}

				int id = cid * nDynaPts + pid;
				if (PerCamDynaFeatureTracks[id][cPid_InTrack].frameID < 0)
					continue;//occluded point

							 //Time:
				if (PerCamDynaFeatureTracks[id][cPid_InTrack].shutterModel != 0)
					RollingShutterOffset = PerCamDynaFeatureTracks[id][cPid_InTrack].pt2D.y / PerCamDynaFeatureTracks[id][cPid_InTrack].imHeight*PerCamDynaFeatureTracks[id][cPid_InTrack].rollingShutterPercent;
				else
					RollingShutterOffset = 0.0;

				double ialpha = 1.0 / PerCamDynaFeatureTracks[id][cPid_InTrack].fps;
				frameID = PerCamDynaFeatureTracks[id][cPid_InTrack].frameID;
				currentTime = (OffsetInfo[cid] + frameID + RollingShutterOffset) * ialpha*Tscale;

				if (currentTime < earliestTime)
				{
					earliestTime = currentTime;
					earliestcid = cid;
					earliestCamFrameID = frameID;
				}
			}

			//If all cameras are done
			if (nfinishedCams == nCams)
				break;

			//Add new point to the sequence
			VectorTime.push_back(earliestTime);
			VectorCamID[pid].push_back(earliestcid);
			VectorFrameID[pid].push_back(earliestCamFrameID);
			DynaTrajAll[pid].push_back(PerCamDynaFeatureTracks[earliestcid*nDynaPts + pid][currentPID_InTrack[earliestcid]]);

			//copy Point3d to double[3] for ceres optim--> Minh (why not directly get double data)
			Point3d P3d = DynaTrajAll[pid].back().pt3D;
			DynaTrajAll[pid].back().pt3d[0] = P3d.x, DynaTrajAll[pid].back().pt3d[1] = P3d.y, DynaTrajAll[pid].back().pt3d[2] = P3d.z;

			currentPID_InTrack[earliestcid]++;
		}

		int nf = (int)DynaTrajAll[pid].size();
		//Motion prior cost by 1st order approx of v
		for (int ll = 0; ll < nf - 1; ll++)
		{
			int cid1 = VectorCamID[pid][ll], cid2 = VectorCamID[pid][ll + 1];

			double shutterOffset1 = 0, shutterOffset2 = 0;
			if (DynaTrajAll[pid][ll].shutterModel != 0)
				shutterOffset1 = DynaTrajAll[pid][ll].pt2D.y / DynaTrajAll[pid][ll].imHeight*DynaTrajAll[pid][ll].rollingShutterPercent;
			else
				shutterOffset1 = 0.0;
			if (DynaTrajAll[pid][ll + 1].shutterModel != 0)
				shutterOffset2 = DynaTrajAll[pid][ll + 1].pt2D.y / DynaTrajAll[pid][ll + 1].imHeight*DynaTrajAll[pid][ll + 1].rollingShutterPercent;
			else
				shutterOffset2 = 0.0;

			double ialpha1 = 1.0 / DynaTrajAll[pid][ll].fps, ialpha2 = 1.0 / DynaTrajAll[pid][ll + 1].fps;
			costi = LeastActionError(DynaTrajAll[pid][ll].pt3d, DynaTrajAll[pid][ll + 1].pt3d, &OffsetInfo[cid1], &OffsetInfo[cid2], shutterOffset1, shutterOffset2, VectorFrameID[pid][ll], VectorFrameID[pid][ll + 1], ialpha1, ialpha2, Tscale, eps, 2);
			MotionPriorCost += costi; nMP++;

			double std3d = DynaTrajAll[pid][ll].std3D;
			if (cid1 == cid2)
			{
				if (std3d < 0.0) //not using scale for determine uncertainty
				{
					ceres::CostFunction* cost_function = LeastMotionPriorCostCeres::CreateAutoDiffSame(VectorFrameID[pid][ll], VectorFrameID[pid][ll + 1], shutterOffset1, shutterOffset2, ialpha1, ialpha2, Tscale, eps, sqrt(1.0 - lamdaStatic)* sqrt(1.0 - lamdaDynaData)*RealOverSfm, 2);
					problem.AddResidualBlock(cost_function, NULL, DynaTrajAll[pid][ll].pt3d, DynaTrajAll[pid][ll + 1].pt3d, &OffsetInfo[cid1]);
				}
				else
				{
					ceres::CostFunction* cost_function = LeastMotionPriorCostCeres::CreateAutoDiffSame(VectorFrameID[pid][ll], VectorFrameID[pid][ll + 1], shutterOffset1, shutterOffset2, ialpha1, ialpha2, Tscale, eps, sqrt(1.0 - lamdaStatic) / std3d, 2);
					problem.AddResidualBlock(cost_function, NULL, DynaTrajAll[pid][ll].pt3d, DynaTrajAll[pid][ll + 1].pt3d, &OffsetInfo[cid1]);
				}
			}
			else
			{
				if (std3d < 0.0)
				{
					ceres::CostFunction* cost_function = LeastMotionPriorCostCeres::CreateAutoDiff(VectorFrameID[pid][ll], VectorFrameID[pid][ll + 1], shutterOffset1, shutterOffset2, ialpha1, ialpha2, Tscale, eps, sqrt(1.0 - lamdaStatic)*sqrt(1.0 - lamdaDynaData)*RealOverSfm, 2);
					problem.AddResidualBlock(cost_function, NULL, DynaTrajAll[pid][ll].pt3d, DynaTrajAll[pid][ll + 1].pt3d, &OffsetInfo[cid1], &OffsetInfo[cid2]);
				}
				else
				{
					ceres::CostFunction* cost_function = LeastMotionPriorCostCeres::CreateAutoDiff(VectorFrameID[pid][ll], VectorFrameID[pid][ll + 1], shutterOffset1, shutterOffset2, ialpha1, ialpha2, Tscale, eps, sqrt(1.0 - lamdaStatic) / std3d, 2);
					problem.AddResidualBlock(cost_function, NULL, DynaTrajAll[pid][ll].pt3d, DynaTrajAll[pid][ll + 1].pt3d, &OffsetInfo[cid1], &OffsetInfo[cid2]);
				}
			}
		}

		//Reprojection cost
		for (int ll = 0; ll < nf; ll++)
		{
			nIP++;
			Point2d P2d(DynaTrajAll[pid][ll].pt2D.x, DynaTrajAll[pid][ll].pt2D.y);
			Point3d P3d(DynaTrajAll[pid][ll].pt3d[0], DynaTrajAll[pid][ll].pt3d[1], DynaTrajAll[pid][ll].pt3d[2]);

			int cid = DynaTrajAll[pid][ll].viewID;
			int fid = DynaTrajAll[pid][ll].frameID;
			CameraData *camera = videoCam[cid].VideoInfo;
			int refFid = sharedIntrinsicCamID[cid] <= -1 ? fid : sharedIntrinsicCamID[cid];
			if (camera[fid].ShutterModel == 0)
			{
				if (distortionCorrected == 1)
				{
					PinholeReprojectionDebug(camera[refFid].intrinsic, camera[fid].rt, P2d, P3d, residuals);

					ceres::CostFunction* cost_function = 0;
					if (DynaTrajAll[pid][ll].std3D < 0.0)  //not using scale for determine uncertainty
						cost_function = PinholeReprojectionError::Create(P2d.x, P2d.y, 1.0 / sqrt(lamdaDynaData) / sqrt(1.0 - lamdaStatic));
					else
						cost_function = PinholeReprojectionError::Create(P2d.x, P2d.y, sqrt(DynaTrajAll[pid][ll].std2D / sqrt(1.0 - lamdaStatic)));
					problem.AddResidualBlock(cost_function, loss_funcion, camera[refFid].intrinsic, camera[fid].rt, DynaTrajAll[pid][ll].pt3d);
				}
				else
				{
					PinholeDistortionReprojectionDebug(camera[refFid].intrinsic, camera[refFid].distortion, camera[fid].rt, P2d, P3d, residuals);

					ceres::CostFunction* cost_function = 0;
					if (DynaTrajAll[pid][ll].std3D < 0.0)  //not using scale for determine uncertainty
						cost_function = PinholeDistortionReprojectionError::Create(P2d.x, P2d.y, 1.0 / sqrt(lamdaDynaData) / sqrt(1.0 - lamdaStatic));
					else
						cost_function = PinholeDistortionReprojectionError::Create(P2d.x, P2d.y, DynaTrajAll[pid][ll].std2D / sqrt(1.0 - lamdaStatic));
					problem.AddResidualBlock(cost_function, loss_funcion, camera[refFid].intrinsic, camera[refFid].distortion, camera[fid].rt, DynaTrajAll[pid][ll].pt3d);
				}
			}
			else //Rolling shutter
			{
				if (distortionCorrected == 1)
				{
					CayleyReprojectionDebug(camera[refFid].intrinsic, camera[fid].rt, camera[fid].wt, P2d, P3d, camera[fid].width, camera[fid].height, residuals);

					ceres::CostFunction* cost_function = 0;
					if (DynaTrajAll[pid][ll].std3D < 0.0)  //not using scale to determine uncertainty
						cost_function = CayleyReprojectionError::Create(camera[refFid].intrinsic, P2d.x, P2d.y, 1.0 / sqrt(lamdaDynaData) / sqrt(1.0 - lamdaStatic), camera[fid].width, camera[fid].height);
					else
						cost_function = CayleyReprojectionError::Create(camera[refFid].intrinsic, P2d.x, P2d.y, DynaTrajAll[pid][ll].std2D / sqrt(1.0 - lamdaStatic), camera[fid].width, camera[fid].height);
					problem.AddResidualBlock(cost_function, loss_funcion, camera[fid].rt, camera[fid].wt, DynaTrajAll[pid][ll].pt3d);
				}
				else //distortion not corrected
				{
					CayleyDistortionReprojectionDebug(camera[refFid].intrinsic, camera[refFid].distortion, camera[fid].rt, camera[fid].wt, P2d, P3d, camera[fid].width, camera[fid].height, residuals);

					ceres::CostFunction* cost_function = 0;
					if (DynaTrajAll[pid][ll].std3D < 0.0)  //not using scale to determine uncertainty
						cost_function = CayleyDistortionReprojectionError::Create(P2d.x, P2d.y, 1.0 / sqrt(lamdaDynaData) / sqrt(1.0 - lamdaStatic), camera[fid].width, camera[fid].height);
					else
						cost_function = CayleyDistortionReprojectionError::Create(P2d.x, P2d.y, DynaTrajAll[pid][ll].std2D / sqrt(1.0 - lamdaStatic), camera[fid].width, camera[fid].height);
					problem.AddResidualBlock(cost_function, loss_funcion, camera[refFid].intrinsic, camera[refFid].distortion, camera[fid].rt, camera[fid].wt, DynaTrajAll[pid][ll].pt3d);
				}
				if (fixLocalPose) //for cayley model
					problem.SetParameterBlockConstant(camera[fid].wt);
			}
			if (fixPose == 1)
				problem.SetParameterBlockConstant(camera[fid].rt);
			if (distortionCorrected == 0)
			{
				if (fixIntrinsic)
					problem.SetParameterBlockConstant(camera[refFid].intrinsic);
				if (fixDistortion)
					problem.SetParameterBlockConstant(camera[refFid].distortion);
				if (fixSkew)
				{
					if (fixSkewView[cid*stopF + fid] == 0)
					{
						std::vector<int> constant_parameters; constant_parameters.push_back(2);
						problem.SetParameterization(camera[refFid].intrinsic, new ceres::SubsetParameterization(5, constant_parameters));
						fixSkewView[cid*stopF + fid] = 1;
					}
				}
				if (!fixDistortion && fixPrism &&camera[refFid].LensModel == RADIAL_TANGENTIAL_PRISM)
				{
					if (fixPrismView[cid*stopF + fid] == 0)
					{
						std::vector<int> constant_parameters; constant_parameters.push_back(5), constant_parameters.push_back(6);
						problem.SetParameterization(camera[refFid].distortion, new ceres::SubsetParameterization(7, constant_parameters));
						fixPrismView[cid*stopF + fid] = 1;
					}
				}
			}

			ProjCost += sqrt(pow(residuals[0], 2) + pow(residuals[1], 2));
		}
	}

	//Set constraint on the time
	int refCamID = 0;
	for (int cid = 0; cid < nCams; cid++)
		if (OffsetInfo[cid] - floor(OffsetInfo[cid]) == 0.0)
			refCamID = cid;
	for (int cid = 0; cid < nCams; cid++)
	{
		if (cid == refCamID)
			continue;
		problem.SetParameterLowerBound(&OffsetInfo[cid], 0, floor(OffsetInfo[cid])), problem.SetParameterUpperBound(&OffsetInfo[cid], 0, ceil(OffsetInfo[cid])); //lock it in the frame
	}
	problem.SetParameterBlockConstant(&OffsetInfo[refCamID]);
	printLOG("Action cost: %e Projection cost: %e\n", MotionPriorCost / nMP, ProjCost / nIP);

	//Run spatialtemporal bundle adjustment!
	ceres::Solver::Options options;
	options.num_threads = omp_get_max_threads();
	options.num_linear_solver_threads = omp_get_max_threads();

	if (validCamID.size() < 1000)
	{
		options.max_num_iterations = 100;
		options.linear_solver_type = ceres::SPARSE_SCHUR;
		options.max_num_iterations = 1000;

		if (validCamID.size() < 300)
			options.function_tolerance = 1.0e-6;
		else
			options.function_tolerance = 1.0e-5;
	}
	else
	{
		if (validCamID.size() < 1500)
			options.max_num_iterations = 30;
		else if (validCamID.size() < 2000)
			options.max_num_iterations = 25;
		else if (validCamID.size() < 4000)
			options.max_num_iterations = 20;
		else if (validCamID.size() < 5000)
			options.max_num_iterations = 10;
		else
			options.max_num_iterations = 7;

		if (validCamID.size() < 1500)
			options.function_tolerance = 1.0e-5;
		if (validCamID.size() < 2000)
			options.function_tolerance = 5.0e-4;
		else if (validCamID.size() < 3000)
			options.function_tolerance = 1.0e-4;
		else
			options.function_tolerance = 5.0e-3;

		options.linear_solver_type = ceres::CGNR;
		options.preconditioner_type = ceres::JACOBI;
	}
	options.minimizer_progress_to_stdout = silent ? false : true;
	options.trust_region_strategy_type = ceres::LEVENBERG_MARQUARDT;
	options.use_nonmonotonic_steps = non_monotonicDescent;

	ceres::Solver::Summary summary;
	ceres::Solve(options, &problem, &summary);
	if (silent)
		std::cout << summary.BriefReport() << "\n";
	else
		std::cout << summary.FullReport() << "\n";

	//Store refined parameters
	for (int pid = 0; pid < nDynaPts; pid++)
	{
		int nf = (int)DynaTrajAll[pid].size();
		if (nf == 0)
			continue;

		for (int ii = 0; ii < nf; ii++)
		{
			bool found = false;
			int camID = VectorCamID[pid][ii], frameID = VectorFrameID[pid][ii];
			for (int kk = 0; kk < (int)PerCamDynaFeatureTracks[camID*nDynaPts + pid].size(); kk++)
			{
				if (frameID == PerCamDynaFeatureTracks[camID*nDynaPts + pid][kk].frameID)
				{
					PerCamDynaFeatureTracks[camID*nDynaPts + pid][kk].pt3D.x = DynaTrajAll[pid][ii].pt3d[0];
					PerCamDynaFeatureTracks[camID*nDynaPts + pid][kk].pt3D.y = DynaTrajAll[pid][ii].pt3d[1];
					PerCamDynaFeatureTracks[camID*nDynaPts + pid][kk].pt3D.z = DynaTrajAll[pid][ii].pt3d[2];
					found = true;
					break;
				}
			}
			if (!found)
			{
				printLOG("Serious bug in point-camera-frame association\n");
				abort();
			}
		}

		for (int ii = 0; ii < nf; ii++)
			DynaTrajAll[pid][ii].pt3D.x = DynaTrajAll[pid][ii].pt3d[0], DynaTrajAll[pid][ii].pt3D.y = DynaTrajAll[pid][ii].pt3d[1], DynaTrajAll[pid][ii].pt3D.z = DynaTrajAll[pid][ii].pt3d[2];
	}

	for (int cid = 0; cid < nCams; cid++)
	{
		CameraData *camera = videoCam[cid].VideoInfo;
		for (int fid = startF; fid < stopF; fid++)
		{
			if (camera[fid].valid &&  sharedIntrinsicCamID[cid] > -1)
			{
				int refFid = sharedIntrinsicCamID[cid];
				CopyCamereInfo(camera[refFid], camera[fid], false);
				GetKFromIntrinsic(camera[fid]);
				GetRTFromrt(camera[fid]);
			}
		}
	}

	printLOG("Error after ST-BA\n");
	//Compute cost after optim: stationary features
	nBadCounts = 0, nPossibleProjections = 0;
	ReProjectionErrorX.clear(), ReProjectionErrorY.clear();
	for (int pid = 0; pid < nStatPts; pid++)
	{
		bool once = true;
		int validFrameCount = 0;
		double pointErrX = 0.0, pointErrY = 0.0;
		for (int kk = 0; kk < (int)StaticViewIdAll3D[pid].size(); kk++)
		{
			int cid = StaticViewIdAll3D[pid][kk] / (stopF + 1);
			int fid = StaticViewIdAll3D[pid][kk] - cid * (stopF + 1);
			CameraData *camera = videoCam[cid].VideoInfo;

			if (camera[fid].valid)
			{
				Point3d pt3D(DStatic3D[3 * pid], DStatic3D[3 * pid + 1], DStatic3D[3 * pid + 2]);
				Point2d uv = StaticUvAll3D[pid][kk];
				if (camera[fid].ShutterModel == 0)
				{
					if (distortionCorrected == 1)
						PinholeReprojectionDebug(camera[fid].intrinsic, camera[fid].rt, uv, pt3D, residuals);
					else
						PinholeDistortionReprojectionDebug(camera[fid].intrinsic, camera[fid].distortion, camera[fid].rt, uv, pt3D, residuals);
				}
				else // Rolling shutter
				{
					if (distortionCorrected == 1)
						CayleyReprojectionDebug(camera[fid].intrinsic, camera[fid].rt, camera[fid].wt, uv, pt3D, camera[fid].width, camera[fid].height, residuals);
					else
						CayleyDistortionReprojectionDebug(camera[fid].intrinsic, camera[fid].distortion, camera[fid].rt, camera[fid].wt, uv, pt3D, camera[fid].width, camera[fid].height, residuals);
				}

				nPossibleProjections++;
				if (abs(residuals[0]) > camera[fid].threshold || abs(residuals[1]) > camera[fid].threshold)
				{
					if (abs(residuals[0]) > maxOutlierX)
						maxOutlierX = residuals[0];
					if (abs(residuals[1]) > maxOutlierY)
						maxOutlierY = residuals[1];
					nBadCounts++;
				}
				else
				{
					validFrameCount++;
					pointErrX += pow(residuals[0], 2), pointErrY += pow(residuals[1], 2);
				}
			}
		}
		if (validFrameCount > 0)
		{
			ReProjectionErrorX.push_back(sqrt(pointErrX / validFrameCount));
			ReProjectionErrorY.push_back(sqrt(pointErrY / validFrameCount));
		}
	}

	miniX = *min_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
	maxiX = *max_element(ReProjectionErrorX.begin(), ReProjectionErrorX.end());
	avgX = MeanArray(ReProjectionErrorX);
	stdX = sqrt(VarianceArray(ReProjectionErrorX, avgX));
	miniY = *min_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
	maxiY = *max_element(ReProjectionErrorY.begin(), ReProjectionErrorY.end());
	avgY = MeanArray(ReProjectionErrorY);
	stdY = sqrt(VarianceArray(ReProjectionErrorY, avgY));
	printLOG("Static features:\n(%d/%d) bad points with maximum reprojection error of (%.2f %.2f) \n", nBadCounts, nPossibleProjections, maxOutlierX, maxOutlierY);
	printLOG("Reprojection: Min: (%.2f, %.2f) Max: (%.2f,%.2f) Mean: (%.2f,%.2f) Std: (%.2f,%.2f)\n", miniX, miniY, maxiX, maxiY, avgX, avgY, stdX, stdY);

	//Compute cost after optim: Dynamic features:
	MotionPriorCost = 0.0, ProjCost = 0.0;
	ReProjectionErrorX.clear(), ReProjectionErrorY.clear();
	nMP = 0, nIP = 0;
	for (int pid = 0; pid < nDynaPts; pid++)
	{
		int nf = (int)DynaTrajAll[pid].size();
		if (nf == 0)
			continue;

		double costi;
		for (int ll = 0; ll < nf - 1; ll++)
		{
			double shutterOffset1 = 0, shutterOffset2 = 0;
			if (DynaTrajAll[pid][ll].shutterModel != 0)
				shutterOffset1 = DynaTrajAll[pid][ll].pt2D.y / DynaTrajAll[pid][ll].imHeight*DynaTrajAll[pid][ll].rollingShutterPercent;
			else
				shutterOffset1 = 0.0;
			if (DynaTrajAll[pid][ll + 1].shutterModel != 0)
				shutterOffset2 = DynaTrajAll[pid][ll + 1].pt2D.y / DynaTrajAll[pid][ll + 1].imHeight*DynaTrajAll[pid][ll + 1].rollingShutterPercent;
			else
				shutterOffset2 = 0.0;

			double ialpha1 = 1.0 / DynaTrajAll[pid][ll].fps, ialpha2 = 1.0 / DynaTrajAll[pid][ll + 1].fps;
			int cid1 = VectorCamID[pid][ll], cid2 = VectorCamID[pid][ll + 1];
			costi = LeastActionError(DynaTrajAll[pid][ll].pt3d, DynaTrajAll[pid][ll + 1].pt3d, &OffsetInfo[cid1], &OffsetInfo[cid2], shutterOffset1, shutterOffset2, VectorFrameID[pid][ll], VectorFrameID[pid][ll + 1], ialpha1, ialpha2, Tscale, eps, 2);
			MotionPriorCost += costi;
			nMP++;
		}

		for (int ll = 0; ll < nf; ll++)
		{
			Point2d P2d(DynaTrajAll[pid][ll].pt2D.x, DynaTrajAll[pid][ll].pt2D.y);
			Point3d P3d(DynaTrajAll[pid][ll].pt3d[0], DynaTrajAll[pid][ll].pt3d[1], DynaTrajAll[pid][ll].pt3d[2]);

			int cid = DynaTrajAll[pid][ll].viewID;
			int fid = DynaTrajAll[pid][ll].frameID;
			CameraData *camera = videoCam[cid].VideoInfo;
			if (camera[fid].ShutterModel == 0)
			{
				if (distortionCorrected == 1)
					PinholeReprojectionDebug(camera[fid].intrinsic, camera[fid].rt, P2d, P3d, residuals);
				else
					PinholeDistortionReprojectionDebug(camera[fid].intrinsic, camera[fid].distortion, camera[fid].rt, P2d, P3d, residuals);
			}
			else //Rolling shutter
			{
				if (distortionCorrected == 1)
					CayleyReprojectionDebug(camera[fid].intrinsic, camera[fid].rt, camera[fid].wt, P2d, P3d, camera[fid].width, camera[fid].height, residuals);
				else //distortion not corrected
					CayleyDistortionReprojectionDebug(camera[fid].intrinsic, camera[fid].distortion, camera[fid].rt, camera[fid].wt, P2d, P3d, camera[fid].width, camera[fid].height, residuals);
			}
			costi = sqrt(pow(residuals[0], 2) + pow(residuals[1], 2));
			ProjCost += costi;
			nIP++;
		}
	}
	printLOG("\nDynamic features:\nAction cost: %e Projection cost: %e\n ", MotionPriorCost / nMP, ProjCost / nIP);

	delete[]VectorCamID, delete[]VectorFrameID, delete[]DynaTrajAll;
	delete[]currentFrame, delete[]PerCam_nf, delete[]currentPID_InTrack;

	return 0;
}
int StaticDynamicSpatialTemporalBundleAdjustmentDriver(char *Path, int nCams, int startF, int stopF, int StaticIncreF,
	int fixIntrinsic, int  fixDistortion, int fixPose, int fixLocalPose, int fix3D, int sharedIntrinsicIndiCam, int fixSkew, int fixPrism, int distortionCorrected,
	int LossType, double threshold, int nViewsPlus, double reprojectThreshold, double Tscale, double eps, double lamdaStatic, double lamdaDynaData, double RealOverSfm)
{
	char Fname[512];

	VideoData *videoCam = new VideoData[nCams];
	for (int cid = 0; cid < nCams; cid++)
		ReadVideoDataI(Path, videoCam[cid], cid, startF, stopF, reprojectThreshold);

	//Read static feature trajectories
	printLOG("Get 3D Static data:\n");
	Corpus CorpusInfo;
	int nCorpusCams, nStatPts, useColor;
	sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
	if (IsFileExist(Fname) == 0)
		sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	fscanf(fp, "%d %d %d", &nCorpusCams, &nStatPts, &useColor);
	CorpusInfo.nCameras = nCorpusCams;
	CorpusInfo.n3dPoints = nStatPts;

	Point3d xyz;	Point3i rgb;
	CorpusInfo.xyz.reserve(nStatPts);
	if (useColor)
	{
		CorpusInfo.rgb.reserve(nStatPts);
		for (int jj = 0; jj < nStatPts; jj++)
		{
			fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
			CorpusInfo.xyz.push_back(xyz);
			CorpusInfo.rgb.push_back(rgb);
		}
	}
	else
	{
		CorpusInfo.rgb.reserve(nStatPts);
		for (int jj = 0; jj < nStatPts; jj++)
		{
			fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
			CorpusInfo.xyz.push_back(xyz);
		}
	}
	fclose(fp);

	//Generate CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D
	CorpusInfo.viewIdAll3D.reserve(nStatPts);
	CorpusInfo.uvAll3D.reserve(nStatPts);
	CorpusInfo.scaleAll3D.reserve(nStatPts);
	vector<int> selectedCamID3D;
	vector<Point2d> uv3D;
	vector<double> scale3D;
	int nframes = (stopF - startF + StaticIncreF) / StaticIncreF;
	for (int ii = 0; ii < nStatPts; ii++)
	{
		CorpusInfo.viewIdAll3D.push_back(selectedCamID3D); CorpusInfo.viewIdAll3D.back().reserve(nframes*nCams);
		CorpusInfo.uvAll3D.push_back(uv3D); CorpusInfo.uvAll3D.back().reserve(nframes*nCams);
		CorpusInfo.scaleAll3D.push_back(scale3D); CorpusInfo.scaleAll3D.back().reserve(nframes*nCams);
	}

	int pid; double s; Point2d uv;
	for (int cid = 0; cid < nCams; cid++)
	{
		for (int fid = startF; fid <= stopF; fid += StaticIncreF)
		{
			sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, cid, fid); fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%d %lf %lf %lf %lf %lf %lf", &pid, &xyz.x, &xyz.y, &xyz.z, &uv.x, &uv.y, &s) != EOF)
			{
				if (pid < 0 || pid > nStatPts)
					continue;
				if (s < 1.0)
					continue;
				if (videoCam[cid].VideoInfo[fid].valid == true)
				{
					CorpusInfo.viewIdAll3D[pid].push_back(fid + cid * (stopF + 1));
					CorpusInfo.uvAll3D[pid].push_back(uv);
					CorpusInfo.scaleAll3D[pid].push_back(s);
				}
			}
			fclose(fp);
		}
	}

	if (distortionCorrected == 1)
	{
		distortionCorrected = 0;
		for (int jj = 0; jj < nStatPts; jj++)
		{
			for (int ii = 0; ii < (int)CorpusInfo.uvAll3D[jj].size(); ii++)
			{
				int id = CorpusInfo.viewIdAll3D[jj][ii];
				int cid = id / (stopF + 1);
				int fid = id - cid * (stopF + 1);
				LensDistortionPoint(&CorpusInfo.uvAll3D[jj][ii], videoCam[cid].VideoInfo[fid].K, videoCam[cid].VideoInfo[fid].distortion);
			}
		}
	}

	//Read dyna feature trajectories
	printLOG("Get Dyna data:\n");
	double u, v;
	int nDynaPts, pid_, cid_, fid_, nf;
	ImgPtEle ptEle;
	vector<ImgPtEle> *PerCamDynaFeatureTracks = 0;
	for (int camID = 0; camID < nCams; camID++)
	{
		sprintf(Fname, "%s/Track2D/Ultimate_%.4d.txt", Path, camID); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		fscanf(fp, "%d ", &nDynaPts);
		if (PerCamDynaFeatureTracks == 0)
			PerCamDynaFeatureTracks = new vector<ImgPtEle>[nCams*nDynaPts];

		for (int pid = 0; pid < nDynaPts; pid++)
			PerCamDynaFeatureTracks[camID*nDynaPts + pid].reserve(stopF - startF + 1);
		while (fscanf(fp, "%d %d ", &pid_, &nf) != EOF)
		{
			for (int fid = 0; fid < nf; fid++)
			{
				fscanf(fp, "%d %lf %lf %lf ", &fid_, &u, &v, &s);
				if (fid_ < videoCam[camID].startTime || fid_>videoCam[camID].stopTime)
					continue;
				if (!videoCam[camID].VideoInfo[fid_].valid)
					continue; //camera not localized

				if (u > 0 && v > 0)
				{
					ptEle.pt2D.x = u, ptEle.pt2D.y = v, ptEle.scale = s, ptEle.viewID = camID, ptEle.frameID = fid_,
						ptEle.imWidth = videoCam[camID].VideoInfo[fid_].width, ptEle.imHeight = videoCam[camID].VideoInfo[fid_].height, ptEle.shutterModel = videoCam[camID].VideoInfo[fid_].ShutterModel;
					//LensCorrectionPoint(&ptEle.pt2D, videoCam[camID].VideoInfo[fid_].K, videoCam[camID].VideoInfo[fid_].distortion); //let try to re-esimate distortion as well
					PerCamDynaFeatureTracks[camID*nDynaPts + pid_].push_back(ptEle);
				}
			}
		}
		fclose(fp);
	}

	//Read 3D location
	for (int pid = 0; pid < nDynaPts; pid++)
	{
		sprintf(Fname, "%s/Track3D/OptimizedRaw_Track_%.4d.txt", Path, pid);  fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}

		double t;
		while (fscanf(fp, "%lf %lf %lf %lf %d %d", &xyz.x, &xyz.y, &xyz.z, &t, &cid_, &fid_) != EOF)
		{
			bool found = false;
			for (int ii = 0; ii < (int)PerCamDynaFeatureTracks[cid_*nDynaPts + pid].size() && !found; ii++)
			{
				if (fid_ == PerCamDynaFeatureTracks[cid_*nDynaPts + pid][ii].frameID)
				{
					PerCamDynaFeatureTracks[cid_*nDynaPts + pid][ii].pt3D = xyz;
					found = true;
				}
			}
			if (!found)
				printLOG("Having problem finding point %d of cam %d\n", fid_, cid_);
		}
		fclose(fp);
	}

	//read timealignment info
	double *OffsetInfo = new double[nCams];
	sprintf(Fname, "%s/FMotionPriorSync.txt", Path);	fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n. Abort!", Fname);
		return 1;
	}
	int cid; double fps, offset;
	while (fscanf(fp, "%d %lf %lf ", &cid, &fps, &offset) != EOF)
		OffsetInfo[cid] = offset;
	fclose(fp);

	vector<int> SharedIntrinsicCamID;
	sprintf(Fname, "%s/CamerasWithFixedIntrinsic.txt", Path);
	if (IsFileExist(Fname) == 1)
	{
		SharedIntrinsicCamID.reserve(nCams);
		for (int camID = 0; camID < nCams; camID++)
			SharedIntrinsicCamID.push_back(-2); //-2: not interested in sharing, -1: want to share but have not found the host, >=0: host is determined

		int camID, count = 0;
		FILE *fp = fopen(Fname, "r");
		printLOG("Shared-Intrinsic enforces for camera: ");
		while (fscanf(fp, "%d ", &camID) != EOF)
		{
			if (camID < 0 || camID > nCams - 1)
				continue;
			printLOG("%d ", camID);
			SharedIntrinsicCamID[camID] = -1;
			count++;
		}
		fclose(fp);
		if (count > 0)
			printLOG(" ... %d cameras in total.\n", count);
	}

	StaticDynamicSpatialTemporalBundleAdjustment(Path, videoCam, nCams, startF, stopF, SharedIntrinsicCamID, OffsetInfo,
		CorpusInfo.xyz, CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D, PerCamDynaFeatureTracks, nDynaPts,
		fixIntrinsic, fixDistortion, fixPose, fixLocalPose, fix3D, fixSkew, fixPrism, distortionCorrected,
		LossType, threshold, nViewsPlus, Tscale, eps, lamdaStatic, lamdaDynaData, RealOverSfm, 0, true, false);

	//Write results:
	printLOG("Writing refined poses ....");
	for (int camID = 0; camID < nCams; camID++)
	{
		vector<int> computedTime;
		for (int fid = startF; fid <= stopF; fid++)
			if (videoCam[camID].VideoInfo[fid].valid)
				computedTime.push_back(fid);
		sprintf(Fname, "%s/aavIntrinsic_%.4d.txt", Path, camID);	SaveVideoCameraIntrinsic(Fname, videoCam[camID].VideoInfo, computedTime, camID, 0);
		sprintf(Fname, "%s/aavCamPose_RSCayley_%.4d.txt", Path, camID);	SaveVideoCameraPoses(Fname, videoCam[camID].VideoInfo, computedTime, camID, 0);
	}
	printLOG("done\n");

	if (fix3D == 0)
	{
		printLOG("ReSave corpus 3D points ...");
		sprintf(Fname, "%s/Corpus/nnCorpus_3D.txt", Path);	fp = fopen(Fname, "w+");
		fprintf(fp, "%d %d ", CorpusInfo.nCameras, CorpusInfo.n3dPoints);
		if (CorpusInfo.rgb.size() == 0)
		{
			fprintf(fp, "0\n");
			for (int jj = 0; jj < CorpusInfo.xyz.size(); jj++)
				fprintf(fp, "%lf %lf %lf \n", CorpusInfo.xyz[jj].x, CorpusInfo.xyz[jj].y, CorpusInfo.xyz[jj].z);
		}
		else
		{
			fprintf(fp, "1\n");
			for (int jj = 0; jj < CorpusInfo.xyz.size(); jj++)
				fprintf(fp, "%lf %lf %lf %d %d %d\n", CorpusInfo.xyz[jj].x, CorpusInfo.xyz[jj].y, CorpusInfo.xyz[jj].z, CorpusInfo.rgb[jj].x, CorpusInfo.rgb[jj].y, CorpusInfo.rgb[jj].z);
		}
		fclose(fp);

		sprintf(Fname, "%s/Corpus/n3dGL.xyz", Path);	fp = fopen(Fname, "w+");
		if (CorpusInfo.rgb.size() == 0)
			for (int jj = 0; jj < CorpusInfo.xyz.size(); jj++)
				fprintf(fp, "%d %lf %lf %lf \n", jj, CorpusInfo.xyz[jj].x, CorpusInfo.xyz[jj].y, CorpusInfo.xyz[jj].z);
		else
			for (int jj = 0; jj < CorpusInfo.xyz.size(); jj++)
				fprintf(fp, "%d %lf %lf %lf %d %d %d\n", jj, CorpusInfo.xyz[jj].x, CorpusInfo.xyz[jj].y, CorpusInfo.xyz[jj].z, CorpusInfo.rgb[jj].x, CorpusInfo.rgb[jj].y, CorpusInfo.rgb[jj].z);
		fclose(fp);

		printLOG("Resave dyna points ...\n");
		for (int pid = 0; pid < nDynaPts; pid++)
		{
			int nframes = 0;
			for (int cid = 0; cid < nCams; cid++)
				for (int fid = 0; fid < (int)PerCamDynaFeatureTracks[cid*nDynaPts + pid].size(); fid++)
					nframes++;
			if (nframes < 5)
				continue;

			sprintf(Fname, "%s/Track3D/STBA_Track_%.4d.txt", Path, pid);  FILE *fp = fopen(Fname, "w+");
			for (int cid = 0; cid < nCams; cid++)
				for (int fid = 0; fid < (int)PerCamDynaFeatureTracks[cid*nDynaPts + pid].size(); fid++)
				{
					ImgPtEle *ptEle = &PerCamDynaFeatureTracks[cid*nDynaPts + pid][fid];

					double RollingShutterOffset = 0.0;
					if (ptEle[0].shutterModel != 0)
						RollingShutterOffset = ptEle[0].pt2D.y / ptEle[0].imHeight*ptEle[0].rollingShutterPercent;

					fprintf(fp, "%.8f %.8f %.8f %.4f %d %d\n", ptEle[0].pt3D.x, ptEle[0].pt3D.y, ptEle[0].pt3D.z, (OffsetInfo[cid] + RollingShutterOffset + ptEle[0].frameID) *  ptEle[0].fps*Tscale, cid, ptEle[0].frameID);
				}
			fclose(fp);
		}
	}

	sprintf(Fname, "%s/FFMotionPriorSync.txt", Path);	fp = fopen(Fname, "w+");
	for (int ii = 0; ii < nCams; ii++)
		fprintf(fp, "%d 1.0 %.6f\n", ii, OffsetInfo[ii]);
	fclose(fp);

	delete[]videoCam; delete[]PerCamDynaFeatureTracks; delete[]OffsetInfo;

	return 0;
}

int AssociatePeopleAndBuild3DFromCalibedSyncedCameras_RansacTri(char *Path, vector<int> &SelectedCams, int startF, int stopF, int timeStep, int LensType, int distortionCorrected, int nViewsPlus, double Reprojectionthreshold, double angleThesh, double detectionThresh, int iterMax)
{
	const int nJointsCOCO = 18;
	int nCams = (int)SelectedCams.size();
	int *frameTimeStamp = new int[nCams];
	for (int ii = 0; ii < nCams; ii++)
		frameTimeStamp[ii] = 0.0;

	int selected; double fps, temp;
	char Fname[512];  sprintf(Fname, "%s/FMotionPriorSync.txt", Path);
	FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		for (int ii = 0; ii < nCams; ii++)
		{
			fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp);
			frameTimeStamp[ii] = round(temp);
		}
		fclose(fp);
	}
	else
	{
		sprintf(Fname, "%s/FGeoSync.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			for (int ii = 0; ii < nCams; ii++)
			{
				fscanf(fp, "%d %lf ", &selected, &temp);
				frameTimeStamp[ii] = round(temp);
			}
			fclose(fp);
		}
		else
		{
			sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				double fps;
				for (int ii = 0; ii < nCams; ii++)
				{
					fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp);
					frameTimeStamp[ii] = round(temp);
				}
				fclose(fp);
			}
			else
				printLOG("Cannot load time stamp info. Assume no frame offsets!");
		}
	}

	VideoData *VideoInfo = new VideoData[(int)SelectedCams.size()];
	for (int ii = 0; ii < (int)SelectedCams.size(); ii++)
		if (ReadVideoDataI(Path, VideoInfo[ii], SelectedCams[ii], -1, -1) == 1)
			return 1;

	//double *P = new double[12 * nCams];
	double P[240];
	Point2d *pts_ = new Point2d[nCams];
	vector<Point2d> pts1, pts2, pts, projectedPts; vector<Point3d> P3d;
	vector<Point2d> *allPts = new vector<Point2d>[nCams];
	vector<Point2d> *assocatedPts = new vector<Point2d>[nCams];

	for (int fid = startF; fid <= stopF; fid += timeStep)
	{
		printLOG("%d..", fid);
		vector<int> allCid;
		for (int cid = 0; cid < nCams; cid++)
		{
			int syncFid = fid - frameTimeStamp[cid];
			allPts[cid].clear();
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, SelectedCams[cid], syncFid); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			double u, v, s;
			CameraData *camI = VideoInfo[cid].VideoInfo;
			if (camI[syncFid].valid != 1)
			{
				fclose(fp);
				continue;
			}
			while (fscanf(fp, "%lf %lf %lf ", &u, &v, &s) != EOF)
			{
				Point2d uv(u, v);
				if (distortionCorrected == 0 && camI[syncFid].LensModel == RADIAL_TANGENTIAL_PRISM)
					LensCorrectionPoint(&uv, camI[syncFid].K, camI[syncFid].distortion);
				else if (distortionCorrected == 0 && camI[syncFid].LensModel == FISHEYE)
					//FishEyeCorrectionPoint(&uv, camI[syncFid].distortion[0], camI[syncFid].distortion[1], camI[syncFid].distortion[2]);
					FishEyeCorrectionPoint(&uv, camI[syncFid].K, camI[syncFid].distortion[0]);

				if (s < detectionThresh)
					allPts[cid].push_back(Point2d(0, 0));
				else
					allPts[cid].push_back(uv);
			}
			fclose(fp);

			allCid.push_back(cid);
		}

		//Ransac everything
		vector<vector<Point2i> > AllAssoID;
		vector<int>* usedPid = new vector<int>[nCams];
		int iter = 0;
		while (iter < iterMax)
		{
			//Check for termination cond
			int nDone = 0;
			for (int cid = 0; cid < nCams; cid++)
				if (usedPid[cid].size() == allPts[cid].size() / nJointsCOCO)
					nDone++;
			if (nDone >= nCams - 1)
				break;

			int cidI, cidJ, cidK, pidI, pidJ, pidK, nvalid = 0;
			double maxAngle = 0, minAngle = 360, avgErr = 0.0;

			//Try 3views triangulation first
			bool TwoView = false;
			if (allCid.size() < 3)
				TwoView = true;
			else
			{
				random_shuffle(allCid.begin(), allCid.end());
				cidI = allCid[0], cidJ = allCid[1], cidK = allCid[2];
				int syncFidI = fid - frameTimeStamp[cidI], syncFidJ = fid - frameTimeStamp[cidJ], syncFidK = fid - frameTimeStamp[cidK];

				//mask out associated people
				int nPeopleI = (int)allPts[cidI].size() / nJointsCOCO, nPeopleJ = (int)allPts[cidJ].size() / nJointsCOCO, nPeopleK = (int)allPts[cidK].size() / nJointsCOCO;
				vector<int> AvaiPidI, AvaiPidJ, AvaiPidK;
				for (int jj = 0; jj < nPeopleI; jj++)
					if (std::find(usedPid[cidI].begin(), usedPid[cidI].end(), jj) == usedPid[cidI].end())
						AvaiPidI.push_back(jj);
				for (int jj = 0; jj < nPeopleJ; jj++)
					if (std::find(usedPid[cidJ].begin(), usedPid[cidJ].end(), jj) == usedPid[cidJ].end())
						AvaiPidJ.push_back(jj);
				for (int jj = 0; jj < nPeopleK; jj++)
					if (std::find(usedPid[cidK].begin(), usedPid[cidK].end(), jj) == usedPid[cidK].end())
						AvaiPidK.push_back(jj);

				if (AvaiPidI.size() == 0 || AvaiPidJ.size() == 0 || AvaiPidK.size() == 0)
					TwoView = true;
				else
				{
					pts.clear(), P3d.resize(nJointsCOCO);
					random_shuffle(AvaiPidI.begin(), AvaiPidI.end());
					random_shuffle(AvaiPidJ.begin(), AvaiPidJ.end());
					random_shuffle(AvaiPidK.begin(), AvaiPidK.end());

					pidI = AvaiPidI[0], pidJ = AvaiPidJ[0], pidK = AvaiPidK[0]; //associate people
					for (int jid = 0; jid < nJointsCOCO; jid++)
						pts.push_back(allPts[cidI][pidI * nJointsCOCO + jid]);
					for (int jid = 0; jid < nJointsCOCO; jid++)
						pts.push_back(allPts[cidJ][pidJ * nJointsCOCO + jid]);
					for (int jid = 0; jid < nJointsCOCO; jid++)
						pts.push_back(allPts[cidK][pidK * nJointsCOCO + jid]);

					CameraData *camI = VideoInfo[cidI].VideoInfo, *camJ = VideoInfo[cidJ].VideoInfo, *camK = VideoInfo[cidK].VideoInfo;
					for (int kk = 0; kk < 12; kk++)
						P[kk] = camI[syncFidI].P[kk], P[kk + 12] = camJ[syncFidJ].P[kk], P[kk + 24] = camK[syncFidK].P[kk];

					NviewTriangulation(&pts[0], P, &P3d[0], 3, nJointsCOCO, NULL, NULL, NULL);

					for (int jid = 0; jid < nJointsCOCO; jid++)
					{
						double angle = CalculateTriangulationAngle(camI[syncFidI].camCenter, camJ[syncFidJ].camCenter, &P3d[jid].x);
						minAngle = min(angle, minAngle), maxAngle = max(angle, maxAngle);
					}
					for (int jid = 0; jid < nJointsCOCO; jid++)
					{
						double angle = CalculateTriangulationAngle(camI[syncFidI].camCenter, camK[syncFidK].camCenter, &P3d[jid].x);
						minAngle = min(angle, minAngle), maxAngle = max(angle, maxAngle);
					}
					for (int jid = 0; jid < nJointsCOCO; jid++)
					{
						double angle = CalculateTriangulationAngle(camJ[syncFidJ].camCenter, camK[syncFidK].camCenter, &P3d[jid].x);
						minAngle = min(angle, minAngle), maxAngle = max(angle, maxAngle);
					}
					if (maxAngle < angleThesh)
					{
						iter++;
						continue;
					}

					//Check 3 views reprojection error
					for (int jid = 0; jid < nJointsCOCO; jid++)
					{
						ProjectandDistort(P3d[jid], pts_, P, NULL, NULL, 3);
						if (pts[jid].x == 0.0 || pts[jid + nJointsCOCO].x == 0.0 || pts[jid + 2 * nJointsCOCO].x == 0)
						{
							P3d[jid] = Point3d(0, 0, 0);
							continue;
						}
						double err1 = (abs(pts[jid].x - pts_[0].x) + abs(pts[jid].y - pts_[0].y));
						double err2 = (abs(pts[jid + nJointsCOCO].x - pts_[1].x) + abs(pts[jid + nJointsCOCO].y - pts_[1].y));
						double err3 = (abs(pts[jid + 2 * nJointsCOCO].x - pts_[2].x) + abs(pts[jid + 2 * nJointsCOCO].y - pts_[2].y));
						avgErr += 0.166666*(err1 + err2 + err3);
						nvalid++;
					}
					avgErr = avgErr / (0.0001 + nvalid);
				}
			}

			if (TwoView)
			{
				random_shuffle(allCid.begin(), allCid.end());
				cidI = allCid[0], cidJ = allCid[1];
				int syncFidI = fid - frameTimeStamp[cidI], syncFidJ = fid - frameTimeStamp[cidJ];

				//mask out associated people
				int nPeopleI = (int)allPts[cidI].size() / nJointsCOCO, nPeopleJ = (int)allPts[cidJ].size() / nJointsCOCO;
				vector<int> AvaiPidI, AvaiPidJ;
				for (int jj = 0; jj < nPeopleI; jj++)
				{
					if (std::find(usedPid[cidI].begin(), usedPid[cidI].end(), jj) == usedPid[cidI].end())
						AvaiPidI.push_back(jj);
				}
				for (int jj = 0; jj < nPeopleJ; jj++)
				{
					if (std::find(usedPid[cidJ].begin(), usedPid[cidJ].end(), jj) == usedPid[cidJ].end())
						AvaiPidJ.push_back(jj);
				}
				if (AvaiPidI.size() == 0 || AvaiPidJ.size() == 0)
				{
					iter++;
					continue;
				}
				random_shuffle(AvaiPidI.begin(), AvaiPidI.end());
				random_shuffle(AvaiPidJ.begin(), AvaiPidJ.end());

				pidI = AvaiPidI[0], pidJ = AvaiPidJ[0]; //associate people

														//2 views triangulation
				pts1.clear(), pts2.clear(), P3d.clear();
				for (int jid = 0; jid < nJointsCOCO; jid++)
					pts1.push_back(allPts[cidI][pidI * nJointsCOCO + jid]), pts2.push_back(allPts[cidJ][pidJ * nJointsCOCO + jid]);

				CameraData *camI = VideoInfo[cidI].VideoInfo, *camJ = VideoInfo[cidJ].VideoInfo;
				for (int kk = 0; kk < 12; kk++)
					P[kk] = camI[syncFidI].P[kk], P[kk + 12] = camJ[syncFidJ].P[kk];

				TwoViewTriangulation(pts1, pts2, P, P + 12, P3d);

				for (int jid = 0; jid < nJointsCOCO; jid++)
				{
					double angle = CalculateTriangulationAngle(camI[syncFidI].camCenter, camJ[syncFidJ].camCenter, &P3d[jid].x);
					minAngle = min(angle, minAngle), maxAngle = max(angle, maxAngle);
				}
				if (maxAngle < angleThesh)
					continue;

				//Check 2 views reprojection error
				for (int jid = 0; jid < nJointsCOCO; jid++)
				{
					ProjectandDistort(P3d[jid], pts_, P, NULL, NULL, 2);
					if (allPts[cidI][pidI * nJointsCOCO + jid].x == 0.0 || allPts[cidJ][pidJ * nJointsCOCO + jid].x == 0.0)
					{
						P3d[jid] = Point3d(0, 0, 0);
						continue;
					}
					double err1 = (abs(pts1[jid].x - pts_[0].x) + abs(pts1[jid].y - pts_[0].y));
					double err2 = (abs(pts2[jid].x - pts_[1].x) + abs(pts2[jid].y - pts_[1].y));
					avgErr += 0.25*(err1 + err2);
					nvalid++;
				}
				avgErr = avgErr / (0.0001 + nvalid);
			}

			if (avgErr < Reprojectionthreshold)
			{
				vector<Point2i> assoID;
				for (int cid = 0; cid < nCams; cid++) //Project to all views
				{
					int syncFid = fid - frameTimeStamp[cid];
					CameraData *camI = VideoInfo[cid].VideoInfo;
					projectedPts.clear();
					for (int jid = 0; jid < nJointsCOCO; jid++)
					{
						if (abs(P3d[jid].x + abs(P3d[jid].y) + abs(P3d[jid].z)) == 0 || camI[syncFid].valid == 0)
							projectedPts.push_back(Point2d(0, 0));
						else
						{
							ProjectandDistort(P3d[jid], pts_, camI[syncFid].P, NULL, NULL, 1);
							projectedPts.push_back(pts_[0]);
						}
					}

					int bestAssoc = -1;
					double minAvgErr = 9e9;
					for (int pid = 0; pid < (int)allPts[cid].size() / nJointsCOCO; pid++) //find the best association within that view
					{
						if (std::find(usedPid[cid].begin(), usedPid[cid].end(), pid) != usedPid[cid].end())
							continue;

						int nvalid = 0;
						avgErr = 0;
						for (int jid = 0; jid < nJointsCOCO; jid++)
						{
							if (allPts[cid][pid * nJointsCOCO + jid].x == 0 || projectedPts[jid].x == 0.0)
								continue;
							avgErr += 0.5*(abs(allPts[cid][pid * nJointsCOCO + jid].x - projectedPts[jid].x) + abs(allPts[cid][pid * nJointsCOCO + jid].y - projectedPts[jid].y));
							nvalid++;
						}
						avgErr /= (0.00001 + nvalid);
						if (minAvgErr > avgErr)
							bestAssoc = pid, minAvgErr = avgErr;
					}

					if (minAvgErr < Reprojectionthreshold)
						assoID.push_back(Point2i(cid, bestAssoc));
				}
				if (1.0*assoID.size() / allCid.size() > 0.5)
				{
					AllAssoID.push_back(assoID);
					for (int ii = 0; ii < assoID.size(); ii++)
						usedPid[assoID[ii].x].push_back(assoID[ii].y);

					for (int cid = 0; cid < nCams; cid++)
					{
						sort(usedPid[cid].begin(), usedPid[cid].end());
						std::vector<int>::iterator it = unique(usedPid[cid].begin(), usedPid[cid].end());
						usedPid[cid].resize(std::distance(usedPid[cid].begin(), it));
					}
				}
			}
			else
				continue;
			iter++;
		}

		//retriangulate associated person using Nviews
		vector<Point3d> *PeopleJoints3D = new vector<Point3d>[(int)AllAssoID.size()];
		for (int pid = 0; pid < (int)AllAssoID.size(); pid++)
		{
			int nValidCams = (int)AllAssoID[pid].size();
			PeopleJoints3D[pid].resize(nJointsCOCO);
			for (int jid = 0; jid < nJointsCOCO; jid++) //incase of missing joint, do per-point DLT triangulation
			{
				int  nvalidPoints = 0;
				for (int ii = 0; ii < nValidCams; ii++)
				{
					int cid = AllAssoID[pid][ii].x, did = AllAssoID[pid][ii].y;
					int syncFid = fid - frameTimeStamp[cid];

					if (allPts[cid][did * nJointsCOCO + jid].x == 0.0)
						continue;
					pts_[nvalidPoints] = allPts[cid][did * nJointsCOCO + jid];

					CameraData *camI = VideoInfo[cid].VideoInfo;
					if (camI[syncFid].valid == 0)
						continue;
					for (int kk = 0; kk < 12; kk++)
						P[kk + 12 * nvalidPoints] = camI[syncFid].P[kk];

					nvalidPoints++;
				}
				if (nvalidPoints > 1)
					NviewTriangulation(pts_, P, &PeopleJoints3D[pid][jid], nvalidPoints, 1, NULL, NULL, NULL);
			}
		}
		if (AllAssoID.size() > 0)
		{
			sprintf(Fname, "%s/MP/%.4d.txt", Path, fid); FILE *fp = fopen(Fname, "w");
			for (int pid = 0; pid < (int)AllAssoID.size(); pid++)
			{
				fprintf(fp, "%d ", AllAssoID[pid].size());
				for (int ii = 0; ii < AllAssoID[pid].size(); ii++)
					fprintf(fp, "( %d, %d ) ", AllAssoID[pid][ii].x, AllAssoID[pid][ii].y);
				fprintf(fp, "\n");
				for (int jid = 0; jid < nJointsCOCO; jid++)
					fprintf(fp, "%.6e %.6e %.6e\n", PeopleJoints3D[pid][jid].x, PeopleJoints3D[pid][jid].y, PeopleJoints3D[pid][jid].z);
			}
			fclose(fp);
		}

		delete[]usedPid, delete[]PeopleJoints3D;
	}

	delete[] VideoInfo, delete[] P, delete[]pts_, delete[]allPts, delete[]assocatedPts;

	return 0;
}
int AssociatePeopleAndBuild3DFromCalibedSyncedCameras_3DVoting(char *Path, vector<int> &SelectedCams, int startF, int stopF, int increF, int LensType, int distortionCorrected, int nViewPlus, double detectionThresh, double reprojectionThesh, double real2SfM, double cellSize)
{
	char Fname[512];
	sprintf(Fname, "%s/VoxelVoting", Path); makeDir(Fname);
	sprintf(Fname, "%s/VoxelVoting/VT", Path); makeDir(Fname);
	sprintf(Fname, "%s/VoxelVoting/T", Path); makeDir(Fname);
	sprintf(Fname, "%s/VoxelVoting/A", Path); makeDir(Fname);

	const int nJointsCOCO = 18;
	int nCams = (int)SelectedCams.size();
	int *frameTimeStamp = new int[nCams];
	for (int ii = 0; ii < nCams; ii++)
		frameTimeStamp[ii] = 0.0;

	int selected; double fps, temp;
	sprintf(Fname, "%s/FMotionPriorSync.txt", Path);
	FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		for (int ii = 0; ii < nCams; ii++)
		{
			fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp);
			frameTimeStamp[ii] = round(temp);
		}
		fclose(fp);
	}
	else
	{
		sprintf(Fname, "%s/FGeoSync.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			for (int ii = 0; ii < nCams; ii++)
			{
				fscanf(fp, "%d %lf ", &selected, &temp);
				frameTimeStamp[ii] = round(temp);
			}
			fclose(fp);
		}
		else
		{
			double fps;
			sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				for (int ii = 0; ii < nCams; ii++)
				{
					fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp);
					frameTimeStamp[ii] = round(temp);
				}
				fclose(fp);
			}
			else
				printLOG("Cannot load time stamp info. Assume no frame offsets!");
		}
	}

	//Get video data
	VideoData *VideoInfo = new VideoData[(int)SelectedCams.size()];
	for (int ii = 0; ii < (int)SelectedCams.size(); ii++)
		if (ReadVideoDataI(Path, VideoInfo[ii], SelectedCams[ii], -1, -1) == 1)
			return 1;

	int count = 0;
	Point3d centroid(0, 0, 0);
	for (int cid = 0; cid < nCams; cid++)
	{
		for (int fid = startF; fid <= stopF; fid++)
		{
			CameraData *camI = VideoInfo[cid].VideoInfo;
			if (camI[fid].valid == 1)
			{
				centroid.x += camI[fid].camCenter[0], centroid.y += camI[fid].camCenter[1], centroid.z += camI[fid].camCenter[2];
				count++;
			}
		}
	}
	centroid.x /= count, centroid.y /= count, centroid.z /= count;

	double currentRadiusSize = 0;
	for (int cid = 0; cid < nCams; cid++)
	{
		for (int fid = startF; fid <= stopF; fid++)
		{
			CameraData *camI = VideoInfo[cid].VideoInfo;
			if (camI[fid].valid == 1)
			{
				double dist = sqrt(pow(centroid.x - camI[fid].camCenter[0], 2) + pow(centroid.y - camI[fid].camCenter[1], 2) + pow(centroid.y - camI[fid].camCenter[2], 2));
				if (dist > currentRadiusSize)
					currentRadiusSize = dist;
			}
		}
	}
	centroid.x = centroid.x - 2;
	cellSize = cellSize / real2SfM; //2cm^3 cell
	int nstep = (int)(currentRadiusSize / cellSize + 0.5);
	Point3i dim = Point3i(2 * nstep + 1, nstep + 1, 2 * nstep + 1);
	dim.x = 2 * (dim.x / 3) + 1;  //make sure it is odd
	dim.z = 2 * (dim.z / 3) + 1;  //make sure it is odd
	dim.y = 2 * (dim.y / 11) + 1;  //make sure it is odd

	float *VTscore = new float[dim.x*dim.y*dim.z];
	float *VTscore2 = new float[dim.x*dim.y*dim.z];
	printLOG("Volume size: %dx%dx%d\n", dim.x, dim.y, dim.z);


	double *P = new double[12 * nCams];
	Point2d *pts_ = new Point2d[nCams];
	vector<Point2d> *allPts = new vector<Point2d>[nCams];
	vector<bool> *allPtsUsed = new vector<bool>[nCams];
	vector<Point2d> *assocatedPts = new vector<Point2d>[nCams];
	vector<Point3d> XYZ; XYZ.reserve(10000);


	for (int fid = startF; fid <= stopF; fid += increF)
	{
		printLOG("(%d..", fid);
		for (int cid = 0; cid < nCams; cid++)
		{
			int localFid = fid - frameTimeStamp[cid];
			allPts[cid].clear(); allPtsUsed[cid].clear();
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, SelectedCams[cid], localFid); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			double u, v, s;
			CameraData *camI = VideoInfo[cid].VideoInfo;
			if (camI[localFid].valid != 1)
			{
				fclose(fp);
				continue;
			}
			while (fscanf(fp, "%lf %lf %lf ", &u, &v, &s) != EOF)
			{
				Point2d uv(u, v);
				if (distortionCorrected == 0 && camI[localFid].LensModel == RADIAL_TANGENTIAL_PRISM)
					LensCorrectionPoint(&uv, camI[localFid].K, camI[localFid].distortion);
				else if (distortionCorrected == 0 && camI[localFid].LensModel == FISHEYE)
					//FishEyeCorrectionPoint(&uv, camI[localFid].distortion[0], camI[localFid].distortion[1], camI[localFid].distortion[2]);
					FishEyeCorrectionPoint(&uv, camI[localFid].K, camI[localFid].distortion[0]);

				if (s < detectionThresh)
					allPts[cid].push_back(Point2d(0, 0));
				else
					allPts[cid].push_back(uv);
			}
			fclose(fp);

			allPtsUsed[cid].resize(allPts[cid].size() / nJointsCOCO);
		}

		{
			FILE *fp = fopen("C:/temp/v.txt", "w");
			int dimxy = dim.x*dim.y, hx = dim.x / 2, hy = dim.y / 2, hz = dim.z / 2;
			omp_set_num_threads(omp_get_max_threads());
			for (int kk = -hz; kk <= hz; kk += 20)
			{
				for (int jj = -hy; jj <= hy; jj += 20)
				{
					for (int ii = -hx; ii <= hx; ii += 20)
					{
						Point3d cellLoc = Point3d(ii, jj, kk)*cellSize + centroid;
						fprintf(fp, "%.4f %.4f %.4f\n", cellLoc.x, cellLoc.y, cellLoc.z);
					}
				}
			}
			fclose(fp);
			return 0;
		}


		XYZ.clear();
		double startTime = omp_get_wtime();
		sprintf(Fname, "%s/VoxelVoting/VT/%.4d.dat", Path, fid);
		ifstream fin;
		fin.open(Fname, ios::binary);
		if (fin.is_open())
		{
			int count = 0;
			float x, y, z, s;
			fin.read(reinterpret_cast<char *>(&count), sizeof(int));
			for (int ii = 0; ii < count; ii++)
			{
				fin.read(reinterpret_cast<char *>(&x), sizeof(float));
				fin.read(reinterpret_cast<char *>(&y), sizeof(float));
				fin.read(reinterpret_cast<char *>(&z), sizeof(float));
				fin.read(reinterpret_cast<char *>(&s), sizeof(float));
				XYZ.push_back(Point3d(x, y, z));
			}
			fin.close();
			printLOG("%.2fs..", omp_get_wtime() - startTime);
		}
		else
		{
			int dimxy = dim.x*dim.y, hx = dim.x / 2, hy = dim.y / 2, hz = dim.z / 2;
			omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic,1)
			for (int kk = -hz; kk <= hz; kk++)
			{
				for (int jj = -hy; jj <= hy; jj++)
				{
					for (int ii = -hx; ii <= hx; ii++)
					{
						Point3d cellLoc = Point3d(ii, jj, kk)*cellSize + centroid;

						double score = 0.0;
						int nVisCam = 0;
						Point2d projectedPt;
						int HitPartID = -1, HitPartIDi;
						for (int cid = 0; cid < nCams; cid++)
						{
							int localFid = fid - frameTimeStamp[cid];
							CameraData *camI = VideoInfo[cid].VideoInfo;
							if (camI[localFid].valid == 0)
								continue;
							ProjectandDistort(cellLoc, &projectedPt, camI[localFid].P, NULL, NULL);

							double mindist = 9e9, dist;
							for (size_t pid = 0; pid < allPts[cid].size(); pid++)
							{
								if (allPts[cid][pid].x != 0)
								{
									dist = norm(projectedPt - allPts[cid][pid]);
									if (mindist > dist)
										mindist = dist, HitPartIDi = (int)pid;
								}
							}
							if (mindist < 1.5*reprojectionThesh)//make it loose
							{
								if (HitPartID != -1 && HitPartID % nJointsCOCO != HitPartIDi % nJointsCOCO)
									mindist = 9e9; //make sure to penalize if it hits diff part
								else
									HitPartID = HitPartIDi;
								nVisCam++;
								score += mindist;
							}
						}
						if (nVisCam > 1)
							VTscore[ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy] = score / nVisCam;
						else
							VTscore[ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy] = (float)9e9;
					}
				}
			}

			//Non-min suppression
			int bw = 3;
#pragma omp parallel for schedule(dynamic,1)
			for (int kk = -hz; kk <= hz; kk++)
			{
				for (int jj = -hy; jj <= hy; jj++)
				{
					for (int ii = -hx; ii <= hx; ii++)
					{
						int id = ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy;
						double orgScore = VTscore[id];
						bool LocalMin = true;
						for (int k = -bw; k <= bw && LocalMin; k++)
						{
							for (int j = -bw; j <= bw && LocalMin; j++)
							{
								for (int i = -bw; i <= bw && LocalMin; i++)
								{
									int kkk = k + kk, jjj = j + jj, iii = i + ii;
									if (kkk<-hz || kkk>hz || jjj<-hy || jjj>hy || iii<-hx || iii>hx)
										continue;
									int id_ = iii + hx + (jjj + hy)*dim.x + (kkk + hz)*dimxy;
									double score = VTscore[id_];
									if (score < orgScore)
										LocalMin = false;
								}
							}
						}

						if (LocalMin)
							VTscore2[id] = orgScore;
						else
							VTscore2[id] = (float)9e9;
					}
				}
			}
			for (int kk = -hz; kk <= hz; kk++)
			{
				for (int jj = -hy; jj <= hy; jj++)
				{
					for (int ii = -hx; ii <= hx; ii++)
					{
						if (VTscore[ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy] < reprojectionThesh*1.5)
							XYZ.push_back(Point3d(centroid.x + ii * cellSize, centroid.y + jj * cellSize, centroid.z + kk * cellSize));
					}
				}
			}

			printLOG("%.2fs..", omp_get_wtime() - startTime);

			ofstream fout;
			sprintf(Fname, "%s/VoxelVoting/VT/%.4d.dat", Path, fid); fout.open(Fname, ios::binary);
			if (!fout.is_open())
			{
				cout << "Cannot write: " << Fname << endl;
				return 1;
			}
			int count = 0;
			for (int kk = -hz; kk <= hz; kk++)
			{
				for (int jj = -hy; jj <= hy; jj++)
				{
					for (int ii = -hx; ii <= hx; ii++)
					{
						double score = VTscore[ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy];
						if (score < reprojectionThesh)
							count++;
					}
				}
			}
			fout.write(reinterpret_cast<char *>(&count), sizeof(int));
			for (int kk = -hz; kk <= hz; kk++)
			{
				for (int jj = -hy; jj <= hy; jj++)
				{
					for (int ii = -hx; ii <= hx; ii++)
					{
						float score = (float)VTscore[ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy];
						float x = centroid.x + ii * cellSize, y = centroid.y + jj * cellSize, z = centroid.z + kk * cellSize;
						if (score < reprojectionThesh)
						{
							fout.write(reinterpret_cast<char *>(&x), sizeof(float));
							fout.write(reinterpret_cast<char *>(&y), sizeof(float));
							fout.write(reinterpret_cast<char *>(&z), sizeof(float));
							fout.write(reinterpret_cast<char *>(&score), sizeof(float));
						}
					}
				}
			}
			fout.close();
		}

		startTime = omp_get_wtime();
		//compute potential assocation for all confident voxels
		Point2d projectedPt;
		vector<int>  HitCameras, HitPeople;
		vector<Point2i> newUniqueAssosID;
		vector<vector<Point2i> > UniqueAssosID;
		sprintf(Fname, "%s/VoxelVoting/T/%.4d.txt", Path, fid);
		if (IsFileExist(Fname) == 1)
		{
			int nasso, cid, pid;
			vector<Point2i> newUniqueAssosID;
			fp = fopen(Fname, "r");
			while (fscanf(fp, "%d ", &nasso) != EOF)
			{
				newUniqueAssosID.clear();
				for (int ii = 0; ii < nasso; ii++)
				{
					fscanf(fp, "%d %d  ", &cid, &pid);
					newUniqueAssosID.push_back(Point2i(cid, pid));
				}
				UniqueAssosID.push_back(newUniqueAssosID);
			}
			fclose(fp);
		}
		else
		{
			for (size_t ii = 0; ii < XYZ.size(); ii++)
			{
				HitCameras.clear(), HitPeople.clear();
				int HitPartID = -1, HitPartIDi;

				for (int cid = 0; cid < nCams; cid++)
				{
					int localFid = fid - frameTimeStamp[cid];
					CameraData *camI = VideoInfo[cid].VideoInfo;
					ProjectandDistort(XYZ[ii], &projectedPt, camI[localFid].P, NULL, NULL);

					double mindist = 9e9, dist;
					for (size_t pid = 0; pid < allPts[cid].size(); pid++)
					{
						if (allPts[cid][pid].x != 0)
						{
							dist = norm(projectedPt - allPts[cid][pid]);
							if (mindist > dist)
								mindist = dist, HitPartIDi = (int)pid;
						}
					}
					if (mindist < reprojectionThesh)
					{
						if (HitPartID != -1 && HitPartID % nJointsCOCO != HitPartIDi % nJointsCOCO)
						{
							HitCameras.clear(), HitPeople.clear(); //inconistent keypoint ID
							break;
						}
						else
						{
							HitPartID = HitPartIDi;
							HitCameras.push_back(cid);
							HitPeople.push_back(HitPartID / nJointsCOCO);
						}
					}
				}

				if (HitCameras.size() < nViewPlus)
					continue;

				//Get uniqueAssoID: trying to merge same asso hypo generated by neighboring voxels
				int foundID = -1;
				for (size_t jj = 0; jj < UniqueAssosID.size() && foundID == -1; jj++)
				{
					if (UniqueAssosID[jj].size() != HitCameras.size())
						continue;

					int allFound = 0;
					for (size_t kk = 0; kk < UniqueAssosID[jj].size(); kk++)
					{
						int foundI = 0;
						for (size_t ll = 0; ll < HitCameras.size() && foundI == 0; ll++)
							if (UniqueAssosID[jj][kk].x == HitCameras[ll] && UniqueAssosID[jj][kk].y == HitPeople[ll])
								foundI = 1;
						if (foundI == 1)
							allFound++;
					}
					if (allFound == UniqueAssosID[jj].size())
						foundID = (int)jj;
				}
				if (foundID == -1)
				{
					newUniqueAssosID.clear();
					for (size_t ll = 0; ll < HitCameras.size(); ll++)
						newUniqueAssosID.push_back(Point2i(HitCameras[ll], HitPeople[ll]));
					UniqueAssosID.push_back(newUniqueAssosID);
				}
			}
			//#ifdef _DEBUG
			sprintf(Fname, "%s/VoxelVoting/T/%.4d.txt", Path, fid);
			fp = fopen(Fname, "w");
			for (size_t ll = 0; ll < UniqueAssosID.size(); ll++)
			{
				fprintf(fp, "%d ", UniqueAssosID[ll].size());
				for (size_t ii = 0; ii < UniqueAssosID[ll].size(); ii++)
					fprintf(fp, "%d %d ", UniqueAssosID[ll][ii].x, UniqueAssosID[ll][ii].y);
				fprintf(fp, "\n");
			}
			fclose(fp);
			//#endif
		}
		printLOG("%.2fs..", omp_get_wtime() - startTime);

		//Take the one with highest #visible cameras and iterate until almost no detection is left
		int *T = new int[UniqueAssosID.size()], *TT = new int[UniqueAssosID.size()];
		for (int ll = 0; ll < (int)UniqueAssosID.size(); ll++)
			T[ll] = -(int)UniqueAssosID[ll].size(), TT[ll] = ll;
		Quick_Sort_Int(T, TT, 0, (int)UniqueAssosID.size() - 1);

		startTime = omp_get_wtime();
		vector<Point3d> body;
		Point3d XYZ[nJointsCOCO];
		vector<Point2i> currentAssoID, fAassoID;
		vector<vector<Point3d> > allBody;
		vector<vector<Point2i> > allAssoID;
		for (int ll = 0; ll < (int)UniqueAssosID.size(); ll++)
		{
			double residuals;
			int  nvalid, nvalidJoints = 0, assoID = TT[ll];

			currentAssoID.clear();
			for (int jid = 0; jid < nJointsCOCO; jid++) //do per-point DLT triangulation due to missing keypoints detections
			{
				nvalid = 0;
				for (auto asso : UniqueAssosID[assoID])
				{
					int cid = asso.x, did = asso.y, localFid = fid - frameTimeStamp[cid];;
					if (allPtsUsed[cid][did] || allPts[cid][did * nJointsCOCO + jid].x == 0.0)
						continue;
					pts_[nvalid] = allPts[cid][did * nJointsCOCO + jid];

					CameraData *camI = VideoInfo[cid].VideoInfo;
					if (camI[localFid].valid == 0)
						continue;
					for (int kk = 0; kk < 12; kk++)
						P[kk + 12 * nvalid] = camI[localFid].P[kk];

					//in case some people keypoints have been claimed
					bool found = false;
					for (auto casso : currentAssoID)
					{
						if (cid == casso.x && did == casso.y)
						{
							found = true;
							break;
						}
					}
					if (!found)
						currentAssoID.push_back(Point2i(cid, did));
					nvalid++;
				}
				if (nvalid > 1)
				{
					NviewTriangulation(pts_, P, &XYZ[jid], nvalid, 1, NULL, NULL, NULL);
					NviewTriangulationNonLinear(P, pts_, &XYZ[jid], &residuals, nvalid, 1);
					if (residuals < reprojectionThesh)
						nvalidJoints++;
				}
			}

			if (nvalidJoints > nJointsCOCO / 3 && currentAssoID.size() > nViewPlus)
			{
				//try to expand asso the last time
				fAassoID.clear();
				for (auto cid : SelectedCams) //Project to all views
				{
					int localFid = fid - frameTimeStamp[cid];
					CameraData *camI = VideoInfo[cid].VideoInfo;

					int nvalidJointsBest = 0, bestPid = -1, bestPid2 = -1;
					double avgErr, avgErrBest = 9e9;
					//for (int pid = 0; pid < (int)allPts[cid].size() / nJointsCOCO; pid++) //find the best association within that view
					for (int pid = 0; pid < (int)allPts[cid].size() / nJointsCOCO - 3; pid++) //find the best association within that view. Avoid the face region
					{
						if (allPtsUsed[cid][pid])
							continue;

						nvalidJoints = 0; avgErr = 0;
						for (int jid = 0; jid < nJointsCOCO; jid++)
						{
							if (abs(XYZ[jid].x + abs(XYZ[jid].y) + abs(XYZ[jid].z)) != 0 && camI[localFid].valid == 1)
							{
								ProjectandDistort(XYZ[jid], pts_, camI[localFid].P, NULL, NULL, 1);
								if (allPts[cid][pid * nJointsCOCO + jid].x == 0 || allPtsUsed[cid][pid])
									continue;

								double err = 0.5*(abs(allPts[cid][pid * nJointsCOCO + jid].x - pts_[0].x) + abs(allPts[cid][pid * nJointsCOCO + jid].y - pts_[0].y));
								if (err < reprojectionThesh)
								{
									avgErr += err;
									nvalidJoints++;
								}
							}
						}
						avgErr = avgErr / (0.0001 + nvalidJoints);

						if (nvalidJoints > nvalidJointsBest)
							nvalidJointsBest = nvalidJoints, bestPid = pid;
						if (nvalidJoints > nJointsCOCO / 3 && avgErrBest > avgErr)
							avgErrBest = avgErr, bestPid2 = pid;
					}
					if (nvalidJointsBest > nJointsCOCO / 4)
						fAassoID.push_back(Point2i(cid, bestPid));
				}

				if (fAassoID.size() >= nViewPlus) //expansion succeeds. Bravo!
				{
					//retriangulation
					for (int jid = 0; jid < nJointsCOCO; jid++) //do per-point DLT triangulation due to missing keypoints detections
					{
						XYZ[jid] = Point3d(0, 0, 0);
						nvalid = 0;
						for (auto asso : fAassoID)
						{
							int cid = asso.x, did = asso.y, localFid = fid - frameTimeStamp[cid];;
							if (allPtsUsed[cid][did] || allPts[cid][did * nJointsCOCO + jid].x == 0.0)
								continue;

							pts_[nvalid] = allPts[cid][did * nJointsCOCO + jid];

							CameraData *camI = VideoInfo[cid].VideoInfo;
							if (camI[localFid].valid == 0)
								continue;
							for (int kk = 0; kk < 12; kk++)
								P[kk + 12 * nvalid] = camI[localFid].P[kk];

							nvalid++;
						}
						if (nvalid > 1)
						{
							NviewTriangulation(pts_, P, &XYZ[jid], nvalid, 1, NULL, NULL, NULL);
							NviewTriangulationNonLinear(P, pts_, &XYZ[jid], &residuals, nvalid, 1);
							if (residuals < reprojectionThesh)
								nvalidJoints++;
						}
					}

					for (auto asso : fAassoID)
						allPtsUsed[asso.x][asso.y] = true; //remove points
					allAssoID.push_back(fAassoID);

					body.clear();
					for (int ii = 0; ii < nJointsCOCO; ii++)
						body.push_back(XYZ[ii]);
					allBody.push_back(body);
				}
			}
		}
		printLOG("%.2fs..", omp_get_wtime() - startTime);

		sprintf(Fname, "%s/VoxelVoting/%.4d.txt", Path, fid); fp = fopen(Fname, "w+");
		for (int pid = 0; pid < (int)allBody.size(); pid++)
			for (int jid = 0; jid < nJointsCOCO; jid++)
				fprintf(fp, "%e %e %e\n", allBody[pid][jid].x, allBody[pid][jid].y, allBody[pid][jid].z);
		fclose(fp);

		//#ifdef _DEBUG
		sprintf(Fname, "%s/VoxelVoting/A/%.4d.txt", Path, fid); fp = fopen(Fname, "w+");
		for (int pid = 0; pid < (int)allBody.size(); pid++)
		{
			fprintf(fp, "%d ", allAssoID[pid].size());
			for (auto asso : allAssoID[pid])
				fprintf(fp, "%d %d  ", asso.x, asso.y);
			fprintf(fp, "\n");
		}
		fclose(fp);
		//#endif
		printLOG(") ");
	}

	delete[]VTscore, delete[]VTscore2;
	delete[] VideoInfo, delete[] P, delete[]allPts, delete[]assocatedPts;

	return 0;
}

int ExtractColorForCorpusCloud(char *Path)
{
	Corpus CorpusInfo;

	int ii, jj, kk, nCameras, nPoints, useColor;
	Point3d xyz;
	Point3i rgb;

	char Fname[512];
	sprintf(Fname, "%s/Corpus/nHCorpus_3D.txt", Path);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/Corpus/nCorpus_3D.txt", Path);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
	}
	FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	fscanf(fp, "%d %d %d", &nCameras, &nPoints, &useColor);
	CorpusInfo.nCameras = nCameras;
	CorpusInfo.n3dPoints = nPoints;
	CorpusInfo.xyz.reserve(nPoints);
	if (useColor)
	{
		CorpusInfo.rgb.reserve(nPoints);
		for (jj = 0; jj < nPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf %d %d %d", &xyz.x, &xyz.y, &xyz.z, &rgb.x, &rgb.y, &rgb.z);
			CorpusInfo.xyz.push_back(xyz);
			CorpusInfo.rgb.push_back(rgb);
		}
	}
	else
	{
		CorpusInfo.rgb.reserve(nPoints);
		for (jj = 0; jj < nPoints; jj++)
		{
			fscanf(fp, "%lf %lf %lf ", &xyz.x, &xyz.y, &xyz.z);
			CorpusInfo.xyz.push_back(xyz);
		}
	}
	fclose(fp);

	CorpusInfo.viewIdAll3D.reserve(nPoints);
	CorpusInfo.uvAll3D.reserve(nPoints);

	int nviews, viewID, npts, pid, totalPts = 0, n3D, id3D;
	vector<int> pointIDs, viewIDs; viewIDs.reserve(nCameras / 10);
	Point2d uv;	vector<Point2d> uvVector; uvVector.reserve(50);
	double scale = 1.0;  vector<double> scaleVector; scaleVector.reserve(2000);

	ifstream fin;
	sprintf(Fname, "%s/Corpus/Corpus_viewIdAll3D.dat", Path), fin.open(Fname, ios::binary);
	for (int jj = 0; jj < nPoints; jj++)
	{
		viewIDs.clear();
		fin.read(reinterpret_cast<char *>(&nviews), sizeof(int));
		for (ii = 0; ii < nviews; ii++)
		{
			fin.read(reinterpret_cast<char *>(&viewID), sizeof(int));
			viewIDs.push_back(viewID);
		}
		CorpusInfo.viewIdAll3D.push_back(viewIDs);
	}
	fin.close();

	sprintf(Fname, "%s/Corpus/Corpus_uvAll3D.dat", Path);  fin.open(Fname, ios::binary);
	for (jj = 0; jj < CorpusInfo.n3dPoints; jj++)
	{
		uvVector.clear(), scaleVector.clear();
		fin.read(reinterpret_cast<char *>(&npts), sizeof(int));
		for (ii = 0; ii < npts; ii++)
		{
			float u, v, s;
			fin.read(reinterpret_cast<char *>(&u), sizeof(int));
			fin.read(reinterpret_cast<char *>(&v), sizeof(int));
			fin.read(reinterpret_cast<char *>(&s), sizeof(int));
			uvVector.push_back(Point2d(u, v)), scaleVector.push_back(s);
		}
		CorpusInfo.uvAll3D.push_back(uvVector);
		CorpusInfo.scaleAll3D.push_back(scaleVector);
	}
	fin.close();

	int per = 5, incre = 5;
	for (int imgId = 0; imgId < CorpusInfo.nCameras; imgId++)
	{
		if (100.0*imgId / CorpusInfo.nCameras >= per)
			printLOG("%d..", per), per += incre;

		sprintf(Fname, "%s/Corpus/%.4d.jpg", Path, imgId);
		Mat img = imread(Fname);
		if (img.empty() == 1)
			continue;

		for (int pid = 0; pid < CorpusInfo.n3dPoints; pid++)
		{
			for (int vid = 0; vid < CorpusInfo.viewIdAll3D[pid].size(); vid++)
			{
				if (CorpusInfo.viewIdAll3D[pid][vid] == imgId)
				{
					int x = (int)CorpusInfo.uvAll3D[pid][vid].x, y = (int)CorpusInfo.uvAll3D[pid][vid].y;

					int id = x + y * img.rows;
					Point3i rgb;
					rgb.z = img.data[3 * id + 0];//b
					rgb.y = img.data[3 * id + 1];//g
					rgb.x = img.data[3 * id + 2];//r
					CorpusInfo.rgb[pid] = rgb;
					break;
				}
			}
		}
	}
	printLOG("\n");

	sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path); fp = fopen(Fname, "w+");
	fprintf(fp, "%d %d 1\n", CorpusInfo.nCameras, CorpusInfo.n3dPoints);
	for (jj = 0; jj < CorpusInfo.xyz.size(); jj++)
		fprintf(fp, "%.8e %.8e %.8e %d %d %d\n", CorpusInfo.xyz[jj].x, CorpusInfo.xyz[jj].y, CorpusInfo.xyz[jj].z, CorpusInfo.rgb[jj].x, CorpusInfo.rgb[jj].y, CorpusInfo.rgb[jj].z); //xyz rgb viewid3D pointid3D 3dId2D cumpoint
	fclose(fp);

	sprintf(Fname, "%s/Corpus/3dGL.xyz", Path); fp = fopen(Fname, "w+");
	for (int ii = 0; ii < CorpusInfo.xyz.size(); ii++)
	{
		if (abs(CorpusInfo.xyz[ii].x) + abs(CorpusInfo.xyz[ii].y) + abs(CorpusInfo.xyz[ii].z) < LIMIT3D)
			continue;
		fprintf(fp, "%d %.8e %.8e %.8e %d %d %d\n", ii, CorpusInfo.xyz[ii].x, CorpusInfo.xyz[ii].y, CorpusInfo.xyz[ii].z, CorpusInfo.rgb[ii].x, CorpusInfo.rgb[ii].y, CorpusInfo.rgb[ii].z);
	}
	fclose(fp);

	return 0;
}
int ReBundleFromDifferentShutterModel(char *Path)
{
	char Fname[512];

	Corpus CorpusInfo;
	sprintf(Fname, "%s/Corpus", Path);
	ReadCorpusInfo(Fname, CorpusInfo, false, false);

	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
	{
		CorpusInfo.camera[ii].threshold = 1000; //make sure that most points are inliers
		CorpusInfo.camera[ii].ShutterModel = 1;
	}

	vector<int>SharedCameraToBuildCorpus, SharedIntrinsicCameras;
	sprintf(Fname, "%s/CamerasWithFixedIntrinsic.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int camID;
		while (fscanf(fp, "%d ", &camID) != EOF)
			SharedIntrinsicCameras.push_back(camID);
		fclose(fp);
	}

	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
		SharedCameraToBuildCorpus.push_back(-1); //first visible camera is the reference camera to build the corpus

	int nDevices = 0;
	if (SharedIntrinsicCameras.size() > 0) //some shares
	{
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int camID, deviceID;
			while (fscanf(fp, "%d %d", &camID, &deviceID) != EOF)
			{
				nDevices = max(nDevices, deviceID);
				bool shared = false;
				for (size_t ii = 0; ii < SharedIntrinsicCameras.size() && !shared; ii++)
					if (SharedIntrinsicCameras[ii] == deviceID)
						shared = true;
				if (shared)
					SharedCameraToBuildCorpus[camID] = deviceID;
			}
			fclose(fp);
		}
	}

	for (int pid = 0; pid < CorpusInfo.scaleAll3D.size(); pid++)
		for (int fid = 0; fid < CorpusInfo.scaleAll3D[pid].size(); fid++)
			CorpusInfo.scaleAll3D[pid][fid] = 1.0;

	int distortionCorrected = 1, nViewsPlus = 2, LossType = 1;
	int fixIntrinsic = 1, fixDistortion = 1, fixPose = 0, fixfirstCamPose = 0, fixLocalPose = 0, fix3D = 0, fixSkew = 1, fixPrism = 1;
	vector<bool>GoodPoints;
	GenericBundleAdjustment(Path, CorpusInfo.camera, CorpusInfo.xyz, CorpusInfo.viewIdAll3D, CorpusInfo.uvAll3D, CorpusInfo.scaleAll3D, SharedCameraToBuildCorpus, CorpusInfo.nCameras,
		fixIntrinsic, fixDistortion, fixPose, fixfirstCamPose, fixLocalPose, fix3D, fixSkew, fixPrism, distortionCorrected, nViewsPlus, LossType, false, false, false);

	printLOG("Write corpus info ....");
	sprintf(Fname, "%s/Corpus/BA_Camera_AllParams_after.txt", Path);
	ReSaveBundleAdjustedNVMResults(Fname, CorpusInfo);

	sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
	fp = fopen(Fname, "w+");
	CorpusInfo.n3dPoints = (int)CorpusInfo.xyz.size();
	fprintf(fp, "%d %d ", CorpusInfo.nCameras, CorpusInfo.n3dPoints);

	//xyz rgb viewid3D pointid3D 3dId2D cumpoint
	if (CorpusInfo.rgb.size() == 0)
	{
		fprintf(fp, "0\n");
		for (int jj = 0; jj < CorpusInfo.xyz.size(); jj++)
			fprintf(fp, "%lf %lf %lf \n", CorpusInfo.xyz[jj].x, CorpusInfo.xyz[jj].y, CorpusInfo.xyz[jj].z);
	}
	else
	{
		fprintf(fp, "1\n");
		for (int jj = 0; jj < CorpusInfo.xyz.size(); jj++)
			fprintf(fp, "%lf %lf %lf %d %d %d\n", CorpusInfo.xyz[jj].x, CorpusInfo.xyz[jj].y, CorpusInfo.xyz[jj].z, CorpusInfo.rgb[jj].x, CorpusInfo.rgb[jj].y, CorpusInfo.rgb[jj].z);
	}
	fclose(fp);

	sprintf(Fname, "%s/Corpus/Corpus_Intrinsics.txt", Path); fp = fopen(Fname, "w+");
	for (int viewID = 0; viewID < CorpusInfo.nCameras; viewID++)
	{
		fprintf(fp, "%d %d %d %d %d ", CorpusInfo.camera[viewID].frameID, CorpusInfo.camera[viewID].LensModel, CorpusInfo.camera[viewID].ShutterModel, CorpusInfo.camera[viewID].width, CorpusInfo.camera[viewID].height);
		for (int ii = 0; ii < 5; ii++)
			fprintf(fp, "%.6f ", CorpusInfo.camera[viewID].intrinsic[ii]);

		if (CorpusInfo.camera[viewID].LensModel == RADIAL_TANGENTIAL_PRISM)
			for (int ii = 0; ii < 7; ii++)
				fprintf(fp, "%.6f ", CorpusInfo.camera[viewID].distortion[ii]);
		else
		{
			for (int ii = 0; ii < 3; ii++)
				fprintf(fp, "%.6f ", CorpusInfo.camera[viewID].distortion[ii]);
		}
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/Corpus/Corpus_Extrinsics.txt", Path); fp = fopen(Fname, "w+");
	for (int viewID = 0; viewID < CorpusInfo.nCameras; viewID++)
	{
		for (int ii = 0; ii < 6; ii++)
			fprintf(fp, "%.16e ", CorpusInfo.camera[viewID].rt[ii]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	sprintf(Fname, "%s/Corpus/Corpus_extendedExtrinsics.txt", Path); fp = fopen(Fname, "w+");
	for (int viewID = 0; viewID < CorpusInfo.nCameras; viewID++)
	{
		for (int ii = 0; ii < 6; ii++)
			fprintf(fp, "%.16e ", CorpusInfo.camera[viewID].wt[ii]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	if (SharedCameraToBuildCorpus.size() > 0)
	{
		SharedCameraToBuildCorpus.clear();
		for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
			SharedCameraToBuildCorpus.push_back(-1); //first visible camera is the reference camera to build the corpus
		sprintf(Fname, "%s/CameraToBuildCorpus.txt", Path); FILE *fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int camID, group;
			while (fscanf(fp, "%d %d", &camID, &group) != EOF)
				SharedCameraToBuildCorpus[camID] = group;
			fclose(fp);
		}
		SaveAvgIntrinsicResults(Path, CorpusInfo.camera, SharedCameraToBuildCorpus);
	}

	vector<int>AvailViews;
	for (int ii = 0; ii < CorpusInfo.nCameras; ii++)
		AvailViews.push_back(ii);

	for (int ii = 0; ii < AvailViews.size(); ii++)
		GetRCGL(CorpusInfo.camera[AvailViews[ii]]);

	sprintf(Fname, "%s/Corpus/DinfoGL.txt", Path);
	fp = fopen(Fname, "w+");
	for (int ii = 0; ii < AvailViews.size(); ii++)
	{
		int viewID = AvailViews.at(ii);
		fprintf(fp, "%d ", viewID);
		if (CorpusInfo.camera[viewID].valid)
		{
			for (int jj = 0; jj < 16; jj++)
				fprintf(fp, "%.16f ", CorpusInfo.camera[viewID].Rgl[jj]);
			for (int jj = 0; jj < 3; jj++)
				fprintf(fp, "%.16f ", CorpusInfo.camera[viewID].camCenter[jj]);
		}
		else
			fprintf(fp, "1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0");
		fprintf(fp, "\n");
	}
	fclose(fp);

	bool hasColor = false;
	if (CorpusInfo.rgb.size() != 0)
		hasColor = true;

	sprintf(Fname, "%s/Corpus/3dGL.xyz", Path);
	fp = fopen(Fname, "w+");
	for (int ii = 0; ii < CorpusInfo.xyz.size(); ii++)
	{
		if (abs(CorpusInfo.xyz[ii].x) + abs(CorpusInfo.xyz[ii].y) + abs(CorpusInfo.xyz[ii].z) < 0.001)
			continue;
		fprintf(fp, "%d %.16f %.16f %.16f ", ii, CorpusInfo.xyz[ii].x, CorpusInfo.xyz[ii].y, CorpusInfo.xyz[ii].z);
		if (hasColor)
			fprintf(fp, "%d %d %d\n", CorpusInfo.rgb[ii].x, CorpusInfo.rgb[ii].y, CorpusInfo.rgb[ii].z);
		else
			fprintf(fp, "\n");
	}
	fclose(fp);

	printLOG("****NOTE: 2d points in Corpus are corrected***\n");

	return 0;
}
int TriangulateSkeleton3DFromCalibSyncedCameras(char *Path, vector<int> &SelectedCams, int startF, int stopF, int increF, int distortionCorrected, int skeletonPointFormat, int nViewsPlus, double Reprojectionthreshold, double detectionThresh, int iterMax, int nMinPointsRanSac)
{
	//set iterMax = 0 to strictly use the provided association
	int nCams = *max_element(SelectedCams.begin(), SelectedCams.end()) + 1;

	double TimeStamp[100], vfps[100];
	for (int ii = 0; ii < nCams; ii++)
		TimeStamp[ii] = 0.0, vfps[ii] = 1.0;

	int selected; double fps;
	char Fname[512];  sprintf(Fname, "%s/FMotionPriorSync.txt", Path);
	FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		double temp;
		for (int ii = 0; ii < nCams; ii++)
		{
			fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp);
			TimeStamp[selected] = temp, vfps[selected] = fps;
		}
		fclose(fp);
	}
	else
	{
		sprintf(Fname, "%s/FGeoSync.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int temp;
			for (int ii = 0; ii < nCams; ii++)
			{
				fscanf(fp, "%d %lf %d ", &selected, &fps, &temp);
				TimeStamp[ii] = (double)temp, vfps[selected] = fps;
			}
			fclose(fp);
		}
		else
		{
			sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				int temp;
				for (int ii = 0; ii < nCams; ii++)
				{
					fscanf(fp, "%d %lf %d ", &selected, &fps, &temp);
					TimeStamp[ii] = (double)temp, vfps[selected] = fps;
				}
				fclose(fp);
			}
			else
				printLOG("Cannot load time stamp info. Assume no frame offsets!");
		}
	}

	int *SkipFrameOffset = new int[nCams];
	for (int ii = 0; ii < nCams; ii++)
		SkipFrameOffset[ii] = 0;
	if (increF != 1)
	{
		int sfo;
		sprintf(Fname, "%s/SkipFrameOffset_%d.txt", Path, increF);	fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			while (fscanf(fp, "%d %d ", &selected, &sfo) != EOF)
				SkipFrameOffset[selected] = sfo;
			fclose(fp);
		}
	}

	int refCid = 0;
	double earliest = DBL_MAX;
	for (int ii = 0; ii < nCams; ii++)
		if (earliest > TimeStamp[ii])
			earliest = TimeStamp[ii], refCid = ii;

	int nMaxPeople = 0;
	vector<vector<Point2i> > *MergedTrackletVec = new vector<vector<Point2i> >[nCams];
	for (auto cid : SelectedCams)
	{
		/*sprintf(Fname, "%s/%d/CleanedMergedTracklets_18_%d_%d.txt", Path, cid, startF, stopF);
		if (!IsFileExist(Fname))
		{
			sprintf(Fname, "%s/%d/CleanedMergedTracklets_%d_%d.txt", Path, cid, startF, stopF);
			if (!IsFileExist(Fname))
			{
				sprintf(Fname, "%s/%d/MergedTracklets_%d_%d.txt", Path, cid, startF, stopF);
				if (!IsFileExist(Fname))
					return 1;
			}
		}
		std::string line, item;
		std::ifstream file(Fname);
		while (std::getline(file, line))
		{
			StringTrim(&line);//remove white space
			if (line.empty())
				break;
			std::stringstream line_stream(line);
			std::getline(line_stream, item, ' ');  //# pairs

			vector<Point2i> jointTrack;
			int fid, did;
			while (!line_stream.eof())
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				fid = atoi(item.c_str());
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				did = atoi(item.c_str());
				jointTrack.push_back(Point2i(fid, did));
			}
			MergedTrackletVec[cid].push_back(jointTrack);
		}
		file.close();*/
		sprintf(Fname, "%s/%d/CleanedMergedTracklets_%d_%d.txt", Path, cid, startF, stopF);
		if (!IsFileExist(Fname))
			return 1;
		std::string line, item;
		std::ifstream file(Fname);
		int pid, fid, did;
		while (std::getline(file, line))
		{
			StringTrim(&line);//remove white space
			if (line.empty())
				break;
			std::stringstream line_stream(line);
			std::getline(line_stream, item, ' ');
			pid = atoi(item.c_str());

			vector<Point2i> jointTrack;
			if (MergedTrackletVec[cid].size() < pid)
			{
				for (int ii = MergedTrackletVec[cid].size(); ii < pid; ii++)
					MergedTrackletVec[cid].push_back(jointTrack);
			}

			std::getline(file, line);
			std::stringstream line_stream_(line);
			while (!line_stream_.eof())
			{
				std::getline(line_stream_, item, ' ');
				StringTrim(&item);
				fid = atoi(item.c_str());
				std::getline(line_stream_, item, ' ');
				StringTrim(&item);
				did = atoi(item.c_str());
				jointTrack.push_back(Point2i(fid, did));
			}
			jointTrack.pop_back();
			MergedTrackletVec[cid].push_back(jointTrack);
		}
		file.close();

		nMaxPeople = max(nMaxPeople, (int)MergedTrackletVec[cid].size());
	}
	nMaxPeople--;//last one is trash category	

	VideoData *VideoInfo = new VideoData[nCams];
	for (auto cid : SelectedCams)
	{
		printLOG("Cam %d ...validating ", cid);
		if (ReadVideoDataI(Path, VideoInfo[cid], cid, -1, -1) == 1)
			continue;
		//InvalidateAbruptCameraPose(VideoInfo[cid], -1, -1, 0);
		printLOG("\n");
	}

	vector<float> *conf = new vector<float>[nCams];
	Point2d *tpts = new Point2d[nCams];
	vector<Point2d> *allPts = new vector<Point2d>[nCams];
	vector<Point2d> *allPts_org = new vector<Point2d>[nCams];

	bool *passTri = new bool[nCams];
	double *allP = new double[12 * nCams], *tallP = new double[12 * nCams];
	double *A = new double[6 * nCams * 2], *B = new double[2 * nCams * 2], *tP = new double[12 * nCams * 2];

	sprintf(Fname, "%s/People", Path), makeDir(Fname);
	sprintf(Fname, "%s/People/@%d", Path, increF), makeDir(Fname);
	for (int pid = 0; pid < nMaxPeople; pid++)
		sprintf(Fname, "%s/People/@%d/%d", Path, increF, pid), makeDir(Fname);
	for (int refFid = startF; refFid <= stopF; refFid += increF)
	{
		printLOG("%d..", refFid);

		vector<int> allCid;
		for (auto cid : SelectedCams)
		{
			allPts[cid].clear(), allPts_org[cid].clear(), conf[cid].clear();
			int localFid = (int)(vfps[refCid] / vfps[cid] * (refFid - TimeStamp[cid]) - SkipFrameOffset[cid] + 0.5);
			localFid = localFid / increF * increF;// ((int)(1.0*localFid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation
			CameraData *camI = VideoInfo[cid].VideoInfo;
			if (camI[localFid].valid != 1)
				continue;

			double u, v, s;
			vector<float> vConf; vector<Point2f> vUV;
			if (readOpenPoseJson(Path, cid, localFid, vUV, vConf) == 1)
			{
				for (int ii = 0; ii < vUV.size(); ii++)
				{
					if (vConf[ii] < detectionThresh)
						allPts[cid].push_back(Point2d(0, 0)), allPts_org[cid].push_back(Point2d(0, 0)), conf[cid].push_back(vConf[ii]);
					else
					{
						Point2d uv(vUV[ii].x, vUV[ii].y);
						allPts_org[cid].push_back(uv);

						if (distortionCorrected == 0 && camI[localFid].LensModel == RADIAL_TANGENTIAL_PRISM)
							LensCorrectionPoint(&uv, camI[localFid].K, camI[localFid].distortion);
						else if (distortionCorrected == 0 && camI[localFid].LensModel == FISHEYE)
							FishEyeCorrectionPoint(&uv, camI[localFid].K, camI[localFid].distortion[0]);

						allPts[cid].push_back(uv), conf[cid].push_back(vConf[ii]);
					}
				}
			}
			else
			{
				sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, localFid); FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				while (fscanf(fp, "%lf %lf %lf ", &u, &v, &s) != EOF)
				{
					if (s < detectionThresh)
						allPts[cid].push_back(Point2d(0, 0)), allPts_org[cid].push_back(Point2d(0, 0));
					else
					{
						Point2d uv(u, v);
						allPts_org[cid].push_back(uv);

						if (distortionCorrected == 0 && camI[localFid].LensModel == RADIAL_TANGENTIAL_PRISM)
							LensCorrectionPoint(&uv, camI[localFid].K, camI[localFid].distortion);
						else if (distortionCorrected == 0 && camI[localFid].LensModel == FISHEYE)
							FishEyeCorrectionPoint(&uv, camI[localFid].K, camI[localFid].distortion[0]);
						allPts[cid].push_back(uv);
					}
					conf[cid].push_back(s);
				}
				fclose(fp);
			}
			AssembleP(camI[localFid].K, camI[localFid].R, camI[localFid].T, camI[localFid].P);
		}

		//recon individual person
		for (int pid = 0; pid < nMaxPeople; pid++)
		{
			vector<Point2i> vCid_Did;
			for (auto cid : SelectedCams) //search for his id in the detection
			{
				if (MergedTrackletVec[cid].size() <= pid)
					continue;
				int localFid = (int)(vfps[refCid] / vfps[cid] * (refFid - TimeStamp[cid]) - SkipFrameOffset[cid] + 0.5);
				localFid = localFid / increF * increF;// ((int)(1.0*localFid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation
				for (int jj = 0; jj < (int)MergedTrackletVec[cid][pid].size(); jj++)
					if (MergedTrackletVec[cid][pid][jj].x == localFid) //found
						vCid_Did.push_back(Point2i(cid, MergedTrackletVec[cid][pid][jj].y));
			}

			//recon per-joint
			Point3d *Vxyz = new Point3d[skeletonPointFormat];
			sprintf(Fname, "%s/People/@%d/%d/%.4d.txt", Path, increF, pid, refFid); FILE *fp = fopen(Fname, "w");
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				int count = 0;
				vector<int> VvalidJoints;
				for (int ii = 0; ii < vCid_Did.size(); ii++)
				{
					int cid = vCid_Did[ii].x, localFid = (int)(vfps[refCid] / vfps[cid] * (refFid - TimeStamp[cid]) - SkipFrameOffset[cid] + 0.5), did = vCid_Did[ii].y;
					localFid = localFid / increF * increF;// ((int)(1.0*localFid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation
					CameraData *camI = VideoInfo[cid].VideoInfo;
					if (camI[localFid].valid != 1)
						continue;

					vector<Point2d> *pts = &allPts[cid];
					if (conf[cid][did*skeletonPointFormat + jid] > detectionThresh)
					{
						tpts[count] = pts[0][did*skeletonPointFormat + jid];

						if (camI[localFid].ShutterModel == GLOBAL_SHUTTER)
							for (int kk = 0; kk < 12; kk++)
								tallP[count * 12 + kk] = camI[localFid].P[kk];
						else if (camI[localFid].ShutterModel == ROLLING_SHUTTER)
							AssembleP_RS(tpts[count], camI[localFid].K, camI[localFid].R, camI[localFid].T, camI[localFid].wt, tallP + 12 * count);

						count++;
						VvalidJoints.push_back(ii);
					}
				}

				if (count < 2)
				{
					fprintf(fp, "%f %f %f 999.999 %d\n", Vxyz[jid].x, Vxyz[jid].y, Vxyz[jid].z, vCid_Did.size());
					for (int ii = 0; ii < vCid_Did.size(); ii++)
					{
						int cid = vCid_Did[ii].x, localFid = (int)(vfps[refCid] / vfps[cid] * (refFid - TimeStamp[cid]) - SkipFrameOffset[cid] + 0.5), did = vCid_Did[ii].y;
						localFid = localFid / increF * increF;// ((int)(1.0*localFid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation
						CameraData *camI = VideoInfo[cid].VideoInfo;

						if (camI[localFid].valid != 1 || conf[cid][did*skeletonPointFormat + jid] < detectionThresh)
							fprintf(fp, "%d %d 0.0 0.0 0.0 0 ", cid, localFid);
						else
						{
							Point2d uv = allPts_org[cid][did*skeletonPointFormat + jid];
							fprintf(fp, "%d %d %.2f %.2f %.2f 0 ", cid, localFid, uv.x, uv.y, conf[cid][did*skeletonPointFormat + jid]);
						}
					}
					fprintf(fp, "\n");
					continue;
				}

				vector<int> Inliers[1];
				double finalerror;
				if (iterMax > 0)
				{
					if (count < nMinPointsRanSac)
					{
						NviewTriangulation(tpts, tallP, &Vxyz[jid], count, 1, NULL, NULL, NULL);
						NviewTriangulationNonLinear(tallP, tpts, &Vxyz[jid], &finalerror, count, 1);
						for (int ii = 0; ii < count; ii++)
							Inliers[0].push_back(1);
					}
					else
						finalerror = NviewTriangulationRANSAC(tpts, tallP, &Vxyz[jid], passTri, Inliers, count, 1, nMinPointsRanSac, iterMax, 0.4, Reprojectionthreshold, A, B, tP, true, true);
				}
				else
				{
					NviewTriangulation(tpts, tallP, &Vxyz[jid], count, 1, NULL, NULL, NULL);
					NviewTriangulationNonLinear(tallP, tpts, &Vxyz[jid], &finalerror, count, 1);
					for (int ii = 0; ii < count; ii++)
						Inliers[0].push_back(1);
				}

				if (finalerror < Reprojectionthreshold)
					fprintf(fp, "%f %f %f %.2f %d\n", Vxyz[jid].x, Vxyz[jid].y, Vxyz[jid].z, finalerror, VvalidJoints.size());
				else
					fprintf(fp, "0.0 0.0 0.0 %.2f %d\n", finalerror, VvalidJoints.size());
				for (int ii = 0; ii < VvalidJoints.size(); ii++)
				{
					int cid = vCid_Did[VvalidJoints[ii]].x, localFid = (int)(vfps[refCid] / vfps[cid] * (refFid - TimeStamp[cid]) - SkipFrameOffset[cid] + 0.5), did = vCid_Did[VvalidJoints[ii]].y;
					localFid = localFid / increF * increF;// ((int)(1.0*localFid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation
					CameraData *camI = VideoInfo[cid].VideoInfo;
					if (camI[localFid].valid != 1 || conf[cid][did*skeletonPointFormat + jid] < detectionThresh)
						fprintf(fp, "%d %d 0.0 0.0 0.0 0 ", cid, localFid);
					else
					{
						Point2d uv = allPts_org[cid][did*skeletonPointFormat + jid];
						if (finalerror < Reprojectionthreshold)
							fprintf(fp, "%d %d %.3f %.3f %.2f %d ", cid, localFid, uv.x, uv.y, conf[cid][did*skeletonPointFormat + jid], Inliers[0][ii]);
						else
							fprintf(fp, "%d %d %.3f %.3f %.2f 0 ", cid, localFid, uv.x, uv.y, conf[cid][did*skeletonPointFormat + jid]);
					}
				}
				fprintf(fp, "\n");
			}
			fclose(fp);

			delete[]Vxyz;
		}
	}

	delete[] VideoInfo, delete[] tallP, delete[]tpts, delete[]allPts, delete[]allPts_org;

	return 0;
}
int WindowSkeleton3DBundleAdjustment(char *Path, int nCams, int startF, int stopF, int increF, int distortionCorrected, int skeletonPointFormat, double detectionThresh, int LossType, double *Weights, double *iSigma, double real2SfM)
{
	printLOG("*****************WindowSkeleton3DBundleAdjustment*****************\n");
	//Weight = [ const limb length, symmetric skeleton, temporal]. It is  helpful for insightful weight setting if metric unit (mm) is used
	double sigma_i2D = iSigma[0], sigma_iL = iSigma[1] * real2SfM, sigma_iVel = iSigma[2] * real2SfM, sigma_iVel2 = iSigma[3] * real2SfM; //also convert physical sigma to sfm scale sigma

	char Fname[512];

	const double ialpha = 1.0 / 60.0; //1/fps

	int nLimbConnections, nSymLimbConnectionID;
	Point2i *LimbConnectionID = NULL;
	Vec4i *SymLimbConnectionID = NULL;
	if (skeletonPointFormat == 18)
	{
		nLimbConnections = 17, nSymLimbConnectionID = 6;
		LimbConnectionID = new Point2i[nLimbConnections];
		SymLimbConnectionID = new Vec4i[nSymLimbConnectionID];
		Point2i _LimbConnectionID[] = { Point2i(0, 1), Point2i(1, 2), Point2i(2, 3), Point2i(3, 4), Point2i(1, 5), Point2i(5, 6), Point2i(6, 7),
			Point2i(1, 8), Point2i(8, 9), Point2i(9, 10), Point2i(1, 11), Point2i(11, 12), Point2i(12, 13), Point2i(0, 14), Point2i(0, 15), Point2i(14, 16), Point2i(15, 17) };
		Vec4i _SymLimbConnectionID[] = { Vec4i(1, 2, 1, 5), Vec4i(2, 3, 5, 6), Vec4i(3, 4, 6, 7), Vec4i(1, 8, 1, 11), Vec4i(8, 9, 11, 12), Vec4i(9, 10, 12, 13) }; //no eyes, ears since they are unreliable
		for (int ii = 0; ii < nLimbConnections; ii++)
			LimbConnectionID[ii] = _LimbConnectionID[ii];
		for (int ii = 0; ii < nLimbConnections; ii++)
			SymLimbConnectionID[ii] = _SymLimbConnectionID[ii];
	}
	else if (skeletonPointFormat == 25)
	{
		nLimbConnections = 32, nSymLimbConnectionID = 18;
		LimbConnectionID = new Point2i[nLimbConnections];
		SymLimbConnectionID = new Vec4i[nSymLimbConnectionID];
		Point2i _LimbConnectionID[] = { Point2i(0, 1), Point2i(1, 2), Point2i(2, 3), Point2i(3, 4), Point2i(1, 5), Point2i(5, 6), Point2i(6, 7),
			Point2i(1, 8), Point2i(8,9),Point2i(9, 10),Point2i(10,11),Point2i(8,12),Point2i(12,13),Point2i(13,14),Point2i(0,15),Point2i(15,17),Point2i(0,16),Point2i(17,18), Point2i(1,9),Point2i(1,12),
			Point2i(11,22),Point2i(11,23),Point2i(11,24),Point2i(22,23),Point2i(22,24),Point2i(23,24),
			Point2i(14,19),Point2i(14,20),Point2i(14,21),Point2i(19,20),Point2i(19,21),Point2i(13,20) };
		Vec4i _SymLimbConnectionID[] = { Vec4i(1, 2, 1, 5), Vec4i(2, 3, 5, 6), Vec4i(3, 4, 6, 7),
			Vec4i(8,9,8,12), Vec4i(1, 9, 1, 12), Vec4i(9,10, 12, 13), Vec4i(10, 11, 13, 14), Vec4i(1, 9, 1, 12),
			Vec4i(22,23,19,20), Vec4i(23,24,20,14), Vec4i(22,24,19,21), Vec4i(11, 22, 14, 19),Vec4i(11, 23, 14, 20),Vec4i(11, 24, 14, 21),
			Vec4i(0,15, 0,16), Vec4i(15,17,16,18) ,Vec4i(0,17, 0,18), Vec4i(15,18,16,17) };
		for (int ii = 0; ii < nLimbConnections; ii++)
			LimbConnectionID[ii] = _LimbConnectionID[ii];
		for (int ii = 0; ii < nLimbConnections; ii++)
			SymLimbConnectionID[ii] = _SymLimbConnectionID[ii];
	}

	double TimeStamp[100], vifps[100], mean_ifps = 0;
	for (int ii = 0; ii < nCams; ii++)
		TimeStamp[ii] = 0.0, vifps[ii] = 1.0;

	int selected; double fps;
	sprintf(Fname, "%s/FMotionPriorSync.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		double temp;
		for (int ii = 0; ii < nCams; ii++)
		{
			fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp);
			TimeStamp[selected] = temp, vifps[selected] = 1.0 / fps;
			mean_ifps += vifps[selected];
		}
		fclose(fp);
	}
	else
	{
		sprintf(Fname, "%s/FGeoSync.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			double temp;
			for (int ii = 0; ii < nCams; ii++)
			{
				fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp);
				TimeStamp[ii] = temp, vifps[selected] = 1.0 / fps;
				mean_ifps += vifps[selected];
			}
			fclose(fp);
		}
		else
		{
			sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				int temp;
				for (int ii = 0; ii < nCams; ii++)
				{
					fscanf(fp, "%d %lf %d ", &selected, &fps, &temp);
					TimeStamp[ii] = (double)temp, vifps[selected] = 1.0 / fps;
					mean_ifps += vifps[selected];
				}
				fclose(fp);
			}
			else
				printLOG("Cannot load time stamp info. Assume no frame offsets!");
		}
	}
	mean_ifps = mean_ifps / nCams;

	int *SkipFrameOffset = new int[nCams];
	for (int ii = 0; ii < nCams; ii++)
		SkipFrameOffset[ii] = 0;
	if (increF != 1)
	{
		int sfo;
		sprintf(Fname, "%s/SkipFrameOffset_%d.txt", Path, increF);	fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			while (fscanf(fp, "%d %d ", &selected, &sfo) != EOF)
				SkipFrameOffset[selected] = sfo;
			fclose(fp);
		}
	}

	int refCid = 0;
	double earliest = DBL_MAX;
	for (int ii = 0; ii < nCams; ii++)
		if (earliest > TimeStamp[ii])
			earliest = TimeStamp[ii], refCid = ii;

	printLOG("Reading all camera poses\n");
	VideoData *VideoInfo = new VideoData[nCams];
	for (int cid = 0; cid < nCams; cid++)
	{
		if (ReadVideoDataI(Path, VideoInfo[cid], cid, -1, -1) == 1)
			continue;
		//InvalidateAbruptCameraPose(VideoInfo[cid], -1, -1, 0);
	}

	double u, v, s, avg_error;
	ceres::LossFunction *loss_funcion = 0;
	if (LossType == 1) //Huber
		loss_funcion = new ceres::HuberLoss(1.0);

	double residuals[3], rho[3];
	int cid, personId = 0;
	while (true)
	{
		printLOG("Person #%d\n", personId);
		printLOG("Invalid frames: ");
		int nvalidFrames = 0;
		vector<double> *vlimblength = new vector<double>[nLimbConnections];
		double *LimbLength = new double[nLimbConnections];
		HumanSkeleton3D *Skeletons = new HumanSkeleton3D[(stopF - startF) / increF + 1];
		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int nvis, nValidJoints = 0, tempFid = (refFid - startF) / increF;
			sprintf(Fname, "%s/People/@%d/%d/%.4d.txt", Path, increF, personId, refFid); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				int pid, nvis, rfid, inlier, dummy; float fdummy;
				for (int jid = 0; jid < skeletonPointFormat; jid++)
				{
					fscanf(fp, "%lf %lf %lf %lf %d ", &Skeletons[tempFid].pt3d[jid].x, &Skeletons[tempFid].pt3d[jid].y, &Skeletons[tempFid].pt3d[jid].z, &avg_error, &nvis);
					for (int kk = 0; kk < nvis; kk++)
					{
						fscanf(fp, "%d %d %lf %lf %lf %d ", &cid, &rfid, &u, &v, &s, &inlier);
						if (!VideoInfo[cid].VideoInfo[rfid].valid)
							continue;

						Skeletons[tempFid].vViewID_rFid[jid].push_back(Point2i(cid, rfid));
						Skeletons[tempFid].vPt2D[jid].push_back(Point2d(u, v));
						Skeletons[tempFid].vConf[jid].push_back(s);
						Skeletons[tempFid].vInlier[jid].push_back(inlier);

						if (distortionCorrected == 0 && VideoInfo[cid].VideoInfo[rfid].LensModel == RADIAL_TANGENTIAL_PRISM)
							LensCorrectionPoint(&Skeletons[tempFid].vPt2D[jid].back(), VideoInfo[cid].VideoInfo[rfid].K, VideoInfo[cid].VideoInfo[rfid].distortion);
						else if (distortionCorrected == 0 && VideoInfo[cid].VideoInfo[rfid].LensModel == FISHEYE)
							FishEyeCorrectionPoint(&Skeletons[tempFid].vPt2D[jid].back(), VideoInfo[cid].VideoInfo[rfid].K, VideoInfo[cid].VideoInfo[rfid].distortion[0]);
					}

					if (IsValid3D(Skeletons[tempFid].pt3d[jid]))
						Skeletons[tempFid].validJoints[jid] = 1, nValidJoints++;
					else
						Skeletons[tempFid].validJoints[jid] = 0;
				}
				fclose(fp);

				if (nValidJoints == 0)
					printLOG("%d..", refFid);

				for (int cid = 0; cid < nLimbConnections; cid++)
				{
					int j0 = LimbConnectionID[cid].x, j1 = LimbConnectionID[cid].y;
					if (Skeletons[tempFid].validJoints[j0] > 0 && Skeletons[tempFid].validJoints[j1] > 0)
						vlimblength[cid].push_back(norm(Skeletons[tempFid].pt3d[j0] - Skeletons[tempFid].pt3d[j1]));
				}
				nvalidFrames++;
			}
		}
		if (nvalidFrames == 0)
		{
			printLOG("\n");
			break;
		}

		//now, dig into the invalid frames
		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int  tempFid = (refFid - startF) / increF;
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				if (!Skeletons[tempFid].validJoints[jid])
				{
					int minDist = 9e9, minFrame = -1;
					for (int refFid2 = startF; refFid2 <= stopF; refFid2 += increF)
					{
						int  tempFid2 = (refFid2 - startF) / increF;
						if (Skeletons[tempFid2].validJoints[jid])
						{
							int Dist = abs(refFid2 - refFid);
							if (Dist < minDist)
								minDist = Dist, minFrame = tempFid2;
						}
					}
					if (minFrame != -1)
					{
						Skeletons[tempFid].validJoints[jid] = 2;
						Skeletons[tempFid].pt3d[jid] = Skeletons[minFrame].pt3d[jid];
					}
				}
			}
		}
		printLOG("\nSet up window BA\n");
		ceres::Problem problem;

		for (int cid = 0; cid < nLimbConnections; cid++)
		{
			if (vlimblength[cid].size() == 0)
				LimbLength[cid] = 0.0;
			else
				LimbLength[cid] = MedianArray(vlimblength[cid]);
		}

		vector<double> VreprojectionError, VUnNormedReprojectionErrorX, VUnNormedReprojectionErrorY, VconstLimbError, VsymLimbError, VtemporalError;

		int nvalidPoints1 = 0, nvalidPoints2 = 0, nvalidPoints3 = 0, nvalidPoints4 = 0;
		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];

			//reprojection error
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				if (Body0[0].validJoints[jid] > 0)
				{
					if (Body0[0].validJoints[jid] == 2)
						int a = 0;
					for (int ii = 0; ii < (int)Body0[0].vConf[jid].size(); ii++)
					{
						int cid = Body0[0].vViewID_rFid[jid][ii].x, rfid = Body0[0].vViewID_rFid[jid][ii].y;
						CameraData *camI = VideoInfo[cid].VideoInfo;
						if (camI[rfid].valid != 1)
							continue;

						Point2d uv = Body0[0].vPt2D[jid][ii]; //has been corrected before
						if (Body0[0].vConf[jid][ii] < detectionThresh || uv.x < 1 || uv.y < 1 || (Body0[0].validJoints[jid] != 2 && Body0[0].vInlier[jid][ii] == 0))
							continue;
						nvalidPoints1++;
					}
				}
			}

			//constant limb length
			for (int cid = 0; cid < nLimbConnections; cid++)
			{
				int j0 = LimbConnectionID[cid].x, j1 = LimbConnectionID[cid].y;
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0)
					nvalidPoints2++;
			}

			//symmetry limb
			for (int cid = 0; cid < nSymLimbConnectionID; cid++)
			{
				int j0 = SymLimbConnectionID[cid](0), j1 = SymLimbConnectionID[cid](1), j0_ = SymLimbConnectionID[cid](2), j1_ = SymLimbConnectionID[cid](3);
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0 && Body0[0].validJoints[j0_] > 0 && Body0[0].validJoints[j1_] > 0)
					nvalidPoints3++;
			}
		}
		for (int refFid = startF; refFid <= stopF - increF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];
			HumanSkeleton3D *Body1 = &Skeletons[tempFid + 1];

			for (int jid = 0; jid < skeletonPointFormat; jid++)
				if (Body0[0].validJoints[jid] > 0 && Body1[0].validJoints[jid] > 0) //temporal smoothing
					nvalidPoints4++;
		}

		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];

			//reprojection error
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				if (Body0[0].validJoints[jid] > 0)
				{
					for (int ii = 0; ii < (int)Body0[0].vConf[jid].size(); ii++)
					{
						int cid = Body0[0].vViewID_rFid[jid][ii].x, rfid = Body0[0].vViewID_rFid[jid][ii].y;
						CameraData *camI = VideoInfo[cid].VideoInfo;
						if (camI[rfid].valid != 1)
							continue;

						Point2d uv = Body0[0].vPt2D[jid][ii]; //has been corrected before
						if (Body0[0].vConf[jid][ii] < detectionThresh || uv.x < 1 || uv.y < 1 || (Body0[0].validJoints[jid] != 2 && Body0[0].vInlier[jid][ii] == 0))
							continue;

						double w = Weights[0] * Body0[0].vConf[jid][ii] / (0.001 + nvalidPoints1);
						ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
						ceres::CostFunction* cost_function = PinholeReprojectionErrorSimple_PointOnly::Create(camI[rfid].P, uv.x, uv.y, sigma_i2D);
						problem.AddResidualBlock(cost_function, ScaleLoss, &Body0[0].pt3d[jid].x);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[jid].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						double loss = residuals[1] * residuals[1] + residuals[1] * residuals[1];
						ScaleLoss->Evaluate(loss, rho);

						VreprojectionError.push_back(w*0.5*rho[0]);
						VUnNormedReprojectionErrorX.push_back(residuals[0] / sigma_i2D), VUnNormedReprojectionErrorY.push_back(residuals[1] / sigma_i2D);
					}
				}
			}

			//constant limb length
			for (int cid = 0; cid < nLimbConnections; cid++)
			{
				int j0 = LimbConnectionID[cid].x, j1 = LimbConnectionID[cid].y;
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0)
				{
					double w = Weights[1] / (0.001 + nvalidPoints2);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					ceres::CostFunction* cost_function = ConstantLimbLengthCost3DCeres2::CreateAutoDiff(sigma_iL);
					problem.AddResidualBlock(cost_function, ScaleLoss, &LimbLength[cid], &Body0[0].pt3d[j0].x, &Body0[0].pt3d[j1].x);

					vector<double *> paras; paras.push_back(&LimbLength[cid]), paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
					VconstLimbError.push_back(rho[0]);
				}
			}

			//symmetry limb
			for (int cid = 0; cid < nSymLimbConnectionID; cid++)
			{
				int j0 = SymLimbConnectionID[cid](0), j1 = SymLimbConnectionID[cid](1), j0_ = SymLimbConnectionID[cid](2), j1_ = SymLimbConnectionID[cid](3);
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0 && Body0[0].validJoints[j0_] > 0 && Body0[0].validJoints[j1_] > 0)
				{
					double w = Weights[2] / (0001 + nvalidPoints3);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					if (j0 == j0_)
					{
						ceres::CostFunction* cost_function = SymLimbLengthCost3DCeres2::CreateAutoDiff(sigma_iL);
						problem.AddResidualBlock(cost_function, ScaleLoss, &Body0[0].pt3d[j0].x, &Body0[0].pt3d[j1].x, &Body0[0].pt3d[j1_].x);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x), paras.push_back(&Body0[0].pt3d[j1_].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
						VsymLimbError.push_back(rho[0]);
					}
					else
					{
						ceres::CostFunction* cost_function = SymLimbLengthCost3DCeres::CreateAutoDiff(sigma_iL);
						problem.AddResidualBlock(cost_function, ScaleLoss, &Body0[0].pt3d[j0].x, &Body0[0].pt3d[j1].x, &Body0[0].pt3d[j0_].x, &Body0[0].pt3d[j1_].x);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x), paras.push_back(&Body0[0].pt3d[j0_].x), paras.push_back(&Body0[0].pt3d[j1_].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
						VsymLimbError.push_back(rho[0]);
					}
				}
			}
		}

		//temporal
		for (int refFid = startF; refFid <= stopF - increF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];
			HumanSkeleton3D *Body1 = &Skeletons[tempFid + 1];

			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				double actingSigma = sigma_iVel;
				if (skeletonPointFormat == 18 && (jid == 4 || jid == 7 || jid == 10 || jid == 13)) //18 joint format
					actingSigma = sigma_iVel2;
				else if (skeletonPointFormat == 25 && (jid == 4 || jid == 7 || jid == 11 || jid == 14 || jid == 19 || jid == 20 || jid == 21 || jid == 22 || jid == 23 || jid == 24))//25 joint format
					actingSigma = sigma_iVel2;

				if (Body0[0].validJoints[jid] > 0 && Body1[0].validJoints[jid] > 0) //temporal smoothing
				{
					double ifps1 = mean_ifps, ifps2 = mean_ifps;
					if (Body0[0].vViewID_rFid[jid].size() > 0)
					{
						int cid1 = Body0[0].vViewID_rFid[jid][0].x;
						ifps1 = vifps[cid1];
					}
					if (Body1[0].vViewID_rFid[jid].size() > 0)
					{
						int cid2 = Body1[0].vViewID_rFid[jid][0].x;
						ifps2 = vifps[cid2];
					}

					double w = Weights[3] / (0.001 + nvalidPoints4);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					ceres::CostFunction* cost_function = LeastMotionPriorCost3DCeres2::CreateAutoDiff(ifps1 * refFid, ifps2 * (refFid + 1), actingSigma);
					problem.AddResidualBlock(cost_function, ScaleLoss, &Body0[0].pt3d[jid].x, &Body1[0].pt3d[jid].x);

					vector<double *> paras; paras.push_back(&Body0[0].pt3d[jid].x), paras.push_back(&Body1[0].pt3d[jid].x);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
					VtemporalError.push_back(rho[0]);
				}
			}
		}

		double 	repro = sqrt(MeanArray(VreprojectionError)),
			unNormedReproX = MeanArray(VUnNormedReprojectionErrorX),
			unNormedReproY = MeanArray(VUnNormedReprojectionErrorY),
			stdUnNormedReproX = sqrt(VarianceArray(VUnNormedReprojectionErrorX, unNormedReproX)),
			stdUnNormedReproY = sqrt(VarianceArray(VUnNormedReprojectionErrorY, unNormedReproY)),
			cLimb = sqrt(MeanArray(VconstLimbError)) / sigma_iL * real2SfM,
			sSkele = sqrt(MeanArray(VsymLimbError)) / sigma_iL * real2SfM,
			motionCo = sqrt(MeanArray(VtemporalError)) / sigma_iVel * real2SfM;
		printLOG("Error before: [NormReprojection, MeanUnNormedRprojection, StdUnNormedRprojection, constLimbLength, symSkeleton, temporal coherent] = [%.3e, (%.3f %.3f) (%.3f %.3f) %.3f, %.3f, %.3f]\n", repro, unNormedReproX, unNormedReproY, stdUnNormedReproX, stdUnNormedReproY, cLimb, sSkele, motionCo);

		ceres::Solver::Options options;
		options.num_threads = omp_get_max_threads(); //jacobian eval
		options.num_linear_solver_threads = omp_get_max_threads(); //linear solver
		options.trust_region_strategy_type = ceres::LEVENBERG_MARQUARDT;
		options.linear_solver_type = ceres::SPARSE_NORMAL_CHOLESKY;
		//options.preconditioner_type = ceres::JACOBI;
		options.use_nonmonotonic_steps = false;
		options.max_num_iterations = 50;
		options.minimizer_progress_to_stdout = true;

		ceres::Solver::Summary summary;
		ceres::Solve(options, &problem, &summary);
		std::cout << summary.BriefReport() << "\n";
		summary.final_cost;

		VreprojectionError.clear(), VconstLimbError.clear(), VsymLimbError.clear(), VtemporalError.clear();
		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];

			//reprojection error
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				if (Body0[0].validJoints[jid] > 0)
				{
					if (Body0[0].validJoints[jid] == 2)
						int a = 0;
					for (int ii = 0; ii < (int)Body0[0].vConf[jid].size(); ii++)
					{
						int cid = Body0[0].vViewID_rFid[jid][ii].x, rfid = Body0[0].vViewID_rFid[jid][ii].y;
						CameraData *camI = VideoInfo[cid].VideoInfo;
						if (camI[rfid].valid != 1)
							continue;

						Point2d uv = Body0[0].vPt2D[jid][ii];
						if (Body0[0].vConf[jid][ii] < detectionThresh || uv.x < 1 || uv.y < 1 || (Body0[0].validJoints[jid] != 2 && Body0[0].vInlier[jid][ii] == 0))
							continue;

						double w = Weights[0] * Body0[0].vConf[jid][ii] / (0.001 + nvalidPoints1);
						ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
						ceres::CostFunction* cost_function = PinholeReprojectionErrorSimple_PointOnly::Create(camI[rfid].P, uv.x, uv.y, sigma_i2D);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[jid].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						double loss = residuals[1] * residuals[1] + residuals[1] * residuals[1];
						ScaleLoss->Evaluate(loss, rho);

						VreprojectionError.push_back(w*0.5*rho[0]);
						VUnNormedReprojectionErrorX.push_back(residuals[0] / sigma_i2D), VUnNormedReprojectionErrorY.push_back(residuals[1] / sigma_i2D);
					}
				}
			}

			//constant limb length
			for (int cid = 0; cid < nLimbConnections; cid++)
			{
				int j0 = LimbConnectionID[cid].x, j1 = LimbConnectionID[cid].y;
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0)
				{
					double w = Weights[1] / (0.001 + nvalidPoints2);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					ceres::CostFunction* cost_function = ConstantLimbLengthCost3DCeres2::CreateAutoDiff(sigma_iL);

					vector<double *> paras; paras.push_back(&LimbLength[cid]), paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
					VconstLimbError.push_back(rho[0]);
				}
			}

			//symmetry limb
			for (int cid = 0; cid < nSymLimbConnectionID; cid++)
			{
				int j0 = SymLimbConnectionID[cid](0), j1 = SymLimbConnectionID[cid](1), j0_ = SymLimbConnectionID[cid](2), j1_ = SymLimbConnectionID[cid](3);
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0 && Body0[0].validJoints[j0_] > 0 && Body0[0].validJoints[j1_] > 0)
				{
					double w = Weights[2] / (0001 + nvalidPoints3);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					if (j0 == j0_)
					{
						ceres::CostFunction* cost_function = SymLimbLengthCost3DCeres2::CreateAutoDiff(sigma_iL);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x), paras.push_back(&Body0[0].pt3d[j1_].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
						VsymLimbError.push_back(rho[0]);
					}
					else
					{
						ceres::CostFunction* cost_function = SymLimbLengthCost3DCeres::CreateAutoDiff(sigma_iL);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x), paras.push_back(&Body0[0].pt3d[j0_].x), paras.push_back(&Body0[0].pt3d[j1_].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
						VsymLimbError.push_back(rho[0]);
					}
				}
			}
		}

		//temporal
		for (int refFid = startF; refFid <= stopF - increF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];
			HumanSkeleton3D *Body1 = &Skeletons[tempFid + 1];

			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				double actingSigma = sigma_iVel;
				if (skeletonPointFormat == 18 && (jid == 4 || jid == 7 || jid == 10 || jid == 13)) //18 joint format
					actingSigma = sigma_iVel2;
				else if (skeletonPointFormat == 25 && (jid == 4 || jid == 7 || jid == 11 || jid == 14 || jid == 19 || jid == 20 || jid == 21 || jid == 22 || jid == 23 || jid == 24)) //25 joint format
					actingSigma = sigma_iVel2;

				if (Body0[0].validJoints[jid] > 0 && Body1[0].validJoints[jid] > 0) //temporal smoothing
				{
					double ifps1 = mean_ifps, ifps2 = mean_ifps;
					if (Body0[0].vViewID_rFid[jid].size() > 0)
					{
						int cid1 = Body0[0].vViewID_rFid[jid][0].x;
						ifps1 = vifps[cid1];
					}
					if (Body1[0].vViewID_rFid[jid].size() > 0)
					{
						int cid2 = Body1[0].vViewID_rFid[jid][0].x;
						ifps2 = vifps[cid2];
					}

					double w = Weights[3] / (0.001 + nvalidPoints4);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					ceres::CostFunction* cost_function = LeastMotionPriorCost3DCeres2::CreateAutoDiff(ifps1 * refFid, ifps2 * (refFid + 1), actingSigma);

					vector<double *> paras; paras.push_back(&Body0[0].pt3d[jid].x), paras.push_back(&Body1[0].pt3d[jid].x);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
					VtemporalError.push_back(rho[0]);
				}
			}
		}

		repro = sqrt(MeanArray(VreprojectionError)),
			unNormedReproX = MeanArray(VUnNormedReprojectionErrorX),
			unNormedReproY = MeanArray(VUnNormedReprojectionErrorY),
			stdUnNormedReproX = sqrt(VarianceArray(VUnNormedReprojectionErrorX, unNormedReproX)),
			stdUnNormedReproY = sqrt(VarianceArray(VUnNormedReprojectionErrorY, unNormedReproY)),
			cLimb = sqrt(MeanArray(VconstLimbError)) / sigma_iL * real2SfM,
			sSkele = sqrt(MeanArray(VsymLimbError)) / sigma_iL * real2SfM,
			motionCo = sqrt(MeanArray(VtemporalError)) / sigma_iVel * real2SfM;
		printLOG("Error after: [NormReprojection, MeanUnNormedRprojection, StdUnNormedRprojection, constLimbLength, symSkeleton, temporal coherent] = [%.3e, (%.3f %.3f) (%.3f %.3f) %.3f, %.3f, %.3f]\n", repro, unNormedReproX, unNormedReproY, stdUnNormedReproX, stdUnNormedReproY, cLimb, sSkele, motionCo);


		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body = &Skeletons[tempFid];
			sprintf(Fname, "%s/People/@%d/%d/m_%.4d.txt", Path, increF, personId, refFid); fp = fopen(Fname, "w");
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				fprintf(fp, "%f %f %f %.2f %d\n", Body[0].pt3d[jid].x, Body[0].pt3d[jid].y, Body[0].pt3d[jid].z, sqrt(MeanArray(VreprojectionError)), (int)Body[0].vViewID_rFid[jid].size());
				for (int ii = 0; ii < Body[0].vViewID_rFid[jid].size(); ii++)
				{
					int cid = Body[0].vViewID_rFid[jid][ii].x, rfid = Body[0].vViewID_rFid[jid][ii].y;
					if (distortionCorrected == 0 && VideoInfo[cid].VideoInfo[rfid].LensModel == RADIAL_TANGENTIAL_PRISM)
						LensDistortionPoint(&Body[0].vPt2D[jid][ii], VideoInfo[cid].VideoInfo[rfid].K, VideoInfo[cid].VideoInfo[rfid].distortion);
					else if (distortionCorrected == 0 && VideoInfo[cid].VideoInfo[rfid].LensModel == FISHEYE)
						FishEyeDistortionPoint(&Body[0].vPt2D[jid][ii], VideoInfo[cid].VideoInfo[rfid].K, VideoInfo[cid].VideoInfo[rfid].distortion[0]);

					fprintf(fp, "%d %d %.3f %.3f %.2f %d ", cid, rfid, Body[0].vPt2D[jid][ii].x, Body[0].vPt2D[jid][ii].y, Body[0].vConf[jid][ii], Body[0].vInlier[jid][ii]);
				}
				fprintf(fp, "\n");
			}
			fclose(fp);
		}

		personId++;
		delete[]LimbLength, delete[]Skeletons;
	}

	return 0;
}
int TriangulateSkeleton3DFromCalibSyncedCameras_DensePose(char *Path, std::vector<char*> SelectedCamNames, int SeqId, std::vector<int> &CamIdsPerSeq, vector<int> &SelectedCams, int startF, int stopF, int increF, int distortionCorrected, int skeletonPointFormat, int nViewsPlus, double Reprojectionthreshold, double detectionThresh, int iterMax, int nMinPointsRanSac)
{
	//set iterMax = 0 to strictly use the provided association
	int nCams = *max_element(SelectedCams.begin(), SelectedCams.end()) + 1;

	double TimeStamp[100], vfps[100];
	for (int ii = 0; ii < nCams; ii++)
		TimeStamp[ii] = 0.0, vfps[ii] = 1.0;

	int selected; double fps;
	char Fname[512];
	sprintf(Fname, "%s/InitSync.txt", Path); FILE * fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int temp;
		for (int ii = 0; ii < nCams; ii++)
		{
			fscanf(fp, "%d %lf %d ", &selected, &fps, &temp);
			TimeStamp[ii] = (double)temp, vfps[selected] = fps;
		}
		fclose(fp);
	}
	else
		printLOG("Cannot load time stamp info. Assume no frame offsets!");

	int *SkipFrameOffset = new int[nCams];
	for (int ii = 0; ii < nCams; ii++)
		SkipFrameOffset[ii] = 0;
	if (increF != 1)
	{
		int sfo;
		sprintf(Fname, "%s/SkipFrameOffset_%d.txt", Path, increF);	fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			while (fscanf(fp, "%d %d ", &selected, &sfo) != EOF)
				SkipFrameOffset[selected] = sfo;
			fclose(fp);
		}
	}

	int refCid = 0;
	double earliest = DBL_MAX;
	for (int ii = 0; ii < nCams; ii++)
		if (earliest > TimeStamp[ii])
			earliest = TimeStamp[ii], refCid = ii;

	VideoData *VideoInfo = new VideoData[nCams];
	for (int ii = 0; ii < (int)SelectedCamNames.size(); ii++)
	{
		for (int jj = 0; jj < (int)CamIdsPerSeq.size(); jj++)
		{
			int cid = ii * CamIdsPerSeq.size() + jj;
			printLOG("Reading Cam %d\n ", cid);
			ReadCamCalibInfo(Path, SelectedCamNames[ii], SeqId, CamIdsPerSeq[jj], VideoInfo[ii*CamIdsPerSeq.size() + jj], startF, stopF);
		}
	}

	int nMaxPeople = 0;
	vector<vector<Point2i> > *MergedTrackletVec = new vector<vector<Point2i> >[nCams];
	for (auto cid : SelectedCams)
	{
		sprintf(Fname, "%s/%d/CleanedMergedTracklets_%d_%d.txt", Path, cid, startF, stopF);
		if (!IsFileExist(Fname))
			return 1;
		std::string line, item;
		std::ifstream file(Fname);
		while (std::getline(file, line))
		{
			StringTrim(&line);//remove white space
			if (line.empty())
				break;
			std::stringstream line_stream(line);
			std::getline(line_stream, item, ' ');  //# pairs

			vector<Point2i> jointTrack;
			int fid, did;
			while (!line_stream.eof())
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				fid = atoi(item.c_str());
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				did = atoi(item.c_str());
				jointTrack.push_back(Point2i(fid, did));
			}
			MergedTrackletVec[cid].push_back(jointTrack);
		}
		file.close();

		nMaxPeople = max(nMaxPeople, (int)MergedTrackletVec[cid].size());
	}
	nMaxPeople--;//last one is trash category	

	vector<float> *conf = new vector<float>[nCams];
	Point2d *tpts = new Point2d[nCams];
	vector<Point2d> *allPts = new vector<Point2d>[nCams];
	vector<Point2d> *allPts_org = new vector<Point2d>[nCams];

	bool *passTri = new bool[nCams];
	double *allP = new double[12 * nCams], *tallP = new double[12 * nCams];
	double *A = new double[6 * nCams * 2], *B = new double[2 * nCams * 2], *tP = new double[12 * nCams * 2];

	sprintf(Fname, "%s/People", Path), makeDir(Fname);
	sprintf(Fname, "%s/People/@%d", Path, increF), makeDir(Fname);
	for (int pid = 0; pid < nMaxPeople; pid++)
		sprintf(Fname, "%s/People/@%d/%d", Path, increF, pid), makeDir(Fname);
	for (int refFid = startF; refFid <= stopF; refFid += increF)
	{
		printLOG("%d..", refFid);

		vector<int> allCid;
		for (auto cid : SelectedCams)
		{
			allPts[cid].clear(), allPts_org[cid].clear(), conf[cid].clear();
			int localFid = (int)(vfps[refCid] / vfps[cid] * (refFid - TimeStamp[cid]) - SkipFrameOffset[cid] + 0.5);
			localFid = localFid / increF * increF;// ((int)(1.0*localFid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation
			CameraData *camI = VideoInfo[cid].VideoInfo;
			if (camI[localFid].valid != 1)
				continue;

			double u, v, s;
			vector<float> vConf; vector<Point2f> vUV;
			sprintf(Fname, "%s/%s/DensePose/general_%d_%d/image_%.10d_0.png.txt", Path, SelectedCamNames[cid / CamIdsPerSeq.size()], SeqId, CamIdsPerSeq[cid%CamIdsPerSeq.size()], localFid);
			if (readKeyPointJson(Fname, vUV, vConf, skeletonPointFormat) > 0)
			{
				for (int ii = 0; ii < vUV.size(); ii++)
				{
					if (vConf[ii] < detectionThresh)
						allPts[cid].push_back(Point2d(0, 0)), allPts_org[cid].push_back(Point2d(0, 0)), conf[cid].push_back(vConf[ii]);
					else
					{
						Point2d uv(vUV[ii].x, vUV[ii].y);
						allPts_org[cid].push_back(uv);

						if (distortionCorrected == 0 && camI[localFid].LensModel == 2)
							LensCorrectionPoint_KB3(uv, camI[localFid].intrinsic, camI[localFid].distortion);
						allPts[cid].push_back(uv), conf[cid].push_back(vConf[ii]);
					}
				}
			}
		}

		//recon individual person
		for (int pid = 0; pid < nMaxPeople; pid++)
		{
			vector<Point2i> vCid_Did;
			for (auto cid : SelectedCams) //search for his id in the detection
			{
				if (MergedTrackletVec[cid].size() <= pid)
					continue;
				int localFid = (int)(vfps[refCid] / vfps[cid] * (refFid - TimeStamp[cid]) - SkipFrameOffset[cid] + 0.5);
				localFid = localFid / increF * increF;// ((int)(1.0*localFid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation
				for (int jj = 0; jj < (int)MergedTrackletVec[cid][pid].size(); jj++)
					if (MergedTrackletVec[cid][pid][jj].x == localFid) //found
						vCid_Did.push_back(Point2i(cid, MergedTrackletVec[cid][pid][jj].y));
			}

			//recon per-joint
			Point3d *Vxyz = new Point3d[skeletonPointFormat];
			sprintf(Fname, "%s/People/@%d/%d/%.4d.txt", Path, increF, pid, refFid); FILE *fp = fopen(Fname, "w");
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				int count = 0;
				vector<int> VvalidJoints;
				for (int ii = 0; ii < vCid_Did.size(); ii++)
				{
					int cid = vCid_Did[ii].x, localFid = (int)(vfps[refCid] / vfps[cid] * (refFid - TimeStamp[cid]) - SkipFrameOffset[cid] + 0.5), did = vCid_Did[ii].y;
					localFid = localFid / increF * increF;// ((int)(1.0*localFid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation
					CameraData *camI = VideoInfo[cid].VideoInfo;
					if (camI[localFid].valid != 1)
						continue;

					vector<Point2d> *pts = &allPts[cid];
					if (conf[cid][did*skeletonPointFormat + jid] > detectionThresh)
					{
						tpts[count] = pts[0][did*skeletonPointFormat + jid];
						for (int kk = 0; kk < 12; kk++)
							tallP[count * 12 + kk] = camI[localFid].P[kk];

						count++;
						VvalidJoints.push_back(ii);
					}
				}

				if (count < 2)
				{
					fprintf(fp, "%f %f %f 999.999 %d\n", Vxyz[jid].x, Vxyz[jid].y, Vxyz[jid].z, vCid_Did.size());
					for (int ii = 0; ii < vCid_Did.size(); ii++)
					{
						int cid = vCid_Did[ii].x, localFid = (int)(vfps[refCid] / vfps[cid] * (refFid - TimeStamp[cid]) - SkipFrameOffset[cid] + 0.5), did = vCid_Did[ii].y;
						localFid = localFid / increF * increF;// ((int)(1.0*localFid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation
						CameraData *camI = VideoInfo[cid].VideoInfo;

						if (camI[localFid].valid != 1 || conf[cid][did*skeletonPointFormat + jid] < detectionThresh)
							fprintf(fp, "%d %d 0.0 0.0 0.0 0 ", cid, localFid);
						else
						{
							Point2d uv = allPts_org[cid][did*skeletonPointFormat + jid];
							fprintf(fp, "%d %d %.2f %.2f %.4f 0 ", cid, localFid, uv.x, uv.y, conf[cid][did*skeletonPointFormat + jid]);
						}
					}
					fprintf(fp, "\n");
					continue;
				}

				vector<int> Inliers[1];
				double finalerror;
				if (iterMax > 0)
				{
					if (count < nMinPointsRanSac)
					{
						NviewTriangulation(tpts, tallP, &Vxyz[jid], count, 1, NULL, NULL, NULL);
						NviewTriangulationNonLinear(tallP, tpts, &Vxyz[jid], &finalerror, count, 1);
						for (int ii = 0; ii < count; ii++)
							Inliers[0].push_back(1);
					}
					else
						finalerror = NviewTriangulationRANSAC(tpts, tallP, &Vxyz[jid], passTri, Inliers, count, 1, nMinPointsRanSac, iterMax, 0.4, Reprojectionthreshold, A, B, tP, true, true);
				}
				else
				{
					NviewTriangulation(tpts, tallP, &Vxyz[jid], count, 1, NULL, NULL, NULL);
					NviewTriangulationNonLinear(tallP, tpts, &Vxyz[jid], &finalerror, count, 1);
					for (int ii = 0; ii < count; ii++)
						Inliers[0].push_back(1);
				}

				if (finalerror < Reprojectionthreshold)
					fprintf(fp, "%f %f %f %.2f %d\n", Vxyz[jid].x, Vxyz[jid].y, Vxyz[jid].z, finalerror, VvalidJoints.size());
				else
					fprintf(fp, "0.0 0.0 0.0 %.2f %d\n", finalerror, VvalidJoints.size());
				for (int ii = 0; ii < VvalidJoints.size(); ii++)
				{
					int cid = vCid_Did[VvalidJoints[ii]].x, localFid = (int)(vfps[refCid] / vfps[cid] * (refFid - TimeStamp[cid]) - SkipFrameOffset[cid] + 0.5), did = vCid_Did[VvalidJoints[ii]].y;
					localFid = localFid / increF * increF;// ((int)(1.0*localFid / increF + 0.5))*increF; //snapping  it the the nearest frame sort of defeat the purese of sync tringulation
					CameraData *camI = VideoInfo[cid].VideoInfo;
					if (camI[localFid].valid != 1 || conf[cid][did*skeletonPointFormat + jid] < detectionThresh)
						fprintf(fp, "%d %d 0.0 0.0 0.0 0 ", cid, localFid);
					else
					{
						Point2d uv = allPts_org[cid][did*skeletonPointFormat + jid];
						if (finalerror < Reprojectionthreshold)
							fprintf(fp, "%d %d %.3f %.3f %.4f %d ", cid, localFid, uv.x, uv.y, conf[cid][did*skeletonPointFormat + jid], Inliers[0][ii]);
						else
							fprintf(fp, "%d %d %.3f %.3f %.2f 0 ", cid, localFid, uv.x, uv.y, conf[cid][did*skeletonPointFormat + jid]);
					}
				}
				fprintf(fp, "\n");
			}
			fclose(fp);

			delete[]Vxyz;
		}
	}

	delete[] VideoInfo, delete[] tallP, delete[]tpts, delete[]allPts, delete[]allPts_org;

	return 0;
}
int WindowSkeleton3DBundleAdjustment_DensePose(char *Path, std::vector<char*> SelectedCamNames, int SeqId, std::vector<int> &CamIdsPerSeq, int nCams, int startF, int stopF, int increF, int distortionCorrected, int skeletonPointFormat, double detectionThresh, int LossType, double *Weights, double *iSigma, double real2SfM, int missingFrameInterp)
{
	char Fname[512];

	printLOG("*****************WindowSkeleton3DBundleAdjustment*****************\n");
	if (missingFrameInterp)
		printLOG("Interp 3D markers\n");
	else
		printLOG("NO Interp 3D markers\n");

	//Weight = [ const limb length, symmetric skeleton, temporal]. It is  helpful for insightful weight setting if metric unit (mm) is used
	double sigma_i2D = iSigma[0], sigma_iL = iSigma[1] * real2SfM, sigma_iVel = iSigma[2] * real2SfM, sigma_iVel2 = iSigma[3] * real2SfM; //also convert physical sigma to sfm scale sigma

	const double ialpha = 1.0 / 60.0; //1/fps

	int nLimbConnections, nSymLimbConnectionID;
	vector<Point2i> LimbConnectionID;
	vector<Vec4i> SymLimbConnectionID;
	if (skeletonPointFormat == 17)
	{
		nLimbConnections = 14, nSymLimbConnectionID = 6;
		Point2i _LimbConnectionID[] = { Point2i(0, 1), Point2i(1, 3), Point2i(0, 2), Point2i(2, 4),
		   Point2i(5, 7), Point2i(7, 9), Point2i(6, 8),	Point2i(8, 10), Point2i(5,6),
			 Point2i(11, 13), Point2i(13, 15), Point2i(12, 14), Point2i(14, 16), Point2i(11, 12) };
		Vec4i _SymLimbConnectionID[] = { Vec4i(0, 1, 0, 2), Vec4i(1,3,2,4), Vec4i(5,7,6,8), Vec4i(7,9,8,10), Vec4i(11,13,12,14), Vec4i(13,15,14,16) }; //no eyes, ears since they are unreliable
		for (int ii = 0; ii < nLimbConnections; ii++)
			LimbConnectionID.push_back(_LimbConnectionID[ii]);
		for (int ii = 0; ii < nLimbConnections; ii++)
			SymLimbConnectionID.push_back(_SymLimbConnectionID[ii]);
	}
	else if (skeletonPointFormat == 18)
	{
		nLimbConnections = 17, nSymLimbConnectionID = 6;
		Point2i _LimbConnectionID[] = { Point2i(0, 1), Point2i(1, 2), Point2i(2, 3), Point2i(3, 4), Point2i(1, 5), Point2i(5, 6), Point2i(6, 7),
			Point2i(1, 8), Point2i(8, 9), Point2i(9, 10), Point2i(1, 11), Point2i(11, 12), Point2i(12, 13), Point2i(0, 14), Point2i(0, 15), Point2i(14, 16), Point2i(15, 17) };
		Vec4i _SymLimbConnectionID[] = { Vec4i(1, 2, 1, 5), Vec4i(2, 3, 5, 6), Vec4i(3, 4, 6, 7), Vec4i(1, 8, 1, 11), Vec4i(8, 9, 11, 12), Vec4i(9, 10, 12, 13) }; //no eyes, ears since they are unreliable
		for (int ii = 0; ii < nLimbConnections; ii++)
			LimbConnectionID.push_back(_LimbConnectionID[ii]);
		for (int ii = 0; ii < nLimbConnections; ii++)
			SymLimbConnectionID.push_back(_SymLimbConnectionID[ii]);
	}
	else if (skeletonPointFormat == 25)
	{
		nLimbConnections = 32, nSymLimbConnectionID = 18;
		Point2i _LimbConnectionID[] = { Point2i(0, 1), Point2i(1, 2), Point2i(2, 3), Point2i(3, 4), Point2i(1, 5), Point2i(5, 6), Point2i(6, 7),
			Point2i(1, 8), Point2i(8,9),Point2i(9, 10),Point2i(10,11),Point2i(8,12),Point2i(12,13),Point2i(13,14),Point2i(0,15),Point2i(15,17),Point2i(0,16),Point2i(17,18), Point2i(1,9),Point2i(1,12),
			Point2i(11,22),Point2i(11,23),Point2i(11,24),Point2i(22,23),Point2i(22,24),Point2i(23,24),
			Point2i(14,19),Point2i(14,20),Point2i(14,21),Point2i(19,20),Point2i(19,21),Point2i(13,20) };
		Vec4i _SymLimbConnectionID[] = { Vec4i(1, 2, 1, 5), Vec4i(2, 3, 5, 6), Vec4i(3, 4, 6, 7),
			Vec4i(8,9,8,12), Vec4i(1, 9, 1, 12), Vec4i(9,10, 12, 13), Vec4i(10, 11, 13, 14), Vec4i(1, 9, 1, 12),
			Vec4i(22,23,19,20), Vec4i(23,24,20,14), Vec4i(22,24,19,21), Vec4i(11, 22, 14, 19),Vec4i(11, 23, 14, 20),Vec4i(11, 24, 14, 21),
			Vec4i(0,15, 0,16), Vec4i(15,17,16,18) ,Vec4i(0,17, 0,18), Vec4i(15,18,16,17) };
		for (int ii = 0; ii < nLimbConnections; ii++)
			LimbConnectionID.push_back(_LimbConnectionID[ii]);
		for (int ii = 0; ii < nLimbConnections; ii++)
			SymLimbConnectionID.push_back(_SymLimbConnectionID[ii]);
	}

	double TimeStamp[100], vifps[100], mean_ifps = 0;
	for (int ii = 0; ii < nCams; ii++)
		TimeStamp[ii] = 0.0, vifps[ii] = 1.0;

	int selected; double fps;
	sprintf(Fname, "%s/InitSync.txt", Path); FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int temp;
		for (int ii = 0; ii < nCams; ii++)
		{
			fscanf(fp, "%d %lf %d ", &selected, &fps, &temp);
			TimeStamp[ii] = (double)temp, vifps[selected] = 1.0 / fps;
			mean_ifps += vifps[selected];
		}
		fclose(fp);
	}
	else
		printLOG("Cannot load time stamp info. Assume no frame offsets!");
	mean_ifps = mean_ifps / nCams;

	int *SkipFrameOffset = new int[nCams];
	for (int ii = 0; ii < nCams; ii++)
		SkipFrameOffset[ii] = 0;

	int refCid = 0;
	double earliest = DBL_MAX;
	for (int ii = 0; ii < nCams; ii++)
		if (earliest > TimeStamp[ii])
			earliest = TimeStamp[ii], refCid = ii;

	printLOG("Reading all camera poses\n");
	VideoData *VideoInfo = new VideoData[nCams];
	for (int ii = 0; ii < (int)SelectedCamNames.size(); ii++)
	{
		for (int jj = 0; jj < (int)CamIdsPerSeq.size(); jj++)
		{
			int cid = ii * CamIdsPerSeq.size() + jj;
			printLOG("Reading Cam %d\n ", cid);
			ReadCamCalibInfo(Path, SelectedCamNames[ii], SeqId, CamIdsPerSeq[jj], VideoInfo[ii*CamIdsPerSeq.size() + jj], startF, stopF);
		}
	}

	double u, v, s, avg_error;
	ceres::LossFunction *loss_funcion = 0;
	if (LossType == 1) //Huber
		loss_funcion = new ceres::HuberLoss(1.0);

	double residuals[3], rho[3];
	int cid, personId = 0;
	while (true)
	{
		printLOG("Person #%d\n", personId);
		printLOG("Invalid frames: ");
		int nvalidFrames = 0;
		vector<double> *vlimblength = new vector<double>[nLimbConnections];
		double *LimbLength = new double[nLimbConnections];
		HumanSkeleton3D *Skeletons = new HumanSkeleton3D[(stopF - startF) / increF + 1];
		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int nvis, nValidJoints = 0, tempFid = (refFid - startF) / increF;
			sprintf(Fname, "%s/People/@%d/%d/%.4d.txt", Path, increF, personId, refFid); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				int pid, nvis, rfid, inlier, dummy; float fdummy;
				for (int jid = 0; jid < skeletonPointFormat; jid++)
				{
					fscanf(fp, "%lf %lf %lf %lf %d ", &Skeletons[tempFid].pt3d[jid].x, &Skeletons[tempFid].pt3d[jid].y, &Skeletons[tempFid].pt3d[jid].z, &avg_error, &nvis);
					for (int kk = 0; kk < nvis; kk++)
					{
						fscanf(fp, "%d %d %lf %lf %lf %d ", &cid, &rfid, &u, &v, &s, &inlier);
						if (!VideoInfo[cid].VideoInfo[rfid].valid)
							continue;

						Skeletons[tempFid].vViewID_rFid[jid].push_back(Point2i(cid, rfid));
						Skeletons[tempFid].vPt2D[jid].push_back(Point2d(u, v));
						Skeletons[tempFid].vConf[jid].push_back(s);
						Skeletons[tempFid].vInlier[jid].push_back(inlier);

						if (distortionCorrected == 0 && VideoInfo[cid].VideoInfo[rfid].LensModel == 2)
							LensCorrectionPoint_KB3(Skeletons[tempFid].vPt2D[jid].back(), VideoInfo[cid].VideoInfo[rfid].intrinsic, VideoInfo[cid].VideoInfo[rfid].distortion);
					}

					if (IsValid3D(Skeletons[tempFid].pt3d[jid]))
						Skeletons[tempFid].validJoints[jid] = 1, nValidJoints++;
					else
						Skeletons[tempFid].validJoints[jid] = 0;
				}
				fclose(fp);

				if (nValidJoints == 0)
					printLOG("%d..", refFid);

				for (int cid = 0; cid < nLimbConnections; cid++)
				{
					int j0 = LimbConnectionID[cid].x, j1 = LimbConnectionID[cid].y;
					if (Skeletons[tempFid].validJoints[j0] > 0 && Skeletons[tempFid].validJoints[j1] > 0)
						vlimblength[cid].push_back(norm(Skeletons[tempFid].pt3d[j0] - Skeletons[tempFid].pt3d[j1]));
				}
				nvalidFrames++;
			}
		}
		if (nvalidFrames == 0)
		{
			printLOG("\n");
			break;
		}

		//now, dig into the invalid frames
		if (missingFrameInterp == 1)
		{
			for (int refFid = startF; refFid <= stopF; refFid += increF)
			{
				int  tempFid = (refFid - startF) / increF;
				for (int jid = 0; jid < skeletonPointFormat; jid++)
				{
					if (!Skeletons[tempFid].validJoints[jid])
					{
						int minDist = 9e9, minFrame = -1;
						for (int refFid2 = startF; refFid2 <= stopF; refFid2 += increF)
						{
							int  tempFid2 = (refFid2 - startF) / increF;
							if (Skeletons[tempFid2].validJoints[jid])
							{
								int Dist = abs(refFid2 - refFid);
								if (Dist < minDist)
									minDist = Dist, minFrame = tempFid2;
							}
						}
						if (minFrame != -1)
						{
							Skeletons[tempFid].validJoints[jid] = 2;
							Skeletons[tempFid].pt3d[jid] = Skeletons[minFrame].pt3d[jid];
						}
					}
				}
			}
		}

		printLOG("\nSet up window BA\n");
		ceres::Problem problem;

		for (int cid = 0; cid < nLimbConnections; cid++)
		{
			if (vlimblength[cid].size() == 0)
				LimbLength[cid] = 0.0;
			else
				LimbLength[cid] = MedianArray(vlimblength[cid]);
		}

		vector<double> VreprojectionError, VUnNormedReprojectionErrorX, VUnNormedReprojectionErrorY, VconstLimbError, VsymLimbError, VtemporalError;

		int nvalidPoints1 = 0, nvalidPoints2 = 0, nvalidPoints3 = 0, nvalidPoints4 = 0;
		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];

			//reprojection error
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				if (Body0[0].validJoints[jid] > 0)
				{
					for (int ii = 0; ii < (int)Body0[0].vConf[jid].size(); ii++)
					{
						int cid = Body0[0].vViewID_rFid[jid][ii].x, rfid = Body0[0].vViewID_rFid[jid][ii].y;
						CameraData *camI = VideoInfo[cid].VideoInfo;
						if (camI[rfid].valid != 1)
							continue;

						Point2d uv = Body0[0].vPt2D[jid][ii]; //has been corrected before
						if (Body0[0].vConf[jid][ii] < detectionThresh || uv.x < 1 || uv.y < 1 || (Body0[0].validJoints[jid] != 2 && Body0[0].vInlier[jid][ii] == 0))
							continue;
						nvalidPoints1++;
					}
				}
			}

			//constant limb length
			for (int cid = 0; cid < nLimbConnections; cid++)
			{
				int j0 = LimbConnectionID[cid].x, j1 = LimbConnectionID[cid].y;
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0)
					nvalidPoints2++;
			}

			//symmetry limb
			for (int cid = 0; cid < nSymLimbConnectionID; cid++)
			{
				int j0 = SymLimbConnectionID[cid](0), j1 = SymLimbConnectionID[cid](1), j0_ = SymLimbConnectionID[cid](2), j1_ = SymLimbConnectionID[cid](3);
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0 && Body0[0].validJoints[j0_] > 0 && Body0[0].validJoints[j1_] > 0)
					nvalidPoints3++;
			}
		}
		for (int refFid = startF; refFid <= stopF - increF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];
			HumanSkeleton3D *Body1 = &Skeletons[tempFid + 1];

			for (int jid = 0; jid < skeletonPointFormat; jid++)
				if (Body0[0].validJoints[jid] > 0 && Body1[0].validJoints[jid] > 0) //temporal smoothing
					nvalidPoints4++;
		}

		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];

			//reprojection error
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				if (Body0[0].validJoints[jid] > 0)
				{
					for (int ii = 0; ii < (int)Body0[0].vConf[jid].size(); ii++)
					{
						int cid = Body0[0].vViewID_rFid[jid][ii].x, rfid = Body0[0].vViewID_rFid[jid][ii].y;
						CameraData *camI = VideoInfo[cid].VideoInfo;
						if (camI[rfid].valid != 1)
							continue;

						Point2d uv = Body0[0].vPt2D[jid][ii]; //has been corrected before
						if (Body0[0].vConf[jid][ii] < detectionThresh || uv.x < 1 || uv.y < 1 || (Body0[0].validJoints[jid] != 2 && Body0[0].vInlier[jid][ii] == 0))
							continue;

						double w = Weights[0] * Body0[0].vConf[jid][ii] / (0.001 + nvalidPoints1);
						ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
						ceres::CostFunction* cost_function = PinholeReprojectionErrorSimple_PointOnly::Create(camI[rfid].P, uv.x, uv.y, sigma_i2D);
						problem.AddResidualBlock(cost_function, ScaleLoss, &Body0[0].pt3d[jid].x);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[jid].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						double loss = residuals[1] * residuals[1] + residuals[1] * residuals[1];
						ScaleLoss->Evaluate(loss, rho);

						VreprojectionError.push_back(w*0.5*rho[0]);
						VUnNormedReprojectionErrorX.push_back(residuals[0] / sigma_i2D), VUnNormedReprojectionErrorY.push_back(residuals[1] / sigma_i2D);
					}
				}
			}

			//constant limb length
			for (int cid = 0; cid < nLimbConnections; cid++)
			{
				int j0 = LimbConnectionID[cid].x, j1 = LimbConnectionID[cid].y;
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0)
				{
					double w = Weights[1] / (0.001 + nvalidPoints2);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					ceres::CostFunction* cost_function = ConstantLimbLengthCost3DCeres2::CreateAutoDiff(sigma_iL);
					problem.AddResidualBlock(cost_function, ScaleLoss, &LimbLength[cid], &Body0[0].pt3d[j0].x, &Body0[0].pt3d[j1].x);

					vector<double *> paras; paras.push_back(&LimbLength[cid]), paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
					VconstLimbError.push_back(rho[0]);
				}
			}

			//symmetry limb
			for (int cid = 0; cid < nSymLimbConnectionID; cid++)
			{
				int j0 = SymLimbConnectionID[cid](0), j1 = SymLimbConnectionID[cid](1), j0_ = SymLimbConnectionID[cid](2), j1_ = SymLimbConnectionID[cid](3);
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0 && Body0[0].validJoints[j0_] > 0 && Body0[0].validJoints[j1_] > 0)
				{
					double w = Weights[2] / (0001 + nvalidPoints3);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					if (j0 == j0_)
					{
						ceres::CostFunction* cost_function = SymLimbLengthCost3DCeres2::CreateAutoDiff(sigma_iL);
						problem.AddResidualBlock(cost_function, ScaleLoss, &Body0[0].pt3d[j0].x, &Body0[0].pt3d[j1].x, &Body0[0].pt3d[j1_].x);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x), paras.push_back(&Body0[0].pt3d[j1_].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
						VsymLimbError.push_back(rho[0]);
					}
					else
					{
						ceres::CostFunction* cost_function = SymLimbLengthCost3DCeres::CreateAutoDiff(sigma_iL);
						problem.AddResidualBlock(cost_function, ScaleLoss, &Body0[0].pt3d[j0].x, &Body0[0].pt3d[j1].x, &Body0[0].pt3d[j0_].x, &Body0[0].pt3d[j1_].x);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x), paras.push_back(&Body0[0].pt3d[j0_].x), paras.push_back(&Body0[0].pt3d[j1_].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
						VsymLimbError.push_back(rho[0]);
					}
				}
			}
		}

		//temporal
		for (int refFid = startF; refFid <= stopF - increF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];
			HumanSkeleton3D *Body1 = &Skeletons[tempFid + 1];

			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				double actingSigma = sigma_iVel;
				if (skeletonPointFormat == 17 && (jid == 9 || jid == 10 || jid == 15 || jid == 16)) //allow hands and feet to move faster
					actingSigma = sigma_iVel2;
				else if (skeletonPointFormat == 18 && (jid == 4 || jid == 7 || jid == 10 || jid == 13)) //18 joint format
					actingSigma = sigma_iVel2;
				else if (skeletonPointFormat == 25 && (jid == 4 || jid == 7 || jid == 11 || jid == 14 || jid == 19 || jid == 20 || jid == 21 || jid == 22 || jid == 23 || jid == 24))//25 joint format
					actingSigma = sigma_iVel2;

				if (Body0[0].validJoints[jid] > 0 && Body1[0].validJoints[jid] > 0) //temporal smoothing
				{
					double ifps1 = mean_ifps, ifps2 = mean_ifps;
					if (Body0[0].vViewID_rFid[jid].size() > 0)
					{
						int cid1 = Body0[0].vViewID_rFid[jid][0].x;
						ifps1 = vifps[cid1];
					}
					if (Body1[0].vViewID_rFid[jid].size() > 0)
					{
						int cid2 = Body1[0].vViewID_rFid[jid][0].x;
						ifps2 = vifps[cid2];
					}

					double w = Weights[3] / (0.001 + nvalidPoints4);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					ceres::CostFunction* cost_function = LeastMotionPriorCost3DCeres2::CreateAutoDiff(ifps1 * refFid, ifps2 * (refFid + 1), actingSigma);
					problem.AddResidualBlock(cost_function, ScaleLoss, &Body0[0].pt3d[jid].x, &Body1[0].pt3d[jid].x);

					vector<double *> paras; paras.push_back(&Body0[0].pt3d[jid].x), paras.push_back(&Body1[0].pt3d[jid].x);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
					VtemporalError.push_back(rho[0]);
				}
			}
		}

		double 	repro = sqrt(MeanArray(VreprojectionError)),
			unNormedReproX = MeanArray(VUnNormedReprojectionErrorX),
			unNormedReproY = MeanArray(VUnNormedReprojectionErrorY),
			stdUnNormedReproX = sqrt(VarianceArray(VUnNormedReprojectionErrorX, unNormedReproX)),
			stdUnNormedReproY = sqrt(VarianceArray(VUnNormedReprojectionErrorY, unNormedReproY)),
			cLimb = sqrt(MeanArray(VconstLimbError)) / sigma_iL * real2SfM,
			sSkele = sqrt(MeanArray(VsymLimbError)) / sigma_iL * real2SfM,
			motionCo = sqrt(MeanArray(VtemporalError)) / sigma_iVel * real2SfM;
		printLOG("Error before: [NormReprojection, MeanUnNormedRprojection, StdUnNormedRprojection, constLimbLength, symSkeleton, temporal coherent] = [%.3e, (%.3f %.3f) (%.3f %.3f) %.3f, %.3f, %.3f]\n", repro, unNormedReproX, unNormedReproY, stdUnNormedReproX, stdUnNormedReproY, cLimb, sSkele, motionCo);

		ceres::Solver::Options options;
		options.num_threads = omp_get_max_threads(); //jacobian eval
		options.num_linear_solver_threads = omp_get_max_threads(); //linear solver
		options.trust_region_strategy_type = ceres::LEVENBERG_MARQUARDT;
		options.linear_solver_type = ceres::SPARSE_NORMAL_CHOLESKY;
		//options.preconditioner_type = ceres::JACOBI;
		options.use_nonmonotonic_steps = false;
		options.max_num_iterations = 50;
		options.minimizer_progress_to_stdout = true;

		ceres::Solver::Summary summary;
		ceres::Solve(options, &problem, &summary);
		std::cout << summary.BriefReport() << "\n";
		summary.final_cost;

		VreprojectionError.clear(), VconstLimbError.clear(), VsymLimbError.clear(), VtemporalError.clear();
		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];

			//reprojection error
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				if (Body0[0].validJoints[jid] > 0)
				{
					for (int ii = 0; ii < (int)Body0[0].vConf[jid].size(); ii++)
					{
						int cid = Body0[0].vViewID_rFid[jid][ii].x, rfid = Body0[0].vViewID_rFid[jid][ii].y;
						CameraData *camI = VideoInfo[cid].VideoInfo;
						if (camI[rfid].valid != 1)
							continue;

						Point2d uv = Body0[0].vPt2D[jid][ii];
						if (Body0[0].vConf[jid][ii] < detectionThresh || uv.x < 1 || uv.y < 1 || (Body0[0].validJoints[jid] != 2 && Body0[0].vInlier[jid][ii] == 0))
							continue;

						double w = Weights[0] * Body0[0].vConf[jid][ii] / (0.001 + nvalidPoints1);
						ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
						ceres::CostFunction* cost_function = PinholeReprojectionErrorSimple_PointOnly::Create(camI[rfid].P, uv.x, uv.y, sigma_i2D);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[jid].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						double loss = residuals[1] * residuals[1] + residuals[1] * residuals[1];
						ScaleLoss->Evaluate(loss, rho);

						VreprojectionError.push_back(w*0.5*rho[0]);
						VUnNormedReprojectionErrorX.push_back(residuals[0] / sigma_i2D), VUnNormedReprojectionErrorY.push_back(residuals[1] / sigma_i2D);
					}
				}
			}

			//constant limb length
			for (int cid = 0; cid < nLimbConnections; cid++)
			{
				int j0 = LimbConnectionID[cid].x, j1 = LimbConnectionID[cid].y;
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0)
				{
					double w = Weights[1] / (0.001 + nvalidPoints2);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					ceres::CostFunction* cost_function = ConstantLimbLengthCost3DCeres2::CreateAutoDiff(sigma_iL);

					vector<double *> paras; paras.push_back(&LimbLength[cid]), paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
					VconstLimbError.push_back(rho[0]);
				}
			}

			//symmetry limb
			for (int cid = 0; cid < nSymLimbConnectionID; cid++)
			{
				int j0 = SymLimbConnectionID[cid](0), j1 = SymLimbConnectionID[cid](1), j0_ = SymLimbConnectionID[cid](2), j1_ = SymLimbConnectionID[cid](3);
				if (Body0[0].validJoints[j0] > 0 && Body0[0].validJoints[j1] > 0 && Body0[0].validJoints[j0_] > 0 && Body0[0].validJoints[j1_] > 0)
				{
					double w = Weights[2] / (0001 + nvalidPoints3);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					if (j0 == j0_)
					{
						ceres::CostFunction* cost_function = SymLimbLengthCost3DCeres2::CreateAutoDiff(sigma_iL);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x), paras.push_back(&Body0[0].pt3d[j1_].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
						VsymLimbError.push_back(rho[0]);
					}
					else
					{
						ceres::CostFunction* cost_function = SymLimbLengthCost3DCeres::CreateAutoDiff(sigma_iL);

						vector<double *> paras; paras.push_back(&Body0[0].pt3d[j0].x), paras.push_back(&Body0[0].pt3d[j1].x), paras.push_back(&Body0[0].pt3d[j0_].x), paras.push_back(&Body0[0].pt3d[j1_].x);
						cost_function->Evaluate(&paras[0], residuals, NULL);
						ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
						VsymLimbError.push_back(rho[0]);
					}
				}
			}
		}

		//temporal
		for (int refFid = startF; refFid <= stopF - increF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body0 = &Skeletons[tempFid];
			HumanSkeleton3D *Body1 = &Skeletons[tempFid + 1];

			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				double actingSigma = sigma_iVel;
				if (skeletonPointFormat == 17 && (jid == 9 || jid == 10 || jid == 15 || jid == 16)) //allow hands and feet to move faster
					actingSigma = sigma_iVel2;
				else if (skeletonPointFormat == 18 && (jid == 4 || jid == 7 || jid == 10 || jid == 13)) //18 joint format
					actingSigma = sigma_iVel2;
				else if (skeletonPointFormat == 25 && (jid == 4 || jid == 7 || jid == 11 || jid == 14 || jid == 19 || jid == 20 || jid == 21 || jid == 22 || jid == 23 || jid == 24))//25 joint format
					actingSigma = sigma_iVel2;

				if (Body0[0].validJoints[jid] > 0 && Body1[0].validJoints[jid] > 0) //temporal smoothing
				{
					double ifps1 = mean_ifps, ifps2 = mean_ifps;
					if (Body0[0].vViewID_rFid[jid].size() > 0)
					{
						int cid1 = Body0[0].vViewID_rFid[jid][0].x;
						ifps1 = vifps[cid1];
					}
					if (Body1[0].vViewID_rFid[jid].size() > 0)
					{
						int cid2 = Body1[0].vViewID_rFid[jid][0].x;
						ifps2 = vifps[cid2];
					}

					double w = Weights[3] / (0.001 + nvalidPoints4);
					ceres::LossFunction *ScaleLoss = new ceres::ScaledLoss(NULL, w, ceres::TAKE_OWNERSHIP);
					ceres::CostFunction* cost_function = LeastMotionPriorCost3DCeres2::CreateAutoDiff(ifps1 * refFid, ifps2 * (refFid + 1), actingSigma);

					vector<double *> paras; paras.push_back(&Body0[0].pt3d[jid].x), paras.push_back(&Body1[0].pt3d[jid].x);
					cost_function->Evaluate(&paras[0], residuals, NULL);
					ScaleLoss->Evaluate(residuals[0] * residuals[0], rho);
					VtemporalError.push_back(rho[0]);
				}
			}
		}

		repro = sqrt(MeanArray(VreprojectionError)),
			unNormedReproX = MeanArray(VUnNormedReprojectionErrorX),
			unNormedReproY = MeanArray(VUnNormedReprojectionErrorY),
			stdUnNormedReproX = sqrt(VarianceArray(VUnNormedReprojectionErrorX, unNormedReproX)),
			stdUnNormedReproY = sqrt(VarianceArray(VUnNormedReprojectionErrorY, unNormedReproY)),
			cLimb = sqrt(MeanArray(VconstLimbError)) / sigma_iL * real2SfM,
			sSkele = sqrt(MeanArray(VsymLimbError)) / sigma_iL * real2SfM,
			motionCo = sqrt(MeanArray(VtemporalError)) / sigma_iVel * real2SfM;
		printLOG("Error after: [NormReprojection, MeanUnNormedRprojection, StdUnNormedRprojection, constLimbLength, symSkeleton, temporal coherent] = [%.3e, (%.3f %.3f) (%.3f %.3f) %.3f, %.3f, %.3f]\n", repro, unNormedReproX, unNormedReproY, stdUnNormedReproX, stdUnNormedReproY, cLimb, sSkele, motionCo);


		for (int refFid = startF; refFid <= stopF; refFid += increF)
		{
			int tempFid = (refFid - startF) / increF;
			HumanSkeleton3D *Body = &Skeletons[tempFid];

			int nValidJoints = 0;
			for (int jid = 0; jid < skeletonPointFormat; jid++)
				if (Body[0].validJoints[jid] > 0)
					nValidJoints++;
			if (nValidJoints == 0)
				continue;

			if (missingFrameInterp == 1)
				sprintf(Fname, "%s/People/@%d/%d/m_%.4d.txt", Path, increF, personId, refFid);
			else
				sprintf(Fname, "%s/People/@%d/%d/f_%.4d.txt", Path, increF, personId, refFid);
			fp = fopen(Fname, "w");
			for (int jid = 0; jid < skeletonPointFormat; jid++)
			{
				fprintf(fp, "%f %f %f %.2f %d\n", Body[0].pt3d[jid].x, Body[0].pt3d[jid].y, Body[0].pt3d[jid].z, sqrt(MeanArray(VreprojectionError)), (int)Body[0].vViewID_rFid[jid].size());
				for (int ii = 0; ii < Body[0].vViewID_rFid[jid].size(); ii++)
				{
					int cid = Body[0].vViewID_rFid[jid][ii].x, rfid = Body[0].vViewID_rFid[jid][ii].y;
					if (distortionCorrected == 0 && VideoInfo[cid].VideoInfo[rfid].LensModel == RADIAL_TANGENTIAL_PRISM)
						LensDistortionPoint(&Body[0].vPt2D[jid][ii], VideoInfo[cid].VideoInfo[rfid].K, VideoInfo[cid].VideoInfo[rfid].distortion);
					else if (distortionCorrected == 0 && VideoInfo[cid].VideoInfo[rfid].LensModel == 2)
						LensDistortionPoint_KB3(Body[0].vPt2D[jid][ii], VideoInfo[cid].VideoInfo[rfid].intrinsic, VideoInfo[cid].VideoInfo[rfid].distortion);
					else if (distortionCorrected == 0 && VideoInfo[cid].VideoInfo[rfid].LensModel == FISHEYE)
						FishEyeDistortionPoint(&Body[0].vPt2D[jid][ii], VideoInfo[cid].VideoInfo[rfid].K, VideoInfo[cid].VideoInfo[rfid].distortion[0]);

					fprintf(fp, "%d %d %.3f %.3f %.3f %d ", cid, rfid, Body[0].vPt2D[jid][ii].x, Body[0].vPt2D[jid][ii].y, Body[0].vConf[jid][ii], Body[0].vInlier[jid][ii]);
				}
				fprintf(fp, "\n");
			}
			fclose(fp);
		}

		personId++;
		delete[]LimbLength, delete[]Skeletons;
	}

	delete[]VideoInfo;

	return 0;
}


int CollectNearestViewsBaseOnGeometry(char *Path, vector<int> &sCams, int startF, int stopF, int kNN, bool useSyncedFramesOnly)
{
	char Fname[512]; FILE *fp = 0;

	//Read calib info
	int nCams = *std::max_element(std::begin(sCams), std::end(sCams)) + 1;
	VideoData *VideoInfo = new VideoData[nCams];
	vector<int>*allVrFid = new vector<int>[nCams];
	vector<Point2i> **allNearestKeyFrames = new vector<Point2i>*[nCams];

	vector<int> TimeStamp(nCams);
	Point3d CamTimeInfo[100];
	for (int ii = 0; ii < nCams; ii++)
		CamTimeInfo[ii].x = 1.0, CamTimeInfo[ii].y = 0.0, CamTimeInfo[ii].z = 0.0;//alpha, beta, rs in t = alpha*(f+rs*row) + beta*alpha_ref

	int selected; double fps;
	sprintf(Fname, "%s/FMotionPriorSync.txt", Path); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		double temp;
		while (fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp) != EOF)
			CamTimeInfo[selected].x = 1.0 / fps, CamTimeInfo[selected].y = temp;
		fclose(fp);
	}
	else
	{
		sprintf(Fname, "%s/FGeoSync.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			int temp;
			while (fscanf(fp, "%d %lf %d ", &selected, &fps, &temp) != EOF)
				CamTimeInfo[selected].x = 1.0 / fps, CamTimeInfo[selected].y = temp;
			fclose(fp);
		}
		else
		{
			sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				int temp;
				while (fscanf(fp, "%d %lf %d ", &selected, &fps, &temp) != EOF)
					CamTimeInfo[selected].x = 1.0 / fps, CamTimeInfo[selected].y = temp;
				fclose(fp);
			}
			else
				printLOG("Cannot load time stamp info. Assume no frame offsets!");
		}
	}

	int refCid = 0;
	double earliest = DBL_MAX;
	for (int ii = 0; ii < nCams; ii++)
		if (earliest > CamTimeInfo[ii].y)
			earliest = CamTimeInfo[ii].y, refCid = ii;

	int cnt = 0;
	for (auto camID : sCams)
	{
		printLOG("%d..", camID);

		int kfid, rfid, cfid, dummy;
		/*sprintf(Fname, "%s/%d/Frame2Corpus.txt", Path, camID); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
		printLOG("Cannot load %s\n", Fname);
		continue;
		}
		while (fscanf(fp, "%d %d %d %d ", &camID, &kfid, &rfid, &dummy) != EOF)
		allVrFid[camID].push_back(rfid);
		fclose(fp);*/
		for (int fid = startF; fid <= stopF; fid++)
			allVrFid[camID].push_back(fid);

		if (ReadVideoDataI(Path, VideoInfo[camID], camID, -1, -1) == 1)
			continue;
		else
		{
			InvalidateAbruptCameraPose(VideoInfo[camID], -1, -1, 0);
			cnt++;
		}
	}
	if (cnt == 0)
		return 1;

	const double cos_45 = cos(Pi / 4);

	vector<Point2i> cid_fid;
	vector<size_t> indexList;
	vector<double> unsorted, sorted;
	for (size_t ii = 18; ii < sCams.size(); ii++)
	{
		printLOG("%d..", sCams[ii]);
		allNearestKeyFrames[sCams[ii]] = new vector<Point2i>[stopF + 1];

		for (int fid = startF; fid <= stopF; fid++)
		{
			CameraData *refCam = &VideoInfo[sCams[ii]].VideoInfo[fid];
			if (!refCam[0].valid)
				continue;

			double uv1[3] = { refCam[0].width / 2, refCam[0].height / 2, 1 }, rayDir[3];
			getRayDir(rayDir, refCam[0].invK, refCam[0].R, uv1);

			cid_fid.clear(), indexList.clear(), unsorted.clear(), sorted.clear();
			//for (size_t jj = 0; jj < sCams.size(); jj++)
			for (int jj = 0; jj < 10; jj++)
			{
				if (useSyncedFramesOnly)
				{
					if (ii == jj)
						continue;

					double ts = CamTimeInfo[sCams[ii]].y / CamTimeInfo[refCid].x + 1.0 * 600 / CamTimeInfo[sCams[ii]].x;
					int fid_nr = (ts - CamTimeInfo[sCams[jj]].y / CamTimeInfo[refCid].x)*CamTimeInfo[sCams[jj]].x;

					//int fid_nr = fid + TimeStamp[ii] - TimeStamp[jj]; //f = f_ref - offset;
					if (fid_nr<startF || fid_nr>stopF)
						continue;
					CameraData *Cam_nr = &VideoInfo[sCams[jj]].VideoInfo[fid_nr];
					if (!Cam_nr[0].valid)
						continue;

					double uv1_nr[3] = { Cam_nr[0].width / 2, Cam_nr[0].height / 2, 1 }, rayDir_nr[3];
					getRayDir(rayDir_nr, Cam_nr[0].invK, Cam_nr[0].R, uv1_nr);

					double angle = dotProduct(rayDir, rayDir_nr);
					if (angle < cos_45)
						continue;

					double baseline = Distance3D(refCam[0].camCenter, Cam_nr[0].camCenter);
					double metric = baseline / angle; //smaller is better

					cid_fid.push_back(Point2i(jj, fid_nr));
					unsorted.push_back(metric);
				}
				else
				{
					for (auto fid_nr : allVrFid[sCams[jj]])//only use keyframes
					{
						if (jj == ii && fid == fid_nr)
							continue;

						CameraData *Cam_nr = &VideoInfo[sCams[jj]].VideoInfo[fid_nr];
						double uv1_nr[3] = { Cam_nr[0].width / 2, Cam_nr[0].height / 2, 1 }, rayDir_nr[3];
						getRayDir(rayDir_nr, Cam_nr[0].invK, Cam_nr[0].R, uv1_nr);

						double angle = dotProduct(rayDir, rayDir_nr);
						if (angle < cos_45)
							continue;

						double baseline = Distance3D(refCam[0].camCenter, Cam_nr[0].camCenter);
						double metric = baseline / angle; //smaller is better

						cid_fid.push_back(Point2i(jj, fid_nr));
						unsorted.push_back(metric);
					}
				}
			}
			SortWithIndex(unsorted, sorted, indexList);

			for (int kk = 0; kk < min(kNN, indexList.size()); kk++)
				allNearestKeyFrames[sCams[ii]][fid].push_back(cid_fid[indexList[kk]]);
		}
	}

	for (size_t ii = 18; ii < sCams.size(); ii++)
	{
		int cid = sCams[ii];
		sprintf(Fname, "%s/%d", Path, cid); makeDir(Fname);
		sprintf(Fname, "%s/%d/kNN4IRB.txt", Path, cid);
		FILE *fp = fopen(Fname, "w");
		for (int fid = startF; fid <= stopF; fid++)
		{
			fprintf(fp, "%d %d ", 600, min(kNN, allNearestKeyFrames[cid][fid].size()));
			for (int ii = 0; ii < min(kNN, allNearestKeyFrames[cid][fid].size()); ii++)
				fprintf(fp, "%d %d ", allNearestKeyFrames[cid][fid][ii].x, allNearestKeyFrames[cid][fid][ii].y);
			fprintf(fp, "\n");
		}
		fclose(fp);

		sprintf(Fname, "%s/%d/kNN4IRB_dif.txt", Path, cid); fp = fopen(Fname, "w");
		for (int fid = startF; fid <= stopF; fid++)
		{
			fprintf(fp, "%d %d %d\n", cid, 600, min(kNN, allNearestKeyFrames[cid][fid].size()));
			for (int ii = 0; ii < min(kNN, allNearestKeyFrames[cid][fid].size()); ii++)
			{
				fprintf(fp, "%d %d ", allNearestKeyFrames[cid][fid][ii].x, allNearestKeyFrames[cid][fid][ii].y);

				CameraData *Ref = &VideoInfo[cid].VideoInfo[fid];
				CameraData *NRef = &VideoInfo[allNearestKeyFrames[cid][fid][ii].x].VideoInfo[allNearestKeyFrames[cid][fid][ii].y];

				double R1to0[9], T1to0[3];
				GetRelativeTransformation(Ref[0].R, Ref[0].T, NRef[0].R, NRef[0].T, R1to0, T1to0);
				for (int jj = 0; jj < 9; jj++)
					fprintf(fp, "%.16f ", R1to0[jj]);
				for (int jj = 0; jj < 3; jj++)
					fprintf(fp, "%.16f ", T1to0[jj]);
				fprintf(fp, "\n");
			}
		}
		fclose(fp);
	}

	if (0)
	{
		for (auto cid : sCams)
		{
			allNearestKeyFrames[cid] = new vector<Point2i>[stopF + 1];

			sprintf(Fname, "%s/%d/kNN4IRB.txt", Path, cid); FILE *fp = fopen(Fname, "r");
			for (int fid = startF; fid <= stopF; fid++)
			{
				int fidi, nn;  fscanf(fp, "%d %d ", &fidi, &nn);
				Point2i cid_fid;
				for (int ii = 0; ii < nn; ii++)
					fscanf(fp, "%d %d ", &cid_fid.x, &cid_fid.y), allNearestKeyFrames[cid][fid].push_back(cid_fid);
			}
			fclose(fp);
		}

		Mat Img1, Img2;
		int ref_cid = 0, ref_fid = startF, nnId = 0, ref_cid0 = ref_cid - 1, ref_fid0 = ref_fid - 1, nnId0 = nnId;
		namedWindow("Image", CV_WINDOW_NORMAL | CV_WINDOW_KEEPRATIO);
		createTrackbar("Ref_Cid", "Image", &ref_cid, nCams, NULL);
		createTrackbar("Ref_Fid", "Image", &ref_fid, stopF, NULL);
		createTrackbar("kNN", "Image", &nnId, kNN - 1, NULL);

		while (true)
		{
			if (nnId >= allNearestKeyFrames[ref_cid][ref_fid].size())
			{
				nnId = allNearestKeyFrames[ref_cid][ref_fid].size() - 1;
				setTrackbarPos("kNN", "Image", nnId);
			}

			if (ref_cid0 != ref_cid || ref_fid0 != ref_fid)
			{
				ref_cid0 = ref_cid, ref_fid0 = ref_fid, nnId = 0, nnId0 = nnId;
				sprintf(Fname, "%s/%d/%.4d.png", Path, ref_cid, ref_fid);
				if (IsFileExist(Fname) == 0)
				{
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, ref_cid, ref_fid);
					if (IsFileExist(Fname) == 0)
						return 0;
				}
				Img1 = imread(Fname, 1);

				sprintf(Fname, "%s/%d/%.4d.png", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
				if (IsFileExist(Fname) == 0)
				{
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
					if (IsFileExist(Fname) == 0)
						return 0;
				}
				Img2 = imread(Fname, 1);
			}
			if (nnId0 != nnId)
			{
				nnId0 = nnId;

				sprintf(Fname, "%s/%d/%.4d.png", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
				if (IsFileExist(Fname) == 0)
				{
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
					if (IsFileExist(Fname) == 0)
						return 0;
				}
				Img2 = imread(Fname, 1);
			}


			CvPoint text_origin = { Img2.rows / 20, Img2.cols / 20 };
			sprintf(Fname, "%d %d", allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
			putText(Img2, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*Img2.cols / 640, cv::Scalar(0, 255, 0), 3);

			cv::Mat BImage(Img1.rows, Img1.cols * 2, Img1.type());
			Img1.copyTo(BImage(cv::Rect(0, 0, Img1.cols, Img1.rows)));
			Img2.copyTo(BImage(cv::Rect(Img1.cols, 0, Img1.cols, Img1.rows)));

			imshow("Image", BImage);
			int key = waitKey(10);
			if (key == 27)
				break;
		}
	}

	delete[]allNearestKeyFrames, delete[]VideoInfo, delete[]allVrFid;
	return 0;
}
int SemanticVisualHull(char *Path, vector<int> &sCams, int startF, int stopF, int increF, int distortionCorrected, int nViewPlus, double real2SfM, double cellSize, double *R_adjust, double *T_adjust, int debug)
{
	char Fname[512];
	sprintf(Fname, "%s/SemanticFusion", Path); makeDir(Fname);
	sprintf(Fname, "%s/SemanticFusion/VoxInfo", Path); makeDir(Fname);
	for (auto cid : sCams)
		sprintf(Fname, "%s/SemanticFusion/%d", Path, cid), makeDir(Fname);

	const int nJointsCOCO = 18;
	int nCams = *std::max_element(std::begin(sCams), std::end(sCams)) + 1;
	int *frameTimeStamp = new int[nCams];
	for (int ii = 0; ii < nCams; ii++)
		frameTimeStamp[ii] = 0.0;

	int selected; double fps, temp;
	sprintf(Fname, "%s/FMotionPriorSync.txt", Path);
	FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		while (fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp) != EOF)
			frameTimeStamp[selected] = round(temp);
		fclose(fp);
	}
	else
	{
		sprintf(Fname, "%s/FGeoSync.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			while (fscanf(fp, "%d %lf ", &selected, &temp) != EOF)
				frameTimeStamp[selected] = round(temp);
			fclose(fp);
		}
		else
		{
			double fps;
			sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				while (fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp) != EOF)
					frameTimeStamp[selected] = round(temp);
				fclose(fp);
			}
			else
				printLOG("Cannot load time stamp info. Assume no frame offsets!");
		}
	}
	//TriangulatePointsFromNonCorpusCameras(Path, sCams, frameTimeStamp, startF);

	//Get video data
	int maxW = 0, maxH = 0;
	VideoData *VideoInfo = new VideoData[nCams];
	for (auto cid : sCams)
		if (ReadVideoDataI(Path, VideoInfo[cid], cid, -1, -1) == 1)
			continue;

	int count = 0;
	Point3d centroid(0, 0, 0);
	for (auto cid : sCams)
	{
		for (int fid = startF; fid <= stopF; fid++)
		{
			CameraData *camI = VideoInfo[cid].VideoInfo;
			if (camI[fid].valid == 1)
			{
				maxW = max(maxW, camI[fid].width), maxH = max(maxH, camI[fid].height);
				centroid.x += camI[fid].camCenter[0], centroid.y += camI[fid].camCenter[1], centroid.z += camI[fid].camCenter[2];
				count++;
			}
		}
	}
	centroid.x /= count, centroid.y /= count, centroid.z /= count;

	double currentRadiusSize = 0;
	for (auto cid : sCams)
	{
		for (int fid = startF; fid <= stopF; fid++)
		{
			CameraData *camI = VideoInfo[cid].VideoInfo;
			if (camI[fid].valid == 1)
			{
				double dist = sqrt(pow(centroid.x - camI[fid].camCenter[0], 2) + pow(centroid.y - camI[fid].camCenter[1], 2) + pow(centroid.y - camI[fid].camCenter[2], 2));
				if (dist > currentRadiusSize)
					currentRadiusSize = dist;
			}
		}
	}
	cellSize = cellSize / real2SfM;
	int nstep = (int)(currentRadiusSize / cellSize + 0.5);
	Point3i dim = Point3i(2 * nstep + 1, nstep + 1, 2 * nstep + 1);
	dim.x = 2 * (dim.x / 4) + 1;  //make sure it is odd
	dim.z = 2 * (dim.z / 4) + 1;  //make sure it is odd
	dim.y = 2 * (dim.y / 12) + 1;  //make sure it is odd
	printLOG("Volume size: %dx%dx%d\n", dim.x, dim.y, dim.z);

	int interpAlgo = -1;//shifted linear
	Mat cvImg;
	double *P = new double[12 * nCams];
	bool *HasMask = new bool[nCams];
	unsigned char *Mask = new unsigned char[maxH*maxW];
	unsigned char *AllMask = new unsigned char[maxH*maxW*nCams];
	unsigned char *CleanedAllMask = new unsigned char[maxH*maxW*nCams];
	double *Para = new double[maxW*maxH];
	double *AllRayDir = new double[3 * nCams];
	bool *VTvalid = new bool[dim.x*dim.y*dim.z];
	int *VTcolor = new int[dim.x*dim.y*dim.z];
	Point2f *AllMapXY = new Point2f[maxW*maxH*nCams];
	vector<Point2i> *AllHitVertices = new vector<Point2i>[nCams];

	for (int fid = startF; fid <= stopF; fid += increF)
	{
		printLOG("(%d: ", fid);
		double startTime = omp_get_wtime();

		int nValid = 0;
		for (auto cid : sCams)
		{
			int localFid = fid - frameTimeStamp[cid];
			HasMask[cid] = false;
			CameraData *camI = VideoInfo[cid].VideoInfo;
			if (camI[localFid].valid != 1)
				continue;

			sprintf(Fname, "%s/Seg/%d/%.4d.png", Path, cid, localFid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/Seg/%d/%.4d.jpg", Path, cid, localFid);
				if (IsFileExist(Fname) == 0)
					continue;
			}
			cvImg = imread(Fname, 0);

			int width = cvImg.cols, height = cvImg.rows;
			unsigned char *iMask = AllMask + maxW * maxH*cid, *iCleanedMask = CleanedAllMask + maxW * maxH*cid;
			for (int ii = 0; ii < width*height; ii++)
				iMask[ii] = cvImg.data[ii], iCleanedMask[ii] = 0;

			Point2f *iMapXY = AllMapXY + maxW * maxH*cid;
			for (int jj = 0; jj < height; jj++)
				for (int ii = 0; ii < width; ii++)
					iMapXY[ii + jj * width] = Point2f(ii, jj);

			if (distortionCorrected == 0)
			{
				if (camI[localFid].LensModel == RADIAL_TANGENTIAL_PRISM)
					LensDistortionPoint(iMapXY, camI[localFid].K, camI[localFid].distortion, width*height);
				else if (camI[localFid].LensModel == FISHEYE)
					FishEyeDistortionPoint(iMapXY, camI[localFid].K, camI[localFid].distortion[0], width*height);

				Generate_Para_Spline(iMask, Para, width, height, interpAlgo);

				double S[3];
				for (int jj = 0; jj < height; jj++)
				{
					for (int ii = 0; ii < width; ii++)
					{
						Point2f ImgPt = iMapXY[ii + jj * width];
						if (ImgPt.x < 0 || ImgPt.x > width - 1 || ImgPt.y<0.0 || ImgPt.y > height - 1)
							iMask[ii + jj * width] = (unsigned char)0;
						else
						{
							Get_Value_Spline(Para, width, height, ImgPt.x, ImgPt.y, S, -1, interpAlgo);
							iMask[ii + jj * width] = (unsigned char)(min(max(S[0], 0.0), 255.0) + 0.5);
						}
					}
				}

				/*sprintf(Fname, "%s/%d/%.4d.png", Path, cid, localFid);
				if (IsFileExist(Fname) == 0)
				{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, localFid);
				if (IsFileExist(Fname) == 0)
				continue;
				}
				cvImg = imread(Fname, 0);
				Generate_Para_Spline(cvImg.data, Para, width, height, interpAlgo);
				for (int jj = 0; jj < height; jj++)
				{
				for (int ii = 0; ii < width; ii++)
				{
				Point2f ImgPt = iMapXY[ii + jj*width];
				if (ImgPt.x < 0 || ImgPt.x > width - 1 || ImgPt.y<0.0 || ImgPt.y > height - 1)
				cvImg.data[ii + jj*width] = (unsigned char)0;
				else
				{
				Get_Value_Spline(Para, width, height, ImgPt.x, ImgPt.y, S, -1, interpAlgo);
				cvImg.data[ii + jj*width] = (unsigned char)(min(max(S[0], 0.0), 255.0) + 0.5);
				}
				}
				}
				sprintf(Fname, "%s/%d/_%.4d.png", Path, cid, localFid);
				imwrite(Fname, cvImg);*/
			}

			double *rayDir = AllRayDir + 3 * cid;
			double principal[] = { camI[localFid].intrinsic[3], camI[localFid].intrinsic[4], 1.0 };
			getRayDir(rayDir, camI[localFid].invK, camI[localFid].R, principal);

			AllHitVertices[cid].clear();
			HasMask[cid] = true;
			nValid++;
		}
		printLOG("(%.1fs... ", omp_get_wtime() - startTime);
		if (nValid < 2)
			continue;

		startTime = omp_get_wtime();

		int dimxy = dim.x*dim.y, hx = dim.x / 2, hy = dim.y / 2, hz = dim.z / 2, hx2 = hx * hx;
		omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic,1)
		for (int kk = -hz; kk <= hz; kk++)
		{
			vector<Point2i> vPt;
			vector<int> vcolors, ucolors, colorCount(255);
			for (int jj = -hy; jj <= hy; jj++)
			{
				for (int ii = -hx; ii <= hx; ii++)
				{
					VTvalid[ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy] = 0;
					if (ii*ii + kk * kk > hx2)
						continue;

					Point3d cellLoc;
					if (R_adjust != NULL && T_adjust != NULL)
					{
						double after[3], org[3] = { cellSize *ii, cellSize *jj, cellSize *kk };
						mat_mul(R_adjust, org, after, 3, 3, 1);
						cellLoc = Point3d(after[0], after[1], after[2]) + centroid + Point3d(T_adjust[0], T_adjust[1], T_adjust[2]);
					}
					else
						cellLoc = Point3d(ii, jj, kk)*cellSize + centroid;

					Point2d projectedPt;
					vcolors.clear(), ucolors.clear(), vPt.clear();

					for (auto cid : sCams)
					{
						int localFid = fid - frameTimeStamp[cid];
						CameraData *camI = VideoInfo[cid].VideoInfo;
						if (!camI[localFid].valid || !HasMask[cid])
						{
							vcolors.push_back(-1);
							vPt.push_back(Point2i(0, 0));
							continue;
						}

						double direction[3] = { cellLoc.x - camI[localFid].camCenter[0], cellLoc.y - camI[localFid].camCenter[1], cellLoc.z - camI[localFid].camCenter[1] };
						double *rayDir = AllRayDir + 3 * cid;
						double dot = dotProduct(rayDir, direction);
						if (dot < 0) //behind the camera
						{
							vcolors.push_back(-1);
							vPt.push_back(Point2i(0, 0));
							continue;
						}

						ProjectandDistort(cellLoc, &projectedPt, camI[localFid].P, NULL, NULL); //approx is fine for this task
																								//if (camI[localFid].ShutterModel == ROLLING_SHUTTER)
																								//{
																								//	ProjectandDistort(cellLoc, &projectedPt, camI[localFid].P, NULL, NULL);
																								//	if (projectedPt.x <0 || projectedPt.y <0 || projectedPt.x > camI[localFid].width - 1 || projectedPt.y > camI[localFid].height - 1)
																								//	{
																								//		vcolors.push_back(-1);
																								//		vPt.push_back(Point2i(0, 0));
																								//		continue;
																								//	}
																								//	CayleyProjection(camI[localFid].intrinsic, camI[localFid].rt, camI[localFid].wt, projectedPt, cellLoc, camI[localFid].width, camI[localFid].height);
																								//}
																								//else
																								//	ProjectandDistort(cellLoc, &projectedPt, camI[localFid].P, NULL, NULL);

						if (projectedPt.x <0 || projectedPt.y <0 || projectedPt.x > camI[localFid].width - 1 || projectedPt.y > camI[localFid].height - 1)
						{
							vcolors.push_back(-1);
							vPt.push_back(Point2i(0, 0));
							continue;
						}

						int color = (int)AllMask[(int)projectedPt.x + (int)projectedPt.y*camI[localFid].width + maxW * maxH*cid];
						if (color == 0) //background
						{
							vcolors.push_back(-1);
							vPt.push_back(Point2i(0, 0));
							continue;
						}

						vcolors.push_back(color), ucolors.push_back(color), vPt.push_back(Point2i(projectedPt.x, projectedPt.y));
					}

					sort(ucolors.begin(), ucolors.end());
					std::vector<int>::iterator it = unique(ucolors.begin(), ucolors.end());
					ucolors.resize(std::distance(ucolors.begin(), it));
					int ncolors = (int)ucolors.size();
					if (ncolors == 0)
						continue;

					int BestCount = 0, bestId = -1;
					for (int mm = 0; mm < ncolors; mm++)
					{
						colorCount[mm] = 0;
						for (int nn = 0; nn < (int)sCams.size(); nn++)
						{
							if (vcolors[nn] == -1)
								continue;
							colorCount[mm]++;
						}
						if (BestCount < colorCount[mm])
							BestCount = colorCount[mm], bestId = mm;
					}

					if (BestCount > nViewPlus)
					{
						for (int nn = 0; nn < (int)sCams.size(); nn++)
						{
							if (vcolors[nn] == ucolors[bestId])
							{
								int cid = sCams[nn], localFid = fid - frameTimeStamp[cid], width = VideoInfo[cid].VideoInfo[localFid].width;
								if (AllMask[sCams[nn] * maxW*maxH + vPt[nn].x + vPt[nn].y* width] > 0)
								{
									Point2f *iMapXY = AllMapXY + maxW * maxH*cid;
									Point2i ImgPt(iMapXY[vPt[nn].x + vPt[nn].y*width].x, iMapXY[vPt[nn].x + vPt[nn].y*width].y);
									CleanedAllMask[sCams[nn] * maxW*maxH + ImgPt.x + ImgPt.y* width] = ucolors[bestId]; //let's get the mask in the distorted image

#pragma omp critical
									AllHitVertices[cid].push_back(ImgPt);
								}
							}
						}

						VTvalid[ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy] = 1;
						VTcolor[ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy] = ucolors[bestId];
					}
				}
			}
		}
		printLOG("(%.1fs)... ", omp_get_wtime() - startTime);

		startTime = omp_get_wtime();
		for (auto cid : sCams)
		{
			int localFid = fid - frameTimeStamp[cid];
			if (!HasMask[cid])
				continue;

			vector<Point2f> vpt;
			for (int ii = 0; ii < AllHitVertices[cid].size(); ii++)
				vpt.push_back(Point2f(AllHitVertices[cid][ii].x, AllHitVertices[cid][ii].y));

			CameraData *camI = VideoInfo[cid].VideoInfo;
			int width = camI[localFid].width, height = camI[localFid].height;
			Rect rect(0, 0, width, height);

			Subdiv2D subdiv(rect);
			for (size_t ii = 0; ii < vpt.size(); ii++)
				subdiv.insert(vpt[ii]);

			vector<Vec6f> triangleList;
			subdiv.getTriangleList(triangleList);

			for (int ii = 0; ii < width*height; ii++)
				Mask[ii] = CleanedAllMask[cid * maxW*maxH + ii];

			int smalledgeThresh = (int)(10.0*width / 1920 + 0.5); //10 pixel
			for (size_t ii = 0; ii < triangleList.size(); ii++)
			{
				Vec6f t = triangleList[ii];
				Point2i pt1(t[0], t[1]), pt2(t[2], t[3]), pt3(t[4], t[5]);
				if (norm(pt1 - pt2) > smalledgeThresh)
					continue;
				if (norm(pt1 - pt3) > smalledgeThresh)
					continue;
				if (norm(pt2 - pt3) > smalledgeThresh)
					continue;

				if (CleanedAllMask[cid * maxW*maxH + pt1.x + pt1.y* width] > 0 &&
					CleanedAllMask[cid * maxW*maxH + pt1.x + pt1.y* width] == CleanedAllMask[cid * maxW*maxH + pt2.x + pt2.y* width] &&
					CleanedAllMask[cid * maxW*maxH + pt1.x + pt1.y* width] == CleanedAllMask[cid * maxW*maxH + pt3.x + pt3.y* width] &&
					CleanedAllMask[cid * maxW*maxH + pt2.x + pt2.y* width] == CleanedAllMask[cid * maxW*maxH + pt3.x + pt3.y* width])
				{
					int minx = min(min(pt1.x, pt2.x), pt3.x), maxx = max(max(pt1.x, pt2.x), pt3.x);
					int miny = min(min(pt1.y, pt2.y), pt3.y), maxy = max(max(pt1.y, pt2.y), pt3.y);
					for (int x = minx; x <= maxx; x++)
						for (int y = miny; y <= maxy; y++)
							if (PointInTriangle(pt1, pt2, pt3, Point2f(x, y)))
								Mask[x + y * width] = CleanedAllMask[cid * maxW*maxH + pt1.x + pt1.y* width];
				}
			}

			sprintf(Fname, "%s/SemanticFusion/%d/%.4d.png", Path, cid, localFid);
			SaveDataToImage(Fname, Mask, VideoInfo[cid].VideoInfo[localFid].width, VideoInfo[cid].VideoInfo[localFid].height);
		}
		printLOG("(%.1fs)... ", omp_get_wtime() - startTime);

		if (debug == 1)
		{
			sprintf(Fname, "%s/SemanticFusion/VoxInfo/%.4d.txt", Path, fid); fp = fopen(Fname, "w+");
			if (R_adjust != NULL && T_adjust != NULL)
			{
				fprintf(fp, "1");//offset given
				for (int ii = 0; ii < 9; ii++)
					fprintf(fp, "%16f ", R_adjust[ii]);
				for (int ii = 0; ii < 3; ii++)
					fprintf(fp, "%16f ", T_adjust[ii]);
			}
			else
				fprintf(fp, "0");//offset not given
			fprintf(fp, "%.16f %.16f %.16f %.16f\n", centroid.x, centroid.y, centroid.z, cellSize);
			fprintf(fp, "%d %d %d\n", hx, hy, hz);
			for (int kk = -hz; kk <= hz; kk++)
				for (int jj = -hy; jj <= hy; jj++)
					for (int ii = -hx; ii <= hx; ii++)
						if (VTvalid[ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy])
							fprintf(fp, "%d %d %d %d\n", ii, jj, kk, VTcolor[ii + hx + (jj + hy)*dim.x + (kk + hz)*dimxy]);
			fclose(fp);
		}
	}

	delete[]VTvalid, delete[]VTcolor;
	delete[]HasMask, delete[]AllMask, delete[]CleanedAllMask, delete[]Para, delete[] VideoInfo, delete[] P;

	return 0;
}

//People assocation
int TrackBody_Landmark_BiDirectLK(char *Path, int cid, int startF, int stopF, int increF, int nJoints, double bwThresh, int debug)
{
	double confThresh = 0.1;
	char Fname[512]; FILE *fp = 0;
	sprintf(Fname, "%s/Logs/TrackBody_Landmark_BiDirectLK_%d_%.4d_%4d.txt", Path, cid, startF, stopF);
	sprintf(Fname, "%s/Vis", Path); makeDir(Fname);
	sprintf(Fname, "%s/Vis/TrackBody_LM", Path); makeDir(Fname);
	if (debug > 1)
		sprintf(Fname, "%s/Vis/TrackBody_LM/%d", Path, cid), makeDir(Fname);

	printLOG("\n\nWorking on %d LM body track: ", cid);
	if (IsFileExist(Fname) == 1)
	{
		printLOG("%s computed\n", Fname);
		//return 0;
	}
	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));

	double bwThresh2 = bwThresh * bwThresh;
	int winSizeI = 31, cvPyrLevel = 5;
	vector<float> err;
	vector<uchar> status;
	Size winSize(winSizeI, winSizeI);
	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 30, 0.01);

	//namedWindow("X", CV_WINDOW_NORMAL);
	//cvSetWindowProperty("X", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);

	Mat Img1, Img2, cImg1, cImg2, bImg, bImg2;
	vector<Point2f> lm1, lm2, lm1_, lm2_; Point2f tl, br, tl2, br2;
	vector<float> vs1, vs2;
	vector<Mat> Img1Pyr, Img2Pyr; vector<Mat> vImg(2);

	sprintf(Fname, "%s/%d/%.4d.png", Path, cid, startF);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, startF);
		if (IsFileExist(Fname) == 0)
			return 1;
	}
	Img1 = imread(Fname, 0);
	buildOpticalFlowPyramid(Img1, Img1Pyr, winSize, cvPyrLevel, false);

	float u, v, s; lm1.clear(), vs1.clear();
	if (readOpenPoseJson(Path, cid, startF, lm1, vs1) == 0)
	{
		sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, startF); fp = fopen(Fname, "r");
		if (fp == NULL)
			return 1;
		while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
			lm1.push_back(Point2f(u, v)), vs1.push_back(s);
		fclose(fp);
	}

	VideoWriter writer;
	int  firstTime = 1; double resizeFactor = 0.25;
	CvSize size; size.width = (int)(resizeFactor*Img1.cols * 2), size.height = (int)(resizeFactor*Img1.rows);
	sprintf(Fname, "%s/Vis/TrackBody_LM/%d_%d_%d.avi", Path, cid, startF, stopF), writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);

	sprintf(Fname, "%s/%d/flowgraph_FromLandmark_%d_%d_%d.txt", Path, cid, startF, stopF, nJoints); FILE *fpOut = fopen(Fname, "w");
	for (int fid = startF + 1; fid < stopF; fid++)
	{
		printLOG("%d..", fid);
		sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid);
		if (IsFileExist(Fname) == 0)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid);
			if (IsFileExist(Fname) == 0)
				continue;
		}
		Img2 = imread(Fname, 0);
		buildOpticalFlowPyramid(Img2, Img2Pyr, winSize, cvPyrLevel, false);

		lm2.clear(), vs2.clear();
		if (readOpenPoseJson(Path, cid, fid, lm2, vs2) == 0)
		{
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, fid); fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				lm2.push_back(Point2f(u, v)), vs2.push_back(s);
			fclose(fp);
		}

		if (lm2.size() == 0)
		{
			lm1.clear();
			continue;
		}
		if (lm1.size() == 0) //no data
		{
			swap(lm1, lm2), swap(vs1, vs2), swap(Img1, Img2), swap(Img1Pyr, Img2Pyr);
			continue;
		}

		lm2_ = lm1, lm1_ = lm2;
		calcOpticalFlowPyrLK(Img1Pyr, Img2Pyr, lm1, lm2_, status, err, winSize, cvPyrLevel, termcrit);
		vector<float> flowrange;
		for (int ii = 0; ii < lm1.size(); ii++)
		{
			float dist = sqrt(pow(lm1[ii].x - lm2_[ii].x, 2) + pow(lm1[ii].y - lm2_[ii].y, 2));
			flowrange.push_back(dist);
		}
		calcOpticalFlowPyrLK(Img2Pyr, Img1Pyr, lm2, lm1_, status, err, winSize, cvPyrLevel, termcrit);
		vector<float> flowrange2;
		for (int ii = 0; ii < lm2.size(); ii++)
		{
			float dist = sqrt(pow(lm1_[ii].x - lm2[ii].x, 2) + pow(lm1_[ii].y - lm2[ii].y, 2));
			flowrange2.push_back(dist);
		}

		int npid1 = lm1.size() / nJoints, npid2 = lm2.size() / nJoints;
		vector<int> association(npid1), used(npid2);
		for (int pid1 = 0; pid1 < npid1; pid1++)
		{
			int nvalidJoints = 0;
			for (int jid = 0; jid < nJoints; jid++)
			{
				if (lm1[pid1*nJoints + jid].x > 0 && vs1[jid + pid1 * nJoints] > 0.2)  //bad detection
					nvalidJoints++;
			}
			if (nvalidJoints < nJoints / 3)  //let's be conservative about occlusion
			{
				association[pid1] = -1;
				continue;
			}

			/*tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
			for (size_t jid = 0; jid < nJoints; jid++)
			if (lm1[pid1*nJoints + jid].x > 0)
			tl.x = min(tl.x, lm1[pid1*nJoints + jid].x), tl.y = min(tl.y, lm1[pid1*nJoints + jid].y), br.x = max(br.x, lm1[pid1*nJoints + jid].x), br.y = max(br.y, lm1[pid1*nJoints + jid].y);
			Mat xxx = Img1.clone(); cvtColor(xxx, xxx, CV_GRAY2BGR);
			rectangle(xxx, tl, br, colors[pid1], 8, 8, 0); 	imwrite("G:/Snow/1.png", xxx);*/

			int bestAssignment = -1, best = 0;
			for (int pid2 = 0; pid2 < npid2; pid2++)
			{
				nvalidJoints = 0;
				for (int jid = 0; jid < nJoints; jid++)
					if (lm2[pid2*nJoints + jid].x > 0 && vs2[jid + pid2 * nJoints] > confThresh)  //bad detection
						nvalidJoints++;
				if (nvalidJoints < nJoints / 3)  //let's be conservative about occlusion
					continue;

				/*tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (size_t jid = 0; jid < nJoints; jid++)
				if (lm2[pid2*nJoints + jid].x > 0)
				tl.x = min(tl.x, lm2[pid2*nJoints + jid].x), tl.y = min(tl.y, lm2[pid2*nJoints + jid].y), br.x = max(br.x, lm2[pid2*nJoints + jid].x), br.y = max(br.y, lm2[pid2*nJoints + jid].y);
				Mat xxx = Img2.clone(); cvtColor(xxx, xxx, CV_GRAY2BGR);
				rectangle(xxx, tl, br, colors[pid1], 8, 8, 0); imwrite("G:/Snow/2.png", xxx);*/

				int good = 0;
				double dist1, dist2;
				for (int jid = 0; jid < nJoints; jid++)
				{
					if (lm1[pid1 * nJoints + jid].x > 0 && lm2[pid2 * nJoints + jid].x > 0)
					{
						Point2f p1 = lm1[pid1 * nJoints + jid], p2 = lm2[pid2 * nJoints + jid];
						Point2f p1_ = lm2_[pid1 * nJoints + jid], p2_ = lm2_[pid1 * nJoints + jid];
						dist1 = pow(lm2_[pid1 * nJoints + jid].x - lm2[pid2 * nJoints + jid].x, 2) + pow(lm2_[pid1 * nJoints + jid].y - lm2[pid2 * nJoints + jid].y, 2);
						dist2 = pow(lm1[pid1 * nJoints + jid].x - lm1_[pid2 * nJoints + jid].x, 2) + pow(lm1[pid1 * nJoints + jid].y - lm1_[pid2 * nJoints + jid].y, 2);
						if (dist1 < bwThresh2 && dist2 < bwThresh2)
							good++;
					}
				}
				if (good > best)
					best = good, bestAssignment = pid2;
			}
			if (best >= nJoints / 3 && used[bestAssignment] == 0) //Let's be conservative at this point
				association[pid1] = bestAssignment, used[bestAssignment] = 1;  //establish link.
			else
				association[pid1] = -1;
		}

		if (debug > 0)//Visualization: draw assocation
		{
			vImg[0] = Img1.clone(), vImg[1] = Img2.clone();
			cvtColor(vImg[0], vImg[0], CV_GRAY2BGR), cvtColor(vImg[1], vImg[1], CV_GRAY2BGR);

			for (int pid1 = 0; pid1 < npid1; pid1++)
			{
				int nvalidJoints = 0;
				for (int jid = 0; jid < nJoints; jid++)
					if (lm1[pid1*nJoints + jid].x > 0)
						nvalidJoints++;
				if (nvalidJoints < 5)
					continue;

				tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (size_t jid = 0; jid < nJoints; jid++)
					if (lm1[pid1*nJoints + jid].x > 0)
						tl.x = min(tl.x, lm1[pid1*nJoints + jid].x), tl.y = min(tl.y, lm1[pid1*nJoints + jid].y), br.x = max(br.x, lm1[pid1*nJoints + jid].x), br.y = max(br.y, lm1[pid1*nJoints + jid].y);
				rectangle(vImg[0], tl, br, colors[pid1 % 9], 8, 8, 0);
				sprintf(Fname, "%d", pid1), putText(vImg[0], Fname, Point2i(tl.x, br.y - vImg[0].cols / 60), CV_FONT_HERSHEY_SIMPLEX, 1.0*vImg[0].cols / 640, colors[pid1 % 9], 3);
				Draw2DCoCoJoints(vImg[0], &lm1[pid1*nJoints], nJoints, 1.0*vImg[1].cols / 640);

				int associated = association[pid1];
				if (associated > -1)
				{
					tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
					for (size_t jid = 0; jid < nJoints; jid++)
						if (lm2[associated*nJoints + jid].x > 0)
							tl.x = min(tl.x, lm2[associated*nJoints + jid].x), tl.y = min(tl.y, lm2[associated*nJoints + jid].y), br.x = max(br.x, lm2[associated*nJoints + jid].x), br.y = max(br.y, lm2[associated*nJoints + jid].y);
					rectangle(vImg[1], tl, br, colors[pid1 % 9], 8, 8, 0);
					sprintf(Fname, "%d", pid1), putText(vImg[1], Fname, Point2i(tl.x, br.y - vImg[0].cols / 60), CV_FONT_HERSHEY_SIMPLEX, 1.0*vImg[1].cols / 640, colors[pid1 % 9], 3);
					Draw2DCoCoJoints(vImg[1], &lm2[associated*nJoints], nJoints, 1.0*vImg[1].cols / 640);
				}
			}
			bImg = DrawTitleImages(vImg, 2.0);
			CvPoint text_origin = { bImg.rows / 20, bImg.cols / 20 };
			sprintf(Fname, "%d", fid - 1), putText(bImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*bImg.cols / 640, colors[0], 3);
			//imshow("X", bImg); waitKey(1);
			resize(bImg, bImg2, Size(resizeFactor* bImg.cols, resizeFactor*bImg.rows), 0, 0, INTER_AREA);
			writer << bImg2;
			if (debug > 1)
				sprintf(Fname, "%s/Vis/TrackBody_LM/%d/%.4d.jpg", Path, cid, fid - 1), imwrite(Fname, bImg2);
		}

		//write out data
		fprintf(fpOut, "%d %d ", fid - 1, association.size());
		for (auto asso : association)
			fprintf(fpOut, "%d ", asso);
		fprintf(fpOut, "\n");

		swap(lm1, lm2), swap(vs1, vs2), swap(Img1, Img2), swap(Img1Pyr, Img2Pyr);
	}
	fclose(fpOut);

	if (debug > 0)
		writer.release();

	sprintf(Fname, "%s/Logs/TrackBody_Landmark_BiDirectLK_%d_%.4d_%4d.txt", Path, cid, startF, stopF);
	fp = fopen(Fname, "w"); fclose(fp);

	return 0;
}
int TrackBody_SmallFeat_BiDirectLK(char *Path, int cid, int startF, int stopF, int increF, double biDirectThresh, double ConsistencyercentThresh, double overlapA_thresh, int debug)
{
	const int nJoints = 25;
	double confThresh = 0.1;
	char Fname[512]; FILE *fp = 0;
	sprintf(Fname, "%s/Logs/TrackLandmarkLK_%d_%d_%.4d_%4d.txt", Path, cid, increF, startF, stopF);
	if (IsFileExist(Fname) == 1)
	{
		printLOG("%s computed\n", Fname);
		//return 0;
	}

	printLOG("\n\nWorking on %d feature body track: ", cid);
	sprintf(Fname, "%s/Vis", Path); makeDir(Fname);
	sprintf(Fname, "%s/Vis/TrackBody_SmallFeat", Path); makeDir(Fname);
	if (debug > 1)
		sprintf(Fname, "%s/Vis/TrackBody_SmallFeat/%d", Path, cid), makeDir(Fname);

	struct TL_BR {
		Point2i tl, br;
	};
	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));

	int winSizeI = 31, cvPyrLevel = 5;
	vector<float> err;
	vector<uchar> status;
	Size winSize(winSizeI, winSizeI);
	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 30, 0.01);
	vector<int> LegTorsoJoints, TorsoJoints;  //torso and legs only. Don't want to get points not on the body
	LegTorsoJoints.push_back(1), LegTorsoJoints.push_back(2), LegTorsoJoints.push_back(5), LegTorsoJoints.push_back(8), LegTorsoJoints.push_back(9), LegTorsoJoints.push_back(10), LegTorsoJoints.push_back(11), LegTorsoJoints.push_back(12), LegTorsoJoints.push_back(13);
	TorsoJoints.push_back(1), TorsoJoints.push_back(2), TorsoJoints.push_back(5), TorsoJoints.push_back(8), TorsoJoints.push_back(11); //torso only

	float u, v, s; Point2f tl, br, tl2, br2;
	Mat Img1, Img2, cImg1, cImg2, cbImg, bImg, bImg2;
	vector<Point2f> tpts1, tpts2, pts1, pts2, pts1_, lm1, lm2;
	vector<float> vs1, vs2;
	vector<Mat> Img1Pyr, Img2Pyr, vImg(2);
	int nInBB2Hist[100], BoxId[100];

	sprintf(Fname, "%s/%d/%.4d.png", Path, cid, startF); Img1 = imread(Fname, 0);
	if (Img1.empty() == 1)
	{
		sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, startF); Img1 = imread(Fname, 0);
		if (Img1.empty() == 1)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
	}
	biDirectThresh = biDirectThresh * Img1.cols / 1920;
	double biDirectThresh2 = biDirectThresh * biDirectThresh;

	lm1.clear(), vs1.clear();

	if (readOpenPoseJson(Path, cid, startF, lm1, vs1) == 0)
	{
		sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, startF); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
			lm1.push_back(Point2f(u, v)), vs1.push_back(s);
		fclose(fp);
	}

	cv::buildOpticalFlowPyramid(Img1, Img1Pyr, winSize, cvPyrLevel, false);

	vector<Point3f> DoG; DoG.reserve(10000); vector<float> radius;
	for (int pid = 0; pid < lm1.size() / nJoints; pid++) 	//remove points outside the detected person bb
	{
		int nvalidJoints = 0;
		for (int jid = 0; jid < nJoints; jid++)
			if (lm1[pid*nJoints + jid].x > 0 && vs1[pid*nJoints + jid] > confThresh)
				nvalidJoints++;
		if (nvalidJoints < 5)
			continue;

		tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
		for (auto jid : LegTorsoJoints)
			if (lm1[pid*nJoints + jid].x > 0)
				tl.x = min(tl.x, lm1[pid*nJoints + jid].x), tl.y = min(tl.y, lm1[pid*nJoints + jid].y), br.x = max(br.x, lm1[pid*nJoints + jid].x), br.y = max(br.y, lm1[pid*nJoints + jid].y);
		br.x = min(br.x, Img1.cols - 1), br.y = min(br.y, Img1.rows - 1);
		if (br.x - tl.x < Img1.rows / 20 || br.y - tl.y < Img1.rows / 20) //very small window, skip it
			continue;
		cv::Rect rect(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
		DoG.clear();  Mat tmat = Img1(rect);
		vl_DoG(tmat, DoG);
		for (auto dog : DoG)
			pts1.push_back(Point2f(dog.x + tl.x, dog.y + tl.y)), radius.push_back(dog.z);
	}


	//cvSetWindowProperty("X", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
	double resizeFactor = 0.5;
	VideoWriter writer;
	CvSize size; size.width = (int)(resizeFactor*Img1.cols * 2), size.height = (int)(resizeFactor*Img1.rows);
	if (debug > 0)
		sprintf(Fname, "%s/Vis/TrackBody_SmallFeat/%d_%d_%d.avi", Path, cid, startF, stopF), writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);

	sprintf(Fname, "%s/%d/flowgraph_FromLocalFeat_%d_%d.txt", Path, cid, startF, stopF);  FILE *fpOut = fopen(Fname, "w");
	for (int fid = startF + 1; fid <= stopF - 1; fid++)
	{
		printLOG("%d..", fid);
		sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid); Img2 = imread(Fname, 0);
		if (Img2.empty() == 1)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid); Img2 = imread(Fname, 0);
			if (Img2.empty() == 1)
			{
				printLOG("Cannot load %s\n", Fname);
				continue;
			}
		}
		lm2.clear(), vs2.clear();
		if (readOpenPoseJson(Path, cid, fid, lm2, vs2) == 0)
		{
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, cid, fid); fp = fopen(Fname, "r");
			if (fp == NULL)
			{
				printLOG("Cannot load %s\n", Fname);
				continue;
			}
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				lm2.push_back(Point2f(u, v)), vs2.push_back(s);
			fclose(fp);
		}

		vector<TL_BR> vbb2, vbb2_torso_only;
		for (int pid2 = 0; pid2 < lm2.size() / nJoints; pid2++)
		{
			tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
			for (auto jid : LegTorsoJoints)
				if (lm2[pid2*nJoints + jid].x > 0) //&& vs2[pid2*nJoints + jid] > confThresh) : not needed since there is a area overlapping check
					tl.x = min(tl.x, lm2[pid2*nJoints + jid].x), tl.y = min(tl.y, lm2[pid2*nJoints + jid].y), br.x = max(br.x, lm2[pid2*nJoints + jid].x), br.y = max(br.y, lm2[pid2*nJoints + jid].y);
			br.x = min(br.x, Img1.cols - 1), br.y = min(br.y, Img1.rows - 1);
			TL_BR bb;
			if (br.x - tl.x < Img1.rows / 20 || br.y - tl.y < Img1.rows / 20)
				bb.tl = Point2f(0, 0), bb.br = Point2f(0, 0), vbb2.push_back(bb);
			else
				bb.tl = tl, bb.br = br, vbb2.push_back(bb);

			tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
			for (auto jid : TorsoJoints)
				if (lm2[pid2*nJoints + jid].x > 0) //&& vs2[pid2*nJoints + jid] > confThresh) : not needed since there is a area overlapping check
					tl.x = min(tl.x, lm2[pid2*nJoints + jid].x), tl.y = min(tl.y, lm2[pid2*nJoints + jid].y), br.x = max(br.x, lm2[pid2*nJoints + jid].x), br.y = max(br.y, lm2[pid2*nJoints + jid].y);
			br.x = min(br.x, Img1.cols - 1), br.y = min(br.y, Img1.rows - 1);
			if (br.x - tl.x < Img1.rows / 20 || br.y - tl.y < Img1.rows / 20)
				bb.tl = Point2f(0, 0), bb.br = Point2f(0, 0), vbb2_torso_only.push_back(bb);
			else
				bb.tl = tl, bb.br = br, vbb2_torso_only.push_back(bb);
		}
		if (vbb2.size() == 0 || vbb2_torso_only.size() == 0)
		{
			pts1.clear(), Img1Pyr.clear(), lm1.clear(), vs1.clear();
			continue;
		}

		cv::buildOpticalFlowPyramid(Img2, Img2Pyr, winSize, cvPyrLevel, false);
		if (pts1.size() == 0) //compute pts1 to swap
		{
			//prepare data
			pts2.clear(), radius.clear();
			for (int pid = 0; pid < lm2.size() / nJoints; pid++)  //remove points outside the detected person bb
			{
				int nvalidJoints = 0;
				for (int jid = 0; jid < nJoints; jid++)
					if (lm2[pid*nJoints + jid].x > 0 && vs2[pid*nJoints + jid] > confThresh)
						nvalidJoints++;
				if (nvalidJoints < 5)
					continue;

				tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (auto jid : LegTorsoJoints)
					if (lm2[pid*nJoints + jid].x > 0 && vs2[pid*nJoints + jid] > confThresh)
						tl.x = min(tl.x, lm2[pid*nJoints + jid].x), tl.y = min(tl.y, lm2[pid*nJoints + jid].y), br.x = max(br.x, lm2[pid*nJoints + jid].x), br.y = max(br.y, lm2[pid*nJoints + jid].y);
				br.x = min(br.x, Img2.cols - 1), br.y = min(br.y, Img2.rows - 1);
				if (br.x - tl.x < Img2.rows / 20 || br.y - tl.y < Img2.rows / 20) //very small window, skip it
					continue;

				cv::Rect rect(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
				DoG.clear(); Mat tmat = Img2(rect); vl_DoG(tmat, DoG);
				for (auto dog : DoG)
					pts2.push_back(Point2f(dog.x + tl.x, dog.y + tl.y)), radius.push_back(dog.z);
			}
			swap(Img1, Img2), swap(Img1Pyr, Img2Pyr), swap(pts1, pts2), swap(lm1, lm2), swap(vs1, vs2);

			continue;
		}

		pts2 = pts1, pts1_ = pts1;
		cv::calcOpticalFlowPyrLK(Img1Pyr, Img2Pyr, pts1, pts2, status, err, winSize, cvPyrLevel, termcrit); //let try fix scale
		cv::calcOpticalFlowPyrLK(Img2Pyr, Img1Pyr, pts2, pts1_, status, err, winSize, cvPyrLevel, termcrit);

		/*Mat xxx = Img1.clone(); cvtColor(xxx, xxx, CV_GRAY2BGR);
		for (size_t ii = 0; ii < pts1.size(); ii++)
		circle(xxx, pts1[ii], 2.0, colors[ii % 9], 1);
		imwrite("C:/Data/Snow/1.png", xxx);

		xxx = Img2.clone(); cvtColor(xxx, xxx, CV_GRAY2BGR);
		for (size_t ii = 0; ii < pts2.size(); ii++)
		circle(xxx, pts2[ii], 2.0, colors[ii % 9], 1);
		imwrite("C:/Data/Snow/2.png", xxx);

		xxx = Img1.clone(); cvtColor(xxx, xxx, CV_GRAY2BGR);
		for (size_t ii = 0; ii < pts1_.size(); ii++)
		circle(xxx, pts1_[ii], 2.0, colors[ii % 9], 1);
		imwrite("C:/Data/Snow/3.png", xxx);*/

		//Check for bb1 with more than 40% (or 50%) more overlapping area
		vector<TL_BR> vbb1;
		for (int pid1 = 0; pid1 < lm1.size() / nJoints; pid1++)
		{
			TL_BR bb; tl = Point2f(9e9, 9e9), br = Point2f(0, 0);

			int nvalidJoints = 0;
			for (int jid = 0; jid < nJoints; jid++)
				if (lm1[pid1*nJoints + jid].x > 0)// && vs1[pid1*nJoints + jid] > confThresh)  not needed since there is a area overlapping check
					nvalidJoints++;
			if (nvalidJoints < 5)
			{
				bb.tl = Point2f(0, 0), bb.br = Point2f(0, 0), vbb1.push_back(bb);
				continue;
			}

			for (auto jid : LegTorsoJoints)
				if (lm1[pid1*nJoints + jid].x > 0)//&& vs1[pid1*nJoints + jid] > confThresh) not needed since there is a area overlapping check
					tl.x = min(tl.x, lm1[pid1*nJoints + jid].x), tl.y = min(tl.y, lm1[pid1*nJoints + jid].y), br.x = max(br.x, lm1[pid1*nJoints + jid].x), br.y = max(br.y, lm1[pid1*nJoints + jid].y);
			br.x = min(br.x, Img1.cols - 1), br.y = min(br.y, Img1.rows - 1);
			if (br.x - tl.x < Img1.rows / 20 || br.y - tl.y < Img1.rows / 20)
				bb.tl = Point2f(0, 0), bb.br = Point2f(0, 0), vbb1.push_back(bb);
			else
				bb.tl = tl, bb.br = br, vbb1.push_back(bb);
		}

		vector<int> ToDiscard1(vbb1.size());
		for (size_t jj = 0; jj < vbb1.size(); jj++)
		{
			double A_jj = (vbb1[jj].br.x - vbb1[jj].tl.x)*(vbb1[jj].br.y - vbb1[jj].tl.y);

			Point2f v1_jj = vbb1[jj].tl, v2_jj = Point2f(vbb1[jj].br.x, vbb1[jj].tl.y), v3_jj = vbb1[jj].br, v4_jj = Point2f(vbb1[jj].tl.x, vbb1[jj].br.y);
			for (size_t ii = 0; ii < vbb1.size(); ii++)
			{
				if (ii == jj)
					continue;
				double A_ii = (vbb1[ii].br.x - vbb1[ii].tl.x)*(vbb1[ii].br.y - vbb1[ii].tl.y);

				double oA = OverlappingArea(vbb1[jj].tl, vbb1[jj].br, vbb1[ii].tl, vbb1[ii].br);
				if (oA / A_jj > overlapA_thresh || oA / A_ii > overlapA_thresh)
				{
					ToDiscard1[jj] = 1;
					break;
				}
			}
		}

		/*{
		Mat xxx = Img1.clone(); cvtColor(xxx, xxx, CV_GRAY2BGR);
		for (size_t jj = 0; jj < vbb1.size(); jj++)
		rectangle(xxx, vbb1[jj].tl, vbb1[jj].br, colors[jj], 8, 8, 0);
		imwrite("C:/Data/Snow/6.png", xxx);

		xxx = Img2.clone(); cvtColor(xxx, xxx, CV_GRAY2BGR);
		for (size_t jj = 0; jj < vbb2.size(); jj++)
		rectangle(xxx, vbb2[jj].tl, vbb2[jj].br, colors[jj], 8, 8, 0);
		imwrite("C:/Data/Snow/7.png", xxx);
		}*/

		vector<int> ToDiscard2(vbb2.size());
		for (size_t jj = 0; jj < vbb2.size(); jj++)
		{
			double A_jj = (vbb2[jj].br.x - vbb2[jj].tl.x)*(vbb2[jj].br.y - vbb2[jj].tl.y);

			Point2f v1_jj = vbb2[jj].tl, v2_jj = Point2f(vbb2[jj].br.x, vbb2[jj].tl.y), v3_jj = vbb2[jj].br, v4_jj = Point2f(vbb2[jj].tl.x, vbb2[jj].br.y);
			for (size_t ii = 0; ii < vbb2.size(); ii++)
			{
				if (ii == jj)
					continue;
				double A_ii = (vbb2[ii].br.x - vbb2[ii].tl.x)*(vbb2[ii].br.y - vbb2[ii].tl.y);

				double oA = OverlappingArea(vbb2[jj].tl, vbb2[jj].br, vbb2[ii].tl, vbb2[ii].br);
				if (oA / A_jj > overlapA_thresh || oA / A_ii > overlapA_thresh)
				{
					ToDiscard2[jj] = 1;
					break;
				}
			}
		}

		//group points into person bb and check for bi-directional consistency
		vector<int> association;
		for (int pid1 = 0; pid1 < lm1.size() / nJoints; pid1++)
		{
			if (ToDiscard1[pid1] == 1) //remove overlapping regions
			{
				association.push_back(-1);
				continue;
			}

			int nvalidJoints = 0;
			for (int jid = 0; jid < nJoints; jid++)
				if (lm1[pid1*nJoints + jid].x > 0 && vs1[pid1*nJoints + jid] > confThresh)
					nvalidJoints++;
			if (nvalidJoints < 5)
			{
				association.push_back(-1);
				continue;
			}

			tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
			for (auto jid : LegTorsoJoints)
				if (lm1[pid1*nJoints + jid].x > 0)
					tl.x = min(tl.x, lm1[pid1*nJoints + jid].x), tl.y = min(tl.y, lm1[pid1*nJoints + jid].y), br.x = max(br.x, lm1[pid1*nJoints + jid].x), br.y = max(br.y, lm1[pid1*nJoints + jid].y);
			br.x = min(br.x, Img1.cols - 1), br.y = min(br.y, Img1.rows - 1);
			if (br.x - tl.x < Img1.rows / 20 || br.y - tl.y < Img1.rows / 20) //very small window, skip it
			{
				association.push_back(-1);
				continue;
			}
			double Area1 = (br.x - tl.x)*(br.y - tl.y);

			/*Mat xxx = Img1.clone(); cvtColor(xxx, xxx, CV_GRAY2BGR);
			rectangle(xxx, tl, br, colors[0], 8, 8, 0);
			for (size_t ii = 0; ii < pts1.size(); ii++)
			if (pts1[ii].x > tl.x && pts1[ii].x < br.x && pts1[ii].y>tl.y && pts1[ii].y <= br.y)
			circle(xxx, pts1[ii], 2.0*radius[ii], colors[ii % 9], 1);
			imwrite("C:/Data/Snow/4.png", xxx);*/

			int nTotalWithinBB1 = 0, nPassBidirect = 0;
			for (int ii = 0; ii < vbb2.size(); ii++)
				nInBB2Hist[ii] = 0, BoxId[ii] = ii;

			Point2f tl2 = Point2f(9e9, 9e9), br2 = Point2f(0, 0);
			for (size_t ii = 0; ii < pts1.size(); ii++)
			{
				if (pts1[ii].x > tl.x && pts1[ii].x < br.x && pts1[ii].y>tl.y && pts1[ii].y <= br.y)
				{
					double bidirecErr2 = pow(pts1[ii].x - pts1_[ii].x, 2) + pow(pts1[ii].y - pts1_[ii].y, 2);
					if (bidirecErr2 < biDirectThresh2)
					{
						bool found = false;
						for (size_t jj = 0; jj < vbb2.size() && !found; jj++) //does it lay on any of the bbs in frame 2?
						{
							if (ToDiscard2[jj] == 1)
								continue;
							if (pts2[ii].x > vbb2[jj].tl.x && pts2[ii].x<vbb2[jj].br.x && pts2[ii].y > vbb2[jj].tl.y && pts2[ii].y < vbb2[jj].br.y)
								nInBB2Hist[jj]--, found = true;
						}
						tl2.x = min(tl2.x, pts1[ii].x), tl2.y = min(tl2.y, pts1[ii].y), br2.x = max(br2.x, pts1[ii].x), br2.y = max(br2.y, pts1[ii].y);
						nPassBidirect++;
					}
					nTotalWithinBB1++;
				}
			}

			Quick_Sort_Int(nInBB2Hist, BoxId, 0, vbb2.size() - 1);
			if (vbb2.size() == 1)
			{
				if (-1.0*nInBB2Hist[0] / nTotalWithinBB1 > ConsistencyercentThresh)
					association.push_back(BoxId[0]);
				else
					association.push_back(-1);
			}
			else if (1.0*nInBB2Hist[0] / (-0.00001 + nInBB2Hist[1]) > 1.5) //in case of splitting, # in domimant splits still has to satisfy the consistency check
			{
				double inArea = (br2.x - tl2.x)*(br2.y - tl2.y);
				double Area2 = (vbb2[BoxId[0]].br.x - vbb2[BoxId[0]].tl.x)*(vbb2[BoxId[0]].br.y - vbb2[BoxId[0]].tl.y);
				if (inArea / Area1 < overlapA_thresh && inArea / Area2 < overlapA_thresh)
					association.push_back(-1);
				else
				{
					if (nTotalWithinBB1 >= 50 && -1.0*nInBB2Hist[0] / nTotalWithinBB1 > 0.5*ConsistencyercentThresh) //so many points, can lower the threshold
						association.push_back(BoxId[0]);
					else if (nTotalWithinBB1 < 50 && -1.0*nInBB2Hist[0] / nTotalWithinBB1 > ConsistencyercentThresh)
						association.push_back(BoxId[0]);
					else
						association.push_back(-1);
				}
			}
			else
				association.push_back(-1);

			if (association.back() == -1) //due to mis detection, legs could be missing, try torso only bb
			{
				tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (auto jid : TorsoJoints)
					if (lm1[pid1*nJoints + jid].x > 0 && vs1[pid1*nJoints + jid] > confThresh)
						tl.x = min(tl.x, lm1[pid1*nJoints + jid].x), tl.y = min(tl.y, lm1[pid1*nJoints + jid].y), br.x = max(br.x, lm1[pid1*nJoints + jid].x), br.y = max(br.y, lm1[pid1*nJoints + jid].y);
				br.x = min(br.x, Img1.cols - 1), br.y = min(br.y, Img1.rows - 1);
				/*Mat xxx = Img1.clone(); cvtColor(xxx, xxx, CV_GRAY2BGR);
				rectangle(xxx, tl, br, colors[0], 8, 8, 0);
				for (size_t ii = 0; ii < pts1.size(); ii++)
				if (pts1[ii].x > tl.x && pts1[ii].x < br.x && pts1[ii].y>tl.y && pts1[ii].y <= br.y)
				circle(xxx, pts1[ii], 2.0*radius[ii], colors[ii % 9], 1);
				imwrite("C:/Data/Snow/5.png", xxx);*/

				int nTotalWithinBB1 = 0, nPassBidirect = 0;
				for (int ii = 0; ii < vbb2.size(); ii++)
					nInBB2Hist[ii] = 0, BoxId[ii] = ii;

				tl2 = Point2f(9e9, 9e9), br2 = Point2f(0, 0);
				for (size_t ii = 0; ii < pts1.size(); ii++)
				{
					if (pts1[ii].x > tl.x && pts1[ii].x < br.x && pts1[ii].y>tl.y && pts1[ii].y <= br.y)
					{
						int x = pts1[ii].x, y = pts1[ii].y;
						double bidirecErr2 = pow(pts1[ii].x - pts1_[ii].x, 2) + pow(pts1[ii].y - pts1_[ii].y, 2);
						if (bidirecErr2 < biDirectThresh2)
						{
							bool found = false;
							for (size_t jj = 0; jj < vbb2.size() && !found; jj++) //does it lay on any of the bbs in frame 2?
							{
								if (ToDiscard2[jj] == 1)
									continue;
								if (pts2[ii].x > vbb2_torso_only[jj].tl.x && pts2[ii].x<vbb2_torso_only[jj].br.x && pts2[ii].y > vbb2_torso_only[jj].tl.y && pts2[ii].y < vbb2_torso_only[jj].br.y)
									nInBB2Hist[jj]--, found = true;
							}
							tl2.x = min(tl2.x, pts1[ii].x), tl2.y = min(tl2.y, pts1[ii].y), br2.x = max(br2.x, pts1[ii].x), br2.y = max(br2.y, pts1[ii].y);
							nPassBidirect++;
						}
						nTotalWithinBB1++;
					}
				}

				Quick_Sort_Int(nInBB2Hist, BoxId, 0, vbb2_torso_only.size() - 1);
				if (vbb2.size() == 1)
				{
					if (-1.0*nInBB2Hist[0] / nTotalWithinBB1 > ConsistencyercentThresh)
						association.back() = BoxId[0];
					else
						association.back() = -1;
				}
				else if (1.0*nInBB2Hist[0] / (-0.00001 + nInBB2Hist[1]) > 1.5) //in case of splitting, # in domimant splits still has to satisfy the consistency check
				{
					double inArea = (br2.x - tl2.x)*(br2.y - tl2.y);
					double Area2 = (vbb2_torso_only[BoxId[0]].br.x - vbb2_torso_only[BoxId[0]].tl.x)*(vbb2_torso_only[BoxId[0]].br.y - vbb2_torso_only[BoxId[0]].tl.y);
					if (inArea / Area1 < overlapA_thresh && inArea / Area2 < overlapA_thresh)
						association.back() = -1;
					else
					{
						if (nTotalWithinBB1 >= 50 && -1.0*nInBB2Hist[0] / nTotalWithinBB1 > 0.5*ConsistencyercentThresh) //so many points, can lower the threshold
							association.back() = BoxId[0];
						else if (nTotalWithinBB1 < 50 && -1.0*nInBB2Hist[0] / nTotalWithinBB1 > ConsistencyercentThresh)
							association.back() = BoxId[0];
						else
							association.back() = -1;
					}
				}
				else
					association.back() = -1;
			}
		}

		if (debug > 0)//Visualization: draw assocation
		{
			vImg[0] = Img1.clone(), vImg[1] = Img2.clone();
			cvtColor(vImg[0], vImg[0], CV_GRAY2BGR), cvtColor(vImg[1], vImg[1], CV_GRAY2BGR);
			for (int ii = 0; ii < pts1.size(); ii++)
				circle(vImg[0], pts1[ii], 2.0*radius[ii], colors[ii % 9], 1);

			for (int pid1 = 0; pid1 < lm1.size() / nJoints; pid1++)
			{
				int nvalidJoints = 0;
				for (int jid = 0; jid < nJoints; jid++)
					if (lm1[pid1*nJoints + jid].x > 0 && vs1[pid1*nJoints + jid] > confThresh)
						nvalidJoints++;
				if (nvalidJoints < 5)
					continue;

				bool found = false;
				tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (auto jid : LegTorsoJoints)
					if (lm1[pid1*nJoints + jid].x > 0 && vs1[pid1*nJoints + jid] > confThresh)
						tl.x = min(tl.x, lm1[pid1*nJoints + jid].x), tl.y = min(tl.y, lm1[pid1*nJoints + jid].y), br.x = max(br.x, lm1[pid1*nJoints + jid].x), br.y = max(br.y, lm1[pid1*nJoints + jid].y), found = true;
				br.x = min(br.x, Img1.cols - 1), br.y = min(br.y, Img1.rows - 1);
				if (!found || br.x - tl.x < Img2.rows / 20 || br.y - tl.y < Img2.rows / 20) //very small window, skip it
					continue;

				rectangle(vImg[0], tl, br, colors[pid1 % 9], 8, 8, 0);
				Draw2DCoCoJoints(vImg[0], &lm1[pid1*nJoints], nJoints, 1.0*vImg[1].cols / 640);
				sprintf(Fname, "%d", pid1), putText(vImg[0], Fname, Point2i(tl.x, br.y - vImg[0].cols / 60), CV_FONT_HERSHEY_SIMPLEX, 1.0*vImg[0].cols / 640, colors[pid1 % 9], 3);

				int associated = association[pid1];
				if (associated > -1)
				{
					bool found = false;
					tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
					for (auto jid : LegTorsoJoints)
						if (lm2[associated*nJoints + jid].x > 0 && vs2[associated*nJoints + jid] > confThresh)
							tl.x = min(tl.x, lm2[associated*nJoints + jid].x), tl.y = min(tl.y, lm2[associated*nJoints + jid].y), br.x = max(br.x, lm2[associated*nJoints + jid].x), br.y = max(br.y, lm2[associated*nJoints + jid].y), found = true;
					br.x = min(br.x, Img1.cols - 1), br.y = min(br.y, Img1.rows - 1);
					if (!found || br.x - tl.x < Img2.rows / 20 || br.y - tl.y < Img2.rows / 20) //very small window, skip it
						continue;

					rectangle(vImg[1], tl, br, colors[pid1 % 9], 8, 8, 0);
					Draw2DCoCoJoints(vImg[1], &lm2[associated*nJoints], nJoints, 1.0*vImg[1].cols / 640);
					sprintf(Fname, "%d", pid1), putText(vImg[1], Fname, Point2i(tl.x, br.y - vImg[1].cols / 60), CV_FONT_HERSHEY_SIMPLEX, 1.0*vImg[1].cols / 640, colors[pid1 % 9], 3);
				}
			}
			bImg = DrawTitleImages(vImg, 2.0);
			CvPoint text_origin = { bImg.rows / 20, bImg.cols / 20 };
			sprintf(Fname, "%d", fid - 1), putText(bImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*bImg.cols / 640, colors[0], 3);
			resize(bImg, bImg2, Size(resizeFactor* bImg.cols, resizeFactor*bImg.rows), 0, 0, INTER_AREA); writer << bImg2;

			if (debug > 1)
				sprintf(Fname, "%s/Vis/TrackBody_SmallFeat/%d/%.4d.jpg", Path, cid, fid - 1), imwrite(Fname, bImg2);
		}

		//write out data
		fprintf(fpOut, "%d %d ", fid - 1, association.size());
		for (auto asso : association)
			fprintf(fpOut, "%d ", asso);
		fprintf(fpOut, "\n");

		//prepare data for the next frame
		cv::buildOpticalFlowPyramid(Img2, Img2Pyr, winSize, cvPyrLevel, false);

		pts2.clear(), radius.clear();
		for (int pid = 0; pid < lm2.size() / nJoints; pid++)  //remove points outside the detected person bb
		{
			int nvalidJoints = 0;
			for (int jid = 0; jid < nJoints; jid++)
				if (lm2[pid*nJoints + jid].x > 0)
					nvalidJoints++;
			if (nvalidJoints < 5)
				continue;

			bool found = false;
			tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
			for (auto jid : LegTorsoJoints)
				if (lm2[pid*nJoints + jid].x > 0)
					tl.x = min(tl.x, lm2[pid*nJoints + jid].x), tl.y = min(tl.y, lm2[pid*nJoints + jid].y), br.x = max(br.x, lm2[pid*nJoints + jid].x), br.y = max(br.y, lm2[pid*nJoints + jid].y), found = true;
			br.x = min(br.x, Img1.cols - 1), br.y = min(br.y, Img1.rows - 1);
			if (!found || br.x - tl.x < Img2.rows / 20 || br.y - tl.y < Img2.rows / 20) //very small window, skip it
				continue;

			br.x = min(br.x, Img2.cols - 1), br.y = min(br.y, Img2.rows - 1);
			cv::Rect rect(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
			DoG.clear(); Mat tMat = Img2(rect); vl_DoG(tMat, DoG);
			for (auto dog : DoG)
				pts2.push_back(Point2f(dog.x + tl.x, dog.y + tl.y)), radius.push_back(dog.z);
		}

		swap(Img1, Img2), swap(Img1Pyr, Img2Pyr), swap(pts1, pts2), swap(lm1, lm2), swap(vs1, vs2);
	}
	fclose(fpOut);

	if (debug > 0)
		writer.release();

	return 0;
}
int TrackBody_Desc_BiDirect(char *Path, int cid, int startF, int stopF, int increF, double simThresh, double ratioThesh, double overlapA_thresh, int debug)
{
	const int descSize = 256, nJoints = 25;
	double confThresh = 0.1;
	//the distance metric is cosine distance
	char Fname[512];
	printLOG("\n\nWorking on %d Desc body track: ", cid);
	sprintf(Fname, "%s/Vis", Path); makeDir(Fname);
	sprintf(Fname, "%s/Vis/TrackBody_Desc", Path); makeDir(Fname);
	if (debug > 1)
		sprintf(Fname, "%s/Vis/TrackBody_Desc/%d", Path, cid), makeDir(Fname);

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));
	struct TL_BR {
		Point2i tl, br;
	};


	float u, v, s, desc, score, norm; Point2f tl, br, tl2, br2;
	Mat Img1, Img2, cImg1, cImg2, cbImg, bImg, bImg2; vector<Mat> vImg(2);
	vector<Point2f> tpts1, tpts2, pts1, pts2, pts1_, lm1, lm2;
	vector<float> vs1, vs2;
	int BoxId[100]; double Score[100];

	float descI[descSize];  vector<float> desc1, desc2;
	desc1.reserve(descSize * 20), desc2.reserve(descSize * 20);

	desc1.clear();
	sprintf(Fname, "%s/MP/%d/Desc/%.4d.txt", Path, cid, startF); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	while (fscanf(fp, "%f ", &desc) != EOF)
	{
		descI[0] = desc, norm = desc * desc;
		for (int ii = 0; ii < 255; ii++)
			fscanf(fp, "%f ", &desc), descI[ii + 1] = desc, norm += desc * desc;

		norm = sqrt(norm);
		for (int ii = 0; ii < descSize; ii++)
			descI[ii] /= norm;

		for (int ii = 0; ii < descSize; ii++)
			desc1.push_back(descI[ii]);
	}
	fclose(fp);

	lm1.clear(), vs1.clear();
	if (readOpenPoseJson(Path, cid, startF, lm1, vs1) == 0)
	{
		sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, startF); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
			lm1.push_back(Point2f(u, v)), vs1.push_back(s);
		fclose(fp);
	}

	VideoWriter writer;
	int firstTime = 1; double resizeFactor = 0.25;
	CvSize size;
	if (debug > 0)
	{
		sprintf(Fname, "%s/%d/%.4d.png", Path, cid, startF); Img1 = imread(Fname, 0);
		if (Img1.empty() == 1)
		{
			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, startF); Img1 = imread(Fname, 0);
			if (Img1.empty() == 1)
			{
				printLOG("Cannot load %s\n", Fname);
				return 1;
			}
		}
		size.width = (int)(resizeFactor*Img1.cols * 2), size.height = (int)(resizeFactor*Img1.rows);
		sprintf(Fname, "%s/Vis/TrackBody_Desc/%d_%d_%d.avi", Path, cid, startF, stopF), writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
	}

	sprintf(Fname, "%s/%d/flowgraph_FromDesc_%d_%d.txt", Path, cid, startF, stopF);  FILE *fpOut = fopen(Fname, "w");
	for (int fid = startF + 1; fid < stopF; fid++)
	{
		printLOG("%d..", fid);

		desc2.clear();
		sprintf(Fname, "%s/MP/%d/Desc/%.4d.txt", Path, cid, fid); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		while (fscanf(fp, "%f ", &desc) != EOF)
		{
			descI[0] = desc, norm = desc * desc;
			for (int ii = 0; ii < 255; ii++)
				fscanf(fp, "%f ", &desc), descI[ii + 1] = desc, norm += desc * desc;

			norm = sqrt(norm);
			for (int ii = 0; ii < descSize; ii++)
				descI[ii] /= norm;

			for (int ii = 0; ii < descSize; ii++)
				desc2.push_back(descI[ii]);
		}
		fclose(fp);

		lm2.clear(), vs2.clear();
		if (readOpenPoseJson(Path, cid, fid, lm2, vs2) == 0)
		{
			sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); fp = fopen(Fname, "r");
			if (fp == NULL)
			{
				printLOG("Cannot load %s\n", Fname);
				continue;
			}
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				lm2.push_back(Point2f(u, v)), vs2.push_back(s);
			fclose(fp);
		}

		if (debug)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid); Img2 = imread(Fname, 0);
			if (Img2.empty() == 1)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid); Img2 = imread(Fname, 0);
				if (Img2.empty() == 1)
				{
					printLOG("Cannot load %s\n", Fname);
					continue;
				}
			}
		}
		if (lm2.size() == 0)
		{
			desc1.clear(), lm1.clear(), vs1.clear();
			continue;
		}
		if (desc1.size() == 0)
		{
			swap(desc1, desc2), swap(lm1, lm2), swap(vs1, vs2), swap(Img1, Img2);
			continue;
		}

		int nP1 = (int)desc1.size() / descSize, nP2 = (int)desc2.size() / descSize;

		//Check for bb with more than 40% (or 50%) more overlapping area
		vector<TL_BR> vbb1, vbb2;
		for (int pid1 = 0; pid1 < lm1.size() / nJoints; pid1++)
		{
			TL_BR bb; tl = Point2f(9e9, 9e9), br = Point2f(0, 0);

			int nvalidJoints = 0;
			for (int jid = 0; jid < nJoints; jid++)
				if (lm1[pid1*nJoints + jid].x > 0)// && vs1[pid1*nJoints + jid] > confThresh)  not needed since there is a area overlapping check
					nvalidJoints++;
			if (nvalidJoints < 5)
			{
				bb.tl = Point2f(0, 0), bb.br = Point2f(0, 0), vbb1.push_back(bb);
				continue;
			}

			for (int jid = 0; jid < nJoints; jid++)
				if (lm1[pid1*nJoints + jid].x > 0)//&& vs1[pid1*nJoints + jid] > confThresh) not needed since there is a area overlapping check
					tl.x = min(tl.x, lm1[pid1*nJoints + jid].x), tl.y = min(tl.y, lm1[pid1*nJoints + jid].y), br.x = max(br.x, lm1[pid1*nJoints + jid].x), br.y = max(br.y, lm1[pid1*nJoints + jid].y);

			if (br.x - tl.x < Img1.rows / 20 || br.y - tl.y < Img1.rows / 20)
				bb.tl = Point2f(0, 0), bb.br = Point2f(0, 0), vbb1.push_back(bb);
			else
				bb.tl = tl, bb.br = br, vbb1.push_back(bb);
		}

		for (int pid2 = 0; pid2 < lm2.size() / nJoints; pid2++)
		{
			TL_BR bb; tl = Point2f(9e9, 9e9), br = Point2f(0, 0);

			int nvalidJoints = 0;
			for (int jid = 0; jid < nJoints; jid++)
				if (lm2[pid2*nJoints + jid].x > 0)// && vs2[pid2*nJoints + jid] > confThresh)  not needed since there is a area overlapping check
					nvalidJoints++;
			if (nvalidJoints < 5)
			{
				bb.tl = Point2f(0, 0), bb.br = Point2f(0, 0), vbb2.push_back(bb);
				continue;
			}

			for (int jid = 0; jid < nJoints; jid++)
				if (lm2[pid2*nJoints + jid].x > 0)//&& vs2[pid2*nJoints + jid] >confThresh) not needed since there is a area overlapping check
					tl.x = min(tl.x, lm2[pid2*nJoints + jid].x), tl.y = min(tl.y, lm2[pid2*nJoints + jid].y), br.x = max(br.x, lm2[pid2*nJoints + jid].x), br.y = max(br.y, lm2[pid2*nJoints + jid].y);

			if (br.x - tl.x < Img2.rows / 20 || br.y - tl.y < Img2.rows / 20)
				bb.tl = Point2f(0, 0), bb.br = Point2f(0, 0), vbb2.push_back(bb);
			else
				bb.tl = tl, bb.br = br, vbb2.push_back(bb);
		}

		vector<int> ToDiscard1(vbb1.size()), ToDiscard2(vbb2.size());
		for (size_t jj = 0; jj < vbb1.size(); jj++)
		{
			double A_jj = (vbb1[jj].br.x - vbb1[jj].tl.x)*(vbb1[jj].br.y - vbb1[jj].tl.y);
			for (size_t ii = 0; ii < vbb1.size(); ii++)
			{
				if (ii == jj)
					continue;
				double A_ii = (vbb1[ii].br.x - vbb1[ii].tl.x)*(vbb1[ii].br.y - vbb1[ii].tl.y);

				double oA = OverlappingArea(vbb1[jj].tl, vbb1[jj].br, vbb1[ii].tl, vbb1[ii].br);
				if (oA / A_jj > overlapA_thresh || oA / A_ii > overlapA_thresh)
				{
					ToDiscard1[jj] = 1;
					break;
				}
			}
		}
		for (size_t jj = 0; jj < vbb2.size(); jj++)
		{
			double A_jj = (vbb2[jj].br.x - vbb2[jj].tl.x)*(vbb2[jj].br.y - vbb2[jj].tl.y);
			for (size_t ii = 0; ii < vbb2.size(); ii++)
			{
				if (ii == jj)
					continue;
				double A_ii = (vbb2[ii].br.x - vbb2[ii].tl.x)*(vbb2[ii].br.y - vbb2[ii].tl.y);

				double oA = OverlappingArea(vbb2[jj].tl, vbb2[jj].br, vbb2[ii].tl, vbb2[ii].br);
				if (oA / A_jj > overlapA_thresh || oA / A_ii > overlapA_thresh)
				{
					ToDiscard2[jj] = 1;
					break;
				}
			}
		}

		vector<int> association(nP1); vector<double> associatedScore(nP1);
		for (int pid1 = 0; pid1 < nP1; pid1++)
		{
			if (ToDiscard1[pid1] == 1)
			{
				association[pid1] = -1, associatedScore[pid1] = 0;
				continue;
			}

			int nvalidJoints = 0;
			for (int jid = 0; jid < nJoints; jid++)
				if (lm1[pid1*nJoints + jid].x > 0 && vs1[jid + pid1 * nJoints] > confThresh)  //bad detection
					nvalidJoints++;
			if (nvalidJoints < 5)
			{
				association[pid1] = -1, associatedScore[pid1] = 0;
				continue;
			}

			for (int pid2 = 0; pid2 < nP2; pid2++)
			{
				if (ToDiscard2[pid2] == 1)
				{
					Score[pid2] = 0, BoxId[pid2] = pid2;
					continue;
				}

				nvalidJoints = 0;
				for (int jid = 0; jid < nJoints; jid++)
					if (lm2[pid2*nJoints + jid].x > 0 && vs2[pid2*nJoints + jid] > confThresh)
						nvalidJoints++;
				if (nvalidJoints < 5)
					Score[pid2] = 0, BoxId[pid2] = pid2;
				else
				{
					double score = 0.0;
					for (int ii = 0; ii < descSize; ii++)
						score += desc1[pid1*descSize + ii] * desc2[pid2*descSize + ii];
					Score[pid2] = -score, BoxId[pid2] = pid2;
				}
			}

			Quick_Sort_Double(Score, BoxId, 0, nP2 - 1);
			if (-Score[0] > simThresh)  //let be conservatinve
			{
				if (nP2 == 1)
					association[pid1] = BoxId[0], associatedScore[pid1] = -Score[0];
				else
				{
					if ((-0.0000001 - Score[1]) / Score[0] < ratioThesh) //let be conservatinve
						association[pid1] = BoxId[0], associatedScore[pid1] = -Score[0];
					else
						association[pid1] = -1, associatedScore[pid1] = -Score[0];
				}
			}
			else
				association[pid1] = -1, associatedScore[pid1] = -Score[0];
		}

		vector<int> association2(nP2); vector<double> associatedScore2(nP2);
		for (int pid2 = 0; pid2 < nP2; pid2++)
		{
			if (ToDiscard2[pid2] == 1)
			{
				association2[pid2] = -1, associatedScore2[pid2] = 0;
				continue;
			}

			int nvalidJoints = 0;
			for (int jid = 0; jid < nJoints; jid++)
				if (lm2[pid2*nJoints + jid].x > 0 && vs2[jid + pid2 * nJoints] > confThresh)  //bad detection
					nvalidJoints++;
			if (nvalidJoints < 5)
			{
				association2[pid2] = -1, associatedScore2[pid2] = 0;
				continue;
			}

			for (int pid1 = 0; pid1 < nP1; pid1++)
			{
				if (ToDiscard1[pid1] == 1)
				{
					Score[pid1] = 0, BoxId[pid1] = pid2;
					continue;
				}

				nvalidJoints = 0;
				for (int jid = 0; jid < nJoints; jid++)
					if (lm1[pid1*nJoints + jid].x > 0 && vs1[pid1*nJoints + jid] > confThresh)
						nvalidJoints++;
				if (nvalidJoints < 5)
					Score[pid1] = 0, BoxId[pid1] = pid1;
				else
				{
					double score = 0.0;
					for (int ii = 0; ii < descSize; ii++)
						score += desc2[pid2*descSize + ii] * desc1[pid1*descSize + ii];
					Score[pid1] = -score, BoxId[pid1] = pid2;
				}
			}

			Quick_Sort_Double(Score, BoxId, 0, nP1 - 1);
			if (-Score[0] > simThresh)  //let be conservatinve
			{
				if (nP1 == 1)
					association2[pid2] = BoxId[0], associatedScore2[pid2] = -Score[0];
				else
				{
					if ((-0.0000001 - Score[1]) / Score[0] < ratioThesh) //let be conservatinve
						association2[pid2] = BoxId[0], associatedScore2[pid2] = -Score[0];
					else
						association2[pid2] = -1, associatedScore2[pid2] = -Score[0];
				}
			}
			else
				association2[pid2] = -1, associatedScore2[pid2] = -Score[0];
		}

		//bidirection check
		for (int pid1 = 0; pid1 < nP1; pid1++)
		{
			int pid2 = association[pid1];
			if (pid2 > -1)
			{
				if (association2.size() == 0)
					association[pid1] = -1;
				else
				{
					int pid1_ = association2[pid2];
					if (pid1_ == -1)
						association[pid1] = -1;
					else if (pid1_ != pid1)
						association[pid1] = -1;
				}
			}
		}

		//Visualization: draw assocation
		if (debug > 0)
		{
			vImg[0] = Img1.clone(), vImg[1] = Img2.clone();
			cvtColor(vImg[0], vImg[0], CV_GRAY2BGR), cvtColor(vImg[1], vImg[1], CV_GRAY2BGR);

			for (int pid1 = 0; pid1 < nP1; pid1++)
			{
				int nvalidJoints = 0;
				for (int jid = 0; jid < nJoints; jid++)
					if (lm1[pid1*nJoints + jid].x > 0 && vs1[pid1*nJoints + jid] > confThresh)
						nvalidJoints++;
				if (nvalidJoints < 5)
					continue;

				tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (size_t jid = 0; jid < nJoints; jid++)
					if (lm1[pid1*nJoints + jid].x > 0)
						tl.x = min(tl.x, lm1[pid1*nJoints + jid].x), tl.y = min(tl.y, lm1[pid1*nJoints + jid].y), br.x = max(br.x, lm1[pid1*nJoints + jid].x), br.y = max(br.y, lm1[pid1*nJoints + jid].y);
				rectangle(vImg[0], tl, br, colors[pid1 % 9], 8, 8, 0);
				Draw2DCoCoJoints(vImg[0], &lm1[pid1*nJoints], nJoints, 1.0*vImg[0].cols / 640);
				sprintf(Fname, "%d:%.2f", pid1, associatedScore[pid1]), putText(vImg[0], Fname, Point2i(tl.x, br.y - vImg[0].cols / 60), CV_FONT_HERSHEY_SIMPLEX, 1.0*vImg[0].cols / 640, colors[pid1 % 9], 3);

				int associated = association[pid1];
				if (associated > -1)
				{
					tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
					for (size_t jid = 0; jid < nJoints; jid++)
						if (lm2[associated*nJoints + jid].x > 0)
							tl.x = min(tl.x, lm2[associated*nJoints + jid].x), tl.y = min(tl.y, lm2[associated*nJoints + jid].y), br.x = max(br.x, lm2[associated*nJoints + jid].x), br.y = max(br.y, lm2[associated*nJoints + jid].y);
					rectangle(vImg[1], tl, br, colors[pid1 % 9], 8, 8, 0);
					Draw2DCoCoJoints(vImg[1], &lm2[associated*nJoints], nJoints, 1.0*vImg[0].cols / 640);
					sprintf(Fname, "%d", pid1), putText(vImg[1], Fname, Point2i(tl.x, br.y - vImg[0].cols / 60), CV_FONT_HERSHEY_SIMPLEX, 1.0*vImg[1].cols / 640, colors[pid1 % 9], 3);
				}
			}
			bImg = DrawTitleImages(vImg, 2.0);
			CvPoint text_origin = { bImg.rows / 20, bImg.cols / 20 };
			sprintf(Fname, "%d", fid - 1), putText(bImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*bImg.cols / 640, colors[0], 3);
			resize(bImg, bImg2, Size(resizeFactor* bImg.cols, resizeFactor*bImg.rows), 0, 0, INTER_AREA);
			writer << bImg2;
			if (debug > 1)
				sprintf(Fname, "%s/Vis/TrackBody_Desc/%d/%.4d.jpg", Path, cid, fid - 1), imwrite(Fname, bImg2);
		}

		//write out data
		fprintf(fpOut, "%d %d ", fid - 1, association.size());
		for (auto asso : association)
			fprintf(fpOut, "%d ", asso);
		fprintf(fpOut, "\n");

		swap(desc1, desc2), swap(lm1, lm2), swap(vs1, vs2), swap(Img1, Img2);
	}
	fclose(fpOut);

	if (debug > 0)
		writer.release();

	return 0;
}

int CleanTrackletBy2DSmoothing(char *Path, int sCamId, int startF, int stopF, int increF, int imWidth, double dispThresh, double  overDispRatioThresh, int debug)
{
	char Fname[512];
	const int nJoints = 25;

	int nf, sf, pid;
	vector<vector<Point2i> >trackletVec;
	sprintf(Fname, "%s/%d/rawTracklet_%d_%d.txt", Path, sCamId, startF, stopF); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
	{
		vector<Point2i> tracklet;
		for (int f = 0; f < nf; f++)
		{
			fscanf(fp, "%d ", &pid);
			tracklet.push_back(Point2i(sf + f, pid));
		}
		trackletVec.push_back(tracklet);
	}
	fclose(fp);

	float u, v, s;
	vector<vector<Point2f> *> allPoses;
	for (int fid = startF; fid <= stopF; fid++)
	{
		vector<Point2f> *PoseI = new vector<Point2f>[1];
		sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, sCamId, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
			PoseI[0].push_back(Point2f(u, v));
		fclose(fp);
		allPoses.push_back(PoseI);
	}

	//Enforce smoothing constraint
	vector<double> disp;
	vector<Point2i> splitingPoint;
	vector<vector<Point2i> > newTrackletVec;
	vector<Point3i> allPair;
	allPair.push_back(Point3i(0, 0, 0));
	allPair.push_back(Point3i(1, 1, 1));
	allPair.push_back(Point3i(2, 2, 5));
	allPair.push_back(Point3i(3, 3, 6));
	allPair.push_back(Point3i(4, 4, 7));
	allPair.push_back(Point3i(5, 5, 2));
	allPair.push_back(Point3i(6, 6, 3));
	allPair.push_back(Point3i(7, 7, 4));
	allPair.push_back(Point3i(8, 8, 11));
	allPair.push_back(Point3i(9, 9, 12));
	allPair.push_back(Point3i(10, 10, 13));
	allPair.push_back(Point3i(11, 11, 8));
	allPair.push_back(Point3i(12, 12, 9));
	allPair.push_back(Point3i(13, 13, 10));
	allPair.push_back(Point3i(14, 14, 15));
	allPair.push_back(Point3i(15, 15, 14));
	allPair.push_back(Point3i(16, 16, 17));
	allPair.push_back(Point3i(17, 17, 16));
	for (int id = 0; id < (int)trackletVec.size(); id++)
	{
		vector <Point2i>  newTracklet;
		newTracklet.push_back(Point2i(trackletVec[id][0].x, trackletVec[id][0].y));
		for (int tid = 0; tid < trackletVec[id].size() - 1; tid++)
		{
			int fid0 = trackletVec[id][tid].x, fid1 = trackletVec[id][tid + 1].x;
			int pid0 = trackletVec[id][tid].y, pid1 = trackletVec[id][tid + 1].y;
			Point2f *pts0 = &allPoses[fid0 - startF][0][nJoints*pid0];
			Point2f *pts1 = &allPoses[fid1 - startF][0][nJoints*pid1];

			disp.clear();
			for (int jid = 0; jid < nJoints; jid++)
			{
				double dist1 = 9e9, dist2 = 9e9, dist;
				if (pts0[allPair[jid].x].x > 0 && pts1[allPair[jid].y].x > 0)
					dist1 = norm(pts0[allPair[jid].x] - pts1[allPair[jid].y]);
				if (pts0[allPair[jid].x].x > 0 && pts1[allPair[jid].z].y > 0)
					dist2 = norm(pts0[allPair[jid].x] - pts1[allPair[jid].z]);
				dist = min(dist1, dist2);
				if (dist < 8e9)
					disp.push_back(dist);
			}

			sort(disp.begin(), disp.end());
			size_t upper = disp.size() * 7 / 10, mid = disp.size() / 2;
			if (disp[upper] > dispThresh*imWidth / 1920 && disp[upper] - disp[0] > overDispRatioThresh*disp[mid])
			{
				splitingPoint.push_back(Point2i(id, tid));
				if (newTracklet.size() > 0) //remove the last element (the next element is also discarded)
					newTracklet.pop_back();
				newTrackletVec.push_back(newTracklet);
				newTracklet.clear(); //start new tracklet;
									 /*//tracklet of 1 one element
									 newTracklet.push_back(Point2i(fid0, pid0));
									 newTrackletVec.push_back(newTracklet);
									 newTracklet.clear(); //start new tracklet;*/

									 //newTracklet.push_back(Point2i(fid1, pid1));
			}
			else
				newTracklet.push_back(Point2i(fid1, pid1));
		}
		newTrackletVec.push_back(newTracklet);
	}

	/*sprintf(Fname, "%s/%d/nTracklet_%d_%d.txt", Path, sCamId, startF, stopF); fp = fopen(Fname, "w");
	for (int id = 0; id < (int)newTrackletVec.size(); id++)
	{
	if (newTrackletVec[id].size() == 0)
	continue;

	fprintf(fp, "%d %d ", (int)newTrackletVec[id].size(), newTrackletVec[id][0].x);
	for (int tid = 0; tid < newTrackletVec[id].size(); tid++)
	fprintf(fp, "%d ", (int)newTrackletVec[id][tid].y);
	fprintf(fp, "%\n");
	}
	fclose(fp);*/

	int count = 0;
	int *dummy = new int[newTrackletVec.size()];
	int *TrackletStartF = new int[newTrackletVec.size()];
	for (int id = 0; id < (int)newTrackletVec.size(); id++)
	{
		if (newTrackletVec[id].size() == 0)
			continue;
		dummy[count] = id;
		TrackletStartF[count] = newTrackletVec[id][0].x;
		count++;
	}
	Quick_Sort_Int(TrackletStartF, dummy, 0, count - 1);

	vector<vector<Point2i> > newSortedTrackletVec;
	for (int ii = 0; ii < count; ii++)
	{
		int tid = dummy[ii];
		vector<Point2i> sortedTracklet;
		for (int jj = 0; jj < newTrackletVec[tid].size(); jj++)
			sortedTracklet.push_back(newTrackletVec[tid][jj]);
		newSortedTrackletVec.push_back(sortedTracklet);
	}
	delete[]dummy, delete[]TrackletStartF;

	sprintf(Fname, "%s/%d/Tracklet_%d_%d.txt", Path, sCamId, startF, stopF); fp = fopen(Fname, "w");
	for (int id = 0; id < (int)newSortedTrackletVec.size(); id++)
	{
		if (newSortedTrackletVec[id].size() == 0)
			continue;

		fprintf(fp, "%d %d ", (int)newSortedTrackletVec[id].size(), newSortedTrackletVec[id][0].x);
		for (int tid = 0; tid < newSortedTrackletVec[id].size(); tid++)
			fprintf(fp, "%d ", (int)newSortedTrackletVec[id][tid].y);
		fprintf(fp, "%\n");
	}
	fclose(fp);

	//Visualize the tracker
	if (debug > 0)
	{
		const int nJoints = 18;
		const double resizeFactor = 0.5;
		float u, v, s;
		vector<vector<Point2f> *> allPoses;
		vector<Mat> allImages; Mat img;

		vector<Scalar> colors;
		colors.push_back(Scalar(0, 0, 255));
		colors.push_back(Scalar(0, 128, 255));
		colors.push_back(Scalar(0, 255, 255));
		colors.push_back(Scalar(0, 255, 0));
		colors.push_back(Scalar(255, 128, 0));
		colors.push_back(Scalar(255, 255, 0));
		colors.push_back(Scalar(255, 0, 0));
		colors.push_back(Scalar(255, 0, 255));
		colors.push_back(Scalar(255, 255, 255));

		int increP = 10;
		printLOG("Visualization... Reading images: ");
		for (int fid = startF; fid <= stopF; fid++)
		{
			vector<Point2f> *PoseI = new vector<Point2f>[1];
			sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, sCamId, fid); fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				PoseI[0].push_back(Point2f(u, v));
			fclose(fp);
			allPoses.push_back(PoseI);

			sprintf(Fname, "%s/%d/%.4d.jpg", Path, sCamId, fid); img = imread(Fname);
			if (img.empty())
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, sCamId, fid); img = imread(Fname);
				if (img.empty())
					continue;
			}
			resize(img, img, Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
			allImages.push_back(img);
			if (100 * (fid - startF) / (stopF - startF) > increP)
				printLOG("%d%%..", increP), increP += 10;
		}
		printLOG("100%%\n");
		if (allImages.size() == 0)
			return 0;

		for (int id = 0; id < (int)newSortedTrackletVec.size(); id++)
		{
			for (int tid = 0; tid < newSortedTrackletVec[id].size(); tid++)
			{
				int fid = newSortedTrackletVec[id][tid].x;
				if (fid - startF > allImages.size() - 1)
					continue;

				vector<Point2f> temp = allPoses[fid - startF][0];
				int pid = newSortedTrackletVec[id][tid].y;
				int s = (int)temp.size(), cs = pid * nJoints + 1;

				Point2f tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (int jid = 0; jid < nJoints; jid++)
				{
					if (temp[pid * nJoints + jid].x > 0)
						tl.x = min(tl.x, temp[pid * nJoints + jid].x), tl.y = min(tl.y, temp[pid * nJoints + jid].y), br.x = max(br.x, temp[pid * nJoints + jid].x), br.y = max(br.y, temp[pid * nJoints + jid].y);
				}
				tl.x *= resizeFactor, tl.y *= resizeFactor, br.x *= resizeFactor, br.y *= resizeFactor;
				rectangle(allImages[fid - startF], tl, br, colors[id % 9], 2, 8, 0);
				Draw2DCoCoJoints(allImages[fid - startF], &temp[pid * nJoints], resizeFactor*allImages[fid - startF].cols / 640, resizeFactor);
				sprintf(Fname, "%d", id); putText(allImages[fid - startF], Fname, Point2i(tl.x, br.y - resizeFactor * allImages[fid - startF].cols / 60), CV_FONT_HERSHEY_SIMPLEX, 0.75*allImages[fid - startF].cols / 640, colors[id % 9], 2);
			}
		}

		sprintf(Fname, "%s/Vis", Path); makeDir(Fname);
		sprintf(Fname, "%s/Vis/Tracklet", Path); makeDir(Fname);
		if (debug > 1)
			sprintf(Fname, "%s/Vis/Tracklet/%d", Path, sCamId), makeDir(Fname);

		printLOG("\nwriting images : "); increP = 10;
		VideoWriter writer;
		CvSize size; size.width = allImages[0].cols, size.height = allImages[0].rows;
		sprintf(Fname, "%s/Vis/Tracklet/%d_%d_%d.avi", Path, sCamId, startF, stopF), writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
		for (int fid = startF; fid <= stopF; fid++)
		{
			if (fid - startF > allImages.size() - 1)
				continue;
			CvPoint text_origin = { allImages[fid - startF].cols / 20, allImages[fid - startF].rows / 15 };
			sprintf(Fname, "%d", fid); putText(allImages[fid - startF], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, allImages[fid - startF].cols / 640, colors[0], 2.0*resizeFactor);

			if (debug > 1)
				sprintf(Fname, "%s/Vis/Tracklet/%d/%.4d.jpg", Path, sCamId, fid), imwrite(Fname, allImages[fid - startF]);
			writer << allImages[fid - startF];

			if (100 * (fid - startF) / (stopF - startF) > increP)
				printLOG("%d%%..", increP), increP += 10;

			//namedWindow("X", CV_WINDOW_NORMAL);
			//cvSetWindowProperty("X", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
			//imshow("X", allImages[fid - startF]); waitKey(10);
		}
		writer.release();
		printLOG("100%%\n");
	}
	return 0;
}
int CleanTrackletBy2DSmoothing_V2(char *Path, int sCamId, int startF, int stopF, int increF, int imWidth, int nJoints, double dispThresh, double  overDispRatioThresh, int debug)
{
	char Fname[512];

	int nf, sf, pid;
	vector<vector<Point2i> >trackletVec;
	sprintf(Fname, "%s/%d/rawTracklet_%d_%d_%d.txt", Path, sCamId, startF, stopF, nJoints); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
	{
		vector<Point2i> tracklet;
		for (int f = 0; f < nf; f++)
		{
			fscanf(fp, "%d ", &pid);
			tracklet.push_back(Point2i(sf + f, pid));
		}
		trackletVec.push_back(tracklet);
	}
	fclose(fp);

	float u, v, s;
	vector<float> vConf;
	vector<vector<Point2f> *> allPoses;
	for (int fid = startF; fid <= stopF; fid++)
	{
		vConf.clear();
		vector<Point2f> *PoseI = new vector<Point2f>[1];
		if (readOpenPoseJson(Path, sCamId, fid, PoseI[0], vConf) == 0)
		{
			sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, sCamId, fid); FILE *fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					PoseI[0].push_back(Point2f(u, v));
				fclose(fp);
			}
		}
		allPoses.push_back(PoseI);
	}

	//Enforce smoothing constraint
	vector<double> disp, disp2;
	vector<Point2i> splitingPoint;
	vector<vector<Point2i> > newTrackletVec;
	vector<Point3i> allPair;
	if (nJoints == 18)
	{
		allPair.push_back(Point3i(0, 0, 0));
		allPair.push_back(Point3i(1, 1, 1));
		allPair.push_back(Point3i(2, 2, 5));
		allPair.push_back(Point3i(3, 3, 6));
		allPair.push_back(Point3i(4, 4, 7));
		allPair.push_back(Point3i(5, 5, 2));
		allPair.push_back(Point3i(6, 6, 3));
		allPair.push_back(Point3i(7, 7, 4));
		allPair.push_back(Point3i(8, 8, 11));
		allPair.push_back(Point3i(9, 9, 12));
		allPair.push_back(Point3i(10, 10, 13));
		allPair.push_back(Point3i(11, 11, 8));
		allPair.push_back(Point3i(12, 12, 9));
		allPair.push_back(Point3i(13, 13, 10));
		allPair.push_back(Point3i(14, 14, 15));
		allPair.push_back(Point3i(15, 15, 14));
		allPair.push_back(Point3i(16, 16, 17));
		allPair.push_back(Point3i(17, 17, 16));
	}
	else
		for (int ii = 0; ii < nJoints; ii++)
			allPair.push_back(Point3i(ii, ii, ii));

	for (int id = 0; id < (int)trackletVec.size(); id++)
	{
		vector <Point2i>  newTracklet;
		newTracklet.push_back(Point2i(trackletVec[id][0].x, trackletVec[id][0].y));

		for (int tid = 0; tid < (int)trackletVec[id].size() - 2; tid++)
		{
			int fid0 = trackletVec[id][tid].x, fid1 = trackletVec[id][tid + 1].x, fid2 = trackletVec[id][tid + 2].x;
			int pid0 = trackletVec[id][tid].y, pid1 = trackletVec[id][tid + 1].y, pid2 = trackletVec[id][tid + 2].y;
			Point2f *pts0 = &allPoses[fid0 - startF][0][nJoints*pid0];
			Point2f *pts1 = &allPoses[fid1 - startF][0][nJoints*pid1];
			Point2f *pts2 = &allPoses[fid2 - startF][0][nJoints*pid2];

			disp.clear();
			for (int jid = 0; jid < nJoints; jid++)
			{
				double dist1 = 9e9, dist2 = 9e9, dist;
				if (pts0[allPair[jid].x].x > 0 && pts1[allPair[jid].y].x > 0)
					dist1 = norm(pts0[allPair[jid].x] - pts1[allPair[jid].y]);
				if (pts0[allPair[jid].x].x > 0 && pts1[allPair[jid].z].y > 0)
					dist2 = norm(pts0[allPair[jid].x] - pts1[allPair[jid].z]);
				dist = min(dist1, dist2);
				if (dist < 8e9)
					disp.push_back(dist);
			}
			disp2.clear();
			for (int jid = 0; jid < nJoints; jid++)
			{
				double dist1 = 9e9, dist2 = 9e9, dist;
				if (pts0[allPair[jid].x].x > 0 && pts2[allPair[jid].y].x > 0)
					dist1 = norm(pts0[allPair[jid].x] - pts2[allPair[jid].y]);
				if (pts0[allPair[jid].x].x > 0 && pts2[allPair[jid].z].y > 0)
					dist2 = norm(pts0[allPair[jid].x] - pts2[allPair[jid].z]);
				dist = min(dist1, dist2);
				if (dist < 8e9)
					disp2.push_back(dist);
			}

			if (disp.size() == 0 || disp2.size() == 0)
				newTracklet.push_back(Point2i(fid1, pid1));
			else
			{
				sort(disp.begin(), disp.end());
				sort(disp2.begin(), disp2.end());
				size_t upper = disp.size() * 7 / 10, mid = disp.size() / 2, upper2 = disp2.size() * 7 / 10, mid2 = disp2.size() / 2;
				bool cond1 = (disp[upper] > dispThresh*imWidth / 1920 && disp[upper] - disp[0] > overDispRatioThresh*disp[mid]), cond2 = (disp2[upper2] > dispThresh*imWidth / 1920 && disp2[upper2] - disp2[0] > overDispRatioThresh*disp2[mid2]);
				if (cond1 || cond2)
				{
					splitingPoint.push_back(Point2i(id, tid));
					if (newTracklet.size() > 0) //remove the last element (the next element is also discarded)
						newTracklet.pop_back();
					newTrackletVec.push_back(newTracklet);

					if (cond2 == true)
						tid++;//the next instance is also bad

					newTracklet.clear(); //start new tracklet
										 /*//tracklet of 1 one element
										 newTracklet.push_back(Point2i(fid0, pid0));
										 newTrackletVec.push_back(newTracklet);
										 newTracklet.clear(); //start new tracklet;*/

										 //newTracklet.push_back(Point2i(fid1, pid1));
				}
				else
					newTracklet.push_back(Point2i(fid1, pid1));
			}
		}
		newTrackletVec.push_back(newTracklet);
	}

	int count = 0;
	int *dummy = new int[newTrackletVec.size()];
	int *TrackletStartF = new int[newTrackletVec.size()];
	for (int id = 0; id < (int)newTrackletVec.size(); id++)
	{
		if (newTrackletVec[id].size() == 0)
			continue;
		dummy[count] = id;
		TrackletStartF[count] = newTrackletVec[id][0].x;
		count++;
	}
	Quick_Sort_Int(TrackletStartF, dummy, 0, count - 1);

	vector<vector<Point2i> > newSortedTrackletVec;
	for (int ii = 0; ii < count; ii++)
	{
		int tid = dummy[ii];
		vector<Point2i> sortedTracklet;
		for (int jj = 0; jj < newTrackletVec[tid].size(); jj++)
			sortedTracklet.push_back(newTrackletVec[tid][jj]);
		newSortedTrackletVec.push_back(sortedTracklet);
	}
	delete[]dummy, delete[]TrackletStartF;

	//detect overlapping boxes and discard
	for (int tid1 = 0; tid1 < newSortedTrackletVec.size(); tid1++)
	{
		for (int tid2 = tid1 + 1; tid2 < newSortedTrackletVec.size(); tid2++)
		{
			bool breakFlag = false;
			for (int inst1 = 0; inst1 < newSortedTrackletVec[tid1].size() && !breakFlag; inst1++)
			{
				for (int inst2 = 0; inst2 < newSortedTrackletVec[tid2].size() && !breakFlag; inst2++)
				{
					int fid = newSortedTrackletVec[tid1][inst1].x, pid = newSortedTrackletVec[tid1][inst1].y;
					if (newSortedTrackletVec[tid1][inst1].x == newSortedTrackletVec[tid2][inst2].x && newSortedTrackletVec[tid1][inst1].y == newSortedTrackletVec[tid2][inst2].y)
					{
						breakFlag = true;
						newSortedTrackletVec[tid1].erase(newSortedTrackletVec[tid1].begin() + inst1, newSortedTrackletVec[tid1].end());
						newSortedTrackletVec[tid2].erase(newSortedTrackletVec[tid2].begin() + inst2, newSortedTrackletVec[tid2].end());
					}
				}
			}
		}
	}

	sprintf(Fname, "%s/%d/Tracklet_%d_%d_%d.txt", Path, sCamId, startF, stopF, nJoints); fp = fopen(Fname, "w");
	for (int id = 0; id < (int)newSortedTrackletVec.size(); id++)
	{
		if (newSortedTrackletVec[id].size() == 0)
			continue;

		fprintf(fp, "%d %d ", (int)newSortedTrackletVec[id].size(), newSortedTrackletVec[id][0].x);
		for (int tid = 0; tid < newSortedTrackletVec[id].size(); tid++)
			fprintf(fp, "%d ", (int)newSortedTrackletVec[id][tid].y);
		fprintf(fp, "\n");
	}
	fclose(fp);

	//Visualize the tracker
	if (debug > 0)
	{
		const int nJoints = 25;
		const double resizeFactor = 0.5;
		float u, v, s;
		vector<vector<Point2f> *> allPoses;
		vector<Mat> allImages; Mat img;

		vector<Scalar> colors;
		colors.push_back(Scalar(0, 0, 255));
		colors.push_back(Scalar(0, 128, 255));
		colors.push_back(Scalar(0, 255, 255));
		colors.push_back(Scalar(0, 255, 0));
		colors.push_back(Scalar(255, 128, 0));
		colors.push_back(Scalar(255, 255, 0));
		colors.push_back(Scalar(255, 0, 0));
		colors.push_back(Scalar(255, 0, 255));
		colors.push_back(Scalar(255, 255, 255));

		int increP = 10;
		vector<float > vConf;
		printLOG("Visualization... Reading images: ");
		for (int fid = startF; fid <= stopF; fid++)
		{
			vConf.clear();
			vector<Point2f> *PoseI = new vector<Point2f>[1];
			if (readOpenPoseJson(Path, sCamId, fid, PoseI[0], vConf) == 0)
			{
				sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, sCamId, fid); fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					PoseI[0].push_back(Point2f(u, v));
				fclose(fp);
			}
			allPoses.push_back(PoseI);

			sprintf(Fname, "%s/%d/%.4d.jpg", Path, sCamId, fid); img = imread(Fname);
			if (img.empty())
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, sCamId, fid); img = imread(Fname);
				if (img.empty())
					continue;
			}
			resize(img, img, Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
			allImages.push_back(img);
			if (100 * (fid - startF) / (stopF - startF) > increP)
				printLOG("%d%%..", increP), increP += 10;
		}
		printLOG("100%%\n");
		if (allImages.size() == 0)
			return 0;

		for (int id = 0; id < (int)newSortedTrackletVec.size(); id++)
		{
			for (int tid = 0; tid < newSortedTrackletVec[id].size(); tid++)
			{
				int fid = newSortedTrackletVec[id][tid].x;
				if (fid - startF > allImages.size() - 1)
					continue;

				vector<Point2f> temp = allPoses[fid - startF][0];
				int pid = newSortedTrackletVec[id][tid].y;
				int s = (int)temp.size(), cs = pid * nJoints + 1;

				Point2f tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (int jid = 0; jid < nJoints; jid++)
				{
					if (temp[pid * nJoints + jid].x > 0)
						tl.x = min(tl.x, temp[pid * nJoints + jid].x), tl.y = min(tl.y, temp[pid * nJoints + jid].y), br.x = max(br.x, temp[pid * nJoints + jid].x), br.y = max(br.y, temp[pid * nJoints + jid].y);
				}
				tl.x *= resizeFactor, tl.y *= resizeFactor, br.x *= resizeFactor, br.y *= resizeFactor;
				float bw = br.x - tl.x, bh = br.y - tl.y;
				tl.x = max(tl.x - bw / 10, 0.f), br.x = min(br.x + bw / 10, 1.f*allImages[fid - startF].cols - 1);
				tl.y = max(tl.y - bh / 10, 0.f), br.y = min(br.y + bh / 10, 1.f*allImages[fid - startF].rows - 1);

				rectangle(allImages[fid - startF], tl, br, colors[id % 9], 1, 8, 0);
				Draw2DCoCoJoints(allImages[fid - startF], &temp[pid * nJoints], nJoints, resizeFactor*allImages[fid - startF].cols / 640, resizeFactor);
				sprintf(Fname, "%d", id); putText(allImages[fid - startF], Fname, Point2i(tl.x, br.y - resizeFactor * allImages[fid - startF].cols / 60), CV_FONT_HERSHEY_SIMPLEX, 0.5*allImages[fid - startF].cols / 640, colors[id % 9], 1.0*resizeFactor);
			}
		}

		sprintf(Fname, "%s/Vis", Path); makeDir(Fname);
		sprintf(Fname, "%s/Vis/Tracklet", Path); makeDir(Fname);
		if (debug > 1)
			sprintf(Fname, "%s/Vis/Tracklet/%d", Path, sCamId), makeDir(Fname);

		printLOG("\nwriting images : "); increP = 10;
		VideoWriter writer;
		CvSize size; size.width = allImages[0].cols, size.height = allImages[0].rows;
		sprintf(Fname, "%s/Vis/Tracklet/%d_%d_%d.avi", Path, sCamId, startF, stopF), writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
		for (int fid = startF; fid <= stopF; fid++)
		{
			if (fid - startF > allImages.size() - 1)
				continue;
			CvPoint text_origin = { allImages[fid - startF].cols / 20, allImages[fid - startF].rows / 15 };
			sprintf(Fname, "%d", fid); putText(allImages[fid - startF], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*allImages[fid - startF].cols / 640, colors[0], 1.0*resizeFactor);

			if (debug > 1)
				sprintf(Fname, "%s/Vis/Tracklet/%d/%.4d.jpg", Path, sCamId, fid), imwrite(Fname, allImages[fid - startF]);
			writer << allImages[fid - startF];

			if (100 * (fid - startF) / (stopF - startF) > increP)
				printLOG("%d%%..", increP), increP += 10;

			//namedWindow("X", CV_WINDOW_NORMAL);
			//cvSetWindowProperty("X", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
			//imshow("X", allImages[fid - startF]); waitKey(10);
		}
		writer.release();
		printLOG("100%%\n");
	}
	return 0;
}
int PerVideoMultiPeopleTracklet(char *Path, int sCamId, int startF, int stopF, int increF, int nJoints, int debug)
{
	char Fname[512];
	sprintf(Fname, "%s/Logs/PerVideoMultiPeopleTracklet_%d_%.4d_%4d.txt", Path, sCamId, startF, stopF);
	//if (IsFileExist(Fname) == 1)
	//{
	//printLOG("%s computed\n", Fname);
	//return 0;
	//}

	printLOG("Cam %d: %d to %d ...Reading and associating data...", sCamId, startF, stopF);

	vector<int> vfid;
	vector<vector<int > >merged_childrenList;

	sprintf(Fname, "%s/%d/flowgraph_%d_%d_%d.txt", Path, sCamId, startF, stopF, nJoints);
	if (IsFileExist(Fname) == 0)
	{
		int fid, pid, nPeople; //expecting to see startF first
		vector<int> list;
		vector<Point2i> FidnP[3];
		vector<vector<int > >childrenList[3];

		vector<char *> FnameX;
		char Fname1[512], Fname2[512], Fname3[512];
		sprintf(Fname1, "%s/%d/flowgraph_FromLandmark_%d_%d_%d.txt", Path, sCamId, startF, stopF, nJoints); FnameX.push_back(Fname1);
		sprintf(Fname2, "%s/%d/flowgraph_FromLandmark_%d_%d_%d.txt", Path, sCamId, startF, stopF, nJoints); FnameX.push_back(Fname2);
		sprintf(Fname3, "%s/%d/flowgraph_FromLandmark_%d_%d_%d.txt", Path, sCamId, startF, stopF, nJoints); FnameX.push_back(Fname3);
		for (int fileID = 0; fileID < 3; fileID++)
		{
			int lastFid = startF - 1;
			std::string line, item;
			std::ifstream file(FnameX[fileID]);
			if (!file.is_open())
				return 0;
			while (std::getline(file, line))
			{
				StringTrim(&line);//remove white space
				if (line.empty())
					continue;

				std::stringstream line_stream(line);
				std::getline(line_stream, item, ' '); fid = atoi(item.c_str());
				if (fid != lastFid)
				{
					list.clear();
					for (int ii = lastFid + 1; ii < fid; ii++)
					{
						FidnP[fileID].push_back(Point2i(ii, 0));
						childrenList[fileID].push_back(list);
					}
				}

				std::getline(line_stream, item, ' '); nPeople = atoi(item.c_str());
				FidnP[fileID].push_back(Point2i(fid, nPeople));

				list.clear();
				while (!line_stream.eof())
				{
					std::getline(line_stream, item, ' '); StringTrim(&item);
					pid = atoi(item.c_str()), list.push_back(pid);
				}
				childrenList[fileID].push_back(list);
				lastFid = fid;

				if (nPeople != (int)list.size())
				{
					printLOG("Problem with %s at frame %d\n", Fname, fid);
					file.close();
					return 1;
				}
			}
			file.close();

			if (lastFid != stopF)
			{
				list.clear();
				for (int ii = lastFid + 1; ii < stopF; ii++)
				{
					FidnP[fileID].push_back(Point2i(ii, 0));
					childrenList[fileID].push_back(list);
				}
			}
		}

		//merge everything
		vector<int> Astack;  //A stack stores all assigment. It allows un assigned children from 1 method to be assgined by other methods
		if (childrenList[0].size() != childrenList[1].size() || childrenList[0].size() != childrenList[2].size())
		{
			printLOG("Problem reading flow graph files\n");
			return 1;
		}

		for (int ii = 0; ii < (int)childrenList[0].size(); ii++)
		{
			if (FidnP[0][ii].x != FidnP[1][ii].x || FidnP[0][ii].x != FidnP[2][ii].x) //fids are diff
			{
				printLOG("fid problem at %d\n", FidnP[0][ii].x);
				return 1;
			}
			if ((FidnP[0][ii].y != 0 && FidnP[1][ii].y != 0 && FidnP[0][ii].y != FidnP[1][ii].y) && (FidnP[0][ii].y != 0 && FidnP[2][ii].y != 0 && FidnP[0][ii].y != FidnP[2][ii].y)) //#people are diff
			{
				printLOG("# people problem at %d\n", FidnP[0][ii].x);
				return 1;
			}
			list.clear();
			/*if (FidnP[0][ii].y != FidnP[1][ii].y || FidnP[0][ii].y != FidnP[2][ii].y) //#people is dif
			{
			for (int jj = 0; jj < max(max(FidnP[0][ii].y, FidnP[1][ii].y), FidnP[2][ii].y); jj++)
			list.push_back(-1);
			vfid.push_back(FidnP[0][ii].x);
			merged_childrenList.push_back(list);
			continue;
			}*/

			for (int jj = 0; jj < max(max(FidnP[0][ii].y, FidnP[1][ii].y), FidnP[2][ii].y); jj++)
			{
				Astack.clear();
				int child1 = -1, child2 = -1, child3 = -1;

				if (childrenList[0][ii].size() > jj)
				{
					child1 = childrenList[0][ii][jj];
					if (child1 > -1)
						Astack.push_back(child1);
				}
				if (childrenList[1][ii].size() > jj)
				{
					child2 = childrenList[1][ii][jj];
					if (child2 > -1)
						Astack.push_back(child2);
				}
				if (childrenList[2][ii].size() > jj)
				{
					child3 = childrenList[2][ii][jj];
					if (child3 > -1)
						Astack.push_back(child3);
				}

				if (child1 > -1)
					list.push_back(child1); //landmark lk has low recall but very high precision.
				else
				{
					if (Astack.size() == 0)
						list.push_back(-1);
					else
					{
						double avg = 0;
						for (auto kk : Astack)
							avg += kk;
						avg = avg / Astack.size();
						if (abs(avg - Astack[0]) > 0.1) //inconsisteny across methods
							list.push_back(-1);
						else
							list.push_back(avg);
					}
				}
			}
			vfid.push_back(FidnP[0][ii].x);
			merged_childrenList.push_back(list);
		}

		//prune for possible 2 dest -> 1 target error
		for (size_t ii = 0; ii < merged_childrenList.size(); ii++)
		{
			for (size_t jj = 0; jj < merged_childrenList[ii].size(); jj++)
			{
				if (merged_childrenList[ii][jj] != -1)
				{
					for (size_t kk = jj + 1; kk < merged_childrenList[ii].size(); kk++)
					{
						if (merged_childrenList[ii][kk] != -1 && merged_childrenList[ii][jj] == merged_childrenList[ii][kk])
							merged_childrenList[ii][jj] = -1, merged_childrenList[ii][kk] = -1;
					}
				}
			}
		}

		sprintf(Fname, "%s/%d/flowgraph_%d_%d_%d.txt", Path, sCamId, startF, stopF, nJoints); FILE *fp = fopen(Fname, "w");
		for (int id = 0; id < (int)merged_childrenList.size(); id++)
		{
			fprintf(fp, "%d ", vfid[id]);
			for (int pid = 0; pid < merged_childrenList[id].size(); pid++)
				fprintf(fp, "%d ", merged_childrenList[id][pid]);
			fprintf(fp, "\n");
		}
		fclose(fp);
	}
	else
	{
		int fid, pid, nPeople, lastFid = -1;
		vector<int> list;

		std::string line, item;
		std::ifstream file(Fname);
		if (!file.is_open())
			return 0;
		while (std::getline(file, line))
		{
			StringTrim(&line);//remove white space
			if (line.empty())
				continue;

			std::stringstream line_stream(line);
			std::getline(line_stream, item, ' '); fid = atoi(item.c_str());
			if (lastFid != -1 && fid != lastFid)
			{
				list.clear();
				for (int ii = lastFid + 1; ii < fid; ii++)
				{
					vfid.push_back(ii);
					merged_childrenList.push_back(list);
				}
			}
			vfid.push_back(fid);

			list.clear();
			while (!line_stream.eof())
			{
				std::getline(line_stream, item, ' '); StringTrim(&item);
				pid = atoi(item.c_str()), list.push_back(pid);
			}
			merged_childrenList.push_back(list);
			lastFid = fid;
		}
		file.close();
	}

	//parse the life tree
	printLOG("Parsing the network...");
	int PersonId = 0;
	vector<vector<int>* > AssignedPeople;
	for (size_t ii = 0; ii < merged_childrenList.size(); ii++)
	{
		vector<int> *temp = new vector<int>[1];
		for (size_t pid = 0; pid < merged_childrenList[ii].size(); pid++)
			temp[0].push_back(-1);
		AssignedPeople.push_back(temp);
	}

	vector<int> VstartFInstance;
	vector<vector<int> >trackletVec;
	for (size_t ii = 0; ii < merged_childrenList.size(); ii++)
	{
		vector<int> *tempAssignedPeople = AssignedPeople[ii];
		vector<int> AssignedId;
		for (size_t pid = 0; pid < merged_childrenList[ii].size(); pid++)
		{
			if (tempAssignedPeople[0][pid] != -1)
				continue;

			AssignedId.clear();
			AssignedId.push_back(pid);
			tempAssignedPeople[0][pid] = 1;
			VstartFInstance.push_back(vfid[ii]);
			int currentRealFid = VstartFInstance.back(), localfid = ii, //localfid is the id of the line.
				currentParent = pid;

			//printLOG("%d/%d.. ", currentRealFid, pid); //frame currentRealFid, point pid, where is your child?
			while (true) //start tracing
			{
				if (localfid + 1 == AssignedPeople.size() || merged_childrenList[localfid].size() == 0) //happen when I try to make sure they have the same # of lines (lastFid!=stopF)
					break;
				int currentChild = merged_childrenList[localfid][currentParent];
				if (currentChild != -1)
				{
					if (AssignedPeople[localfid + 1][0].size() == 0)
						break;

					//printLOG("%d/%d.. ", currentRealFid, currentChild); //here is my child in frame currentRealFid+1
					AssignedId.push_back(currentChild);
					AssignedPeople[localfid + 1][0][currentChild] = 1;
					currentParent = currentChild;
					localfid++;
					currentRealFid++;

				}
				else
					break;
				if (vfid[localfid - 1] + 1 != vfid[localfid]) //discontinued tracklet
					break;
			}
			if (AssignedId.size() > 1)
				trackletVec.push_back(AssignedId);
			else
				VstartFInstance.pop_back();
			//printLOG("\n");
		}
	}

	//write data
	printLOG("Done! Write output\n");
	sprintf(Fname, "%s/%d/rawTracklet_%d_%d_%d.txt", Path, sCamId, startF, stopF, nJoints); FILE *fp = fopen(Fname, "w");
	for (int id = 0; id < (int)trackletVec.size(); id++)
	{
		fprintf(fp, "%d %d ", (int)trackletVec[id].size(), VstartFInstance[id]);
		for (int tid = 0; tid < trackletVec[id].size(); tid++)
			fprintf(fp, "%d ", (int)trackletVec[id][tid]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	//Visualize the tracker
	if (debug > 0)
	{
		const double resizeFactor = 0.75;
		float u, v, s;
		vector<vector<Point2f> *> allPoses;
		vector<Mat> allImages; Mat img;

		vector<Scalar> colors;
		colors.push_back(Scalar(0, 0, 255));
		colors.push_back(Scalar(0, 128, 255));
		colors.push_back(Scalar(0, 255, 255));
		colors.push_back(Scalar(0, 255, 0));
		colors.push_back(Scalar(255, 128, 0));
		colors.push_back(Scalar(255, 255, 0));
		colors.push_back(Scalar(255, 0, 0));
		colors.push_back(Scalar(255, 0, 255));
		colors.push_back(Scalar(255, 255, 255));

		int increP = 10;
		vector<float>vConf;
		printLOG("Visualization... Reading images: ");
		for (int fid = startF; fid <= stopF; fid++)
		{
			vConf.clear();
			vector<Point2f> *PoseI = new vector<Point2f>[1];
			if (readOpenPoseJson(Path, sCamId, fid, PoseI[0], vConf) == 0)
			{
				sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, sCamId, fid); fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					PoseI[0].push_back(Point2f(u, v));
				fclose(fp);
			}
			allPoses.push_back(PoseI);

			sprintf(Fname, "%s/%d/%.4d.jpg", Path, sCamId, fid);
			img = imread(Fname);
			if (img.empty())
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, sCamId, fid); img = imread(Fname);
				if (img.empty())
					continue;
			}
			resize(img, img, Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
			allImages.push_back(img);
			if (100 * (fid - startF) / (stopF - startF) > increP)
				printLOG("%d%%..", increP), increP += 10;
		}
		printLOG("100%%\n");
		if (allImages.size() == 0)
			return 0;

		for (int id = 0; id < (int)trackletVec.size(); id++)
		{
			for (int tid = 0; tid < trackletVec[id].size(); tid++)
			{
				int fid = VstartFInstance[id] + tid;
				if (fid - startF > allImages.size() - 1)
					continue;

				vector<Point2f> temp = allPoses[fid - startF][0];
				int pid = trackletVec[id][tid];
				int s = (int)temp.size(), cs = pid * nJoints + 1;

				Point2f tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (int jid = 0; jid < nJoints; jid++)
				{
					if (temp[pid * nJoints + jid].x > 0)
						tl.x = min(tl.x, temp[pid * nJoints + jid].x), tl.y = min(tl.y, temp[pid * nJoints + jid].y), br.x = max(br.x, temp[pid * nJoints + jid].x), br.y = max(br.y, temp[pid * nJoints + jid].y);
				}
				tl.x *= resizeFactor, tl.y *= resizeFactor, br.x *= resizeFactor, br.y *= resizeFactor;
				rectangle(allImages[fid - startF], tl, br, colors[id % 9], 2, 8, 0);
				Draw2DCoCoJoints(allImages[fid - startF], &temp[pid * nJoints], nJoints, resizeFactor*allImages[fid - startF].cols / 640, resizeFactor);
				sprintf(Fname, "%d", id); putText(allImages[fid - startF], Fname, Point2i(tl.x, br.y - resizeFactor * allImages[fid - startF].cols / 60), CV_FONT_HERSHEY_SIMPLEX, 0.75*allImages[fid - startF].cols / 640, colors[id % 9], 2);
			}
		}


		sprintf(Fname, "%s/Vis", Path); makeDir(Fname);
		sprintf(Fname, "%s/Vis/rawTracklet", Path); makeDir(Fname);
		if (debug > 1)
			sprintf(Fname, "%s/Vis/rawTracklet/%d", Path, sCamId), makeDir(Fname);

		VideoWriter writer;
		CvSize size; size.width = allImages[0].cols, size.height = allImages[0].rows;
		sprintf(Fname, "%s/Vis/rawTracklet/%d_%d_%d.avi", Path, sCamId, startF, stopF), writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
		for (int fid = startF; fid <= stopF; fid++)
		{
			if (fid - startF > allImages.size() - 1)
				continue;
			CvPoint text_origin = { allImages[fid - startF].cols / 20, allImages[fid - startF].rows / 15 };
			sprintf(Fname, "%d", fid); putText(allImages[fid - startF], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, allImages[fid - startF].cols / 640, colors[0], 2);

			if (debug > 1)
				sprintf(Fname, "%s/Vis/rawTracklet/%d/%.4d.jpg", Path, sCamId, fid), imwrite(Fname, allImages[fid - startF]);
			writer << allImages[fid - startF];

			//namedWindow("X", CV_WINDOW_NORMAL);
			//cvSetWindowProperty("X", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN);
			//imshow("X", allImages[fid - startF]); waitKey(10);
		}
		writer.release();
	}

	sprintf(Fname, "%s/Logs/PerVideoMultiPeopleTracklet_%d_%.4d_%4d.txt", Path, sCamId, startF, stopF);
	fp = fopen(Fname, "w"); fclose(fp);

	return 0;
}
int ReAssociateTracklets(char *Path, int sCamId, int startF, int stopF, int increF)
{
	char Fname[512];
	//Read tracklet info
	int nf, sf, pid;
	vector<vector<Point2i> >trackletVec;
	sprintf(Fname, "%s/%d/Tracklet_%d_%d.txt", Path, sCamId, startF, stopF); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
	{
		vector<Point2i> tracklet;
		for (int f = 0; f < nf; f++)
		{
			fscanf(fp, "%d ", &pid);
			tracklet.push_back(Point2i(sf + f, pid));
		}
		trackletVec.push_back(tracklet);
	}
	fclose(fp);

	//Read all desc
	vector<Mat> allDesc;
	const int descLength = 256;
	vector<float> desc;
	for (int fid = 0; fid < startF; fid++)
		allDesc.push_back(Mat());
	for (int fid = startF; fid <= stopF; fid++)
	{
		sprintf(Fname, "%s/MP/%d/Desc/%.4d.txt", Path, sCamId, fid); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		float d; desc.clear();
		while (fscanf(fp, "%f ", &d) != EOF)
		{
			desc.push_back(d);
			for (int ii = 0; ii < descLength - 1; ii++)
			{
				fscanf(fp, "%f ", &d); desc.push_back(d);
			}
		}
		fclose(fp);
		int npeople = (int)desc.size() / descLength;
		Mat Desc = Mat::zeros(npeople, descLength, CV_32F);
		float *ptr = Desc.ptr<float>(0);
		for (int ii = 0; ii < npeople*descLength; ii++)
			ptr[ii] = desc[ii];

		allDesc.push_back(Desc);
	}

	//re-associate tracklet using desc
	int  matchingWindow = 1;
	vector<float> FirstdescI, LastdescI, FirstdescJ, LastdescJ;
	FirstdescI.reserve(matchingWindow*descLength), LastdescI.reserve(matchingWindow*descLength),
		FirstdescJ.reserve(matchingWindow*descLength), LastdescJ.reserve(matchingWindow*descLength);
	vector<Point2i> trackletAsso;
	int ID[1000]; double CostArray[1000];
	for (size_t trajI = 0; trajI < trackletVec.size() - 1; trajI++)
	{
		int trackLength = (int)trackletVec[trajI].size();
		vector<Point2i> nfirstPidI, nlastPidI;
		for (int ii = 0; ii < min(matchingWindow, trackLength); ii++)
			nfirstPidI.push_back(trackletVec[trajI][ii]);
		for (int ii = 0; ii < min(matchingWindow, trackLength); ii++)
			nlastPidI.push_back(trackletVec[trajI][trackLength - 1 - ii]);

		//Look up desc
		FirstdescI.clear(), LastdescI.clear();
		for (size_t ii = 0; ii < FirstdescI.size(); ii++)
		{
			int f = nfirstPidI[ii].x, p = nfirstPidI[ii].y;
			const float *ptr = allDesc[f].ptr<float>(0);
			for (int jj = 0; jj < descLength; jj++)
				FirstdescI.push_back(ptr[jj + p * descLength]);
		}
		for (size_t ii = 0; ii < nlastPidI.size(); ii++)
		{
			int f = nlastPidI[ii].x, p = nlastPidI[ii].y;
			const float *ptr = allDesc[f].ptr<float>(0);
			for (int jj = 0; jj < descLength; jj++)
				LastdescI.push_back(ptr[jj + p * descLength]);
		}

		int count = 0;
		for (size_t trajJ = 0; trajJ < trackletVec.size(); trajJ++)
		{
			if (trajI == trajJ)
				continue;

			int trackLength = (int)trackletVec[trajJ].size();
			vector<Point2i> nfirstPidJ, nlastPidJ;
			for (int ii = 0; ii < min(matchingWindow, trackLength); ii++)
				nfirstPidJ.push_back(trackletVec[trajJ][ii]);
			for (int ii = 0; ii < min(matchingWindow, trackLength); ii++)
				nlastPidJ.push_back(trackletVec[trajJ][trackLength - 1 - ii]);

			//Look up desc
			FirstdescJ.clear(), LastdescJ.clear();
			for (size_t ii = 0; ii < nfirstPidJ.size(); ii++)
			{
				int f = nfirstPidJ[ii].x, p = nfirstPidJ[ii].y;
				const float *ptr = allDesc[f].ptr<float>(0);
				for (int jj = 0; jj < descLength; jj++)
					FirstdescJ.push_back(ptr[jj + p * descLength]);
			}
			for (size_t ii = 0; ii < nlastPidJ.size(); ii++)
			{
				int f = nlastPidJ[ii].x, p = nlastPidJ[ii].y;
				const float *ptr = allDesc[f].ptr<float>(0);
				for (int jj = 0; jj < descLength; jj++)
					LastdescJ.push_back(ptr[jj + p * descLength]);
			}

			//compute L2 score
			double CostEndI_StartJ = 0;
			int nEndI_StartJ = min((int)LastdescI.size() / descLength, (int)FirstdescJ.size() / descLength);
			if (nEndI_StartJ > 0)
			{
				for (int ii = 0; ii < nEndI_StartJ; ii++)
				{
					double cost = 0;
					for (int jj = 0; jj < descLength; jj++)
						cost += pow(LastdescI[jj + ii * descLength] - FirstdescJ[jj + ii * descLength], 2);
					CostEndI_StartJ += sqrt(cost);
				}
				CostEndI_StartJ = CostEndI_StartJ / nEndI_StartJ;
			}
			else
				CostEndI_StartJ = 9e9;

			double CostStartI_EndJ = 0;
			int nStartI_EndJ = min((int)FirstdescI.size() / descLength, (int)LastdescJ.size() / descLength);
			if (nStartI_EndJ > 0)
			{
				for (int ii = 0; ii < nStartI_EndJ; ii++)
				{
					double cost = 0;
					for (int jj = 0; jj < descLength; jj++)
						cost += pow(FirstdescI[jj + ii * descLength] - LastdescJ[jj + ii * descLength], 2);
					CostStartI_EndJ += sqrt(cost);
				}
				CostStartI_EndJ = CostStartI_EndJ / nStartI_EndJ;
			}
			else
				CostStartI_EndJ = 9e9;

			CostArray[count] = min(CostEndI_StartJ, CostStartI_EndJ);
			ID[count] = trajJ;
			count++;
		}
		if (count > 1)
			Quick_Sort_Double(CostArray, ID, 0, count - 1);
		double minCost = CostArray[0]; int bestAsso = ID[0];
		if (minCost < 0.8)
			trackletAsso.push_back(Point2i(trajI, bestAsso));
	}

	sprintf(Fname, "%s/%d/AssignedTracklet_%d_%d.txt", Path, sCamId, startF, stopF);  fp = fopen(Fname, "w");
	for (size_t ii = 0; ii < trackletAsso.size(); ii++)
		fprintf(fp, "%d %d\n", trackletAsso[ii].x, trackletAsso[ii].y);
	fclose(fp);

	return 0;
}


int MultiviewPeopleAssociationFundMat(char *Path, int nCams, int startF, int stopF, int increF, int Debug = 0)
{
	//assume approx sync video images.
	vector<int> jList; jList.push_back(0), jList.push_back(1), jList.push_back(2), jList.push_back(5), jList.push_back(8), jList.push_back(11);

	char Fname[512]; sprintf(Fname, "%s/MultiviewReID", Path); makeDir(Fname);

	CameraData *allCamInfo = new CameraData[nCams];
	ReadIntrinsicResults(Path, allCamInfo);

	omp_set_num_threads(omp_get_max_threads());
	//#pragma omp parallel for
	for (int fid = startF; fid <= stopF; fid++)
	{
		char Fname[512];
		double u, v, s;
		vector<Point2d> pts0, pts1;
		vector<int> randNum(100);
		int ninlierThresh = 8, iterMax = 10000;
		double detectionThresh = 0.5, reprojectionThresh = 20.0;
		double Fmat[9], BestFmat[9], meanErr = 9e9;
		vector<int> vinliers;
		vector<Point2d> * allPts = new vector<Point2d>[nCams];

		//read pose detection
		for (int cid = 0; cid < nCams; cid++)
		{
			allPts[cid].clear();
			sprintf(Fname, "%s/Pose/%d/%d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%lf %lf %lf ", &u, &v, &s) != EOF)
			{
				if (s < detectionThresh)
					allPts[cid].push_back(Point2d(0, 0));
				else
				{
					Point2d uv(u, v);
					if (allCamInfo[cid].LensModel == RADIAL_TANGENTIAL_PRISM)
						LensCorrectionPoint(&uv, allCamInfo[cid].K, allCamInfo[cid].distortion);
					else
						//FishEyeCorrectionPoint(&uv, allCamInfo[cid].distortion[0], allCamInfo[cid].distortion[1], allCamInfo[cid].distortion[1]);
						FishEyeCorrectionPoint(&uv, allCamInfo[cid].K, allCamInfo[cid].distortion[0]);

					allPts[cid].push_back(uv);
				}
			}
			fclose(fp);
		}

		double startTime = omp_get_wtime();
		vector<Point2i>  *allBestPeopleParing = new vector<Point2i>[nCams*nCams];
		double *allBestAvgErr = new double[nCams*nCams];

		sprintf(Fname, "%s/MultiviewReID/_%d.txt", Path, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			for (int cidJ = 0; cidJ < nCams; cidJ++)
			{
				for (int cidI = cidJ + 1; cidI < nCams; cidI++)
				{
					//lets get 2 detections from each view to do Fmat (10 points)
					double bestMeanErr = 9e9;
					allBestAvgErr[cidI + cidJ * nCams] = 0.0;
					int nIinliers = 0, BestnInliers = 0, iter = 0;
					vector<Point2i> BestPeoplePairing;
					while (iter < iterMax)
					{
						int nPeopleJ = (int)allPts[cidJ].size() / 15, nPeopleI = (int)allPts[cidI].size() / 15;
						if (BestPeoplePairing.size() > 7 * nPeopleJ / 10) //threshold for people asso
							break;

						randNum.clear();
						for (int ii = 0; ii < nPeopleJ; ii++)
							randNum.push_back(ii);
						random_shuffle(randNum.begin(), randNum.end());
						vector<int> pidJ;
						for (int ii = 0; ii < min(2, nPeopleJ); ii++)
							pidJ.push_back(randNum[ii]);

						randNum.clear();
						for (int ii = 0; ii < nPeopleI; ii++)
							randNum.push_back(ii);
						random_shuffle(randNum.begin(), randNum.end());
						vector<int> pidI;
						for (int ii = 0; ii < min(2, nPeopleI); ii++)
							pidI.push_back(randNum[ii]);

						int nPeopleSample = min(pidJ.size(), pidI.size());
						pts0.clear(), pts1.clear();
						for (int ii = 0; ii < nPeopleSample; ii++)
						{
							for (auto jid : jList)
							{
								if (allPts[cidJ][pidJ[ii] * 15 + jid].x == 0 || allPts[cidI][pidI[ii] * 15 + jid].x == 0)
									continue;

								pts0.push_back(allPts[cidJ][pidJ[ii] * 15 + jid]);
								pts1.push_back(allPts[cidI][pidI[ii] * 15 + jid]);
							}
						}

						//compute Fmat
						vinliers.clear();
						computeFmat8Point(pts0, pts1, Fmat);
						nIinliers = EvaluateFmat(pts0, pts1, Fmat, vinliers, meanErr, reprojectionThresh);
						if (nIinliers > BestnInliers)
						{
							BestnInliers = nIinliers;
							for (int ii = 0; ii < 9; ii++)
								BestFmat[ii] = Fmat[ii];

							int onBestPeoplePairing = 0, nnBestPeopleParing = 1;
							while (true)
							{
								if (onBestPeoplePairing == nnBestPeopleParing)
									break;

								//lets find more people asso
								vector<int> used(nPeopleI);
								vector<Point2i> peoplePairing;
								for (int pidj = 0; pidj < nPeopleJ; pidj++)
								{
									pts0.clear();
									for (auto jid : jList)
										pts0.push_back(allPts[cidJ][pidj * 15 + jid]);

									int bestAsso = 0, bestInlierI = 0; double bestMeanErr = 9e9;
									for (int pidi = 0; pidi < nPeopleI; pidi++)
									{
										if (used[pidi] == 1)
											continue;
										pts1.clear();
										for (auto jid : jList)
											pts1.push_back(allPts[cidI][pidi * 15 + jid]);

										int ninliers = 0;
										double meanError = 0, error;
										for (int ii = 0; ii < (int)pts0.size(); ii++)
										{
											error = FmatPointError(Fmat, pts0[ii], pts1[ii]);
											if (error < reprojectionThresh)
											{
												ninliers++;
												meanError += error;
											}
										}
										meanError /= (0.00000001 + ninliers);

										if (meanError < reprojectionThresh && meanError < bestMeanErr &&	ninliers > 2 && bestInlierI < ninliers)
											bestMeanErr = meanError, bestInlierI = ninliers, bestAsso = pidi;
									}

									if (bestMeanErr < reprojectionThresh && bestInlierI>2 && used[bestAsso] == 0)
										used[bestAsso] = 1, peoplePairing.push_back(Point2i(pidj, bestAsso));
								}

								nPeopleSample = peoplePairing.size();
								onBestPeoplePairing = nnBestPeopleParing;
								if (nPeopleSample > 2)
								{
									pts0.clear(), pts1.clear();
									for (int ii = 0; ii < nPeopleSample; ii++)
									{
										for (auto jid : jList)
										{
											if (allPts[cidJ][peoplePairing[ii].x * 15 + jid].x == 0 || allPts[cidI][peoplePairing[ii].y * 15 + jid].x == 0)
												continue;
											pts0.push_back(allPts[cidJ][peoplePairing[ii].x * 15 + jid]);
											pts1.push_back(allPts[cidI][peoplePairing[ii].y * 15 + jid]);
										}
									}

									vinliers.clear();
									computeFmat8Point(pts0, pts1, Fmat);
									nIinliers = EvaluateFmat(pts0, pts1, Fmat, vinliers, meanErr, reprojectionThresh);
									if (nIinliers > BestnInliers)
									{
										nnBestPeopleParing = (int)peoplePairing.size();
										BestPeoplePairing = peoplePairing;
										BestnInliers = nIinliers; bestMeanErr = meanErr;
										for (int ii = 0; ii < 9; ii++)
											BestFmat[ii] = Fmat[ii];

										if (BestPeoplePairing.size() > 7 * nPeopleJ / 10) //threshold for people asso
											break;
									}
								}
								else
									break;
							}
						}
						iter++;
					}

					allBestAvgErr[cidI + cidJ * nCams] = bestMeanErr, allBestAvgErr[cidJ + cidI * nCams] = bestMeanErr;
					allBestPeopleParing[cidI + cidJ * nCams] = BestPeoplePairing;
					for (size_t ii = 0; ii < BestPeoplePairing.size(); ii++)
						allBestPeopleParing[cidJ + cidI * nCams].push_back(Point2i(BestPeoplePairing[ii].y, BestPeoplePairing[ii].x));
				}
			}

			sprintf(Fname, "%s/MultiviewReID/_%d.txt", Path, fid); fp = fopen(Fname, "w");
			for (int cidJ = 0; cidJ < nCams; cidJ++)
			{
				for (int cidI = cidJ + 1; cidI < nCams; cidI++)
				{
					if (allBestPeopleParing[cidI + cidJ * nCams].size() < 2)
						continue;
					fprintf(fp, "%d %d %d %.2f ", cidJ, cidI, allBestPeopleParing[cidI + cidJ * nCams].size(), allBestAvgErr[cidI + cidJ * nCams]);
					for (size_t asso = 0; asso < allBestPeopleParing[cidI + cidJ * nCams].size(); asso++)
						fprintf(fp, "%d %d ", allBestPeopleParing[cidI + cidJ * nCams][asso].x, allBestPeopleParing[cidI + cidJ * nCams][asso].y);
					fprintf(fp, "\n");
				}
			}
			fclose(fp);
		}
		else
		{
			int cidI, cidJ, pidI, pidJ, nasso; float score;
			while (fscanf(fp, "%d %d %d %f ", &cidJ, &cidI, &nasso, &score) != EOF)
			{
				vector<Point2i> BestPeoplePairing;
				for (int ii = 0; ii < nasso; ii++)
				{
					fscanf(fp, "%d %d ", &pidJ, &pidI);
					BestPeoplePairing.push_back(Point2i(pidJ, pidI));
				}
				allBestAvgErr[cidI + cidJ * nCams] = score, allBestAvgErr[cidJ + cidI * nCams] = score;
				allBestPeopleParing[cidI + cidJ * nCams] = BestPeoplePairing;
				for (size_t ii = 0; ii < BestPeoplePairing.size(); ii++)
					allBestPeopleParing[cidJ + cidI * nCams].push_back(Point2i(BestPeoplePairing[ii].y, BestPeoplePairing[ii].x));
			}
			fclose(fp);
		}

		vector<vector<Point2i> > UniqueAssosID; //describe by cid and pid. One unique asso track is described by multiple (cid, pid) pairs.
		for (int cidJ = 0; cidJ < nCams; cidJ++)
		{
			for (int cidI = cidJ + 1; cidI < nCams; cidI++)
			{
				vector<Point2i> PeoplePair = allBestPeopleParing[cidI + cidJ * nCams];
				if (PeoplePair.size() < 2)
					continue;

				vector<int> asso;
				for (size_t ii = 0; ii < PeoplePair.size(); ii++)
				{
					int  pidJ = PeoplePair[ii].x, pidI = PeoplePair[ii].y;

					//Get uniqueAssoID
					int foundID = -1, left = 0, right = 0;
					for (size_t jj = 0; jj < UniqueAssosID.size() && foundID == -1; jj++)
					{
						for (size_t kk = 0; kk < UniqueAssosID[jj].size() && foundID == -1; kk++)
						{
							if (UniqueAssosID[jj][kk].x == cidI && UniqueAssosID[jj][kk].y == pidI)
								foundID = jj, left = 1;
							else if (UniqueAssosID[jj][kk].x == cidJ && UniqueAssosID[jj][kk].y == pidJ)
								foundID = jj, right = 1;
						}
					}
					if (foundID == -1)
					{
						vector<Point2i> newUniqueAssosID;
						newUniqueAssosID.push_back(Point2i(cidI, pidI)), newUniqueAssosID.push_back(Point2i(cidJ, pidJ));
						UniqueAssosID.push_back(newUniqueAssosID);
					}
					else
					{
						if (right == 1)
							UniqueAssosID[foundID].push_back(Point2i(cidI, pidI));
						else if (left == 1)
							UniqueAssosID[foundID].push_back(Point2i(cidJ, pidJ));
					}
				}
			}
		}

		//lets go through all UniqueAssosID and determine if wrong asso happens in a loop
		for (size_t id = 0; id < UniqueAssosID.size(); id++)
		{
			bool AssoFailure = false;
			for (size_t assoC = 0; assoC < UniqueAssosID[id].size() && !AssoFailure; assoC++) //same cid but different pid;
			{
				for (size_t assoP = 0; assoP < UniqueAssosID[id].size() && !AssoFailure; assoP++)
				{
					if (UniqueAssosID[id][assoC].x == UniqueAssosID[id][assoP].x && UniqueAssosID[id][assoC].y != UniqueAssosID[id][assoP].y) //lets be conservative and delete the entire track
					{
						AssoFailure = true;
						printLOG("Inconsistency association detected @ %d of %d\n", id, fid);
					}
				}
			}

			if (AssoFailure)
				UniqueAssosID[id].clear();
		}

		//Now that we can find the same ID accross view
		sprintf(Fname, "%s/MultiviewReID/%d.txt", Path, fid); fp = fopen(Fname, "w");
		for (size_t id = 0; id < UniqueAssosID.size(); id++)
		{
			if (UniqueAssosID[id].size() < 2)
				continue;
			for (size_t asso = 0; asso < UniqueAssosID[id].size(); asso++)
				fprintf(fp, "%d ", UniqueAssosID[id][asso].x);
			fprintf(fp, "\n");
		}
		fclose(fp);

		if (Debug == 1)
		{
			double resizeFactor = 0.4;
			vector<Mat> img;
			for (int cid = 0; cid < nCams; cid++)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid); Mat imgi = imread(Fname);
				resize(imgi, imgi, Size(resizeFactor* imgi.cols, resizeFactor*imgi.rows), 0, 0, INTER_AREA);
				img.push_back(imgi);
			}

			vector<int> Hit(nCams);
			for (size_t id = 0; id < UniqueAssosID.size(); id++)
			{
				if (UniqueAssosID[id].size() < 2)
					continue;
				for (size_t asso = 0; asso < UniqueAssosID[id].size(); asso++)
				{
					int cid = UniqueAssosID[id][asso].x, pid = UniqueAssosID[id][asso].y;
					Hit[cid] = 1;
					CvPoint text_origin = { (int)(resizeFactor*(allPts[cid][pid * 15 + 1].x - 10)), (int)(resizeFactor*(allPts[cid][pid * 15 + 1].y - 10)) };
					sprintf(Fname, "%d", id);
					putText(img[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*img[cid].cols / 640, CV_RGB(0, 255, 0), 1);
				}
			}

			for (int cid = 0; cid < nCams; cid++)
				if (Hit[cid] == 1)
					sprintf(Fname, "%s/MultiviewReID/%.4d_%d.jpg", Path, fid, cid), imwrite(Fname, img[cid]);
		}

#pragma omp critical
		printLOG("(%d: %.2fs) ..", fid, omp_get_wtime() - startTime);
		delete[]allPts, delete[]allBestPeopleParing, delete[]allBestAvgErr;
	}

	return 0;
}

struct TripletOfTtriplet {
	int id[9];
};
int MatchPeopleDescAllPairs(char *Path, int nCams, int startF, int stopF, int increF, vector<int> &TimeStamp)
{
	const int descSize = 256;

	//the distance metric is cosine distance
	char Fname[512];
	FILE *fp = 0;

	sprintf(Fname, "%s/Logs", Path); makeDir(Fname);
	sprintf(Fname, "%s/Logs/MatchPeopleDescAllPairs_%d_%d_%d.txt", Path, nCams, startF, stopF);
	if (IsFileExist(Fname) == 1)
	{
		printLOG("%s computed\n", Fname);
		return 0;
	}

	float desc, score, norm;
	vector<float> desc1, desc2;
	desc1.reserve(descSize * 20), desc2.reserve(descSize * 20);

	sprintf(Fname, "%s/MP/Matches", Path); makeDir(Fname);

	for (int fid = startF; fid <= stopF; fid += increF)
	{
		for (int cidI = 0; cidI < nCams - 1; cidI++)
		{
			sprintf(Fname, "%s/MP/%d/Desc/%.4d.txt", Path, cidI, fid - TimeStamp[cidI]);
			if (IsFileExist(Fname) == 0)
				continue;

			desc1.clear();
			fp = fopen(Fname, "r");
			while (fscanf(fp, "%f ", &desc) != EOF)
			{
				desc1.push_back(desc);
				for (int ii = 0; ii < 255; ii++)
					fscanf(fp, "%f ", &desc), desc1.push_back(desc);
			}
			fclose(fp);

			//normalize desc
			int nP1 = (int)desc1.size() / descSize;
			for (int pid = 0; pid < nP1; pid++)
			{
				norm = 0;
				for (int jj = 0; jj < descSize; jj++)
					norm += pow(desc1[pid*descSize + jj], 2);
				norm = sqrt(norm);
				for (int jj = 0; jj < descSize; jj++)
					desc1[pid*descSize + jj] /= norm;
			}

			for (int cidJ = cidI + 1; cidJ < nCams; cidJ++)
			{
				sprintf(Fname, "%s/MP/%d/Desc/%.4d.txt", Path, cidJ, fid - TimeStamp[cidJ]);
				if (IsFileExist(Fname) == 0)
					continue;

				desc2.clear();
				fp = fopen(Fname, "r");
				while (fscanf(fp, "%f ", &desc) != EOF)
				{
					desc2.push_back(desc);
					for (int ii = 0; ii < 255; ii++)
						fscanf(fp, "%f ", &desc), desc2.push_back(desc);
				}
				fclose(fp);

				//normalize desc
				int nP2 = (int)desc2.size() / descSize;
				for (int pid = 0; pid < nP2; pid++)
				{
					norm = 0;
					for (int jj = 0; jj < descSize; jj++)
						norm += pow(desc2[pid*descSize + jj], 2);
					norm = sqrt(norm);
					for (int jj = 0; jj < descSize; jj++)
						desc2[pid*descSize + jj] /= norm;
				}

				//matching
				sprintf(Fname, "%s/MP/Matches/%d_%d_%d.txt", Path, fid, cidI, cidJ); fp = fopen(Fname, "w");
				for (int pid1 = 0; pid1 < nP1; pid1++)
				{
					for (int pid2 = 0; pid2 < nP2; pid2++)
					{
						score = 0.0;
						for (int ii = 0; ii < descSize; ii++)
							score += desc1[pid1*descSize + ii] * desc2[pid2*descSize + ii];
						fprintf(fp, "%d %d %.3f\n", pid1, pid2, score);
					}
				}
				fclose(fp);
			}
		}
	}

	sprintf(Fname, "%s/Logs/MatchPeopleDescAllPairs_%d_%d_%d.txt", Path, nCams, startF, stopF);
	fp = fopen(Fname, "w"); fclose(fp);

	return 0;
}
int MatchPeopleDescPerTimeInstance(char *Path, vector<int> &sCams, vector<int> &TimeStamp, int startF, int stopF, int increF, int distanceMetricType = 1)
{
	const int descSize = 256, maxPeople = 20, maxnCams = 20;
	int KNN = (int)sCams.size(); double ScoreThesh = 0.75, ScoreRatio = 0.8;

	//the distance metric is cosine distance
	char Fname[512];
	FILE *fp = 0;

	float desc, score, norm;
	vector<float> AllDescs[maxPeople * maxnCams];
	int matchID[maxPeople * maxnCams];
	double Score[maxPeople * maxnCams];
	float descI[descSize];
	vector<Point2i> CidPid;
	vector<Point2i> mCidPid;

	sprintf(Fname, "%s/MP/MatchesInstances", Path); makeDir(Fname);

	for (int fid = startF; fid <= stopF; fid += increF)
	{
		printLOG("%d..", fid);
		int pidCount = 0; CidPid.clear();
		for (auto cid : sCams)
		{
			sprintf(Fname, "%s/MP/%d/Desc/%.4d.txt", Path, cid, fid - TimeStamp[cid]);
			if (IsFileExist(Fname) == 0)
				continue;

			fp = fopen(Fname, "r");
			int pid = 0;
			while (fscanf(fp, "%f ", &desc) != EOF)
			{
				descI[0] = desc, norm = desc * desc;
				for (int ii = 0; ii < 255; ii++)
					fscanf(fp, "%f ", &desc), descI[ii + 1] = desc, norm += desc * desc;

				norm = sqrt(norm);
				for (int ii = 0; ii < descSize; ii++)
					descI[ii] /= norm;

				AllDescs[pidCount].clear();
				for (int ii = 0; ii < descSize; ii++)
					AllDescs[pidCount].push_back(descI[ii]);
				CidPid.push_back(Point2i(cid, pid));
				pidCount++, pid++;
			}
			fclose(fp);
		}

		//matching
		sprintf(Fname, "%s/MP/MatchesInstances/%.4d.txt", Path, fid); fp = fopen(Fname, "w");
		for (int ii = 0; ii < pidCount; ii++)
		{
			int count = 0;
			for (int jj = 0; jj < pidCount; jj++)
			{
				if (ii == jj || CidPid[ii].x == CidPid[jj].x)
					continue;
				score = 0.0;
				for (int kk = 0; kk < descSize; kk++)
					score += AllDescs[ii][kk] * AllDescs[jj][kk];
				matchID[count] = jj; Score[count] = -score;
				count++;
			}

			Quick_Sort_Double(Score, matchID, 0, count - 1);

			mCidPid.clear();
			for (int kk = 0; kk < KNN; kk++)
			{
				if (-Score[kk] < ScoreThesh)
					break;
				if (kk > 0 && -Score[0] * ScoreRatio > -Score[kk])
					break;
				mCidPid.push_back(CidPid[matchID[kk]]);
			}

			if (mCidPid.size() > 0)
			{
				fprintf(fp, "%d %d %d ", mCidPid.size() + 1, CidPid[ii].x, CidPid[ii].y);
				for (size_t kk = 0; kk < mCidPid.size(); kk++)
					fprintf(fp, "%d %d %.2f ", mCidPid[kk].x, mCidPid[kk].y, -Score[kk]);
				fprintf(fp, "\n");
			}
		}
		fclose(fp);
	}

	sprintf(Fname, "%s/Logs/MatchPeopleDescPerTimeInstance_%d_%d.txt", Path, startF, stopF); fp = fopen(Fname, "w"); fclose(fp);

	return 0;
}
int FindPerPersonPerFrameKnnDescTemporalPoolingSpatioMatching(char *Path, vector<int> sCams, vector<int> &TimeStamp, int knn, int refStartF, int refStopF, int startF, int stopF, int increF, bool temporalPooling, int metriclearning = 1, int visPeriod = 0)
{
	bool debug = 0;
	double resizeFactor = 0.25;

	//Lets take the manually created merged_trackets to pin-point the people and compute knn of those people. Using the manually labeled data is not needed but it helps with visualization.
	char Fname[512];
	sprintf(Fname, "%s/Vis/SpatioMatching", Path); makeDir(Fname);

	const int nJoints = 18, descSize = 256, maxPeople = 60;
	struct PDesc {
		double desc[descSize];
	};
	struct TL_BR {
		Point2i tl, br;
	};

	int wholeImage = 0;
	int nf, sf, pid, nCams = (int)TimeStamp.size();
	vector<Point2i> tracklet, trackletID;
	vector<vector<Point2i> > *trackletVec = new vector<vector<Point2i> >[nCams];
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/%d/CleanTracklet_%d_%d.txt", Path, cid, refStartF, refStopF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/Tracklet_%d_%d.txt", Path, cid, refStartF, refStopF);
		FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
		{
			tracklet.clear();
			for (int f = 0; f < nf; f++)
			{
				fscanf(fp, "%d ", &pid);
				if (sf + f - TimeStamp[cid] < stopF && sf + f - TimeStamp[cid] >= startF)
					tracklet.push_back(Point2i(sf + f, pid));
			}
			trackletID.push_back(Point2i(cid, trackletVec[cid].size()));
			trackletVec[cid].push_back(tracklet);
		}
		fclose(fp);
	}

	PDesc pdesc;
	vector<PDesc> *allPDesc = new vector <PDesc>[nCams*stopF];
	vector<Point2f> *allLM = new vector<Point2f>[nCams];
	int *allNPeople = new int[nCams*stopF];
	for (int ii = 0; ii < nCams*stopF; ii++)
		allNPeople[ii] = 0;

	float u, v, s, desc, norm, descI[descSize];
	if (metriclearning == 0)
		sprintf(Fname, "%s/MP/AllTracklets_Dist.dat", Path);
	else if (metriclearning == 1)
		sprintf(Fname, "%s/MP/AllTracklets_Dist_TM.dat", Path);
	else if (metriclearning == 2)
		sprintf(Fname, "%s/MP/AllTracklets_Dist_STM4.dat", Path);
	else if (metriclearning == 3)
		sprintf(Fname, "%s/MP/AllTracklets_Dist_SM.dat", Path);
	if (IsFileExist(Fname) == 0)
	{
		for (auto cid : sCams)
		{
			for (int fid = startF; fid < stopF; fid += increF)
			{
				if (metriclearning == 0)
					sprintf(Fname, "%s/MP/%d/Desc/%.4d.txt", Path, cid, fid - TimeStamp[cid]);
				else if (metriclearning == 1)
					sprintf(Fname, "%s/MP/%d/Desc256_TM/%.4d.txt", Path, cid, fid - TimeStamp[cid]);
				else if (metriclearning == 2)
					sprintf(Fname, "X:/User/minh/Haloween/MP/%d/Desc256_STM4/%.4d.txt", cid, fid - TimeStamp[cid]);
				else if (metriclearning == 3)
					sprintf(Fname, "%s/MP/%d/Desc256_SM/%.4d.txt", Path, cid, fid - TimeStamp[cid]);
				FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
				{
					printLOG("Cannot load %s\n", Fname);
					continue;
				}
				int pid = 0;
				while (fscanf(fp, "%f ", &desc) != EOF)
				{
					pdesc.desc[0] = desc, norm = desc * desc;
					for (int ii = 0; ii < descSize - 1; ii++)
						fscanf(fp, "%f ", &desc), pdesc.desc[ii + 1] = desc, norm += desc * desc;

					norm = sqrt(norm);
					for (int ii = 0; ii < descSize; ii++)
						pdesc.desc[ii] /= norm;
					allPDesc[cid*stopF + fid].push_back(pdesc);
					pid++;
				}
				fclose(fp);

				allNPeople[cid*stopF + fid] = pid;
			}
		}
	}
	else
	{
		sprintf(Fname, "%s/MP/allNPeople.txt", Path);
		if (IsFileExist(Fname) == 0)
		{
			printLOG("Reading pose: ");
			for (auto cid : sCams)
			{
				printLOG("%d ..", cid);
				float u, v, s;
				for (int fid = startF; fid < stopF; fid += increF)
				{
					sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid - TimeStamp[cid]); FILE *fp = fopen(Fname, "r");
					if (fp == NULL)
						continue;
					int cnt = 0;
					while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
						cnt++;
					fclose(fp);
					allNPeople[cid*stopF + fid] = cnt / nJoints;
				}
			}
			printLOG("\n");
			sprintf(Fname, "%s/MP/allNPeople.txt", Path); FILE *fp = fopen(Fname, "w");
			for (int cid = 0; cid < nCams; cid++)
			{
				for (int fid = startF; fid < stopF; fid++)
					fprintf(fp, "%d ", allNPeople[cid*stopF + fid]);
				fprintf(fp, "\n");
			}
			fclose(fp);
		}
		else
		{
			FILE *fp = fopen(Fname, "r");
			for (int cid = 0; cid < nCams; cid++)
			{
				for (int fid = startF; fid < stopF; fid++)
					fscanf(fp, "%d ", &allNPeople[cid*stopF + fid]);
			}
			fclose(fp);
		}
	}

	sprintf(Fname, "%s/MP/PeopleDescSmatching", Path); makeDir(Fname);
	if (temporalPooling)
	{
		int ntracklets = (int)trackletID.size();
		double *AllDist = new double[ntracklets*ntracklets];
		if (metriclearning == 0)
			sprintf(Fname, "%s/MP/AllTracklets_Dist.dat", Path);
		else if (metriclearning == 1)
			sprintf(Fname, "%s/MP/AllTracklets_Dist_TM.dat", Path);
		else if (metriclearning == 2)
			sprintf(Fname, "%s/MP/AllTracklets_Dist_STM4.dat", Path);
		else if (metriclearning == 3)
			sprintf(Fname, "%s/MP/AllTracklets_Dist_SM.dat", Path);

		if (IsFileExist(Fname) == 0)
		{
			printLOG("Computing tracklet distance:");
			omp_set_num_threads(omp_get_max_threads());
#pragma omp parallel for schedule(dynamic,1)
			for (int tid1 = 0; tid1 < ntracklets - 1; tid1++)
			{
				vector<double> vscore;
				int cid1 = trackletID[tid1].x, id1 = trackletID[tid1].y;
				AllDist[tid1 + tid1 * ntracklets] = 1.0;
				for (int tid2 = tid1 + 1; tid2 < ntracklets; tid2++)
				{
					int cid2 = trackletID[tid2].x, id2 = trackletID[tid2].y;

					vscore.clear();
					for (int ii1 = 0; ii1 < trackletVec[cid1][id1].size(); ii1++)
					{
						int fid1 = trackletVec[cid1][id1][ii1].x + TimeStamp[cid1], pid1 = trackletVec[cid1][id1][ii1].y;
						if (fid1 < 0 || fid1>stopF || allPDesc[cid1*stopF + fid1].size() == 0)
							continue;
						for (int ii2 = 0; ii2 < trackletVec[cid2][id2].size(); ii2++)
						{
							int fid2 = trackletVec[cid2][id2][ii2].x + TimeStamp[cid2], pid2 = trackletVec[cid2][id2][ii2].y;
							if (fid2<0 || fid2>stopF || allPDesc[cid2*stopF + fid2].size() == 0)
								continue;

							double score = 0.0;
							for (int kk = 0; kk < descSize; kk++)
								score += allPDesc[cid1*stopF + fid1][pid1].desc[kk] * allPDesc[cid2*stopF + fid2][pid2].desc[kk];
							vscore.push_back(score);
						}
					}
					if (vscore.size() == 0)
						AllDist[tid1 + tid2 * ntracklets] = -1, AllDist[tid2 + tid1 * ntracklets] = -1;
					else
					{
						AllDist[tid1 + tid2 * ntracklets] = Median(vscore); //maybe more robust
						AllDist[tid2 + tid1 * ntracklets] = AllDist[tid1 + tid2 * ntracklets];
					}
				}
			}
			printLOG("Done\n");
			if (metriclearning == 0)
				sprintf(Fname, "%s/MP/AllTracklets_Dist.dat", Path);
			else if (metriclearning == 1)
				sprintf(Fname, "%s/MP/AllTracklets_Dist_TM.dat", Path);
			else if (metriclearning == 2)
				sprintf(Fname, "%s/MP/AllTracklets_Dist_STM4.dat", Path);
			else if (metriclearning == 3)
				sprintf(Fname, "%s/MP/AllTracklets_Dist_SM.dat", Path);
			WriteGridBinary(Fname, AllDist, ntracklets, ntracklets);
		}
		else
		{
			ReadGridBinary(Fname, AllDist, ntracklets, ntracklets);

			if (debug)
			{
				if (metriclearning == 0)
					sprintf(Fname, "%s/MP/AllTracklets_Dist.txt", Path);
				else if (metriclearning == 1)
					sprintf(Fname, "%s/MP/AllTracklets_Dist_TM.txt", Path);
				else if (metriclearning == 2)
					sprintf(Fname, "%s/MP/AllTracklets_Dist_STM4.txt", Path);
				else if (metriclearning == 3)
					sprintf(Fname, "%s/MP/AllTracklets_Dist_SM.txt", Path);
				if (IsFileExist(Fname) == 0)
				{
					FILE *fp = fopen(Fname, "w");
					for (int j = 0; j < ntracklets; ++j)
					{
						for (int i = 0; i < ntracklets; ++i)
							fprintf(fp, "%.3f ", AllDist[i + j * ntracklets]);
						fprintf(fp, "\n");
					}
					fclose(fp);
				}
			}
		}

		vector<Mat> vImg, allImg; Mat img, sImg, bImg, rbImg;
		int *tempID = new int[maxPeople*nCams];
		double *tempS = new double[maxPeople*nCams];
		for (int fid = startF; fid < stopF; fid += increF)
		{
			printLOG("%d..", fid);
			vector<Point3i> valid;
			for (auto cid : sCams)
			{
				for (int pid = 0; pid < allNPeople[cid*stopF + fid]; pid++)
				{
					int foundId = -1;
					for (size_t tid = 0; tid < trackletVec[cid].size() && foundId == -1; tid++) //grab all desc of the all tracklets within that instance
					{
						for (size_t lid = 0; lid < trackletVec[cid][tid].size() && foundId == -1; lid++)
							if (trackletVec[cid][tid][lid].x + TimeStamp[cid] == fid && trackletVec[cid][tid][lid].y == pid)
								foundId = tid;
					}

					if (foundId > -1)
					{
						int foundId2 = -1;
						for (int gtid = 0; gtid < ntracklets && foundId2 == -1; gtid++)
							if (cid == trackletID[gtid].x &&  foundId == trackletID[gtid].y)
								foundId2 = gtid;

						if (foundId2 > -1)
							valid.push_back(Point3i(cid, pid, foundId2)); //real fid, global tid in the distance matrix
					}
				}
			}

			if (metriclearning == 0)
				sprintf(Fname, "%s/MP/PeopleDescSmatching/%.4d.txt", Path, fid);
			else if (metriclearning == 1)
				sprintf(Fname, "%s/MP/PeopleDescSmatching/TM_%.4d.txt", Path, fid);
			else if (metriclearning == 2)
				sprintf(Fname, "%s/MP/PeopleDescSmatching/STM4_%.4d.txt", Path, fid);
			else if (metriclearning == 3)
				sprintf(Fname, "%s/MP/PeopleDescSmatching/SM_%.4d.txt", Path, fid);
			FILE *fp = fopen(Fname, "w");
			for (size_t ii = 0; ii < valid.size(); ii++)
			{
				int cid1 = valid[ii].x, pid1 = valid[ii].y, tid1 = valid[ii].z;
				for (size_t jj = 0; jj < valid.size(); jj++)
				{
					int cid2 = valid[jj].x, pid2 = valid[jj].y, tid2 = valid[jj].z;
					tempID[jj] = jj, tempS[jj] = -AllDist[tid2 + tid1 * ntracklets];
				}
				Quick_Sort_Double(tempS, tempID, 0, valid.size() - 1); //ascending order
																	   //for (int kk = 0; kk < min(knn + 1, (int)valid.size()); kk++)
																	   //	tempTID[kk] = valid[tempID[kk]].z;

				fprintf(fp, "%d ", valid.size());
				for (int kk = 0; kk < (int)valid.size(); kk++)
				{
					int id = tempID[kk];
					int cid = valid[id].x, pidi = valid[id].y, tid = valid[id].z;
					fprintf(fp, "%d %d %d %.2f ", cid, pidi, tid, -tempS[kk]);
					//printLOG("%d %d %d %.2f ", cid, pidi, tid, -tempS[kk]);
				}
				fprintf(fp, "\n");
				//printLOG("\n");
			}
			fclose(fp);

			if (visPeriod > 0 && fid%visPeriod == 0)
			{
				if (metriclearning == 0)
					sprintf(Fname, "%s/MP/PeopleDescSmatching/%.4d.txt", Path, fid);
				else if (metriclearning == 1)
					sprintf(Fname, "%s/MP/PeopleDescSmatching/TM_%.4d.txt", Path, fid);
				else if (metriclearning == 2)
					sprintf(Fname, "%s/MP/PeopleDescSmatching/STM4_%.4d.txt", Path, fid);
				else if (metriclearning == 3)
					sprintf(Fname, "%s/MP/PeopleDescSmatching/SM_%.4d.txt", Path, fid);
				FILE *fp = fopen(Fname, "r");
				int nn, cid, pid, gtid; float s;
				vector<Point2i> cidpid; vector<float> score;
				vector<vector<Point2i> > Vcidpid;
				vector<vector<float> > Vscore;
				while (fscanf(fp, "%d ", &nn) != EOF)
				{
					cidpid.clear(), score.clear();
					for (int kk = 0; kk < nn; kk++)
					{
						fscanf(fp, "%d %d %d %f ", &cid, &pid, &gtid, &s);
						cidpid.push_back(Point2i(cid, pid)), score.push_back(s);
					}
					Vcidpid.push_back(cidpid), Vscore.push_back(score);
				}
				fclose(fp);

				allImg.clear(); allImg.resize(nCams);
				for (auto cid : sCams)
				{
					allLM[cid].clear();
					sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid - TimeStamp[cid]); FILE *fp = fopen(Fname, "r");
					if (fp == NULL)
						continue;
					while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
						allLM[cid].push_back(Point2f(u, v));
					fclose(fp);

					sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid - TimeStamp[cid]);
					if (IsFileExist(Fname) == 0)
					{
						sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid - TimeStamp[cid]);
						if (IsFileExist(Fname) == 0)
							continue;
					}
					allImg[cid] = imread(Fname);
				}

				VideoWriter writer;
				CvSize size;
				if (wholeImage == 1)
					size.width = (int)(resizeFactor*allImg[0].cols), size.height = (int)(resizeFactor* allImg[0].rows);
				else
					size.width = 96 * (knn + 1), size.height = 220;
				if (metriclearning == 0)
					sprintf(Fname, "%s/Vis/SpatioMatching/%d.avi", Path, fid);
				else if (metriclearning == 1)
					sprintf(Fname, "%s/Vis/SpatioMatching/TM_%d.avi", Path, fid);
				else if (metriclearning == 2)
					sprintf(Fname, "%s/Vis/SpatioMatching/STM4_%d.avi", Path, fid);
				else if (metriclearning == 3)
					sprintf(Fname, "%s/Vis/SpatioMatching/TMGT_%d.avi", Path, fid);
				writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 60, size);
				for (int ll = 0; ll < (int)Vcidpid.size(); ll++)
				{
					vImg.clear();
					if (wholeImage == 1)
					{
						for (int cid = 0; cid < nCams; cid++)
						{
							if (allImg[cid].empty() == 0)
								vImg.push_back(allImg[cid].clone());
							else
								vImg.push_back(Mat(vImg[0].rows, vImg[0].cols, CV_8UC3, Scalar(0, 0, 0)));
						}
					}

					for (int ii = 0; ii < min(Vcidpid.size(), knn + 1); ii++)
					{
						int cid = Vcidpid[ll][ii].x, pidi = Vcidpid[ll][ii].y;
						if (allLM[cid].size() == 0)
							continue;
						Point2f tl(9e9, 9e9), br(0, 0);
						for (size_t jid = 0; jid < nJoints; jid++)
						{
							if (allLM[cid][pidi*nJoints + jid].x > 0)
								tl.x = min(tl.x, allLM[cid][pidi*nJoints + jid].x), tl.y = min(tl.y, allLM[cid][pidi*nJoints + jid].y), br.x = max(br.x, allLM[cid][pidi*nJoints + jid].x), br.y = max(br.y, allLM[cid][pidi*nJoints + jid].y);
						}
						tl.x = max(tl.x - allImg[cid].cols / 30, 0), tl.y = max(tl.y - allImg[cid].cols / 30, 0), br.x = min(br.x + allImg[cid].cols / 30, allImg[cid].cols), br.y = min(br.y + allImg[cid].cols / 30, allImg[cid].rows);

						if (wholeImage == 1)
						{
							if (ii == 0)
							{
								rectangle(vImg[cid], tl, br, Scalar(0, 0, 255), 2);
								CvPoint text_origin = { MyFtoI(tl.x),MyFtoI(tl.y) - 20 }; sprintf(Fname, "%d_%d", cid, pidi);
								putText(vImg[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 2.0, Scalar(0, 0, 255), 1);
							}
							else
							{
								rectangle(vImg[cid], tl, br, Scalar(0, 255, 0), 2);
								CvPoint text_origin = { MyFtoI(tl.x) - 200, MyFtoI(tl.y) - 20 }; sprintf(Fname, "%d_%d %.2f", cid, pidi, -Vscore[ll][ii]);
								putText(vImg[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 2.0, Scalar(0, 0, 255), 1);
							}
						}
						else
						{
							Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
							Mat croppedImage = allImg[cid](myROI);
							resize(croppedImage.clone(), sImg, Size(96, 192));

							Rect rect(0, 0, 96, 192); Mat eImg(220, 96, CV_8UC3, Scalar(255, 255, 255)); sImg.copyTo(eImg(rect));
							if (ii == 0)
							{
								CvPoint text_origin = { 30, 220 - 15 }; sprintf(Fname, "%d_%d", cid, pidi);
								putText(eImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 255), 1);
							}
							else
							{
								CvPoint text_origin = { 10, 220 - 15 }; sprintf(Fname, "%d_%d %.2f", cid, pidi, Vscore[ll][ii]);
								putText(eImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 255), 1);
							}
							vImg.push_back(eImg.clone());
						}
					}
					if (vImg.size() == 0)
						continue;

					if (wholeImage == 1)
					{
						rbImg = DrawTitleImages(vImg);
						resize(rbImg, bImg, Size(resizeFactor* rbImg.cols, resizeFactor*rbImg.rows), 0, 0, INTER_AREA);
					}
					else
					{
						bImg = DrawTitleImages(vImg, 96.0*knn / 192.0);
						rectangle(bImg, Point2i(0, 0), Point2i(96, 192), Scalar(0, 255, 0), 2);
					}
					writer << bImg;
				}
				writer.release();
			}
		}
	}

#if 0

	double *AllDist = new double[maxPeople*maxPeople*nCams*nCams];
	int *Id = new int[nCams * maxPeople];
	double *Score = new double[nCams * maxPeople];
	vector<Mat> vImg, allImg; Mat img, sImg, bImg;
	vector<Point2i> descPos; descPos.reserve(nCams * maxPeople);//maxpeople = 50
	vector<PDesc> descPool; descPool.reserve(maxPeople);//maxpeople = 50
	vector<vector<PDesc> > descPoolTrack;
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		printLOG("%d..", fid);
		descPos.clear(), descPoolTrack.clear();
		for (auto cid : sCams)
		{
			for (int pid = 0; pid < allPDesc[cid*stopF + fid].size(); pid++)
			{
				descPool.clear();
				int foundId = -1;
				for (size_t tid = 0; tid < trackletVec[cid].size() && foundId == -1; tid++) //grab all desc of the all tracklets within that instance
				{
					for (size_t lid = 0; lid < trackletVec[cid][tid].size() && foundId == -1; lid++)
						if (trackletVec[cid][tid][lid].x + TimeStamp[cid] == fid && trackletVec[cid][tid][lid].y == pid)
							foundId = lid;
					if (foundId > -1)
					{
						int fidi = trackletVec[cid][tid][foundId].x + TimeStamp[cid], pidi = trackletVec[cid][tid][foundId].y;
						descPool.push_back(allPDesc[cid*stopF + fidi][pidi]);
					}
				}
				descPos.push_back(Point2i(cid, pid));
				descPoolTrack.push_back(descPool);
			}
		}

		for (int ii = 0; ii < maxPeople*maxPeople*nCams*nCams; ii++)
			AllDist[ii] = 0;
		for (int ii1 = 0; ii1 < descPoolTrack.size() - 1; ii1++)
		{
			for (int ii2 = ii1 + 1; ii2 < descPoolTrack.size(); ii2++)
			{
				for (int kk = 0; kk < descSize; kk++)
					AllDist[ii1 + ii2 * descPoolTrack.size()] += descPoolTrack[ii1][0].desc[kk] * descPoolTrack[ii2][0].desc[kk];
				AllDist[ii2 + ii1 * descPoolTrack.size()] = AllDist[ii1 + ii2 * descPoolTrack.size()];
			}
		}

		sprintf(Fname, "%s/MP/PeopleDescSmatching/%d.txt", Path, fid);  FILE *fp = fopen(Fname, "w");
		for (auto cid : sCams)
		{
			for (int pid = 0; pid < allPDesc[cid*stopF + fid].size(); pid++)
			{
				int foundID = -1;
				for (int ii = 0; ii < descPos.size() && foundID == -1; ii++)
					if (cid == descPos[ii].x && pid == descPos[ii].y)
						foundID = ii;

				if (foundID == -1)
					continue;

				descPool = descPoolTrack[foundID];
				for (size_t di = 0; di < descPoolTrack.size(); di++)
				{
					int cidJ = descPos[di].x, pidJ = descPos[di].y;
					if (cid == cidJ && pid == pidJ) //it self
						Score[di] = -1.0, Id[di] = di;
					else
						Score[di] = AllDist[foundID + di * descPoolTrack.size()], Id[di] = di;
				}

				Quick_Sort_Double(Score, Id, 0, (int)descPoolTrack.size() - 1);
				fprintf(fp, "%d ", min(knn + 1, (int)descPoolTrack.size()));
				for (int ii = 0; ii < min(knn + 1, (int)descPoolTrack.size()); ii++)
				{
					int cid = descPos[Id[ii]].x, pidi = descPos[Id[ii]].y;
					fprintf(fp, "%d %d %.2f ", cid, pidi, -Score[ii]);
				}
				fprintf(fp, "\n");
			}
		}
		fclose(fp);

		if (visPeriod > 0 && fid%visPeriod == 0)
		{
			sprintf(Fname, "%s/MP/PeopleDescSmatching/%d.txt", Path, fid);  FILE *fp = fopen(Fname, "r");
			int nn, cid, pid, gtid; float s;
			vector<Point2i> cidpid; vector<float> score;
			vector<vector<Point2i> > Vcidpid;
			vector<vector<float> > Vscore;
			while (fscanf(fp, "%d ", &nn) != EOF)
			{
				cidpid.clear(), score.clear();
				for (int kk = 0; kk < nn; kk++)
				{
					fscanf(fp, "%d %d %d %f ", &cid, &pid, &gtid, &s);
					cidpid.push_back(Point2i(cid, pid)), score.push_back(s);
				}
				Vcidpid.push_back(cidpid), Vscore.push_back(score);
			}
			fclose(fp);

			for (auto cid : sCams)
			{
				int np = (int)allPDesc[cid*stopF + fid].size();
				allLM[cid].clear();
				sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid - TimeStamp[cid]); FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				for (int ii = 0; ii < np * nJoints; ii++)
				{
					fscanf(fp, "%f %f %f ", &u, &v, &s);
					allLM[cid].push_back(Point2f(u, v));
				}
				fclose(fp);

				sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid - TimeStamp[cid]); img = imread(Fname);
				if (img.empty() == 1)
				{
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid - TimeStamp[cid]); img = imread(Fname);
					if (img.empty() == 1)
						continue;
				}
				//resize(img, allImg[cid], Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
			}

			VideoWriter writer;
			double resizeFactor = 0.25;
			CvSize size;
			if (wholeImage == 1)
				size.width = (int)(resizeFactor*img.cols), size.height = (int)(resizeFactor* img.rows);
			else
				size.width = 96, size.height = 192;
			sprintf(Fname, "%s/Vis/SpatioMatching/%.4d.avi", Path, fid), writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 60, size);

			for (int ll = 0; ll < Vcidpid.size(); ll++)
			{
				vImg.clear();
				if (wholeImage == 1)
				{
					for (int cid = 0; cid < nCams; cid++)
					{
						if (allImg[cid].empty() == 0)
							vImg.push_back(allImg[cid].clone());
						else
							vImg.push_back(Mat(vImg[0].rows, vImg[0].cols, CV_8UC3, Scalar(0, 0, 0)));
					}
				}

				for (int ii = 0; ii < Vcidpid[ll].size(); ii++)
				{
					int cid = Vcidpid[ll][ii].x, pidi = Vcidpid[ll][ii].y;
					if (allLM[cid].size() == 0)
						continue;
					Point2f tl(9e9, 9e9), br(0, 0);
					for (size_t jid = 0; jid < nJoints; jid++)
						if (allLM[cid][pidi*nJoints + jid].x > 0)
							tl.x = min(tl.x, allLM[cid][pidi*nJoints + jid].x), tl.y = min(tl.y, allLM[cid][pidi*nJoints + jid].y), br.x = max(br.x, allLM[cid][pidi*nJoints + jid].x), br.y = max(br.y, allLM[cid][pidi*nJoints + jid].y);

					tl.x = tl.x - allImg[cid].cols / 20, tl.y = tl.y - allImg[cid].cols / 20, br.x = br.x + allImg[cid].cols / 20, br.y = br.y + allImg[cid].cols / 20;
					tl.x = max(tl.x, 0.f), tl.y = max(tl.y, 0.f), br.x = min(br.x, 1.0f*allImg[cid].cols / resizeFactor - 1), br.y = min(br.y, 1.0f*allImg[cid].rows / resizeFactor - 1);

					Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
					Mat croppedImage = allImg[cid](myROI);
					resize(croppedImage.clone(), sImg, Size(96, 192));

					if (wholeImage == 1)
					{
						if (ii == 0)
						{
							rectangle(vImg[cid], tl, br, Scalar(0, 0, 255), 2);
							CvPoint text_origin = { tl.x, tl.y - 20 }; sprintf(Fname, "%d_%d", cid, pidi);
							putText(vImg[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 2.0, Scalar(0, 0, 255), 1);
						}
						else
						{
							rectangle(vImg[cid], tl, br, Scalar(0, 255, 0), 2);
							CvPoint text_origin = { tl.x - 200, tl.y - 20 }; sprintf(Fname, "%d_%d %.2f", cid, pidi, -Vscore[ll][ii]);
							putText(vImg[cid], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 2.0, Scalar(0, 0, 255), 1);
						}
					}
					else
					{
						Rect rect(0, 0, 96, 192); Mat eImg(220, 96, CV_8UC3, Scalar(255, 255, 255)); sImg.copyTo(eImg(rect));
						if (ii == 0)
						{
							CvPoint text_origin = { 30, 220 - 15 }; sprintf(Fname, "%d_%d", cid, pid);
							putText(eImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 255), 1);
						}
						else
						{
							CvPoint text_origin = { 10, 220 - 15 }; sprintf(Fname, "%d_%d %.2f", cid, pidi, -Vscore[ll][ii]);
							putText(eImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 255), 1);
						}
						vImg.push_back(eImg.clone());
					}
				}

				if (vImg.size() == 0)
					continue;
				if (wholeImage == 1)
					bImg = DrawTitleImages(vImg);
				else
				{
					bImg = DrawTitleImages(vImg, 96.0*knn / 192.0);
					rectangle(bImg, Point2i(0, 0), Point2i(96, 192), Scalar(0, 255, 0), 2);
				}
				CvPoint text_origin = { bImg.cols / 20, bImg.rows / 20 }; sprintf(Fname, "%d_%d_%d", Path, cid, fid, pid);
				putText(bImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * bImg.cols / 640, Scalar(0, 0, 255), 1);
				writer << bImg;
			}
			writer.release();
		}
	}
	delete[]AllDist, delete[]Id, delete[]Score;
#endif

	delete[]trackletVec, delete[]allPDesc, delete[]allLM, delete[]allNPeople;


	return 0;
}
int ValidateSpatialAssociation(char *Path, vector<int> &sCams, vector<int> &Timestamp, int refStartF, int refStopF, int startF, int stopF, int nPeople, int knn, double thresh, int metricLearning)
{
	printLOG("\nRun ValidateSpatialAssociation\n");

	char Fname[512];
	int nCams = *std::max_element(std::begin(sCams), std::end(sCams)) + 1;

	int nf, sf, fid, pid;
	vector<Point2i> tracklet, GTid2CidLTid;
	vector<vector<Point2i> > *trackletVec = new vector<vector<Point2i> >[nCams];
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/%d/CleanedMergedTracklets_%d_%d.txt", Path, cid, refStartF, refStopF); FILE*fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		int np = 0;
		while (fscanf(fp, "%d ", &nf) != EOF)
		{
			tracklet.clear();
			for (int f = 0; f < nf; f++)
			{
				fscanf(fp, "%d %d ", &fid, &pid);
				tracklet.push_back(Point2i(fid, pid));
			}
			GTid2CidLTid.push_back(Point2i(cid, trackletVec[cid].size()));
			trackletVec[cid].push_back(tracklet);
			np++;
			if (np >= nPeople)
				break;
		}
		fclose(fp);
	}

	const int nJoints = 18;
	vector<vector<int> *> *allPersonID = new vector<vector<int> *>[nCams];
	vector<vector<Point2f> *> *allPoses = new vector<vector<Point2f> *>[nCams];

	sprintf(Fname, "%s/MP/allPersonID.txt", Path);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/MP/allPersonID_creation.txt", Path); FILE *fp1 = fopen(Fname, "w");
		for (auto cid : sCams)
		{
			printLOG("%d: ", cid);
			fprintf(fp1, "%d %d ", cid, stopF);
			for (int fid = 0; fid <= stopF; fid++)
			{
				vector<int> *PersonID = new vector<int>[1];
				vector<Point2f> *PoseI = new vector<Point2f>[1];
				if (fid >= startF && fid <= stopF)
				{
					sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
					if (fp != NULL)
					{
						float u, v, s;
						while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
							PoseI[0].push_back(Point2f(u, v));
						fclose(fp);
					}
					for (int ii = 0; ii < PoseI[0].size() / nJoints; ii++)
						PersonID[0].push_back(-1);
				}
				allPoses[cid].push_back(PoseI);
				allPersonID[cid].push_back(PersonID);
				fprintf(fp1, "%d %d ", fid, PersonID[0].size());
			}
			fprintf(fp1, "\n");
		}
		fclose(fp1);


		sprintf(Fname, "%s/MP/allPersonID.txt", Path); FILE *fp = fopen(Fname, "w");
		for (auto cid : sCams)
		{
			for (int gpid = 0; gpid < trackletVec[cid].size(); gpid++)
			{
				for (int ii = 0; ii < trackletVec[cid][gpid].size(); ii++)
				{
					int fid = trackletVec[cid][gpid][ii].x, lpid = trackletVec[cid][gpid][ii].y;
					allPersonID[cid][fid][0][lpid] = gpid;
					fprintf(fp, "%d %d %d %d\n", cid, fid, lpid, allPersonID[cid][fid][0][lpid]);
				}
			}
		}
		fclose(fp);
	}
	else
	{
		int cid, lpid, gpid, nf, np;
		sprintf(Fname, "%s/MP/allPersonID_creation.txt", Path); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d ", &cid, &nf) != EOF)
		{
			for (int ii = 0; ii <= nf; ii++)
			{
				fscanf(fp, "%d %d ", &fid, &np);
				vector<int> *PersonID = new vector<int>[1];
				for (int jj = 0; jj < np; jj++)
					PersonID[0].push_back(-1);
				allPersonID[cid].push_back(PersonID);
			}
		}
		fclose(fp);

		sprintf(Fname, "%s/MP/allPersonID.txt", Path); fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %d %d ", &cid, &fid, &lpid, &gpid) != EOF)
			allPersonID[cid][fid][0][lpid] = gpid;
		fclose(fp);
	}

	vector<Point2i> cidpid; vector<float> vAllScore;
	int nPairwiseMatches, cid, gtid; float score;
	int *Confusion = new int[nPeople*nPeople];
	for (int ii = 0; ii < nPeople*nPeople; ii++)
		Confusion[ii] = 0;

	unsigned int nTruePair = 0;
	vector<unsigned int> CMC(knn * 20);
	for (int fid = startF; fid <= stopF; fid++)
	{
		printLOG("%d..", fid);
		if (metricLearning == 0)
			sprintf(Fname, "%s/MP/PeopleDescSmatching/%.4d.txt", Path, fid);
		else if (metricLearning == 1)
			sprintf(Fname, "%s/MP/PeopleDescSmatching/TM_%.4d.txt", Path, fid);
		else if (metricLearning == 2)
			sprintf(Fname, "%s/MP/PeopleDescSmatching/STMGT3_%.4d.txt", Path, fid);
		else if (metricLearning == 3)
			sprintf(Fname, "%s/MP/PeopleDescSmatching/SM_%.4d.txt", Path, fid);
		FILE*fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		while (fscanf(fp, "%d ", &nPairwiseMatches) != EOF)
		{
			cidpid.clear(), vAllScore.clear();
			for (int ii = 0; ii < nPairwiseMatches; ii++)
			{
				fscanf(fp, "%d %d %d %f ", &cid, &pid, &gtid, &score);
				cidpid.push_back(Point2i(cid, pid)); //cid, pid is in synced time-->need to convert to use local track
				vAllScore.push_back(score);
			}

			int refcid = cidpid[0].x, reflfid = fid - Timestamp[refcid], refpid = cidpid[0].y;
			if (reflfid<startF || reflfid>stopF)
				continue;
			int RefPersonID = allPersonID[refcid][reflfid][0][refpid];

			for (int ii = 0; ii < sCams.size(); ii++)
			{
				int ocid = sCams[ii], olfid = fid - Timestamp[ocid];
				if (ocid == refcid || olfid<startF || olfid>stopF)
					continue;

				//gather nn for this camera
				vector<int> vpid; vector<double> vscore;
				for (int jj = 1; jj < cidpid.size(); jj++)
				{
					if (cidpid[jj].x == ocid)
					{
						//if (vAllScore[jj] > thresh)
						//{
						vpid.push_back(cidpid[jj].y), vscore.push_back(vAllScore[jj]);
						//}
					}
				}

				//look for other cameras to see if the same person exists
				bool exist = false;
				for (int jj = 0; jj < allPersonID[ocid][olfid][0].size() && !exist; jj++)
				{
					if (allPersonID[ocid][olfid][0][jj] == RefPersonID)
					{
						exist = true;
					}
				}

				//CMC curve: only do nn if the person exists
				if (exist)
				{
					nTruePair++;
					for (int jj = 0; jj < min(vpid.size(), knn); jj++)
					{
						int oPersonID = allPersonID[ocid][olfid][0][vpid[jj]];
						if (RefPersonID == oPersonID)
						{
							for (int kk = jj; kk < knn; kk++) //if found at jj, the rest is done
								CMC[kk]++;
							break;
						}
					}
				}

				//confusion matrix of the best nn. If the person in other view does not exist, the sim score should be low and vpid should be empty. If the person exist, you must predict
				if (vpid.size() > 0 && (exist || vscore[0] > thresh))
					Confusion[RefPersonID*nPeople + allPersonID[ocid][olfid][0][vpid[0]]]++;
			}
		}
		fclose(fp);
	}

	if (metricLearning == 0)
		sprintf(Fname, "%s/MP/Spatial_CMC.txt", Path);
	else if (metricLearning == 1)
		sprintf(Fname, "%s/MP/Spatial_CMT_TM.txt", Path);
	else if (metricLearning == 2)
		sprintf(Fname, "%s/MP/Spatial_CMC_STMGT3.txt", Path);
	else if (metricLearning == 3)
		sprintf(Fname, "%s/MP/Spatial_CMC_SM.txt", Path);
	FILE *fp = fopen(Fname, "w");
	for (int ii = 0; ii < knn; ii++)
		fprintf(fp, "%.3f ", 1.0*CMC[ii] / nTruePair);
	fclose(fp);

	if (metricLearning == 0)
		sprintf(Fname, "%s/MP/Spatial_ConfustionM.txt", Path);
	else if (metricLearning == 1)
		sprintf(Fname, "%s/MP/Spatial_ConfustionM_TM.txt", Path);
	else if (metricLearning == 2)
		sprintf(Fname, "%s/MP/Spatial_ConfustionM_STMGT3.txt", Path);
	else if (metricLearning == 3)
		sprintf(Fname, "%s/MP/Spatial_ConfustionM_SM.txt", Path);
	fp = fopen(Fname, "w");
	for (int ii = 0; ii < nPeople; ii++)
	{
		for (int jj = 0; jj < nPeople; jj++)
			fprintf(fp, "%d ", Confusion[ii*nPeople + jj]);
		fprintf(fp, "\n");
	}
	fclose(fp);

	return 0;
}
int GenerateTripletAssociationHypothesisFromDescMatching(char *Path, int fid, int *TripletCam, int *nPeoplePerCam, int nBestMatches, vector<TripletOfTtriplet> &ToT, double simThresh = 0.5, double ratio = 0.8)
{
	char Fname[512];
	int cidK = TripletCam[0], cidJ = TripletCam[1], cidI = TripletCam[2];
	int nPeopleK = nPeoplePerCam[0], nPeopleJ = nPeoplePerCam[1], nPeopleI = nPeoplePerCam[2];
	int minGivenPeople = min(nPeopleI, min(nPeopleJ, nPeopleK));
	if (minGivenPeople < 3)
		return 1; //for robustness, it requires to sample 3 people from each camera for Tfocal

				  //let's generate all possible association (O(n^3) choices)
	const int maxPeople = 10, maxnTriplets = 1000;// pow(maxPeople*(maxPeople - 1), 3); //assuming 2-nn
	vector<Point3i> Triplets[maxnTriplets];

	int dummy; float s1;
	int id_dummy[30]; float s_dummy[30];
	vector<Point2i> KJ, KI, JI;
	sprintf(Fname, "%s/MP/Matches/%d_%d_%d.txt", Path, fid, cidK, cidJ); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
		return 1;
	for (int ii = 0; ii < nPeopleK; ii++)
	{
		int count = 0;
		for (int jj = 0; jj < nPeopleJ; jj++)
		{
			fscanf(fp, "%d %d %f ", &dummy, &dummy, &s1);
			if (s1 > simThresh)
			{
				id_dummy[count] = jj, s_dummy[count] = -s1;
				count++;
			}
		}

		Quick_Sort_Float(s_dummy, id_dummy, 0, count - 1);
		for (int jj = 0; jj < min(nBestMatches, count); jj++)
		{
			KJ.push_back(Point2i(ii, id_dummy[jj]));
			if (jj + 1 < count && abs(s_dummy[jj]) * ratio > abs(s_dummy[jj + 1]))
				break;
		}
	}
	fclose(fp);

	sprintf(Fname, "%s/MP/Matches/%d_%d_%d.txt", Path, fid, cidK, cidI); fp = fopen(Fname, "r");
	if (fp == NULL)
		return 1;
	for (int ii = 0; ii < nPeopleK; ii++)
	{
		int count = 0;
		for (int jj = 0; jj < nPeopleI; jj++)
		{
			fscanf(fp, "%d %d %f ", &dummy, &dummy, &s1);
			if (s1 > simThresh)
			{
				id_dummy[count] = jj, s_dummy[count] = -s1;
				count++;
			}
		}

		Quick_Sort_Float(s_dummy, id_dummy, 0, count - 1);
		for (int jj = 0; jj < min(nBestMatches, count); jj++)
		{
			KI.push_back(Point2i(ii, id_dummy[jj]));
			if (jj + 1 < count && abs(s_dummy[jj]) * ratio > abs(s_dummy[jj + 1]))
				break;
		}
	}
	fclose(fp);

	sprintf(Fname, "%s/MP/Matches/%d_%d_%d.txt", Path, fid, cidJ, cidI); fp = fopen(Fname, "r");
	if (fp == NULL)
		return 1;
	for (int ii = 0; ii < nPeopleJ; ii++)
	{
		int count = 0;
		for (int jj = 0; jj < nPeopleI; jj++)
		{
			fscanf(fp, "%d %d %f ", &dummy, &dummy, &s1);
			if (s1 > simThresh)
			{
				id_dummy[count] = jj, s_dummy[count] = -s1;
				count++;
			}
		}

		Quick_Sort_Float(s_dummy, id_dummy, 0, count - 1);
		for (int jj = 0; jj < min(nBestMatches, count); jj++)
		{
			JI.push_back(Point2i(ii, id_dummy[jj]));
			if (jj + 1 < count && abs(s_dummy[jj]) * ratio > abs(s_dummy[jj + 1]))
				break;
		}
	}
	fclose(fp);

	for (int ii = 0; ii < maxPeople; ii++)
		Triplets[ii].clear();
	for (size_t ii = 0; ii < KJ.size(); ii++)
	{
		for (size_t jj = 0; jj < KI.size(); jj++)
		{
			if (KJ[ii].x == KI[jj].x)
			{
				Triplets[KJ[ii].x].push_back(Point3i(KJ[ii].x, KJ[ii].y, KI[jj].y));
			}
		}
	}
	for (size_t ii = 0; ii < KJ.size(); ii++)
	{
		for (size_t jj = 0; jj < JI.size(); jj++)
		{
			if (KJ[ii].y == JI[jj].x)
			{
				bool found = false;
				for (size_t ll = 0; ll < Triplets[KJ[ii].x].size() && !found; ll++)
					if (Triplets[KJ[ii].x][ll].x == KJ[ii].x &&Triplets[KJ[ii].x][ll].y == KJ[ii].y &&Triplets[KJ[ii].x][ll].z == JI[jj].y)
						found = true;
				if (!found) //no duplication
					Triplets[KJ[ii].x].push_back(Point3i(KJ[ii].x, KJ[ii].y, JI[jj].y));
			}
		}
	}

	//Pick 3 person from camK
	Combination PeopleKCom(nPeopleK, 3);
	int nPeopleKCom = PeopleKCom.total_com;
	int *allPeopleKCom = new int[3 * nPeopleKCom];
	PeopleKCom.All_Com(allPeopleKCom);

	ToT.clear();
	for (int ii = 0; ii < nPeopleKCom; ii++)
	{
		int pid0 = allPeopleKCom[3 * ii], pid1 = allPeopleKCom[3 * ii + 1], pid2 = allPeopleKCom[3 * ii + 2];
		for (int jj = 0; jj < Triplets[pid0].size(); jj++)
		{
			for (int kk = 0; kk < Triplets[pid1].size(); kk++)
			{
				for (int ll = 0; ll < Triplets[pid2].size(); ll++)
				{
					TripletOfTtriplet tot;
					tot.id[0] = Triplets[pid0][jj].x, tot.id[1] = Triplets[pid0][jj].y, tot.id[2] = Triplets[pid0][jj].z;
					tot.id[3] = Triplets[pid1][kk].x, tot.id[4] = Triplets[pid1][kk].y, tot.id[5] = Triplets[pid1][kk].z;
					tot.id[6] = Triplets[pid2][ll].x, tot.id[7] = Triplets[pid2][ll].y, tot.id[8] = Triplets[pid2][ll].z;
					ToT.push_back(tot);
				}
			}
		}
	}

	return 0;
}
int MultiviewPeopleAssociationTrifocal(char *Path, vector<int> &sCams, vector<int> &TimeStamp, int startF, int stopF, int increF)
{
	//Exploit desc matching to prune triplet choices and implement "correct" cycle consistency pruning to the assoID via incremental common asso findings.
	//Hard constraint: if there are at least 4 people per assignment with error less than some threshold, treat it as accurate. There is mechanisim to remove the entire traj if cycle consistency is wrong at the very end.
	//assume approx sync video images.
	const int nBestMatches = 3, maxPeople = 30;
	const double hardReprojectionThreshold = 5.0;

	int nJoints = 18;
	vector<int> jList, jList2; //jList.push_back(0), jList.push_back(1), jList.push_back(2), jList.push_back(5), jList.push_back(8), jList.push_back(11);
	jList.push_back(0), jList.push_back(1), jList.push_back(2), jList.push_back(5), jList.push_back(8), jList.push_back(11);
	jList.push_back(14), jList.push_back(15), jList.push_back(16), jList.push_back(17);
	//jList2.push_back(0), jList2.push_back(1), jList2.push_back(2), jList2.push_back(3), jList2.push_back(5), jList2.push_back(6),
	//	jList2.push_back(8), jList2.push_back(9), jList2.push_back(11), jList2.push_back(12),
	//	jList2.push_back(14), jList2.push_back(15), jList2.push_back(16), jList2.push_back(17);

	for (int ii = 0; ii < nJoints; ii++)
		jList2.push_back(ii);

	char Fname[512]; sprintf(Fname, "%s/MultiviewReID", Path); makeDir(Fname);


	int nCams = (int)sCams.size();
	CameraData *allCamInfo = new CameraData[nCams];
	ReadIntrinsicResults(Path, allCamInfo);

	omp_set_num_threads(omp_get_max_threads());
	//#pragma omp parallel for schedule(dynamic,1)
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		char Fname[512];
		sprintf(Fname, "%s/MultiviewReID/%d.txt", Path, fid);
		if (IsFileExist(Fname) == 1)
		{
			printLOG("%s computed\n", Fname);
			continue;
		}

		double u, v, s;
		vector<Point2d> pts0, pts1, pts2;
		vector<int> randNum(100);
		int inlierThresh = 8;
		double detectionThresh = 0.5, reprojectionThresh = 7.0,//18.0,
			inlierPerThresh = 0.8, inlierPerThresh2 = 0.95;
		double Tmat[27], bestTmat[27], bestTmat2[27], meanErr = 9e9;
		vector<int> vinliers;
		vector<Point2d> * allPts = new vector<Point2d>[sCams.size()];

		//read pose detection
		for (int ii = 0; ii < nCams; ii++)
		{
			allPts[ii].clear();
			int cid = sCams[ii];
			sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid - TimeStamp[cid]); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%lf %lf %lf ", &u, &v, &s) != EOF)
			{
				if (s < detectionThresh)
					allPts[ii].push_back(Point2d(0, 0));
				else
				{
					Point2d uv(u, v);
					if (allCamInfo[ii].LensModel == RADIAL_TANGENTIAL_PRISM)
						LensCorrectionPoint(&uv, allCamInfo[ii].K, allCamInfo[ii].distortion);
					else
						//FishEyeCorrectionPoint(&uv, allCamInfo[ii].distortion[0], allCamInfo[ii].distortion[1], allCamInfo[ii].distortion[1]);
						FishEyeCorrectionPoint(&uv, allCamInfo[ii].K, allCamInfo[ii].distortion[0]);

					allPts[ii].push_back(uv);
				}
			}
			fclose(fp);
		}

		double startTime = omp_get_wtime();
		vector<Point3i> peoplePairing;
		vector<Point3i>  *allBestPeopleParing = new vector<Point3i>[nCams*nCams*nCams];
		double *allBestAvgErr = new double[nCams*nCams*nCams];

		sprintf(Fname, "%s/MultiviewReID/T_%d.txt", Path, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			vector<TripletOfTtriplet> ToT; ToT.reserve(1e6); //~P(10, 3)^3
			Combination CamCom(nCams, 3);
			int ntriplets = CamCom.total_com;
			int *allCamCom = new int[3 * ntriplets];
			CamCom.All_Com(allCamCom);

			printLOG("Frame %d with %d triplets\n", fid, ntriplets);
			for (int triplet = 0; triplet < ntriplets; triplet++)
			{
				double startTi = omp_get_wtime();
				int cidK = allCamCom[3 * triplet], cidJ = allCamCom[3 * triplet + 1], cidI = allCamCom[3 * triplet + 2];
				int nPeopleK = (int)allPts[cidK].size() / nJoints, nPeopleJ = (int)allPts[cidJ].size() / nJoints, nPeopleI = (int)allPts[cidI].size() / nJoints;
				int maxPeople = max(max(nPeopleK, nPeopleJ), nPeopleI), WantedPeopleSample = 3;

				//let's generate all possible association (O(n^3) choices)
				int nPeoplePerCam[3] = { nPeopleK, nPeopleJ, nPeopleI };
				ToT.clear();
				GenerateTripletAssociationHypothesisFromDescMatching(Path, fid, &allCamCom[3 * triplet], nPeoplePerCam, nBestMatches, ToT);
				if (ToT.size() == 0)
					continue;

				/*for (int ii = 0; ii < ToT.size(); ii++)
				{
				if ((ToT[ii].id[0] == 0 && ToT[ii].id[1] == 3 && ToT[ii].id[2] == 0) || (ToT[ii].id[0] == 0 && ToT[ii].id[1] == 3 && ToT[ii].id[2] == 0) || (ToT[ii].id[2] == 0 && ToT[ii].id[5] == 3 && ToT[ii].id[8] == 0))
				{
				for (int jj = 0; jj < 9; jj++)
				printLOG("%d ", ToT[ii].id[jj]);
				printLOG("\n");
				}
				if ((ToT[ii].id[0] == 3 && ToT[ii].id[3] == 2 && ToT[ii].id[6] == 1) || (ToT[ii].id[1] == 3 && ToT[ii].id[4] == 2 && ToT[ii].id[7] == 1) || (ToT[ii].id[2] == 3 && ToT[ii].id[5] == 2 && ToT[ii].id[8] == 1))
				{
				for (int jj = 0; jj < 9; jj++)
				printLOG("%d ", ToT[ii].id[jj]);
				printLOG("\n");
				}
				if ((ToT[ii].id[0] == 2 && ToT[ii].id[3] == 4 && ToT[ii].id[6] == 3) || (ToT[ii].id[1] == 2 && ToT[ii].id[4] == 4 && ToT[ii].id[7] == 3) || (ToT[ii].id[2] == 2 && ToT[ii].id[5] == 4 && ToT[ii].id[8] == 3))
				{
				for (int jj = 0; jj < 9; jj++)
				printLOG("%d ", ToT[ii].id[jj]);
				printLOG("\n");
				}
				}*/
				//lets get 2-3 (WantedPeopleSample) detections from each view to do Tfocal (nJoints points)
				double bestMeanErrAllAsso = 9e9, bestMeanErrAllAsso2 = 9e9;
				int nIinliers = 0, BestnInliers = 0, BestnInliers2 = 0, BestnInliers3 = 0, iter = 0;
				vector<Point3i> BestPeoplePairing, BestPeoplePairing2;
				vector<int> pidK, pidJ, pidI;
				for (iter = 0; iter < ToT.size(); iter++)
				{
					if (BestPeoplePairing2.size() > inlierPerThresh* maxPeople) //threshold for people asso
						break;

					pidK.clear(), pidJ.clear(), pidI.clear();
					pidK.push_back(ToT[iter].id[0]), pidK.push_back(ToT[iter].id[3]), pidK.push_back(ToT[iter].id[6]);
					pidJ.push_back(ToT[iter].id[1]), pidJ.push_back(ToT[iter].id[4]), pidJ.push_back(ToT[iter].id[7]);
					pidI.push_back(ToT[iter].id[2]), pidI.push_back(ToT[iter].id[5]), pidI.push_back(ToT[iter].id[8]);

					int nPeopleSample = (int)min(pidK.size(), min(pidJ.size(), pidI.size()));
					pts0.clear(), pts1.clear(), pts2.clear(), peoplePairing.clear();
					for (int ii = 0; ii < nPeopleSample; ii++)
					{
						bool valid = false;
						for (auto jid : jList)
						{
							if (allPts[cidK][pidK[ii] * nJoints + jid].x == 0 || allPts[cidJ][pidJ[ii] * nJoints + jid].x == 0 || allPts[cidI][pidI[ii] * nJoints + jid].x == 0)
								continue;

							valid = true;
							pts0.push_back(allPts[cidK][pidK[ii] * nJoints + jid]);
							pts1.push_back(allPts[cidJ][pidJ[ii] * nJoints + jid]);
							pts2.push_back(allPts[cidI][pidI[ii] * nJoints + jid]);
						}
						if (valid)
							peoplePairing.push_back(Point3i(pidK[ii], pidJ[ii], pidI[ii]));
					}

					if (nPeopleSample < 3)
						continue;

					//compute Tfocal
					vinliers.clear();
					ComputeTrifocalTensorDLT(pts0, pts1, pts2, Tmat);
					nIinliers = EvaluteTfocal(pts0, pts1, pts2, Tmat, vinliers, meanErr, reprojectionThresh);
					if ((nIinliers > inlierPerThresh2*pts0.size() && peoplePairing.size() >= BestPeoplePairing.size() && nIinliers / meanErr >= BestnInliers / bestMeanErrAllAsso) || //almost all inliers but due to some missing points
						(nIinliers >= BestnInliers && nIinliers > inlierPerThresh*pts0.size()))
					{
						int idummy = BestnInliers; double ddummy = bestMeanErrAllAsso; vector<Point3i> vdummy = BestPeoplePairing;
						BestPeoplePairing = peoplePairing, BestnInliers = nIinliers, bestMeanErrAllAsso = meanErr;
						for (int ii = 0; ii < 27; ii++)
							bestTmat[ii] = Tmat[ii];

						//lets bruteforcely find more people asso given Tfocal
						int cumInliers = 0;
						peoplePairing.clear();
						vector<int> usedI(nPeopleI), usedJ(nPeopleJ);
						for (int pidk = 0; pidk < nPeopleK; pidk++)
						{
							pts0.clear();
							for (auto jid : jList2)
								pts0.push_back(allPts[cidK][pidk * nJoints + jid]);

							int bestAssoI = 0, bestAssoJ = 0, bestInlierI = 0; double bestMeanErr = 9e9;
							for (int pidj = 0; pidj < nPeopleJ; pidj++)
							{
								if (usedJ[pidj] == 1)
									continue;

								pts1.clear();
								for (auto jid : jList2)
									pts1.push_back(allPts[cidJ][pidj * nJoints + jid]);

								for (int pidi = 0; pidi < nPeopleI; pidi++)
								{
									if (usedI[pidi] == 1)
										continue;

									pts2.clear();
									for (auto jid : jList2)
										pts2.push_back(allPts[cidI][pidi * nJoints + jid]);

									vinliers.clear();
									int ninliers = EvaluteTfocal(pts0, pts1, pts2, bestTmat, vinliers, meanErr, reprojectionThresh);
									if (meanErr < reprojectionThresh && meanErr < bestMeanErr &&	ninliers >= 0.6*vinliers.size() && bestInlierI < ninliers)
										bestMeanErr = meanErr, bestInlierI = ninliers, bestAssoI = pidi, bestAssoJ = pidj;
								}
							}
							if (bestMeanErr < reprojectionThresh && bestInlierI>2 && usedI[bestAssoI] == 0 && usedJ[bestAssoJ] == 0)
								usedJ[bestAssoJ] = 1, usedI[bestAssoI] = 1, peoplePairing.push_back(Point3i(pidk, bestAssoJ, bestAssoI)), cumInliers += bestInlierI;
						}
						if (peoplePairing.size() < 3) //not relieable
						{
							BestPeoplePairing = vdummy, BestnInliers = idummy, bestMeanErrAllAsso = ddummy; //bring back the real good hypo
							continue;
						}

						if (cumInliers > BestnInliers2) //only make sense if you indeed found more inliers
						{
							BestnInliers2 = cumInliers;
							pts0.clear(), pts1.clear(), pts2.clear();
							for (int ii = 0; ii < (int)peoplePairing.size(); ii++)
							{
								for (auto jid : jList2)
								{
									if (allPts[cidK][peoplePairing[ii].x * nJoints + jid].x == 0 || allPts[cidJ][peoplePairing[ii].y * nJoints + jid].x == 0 || allPts[cidI][peoplePairing[ii].z * nJoints + jid].x == 0)
										continue;
									pts0.push_back(allPts[cidK][peoplePairing[ii].x * nJoints + jid]);
									pts1.push_back(allPts[cidJ][peoplePairing[ii].y * nJoints + jid]);
									pts2.push_back(allPts[cidI][peoplePairing[ii].z * nJoints + jid]);
								}
							}

							vinliers.clear();
							ComputeTrifocalTensorDLT(pts0, pts1, pts2, Tmat);
							nIinliers = EvaluteTfocal(pts0, pts1, pts2, Tmat, vinliers, meanErr, reprojectionThresh);
							if (nIinliers > BestnInliers3) //last test
							{
								BestPeoplePairing2 = peoplePairing;
								BestnInliers3 = nIinliers; bestMeanErrAllAsso2 = meanErr;
								for (int ii = 0; ii < 27; ii++)
									bestTmat2[ii] = Tmat[ii];
							}
						}
					}
				}

				int id = cidI + cidJ * nCams + cidK * nCams*nCams;
				allBestAvgErr[id] = bestMeanErrAllAsso2, allBestPeopleParing[id] = BestPeoplePairing2;
				if (BestPeoplePairing2.size() == 0)
					printLOG("@Triplet %d of frame %d (%d, %d, %d) with %d hypos: %d assocations, error NAN , %d iter ... %.2fs\n", triplet, fid, cidK, cidJ, cidI, ToT.size(), BestPeoplePairing2.size(), iter, omp_get_wtime() - startTi);
				else
					printLOG("@Triplet %d of frame %d (%d, %d, %d) with %d hypos: %d assocations, error %.1f , %d iter ... %.2fs\n", triplet, fid, cidK, cidJ, cidI, ToT.size(), BestPeoplePairing2.size(), bestMeanErrAllAsso2, iter, omp_get_wtime() - startTi);
			}

			sprintf(Fname, "%s/MultiviewReID/T_%d.txt", Path, fid); fp = fopen(Fname, "w");
			for (int triplet = 0; triplet < ntriplets; triplet++)
			{
				int cidK = allCamCom[3 * triplet], cidJ = allCamCom[3 * triplet + 1], cidI = allCamCom[3 * triplet + 2];
				int id = cidI + cidJ * nCams + cidK * nCams*nCams;
				if (allBestPeopleParing[id].size() == 0)
					continue;
				fprintf(fp, "%d %d %d %d %.2f ", cidK, cidJ, cidI, allBestPeopleParing[id].size(), allBestAvgErr[id]); //note that cid is relative to the sCams.
				for (size_t asso = 0; asso < allBestPeopleParing[id].size(); asso++)
					fprintf(fp, "%d %d %d ", allBestPeopleParing[id][asso].x, allBestPeopleParing[id][asso].y, allBestPeopleParing[id][asso].z);
				fprintf(fp, "\n");
			}
			fclose(fp);

			delete[]allCamCom;
		}
		else
		{
			int cidI, cidJ, cidK, pidI, pidJ, pidK, nasso; float score;
			while (fscanf(fp, "%d %d %d %d %f ", &cidK, &cidJ, &cidI, &nasso, &score) != EOF)
			{
				vector<Point3i> BestPeoplePairing;
				for (int ii = 0; ii < nasso; ii++)
				{
					fscanf(fp, "%d %d %d ", &pidK, &pidJ, &pidI);
					BestPeoplePairing.push_back(Point3i(pidK, pidJ, pidI));
				}
				int id = cidI + cidJ * nCams + cidK * nCams*nCams;
				allBestAvgErr[id] = score, allBestAvgErr[id] = score, allBestPeopleParing[id] = BestPeoplePairing;
			}
			fclose(fp);
		}

		vector<vector<Point2i> > ReliableAssosID; // One unique asso track is described by multiple (cid, pid) pairs.
		for (int cidK = 0; cidK < nCams; cidK++)
		{
			for (int cidJ = 0; cidJ < nCams; cidJ++)
			{
				for (int cidI = 0; cidI < nCams; cidI++)
				{
					int id = cidI + cidJ * nCams + cidK * nCams*nCams;

					if (allBestPeopleParing[id].size() > 3 && allBestAvgErr[id] < hardReprojectionThreshold) //hard constraint: if there are at least 4 people per assignment with error less than some threshold, treat it as accurate
					{
						for (size_t ll = 0; ll < allBestPeopleParing[id].size(); ll++)
						{
							vector<Point2i> PeoplePair;
							PeoplePair.push_back(Point2i(cidK, allBestPeopleParing[id][ll].x)), PeoplePair.push_back(Point2i(cidJ, allBestPeopleParing[id][ll].y)), PeoplePair.push_back(Point2i(cidI, allBestPeopleParing[id][ll].z));

							size_t currentAssoID = -1;
							vector<int> foundID;
							for (size_t ii = 0; ii < ReliableAssosID.size() && currentAssoID == -1; ii++) //see if the assos has been added
							{
								foundID.clear();
								for (size_t jj = 0; jj < PeoplePair.size(); jj++)
								{
									foundID.push_back(-1);
									for (size_t kk = 0; kk < ReliableAssosID[ii].size() && foundID[jj] == -1; kk++)
										if (ReliableAssosID[ii][kk].x == PeoplePair[jj].x && ReliableAssosID[ii][kk].y == PeoplePair[jj].y)
											foundID[jj] = kk, currentAssoID = ii;
								}
							}

							if (currentAssoID == -1) //add the entire traj
							{
								vector<Point2i> newUniqueAssosID;
								for (size_t jj = 0; jj < PeoplePair.size(); jj++)
									newUniqueAssosID.push_back(PeoplePair[jj]);
								ReliableAssosID.push_back(newUniqueAssosID);
							}
							else
							{
								for (size_t jj = 0; jj < PeoplePair.size(); jj++)
									if (foundID[jj] == -1)
										ReliableAssosID[currentAssoID].push_back(PeoplePair[jj]);
							}
						}
					}
				}
			}
		}

		//find all triplets
		vector<vector<Point2i> > allTriplets;
		for (int cidK = 0; cidK < nCams; cidK++)
		{
			for (int cidJ = 0; cidJ < nCams; cidJ++)
			{
				for (int cidI = 0; cidI < nCams; cidI++)
				{
					int id = cidI + cidJ * nCams + cidK * nCams*nCams;
					vector<Point3i> PeoplePair = allBestPeopleParing[id];
					if (PeoplePair.size() < 3)
						continue;

					for (size_t ii = 0; ii < PeoplePair.size(); ii++)
					{
						vector<Point2i> tripleti;
						tripleti.push_back(Point2i(cidK, PeoplePair[ii].x));
						tripleti.push_back(Point2i(cidJ, PeoplePair[ii].y));
						tripleti.push_back(Point2i(cidI, PeoplePair[ii].z));
						allTriplets.push_back(tripleti);
					}
				}
			}
		}

		//go through all triplets and find other triplets with shared edge to see if there are common new points formed within the other triplets (cycle consistency)
		vector<int> commonTipVote;
		vector<Point2i> commonTips;
		for (size_t ii = 0; ii < allTriplets.size(); ii++)
		{
			int cidK = allTriplets[ii][0].x, cidJ = allTriplets[ii][1].x, cidI = allTriplets[ii][2].x;
			int pidK = allTriplets[ii][0].y, pidJ = allTriplets[ii][1].y, pidI = allTriplets[ii][2].y;

			commonTipVote.clear(), commonTips.clear();
			for (size_t jj = 0; jj < allTriplets.size(); jj++)
			{
				if (ii == jj)
					continue;

				int cidK_ = allTriplets[jj][0].x, cidJ_ = allTriplets[jj][1].x, cidI_ = allTriplets[jj][2].x;
				int pidK_ = allTriplets[jj][0].y, pidJ_ = allTriplets[jj][1].y, pidI_ = allTriplets[jj][2].y;

				int found1 = -1;
				for (int kk = 0; kk < 3 && found1 == -1; kk++)
					if (cidK_ == allTriplets[ii][kk].x && pidK_ == allTriplets[ii][kk].y)
						found1 = 1;
				int found2 = -1;
				for (int kk = 0; kk < 3 && found2 == -1; kk++)
					if (cidJ_ == allTriplets[ii][kk].x && pidJ_ == allTriplets[ii][kk].y)
						found2 = 1;
				int found3 = -1;
				for (int kk = 0; kk < 3 && found3 == -1; kk++)
					if (cidI_ == allTriplets[ii][kk].x && pidI_ == allTriplets[ii][kk].y)
						found3 = 1;

				int good = 0; Point2i tip;
				if (found1 > 0 && found2 > 0)
					good = 1, tip = allTriplets[jj][2];
				if (found1 > 0 && found3 > 0)
					good = 1, tip = allTriplets[jj][1];
				if (found2 > 0 && found3 > 0)
					good = 1, tip = allTriplets[jj][0];

				if (good == 1)  //shared edge
				{
					int foundID = -1;
					for (size_t kk = 0; kk < commonTips.size() && foundID == -1; kk++)
					{
						if (commonTips[kk].x == tip.x && commonTips[kk].y == tip.y)
							foundID = kk;
					}
					if (foundID == -1)
						commonTips.push_back(tip), commonTipVote.push_back(1);
					else
						commonTipVote[foundID]++;
				}
			}

			//No common tip--> bad triplet
			bool foundCommonTip = false;
			for (size_t jj = 0; jj < commonTips.size() && !foundCommonTip; jj++)
				if (commonTipVote[jj] > 2) //let be strict: only tip form by 3 edge shared triplet is considered.
					foundCommonTip = true;
			if (!foundCommonTip)
				continue;

			//see if the testing triplet has been added
			size_t currentAssoID = -1;
			for (size_t kk = 0; kk < ReliableAssosID.size() && currentAssoID == -1; kk++)
			{
				for (size_t ll = 0; ll < ReliableAssosID[kk].size() && currentAssoID == -1; ll++)
				{
					if (ReliableAssosID[kk][ll].x == cidI && ReliableAssosID[kk][ll].y == pidI)
						currentAssoID = kk;
					else if (ReliableAssosID[kk][ll].x == cidJ && ReliableAssosID[kk][ll].y == pidJ)
						currentAssoID = kk;
					else if (ReliableAssosID[kk][ll].x == cidK && ReliableAssosID[kk][ll].y == pidK)
						currentAssoID = kk;
				}
			}
			if (currentAssoID == -1)
			{
				currentAssoID = ReliableAssosID.size();
				vector<Point2i> newUniqueAssosID;
				newUniqueAssosID.push_back(Point2i(cidK, pidK));
				newUniqueAssosID.push_back(Point2i(cidJ, pidJ));
				newUniqueAssosID.push_back(Point2i(cidI, pidI));
				ReliableAssosID.push_back(newUniqueAssosID);
			}
			else
			{
				int foundID2 = -1;
				for (size_t kk = 0; kk < ReliableAssosID[currentAssoID].size() && foundID2 == -1; kk++)
				{
					if (ReliableAssosID[currentAssoID][kk].x == cidK && ReliableAssosID[currentAssoID][kk].y == pidK)
						foundID2 = kk;
				}
				if (foundID2 == -1)
					ReliableAssosID[currentAssoID].push_back(Point2i(cidK, pidK));

				foundID2 = -1;
				for (size_t kk = 0; kk < ReliableAssosID[currentAssoID].size() && foundID2 == -1; kk++)
				{
					if (ReliableAssosID[currentAssoID][kk].x == cidJ && ReliableAssosID[currentAssoID][kk].y == pidJ)
						foundID2 = kk;
				}
				if (foundID2 == -1)
					ReliableAssosID[currentAssoID].push_back(Point2i(cidJ, pidJ));

				foundID2 = -1;
				for (size_t kk = 0; kk < ReliableAssosID[currentAssoID].size() && foundID2 == -1; kk++)
				{
					if (ReliableAssosID[currentAssoID][kk].x == cidI && ReliableAssosID[currentAssoID][kk].y == pidI)
						foundID2 = kk;
				}
				if (foundID2 == -1)
					ReliableAssosID[currentAssoID].push_back(Point2i(cidI, pidI));
			}

			for (size_t jj = 0; jj < commonTips.size(); jj++)
			{
				if (commonTipVote[jj] > 1)
				{
					//find if the common point has been added
					int foundID = -1;
					for (size_t ll = 0; ll < ReliableAssosID[currentAssoID].size() && foundID == -1; ll++)
					{
						if (ReliableAssosID[currentAssoID][ll].x == commonTips[jj].x && ReliableAssosID[currentAssoID][ll].y == commonTips[jj].y)
							foundID = ll;
					}
					if (foundID == -1)
						ReliableAssosID[currentAssoID].push_back(commonTips[jj]);
				}
			}
		}
		allTriplets.clear();

		//lets go through all ReliableAssosID and determine if wrong asso happens in a loop
		for (size_t id = 0; id < ReliableAssosID.size(); id++)
		{
			bool AssoFailure = false;
			for (size_t assoC = 0; assoC < ReliableAssosID[id].size() && !AssoFailure; assoC++) //same cid but different pid;
			{
				for (size_t assoP = 0; assoP < ReliableAssosID[id].size() && !AssoFailure; assoP++)
				{
					if (ReliableAssosID[id][assoC].x == ReliableAssosID[id][assoP].x && ReliableAssosID[id][assoC].y != ReliableAssosID[id][assoP].y) //lets be conservative and delete the entire track
					{
						AssoFailure = true;
						printLOG("Inconsistency association detected @ %d of %d\n", id, fid);
					}
				}
			}

			if (AssoFailure)
				ReliableAssosID[id].clear();
		}

		//Now that we can find the same ID accross view
		sprintf(Fname, "%s/MultiviewReID/%d.txt", Path, fid); fp = fopen(Fname, "w");
		fprintf(fp, "%d\n", ReliableAssosID.size());
		for (size_t id = 0; id < ReliableAssosID.size(); id++)
		{
			fprintf(fp, "%d ", ReliableAssosID[id].size());
			for (size_t asso = 0; asso < ReliableAssosID[id].size(); asso++)
				fprintf(fp, "%d %d ", sCams[ReliableAssosID[id][asso].x], ReliableAssosID[id][asso].y);
			fprintf(fp, "\n");
		}
		fclose(fp);

		delete[]allBestPeopleParing, delete[]allBestAvgErr;
	}

	return 0;
}

int GenerateGTTracklets(char *Path, vector<int>& sCams, int RefstartF, int RefstopF, int startF, int stopF, int debug = 0)
{
	size_t offset = 0;
	char Fname[512];

	//Tracklet
	printLOG("Reading trackets...\n");
	int nf, sf, fid, pid, nCams = *std::max_element(std::begin(sCams), std::end(sCams)) + 1;
	vector<Point2i> tracklet;
	vector<vector<Point2i> > *GTtrackletVec = new vector<vector<Point2i> >[nCams];
	for (int ii = 0; ii < sCams.size(); ii++)
	{
		int cid = sCams[ii];

		sprintf(Fname, "%s/%d/CleanedMergedTracklets_%d_%d.txt", Path, cid, RefstartF, RefstopF); FILE*fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		int np = 0;
		while (fscanf(fp, "%d ", &nf) != EOF)
		{
			tracklet.clear();
			for (int f = 0; f < nf; f++)
			{
				fscanf(fp, "%d %d ", &fid, &pid);
				tracklet.push_back(Point2i(fid, pid));
			}
			GTtrackletVec[cid].push_back(tracklet);
		}
		fclose(fp);

		tracklet.clear();
		vector<vector<Point2i> > rawTrackletVec, TrackletVec;
		for (int gpid = 0; gpid < GTtrackletVec[cid].size() - 1; gpid++)
		{
			int lastfid = 0;
			for (int nf = 0; nf < GTtrackletVec[cid][gpid].size(); nf++)
			{
				int fid = GTtrackletVec[cid][gpid][nf].x, pid = GTtrackletVec[cid][gpid][nf].y;
				if (abs(fid - lastfid) > 1)
				{
					if (tracklet.size() != 0)
						rawTrackletVec.push_back(tracklet);
					tracklet.clear();
				}
				lastfid = fid;
				tracklet.push_back(Point2i(fid, pid));
			}
			if (tracklet.size() != 0)
				rawTrackletVec.push_back(tracklet);
			tracklet.clear();
		}

		vector<int> unsorted, sorted; vector<size_t> indexList;
		for (int tid = 0; tid < rawTrackletVec.size(); tid++)
			unsorted.push_back(rawTrackletVec[tid][0].x);
		SortWithIndex(unsorted, sorted, indexList);

		for (int ii = 0; ii < rawTrackletVec.size(); ii++)
		{
			int tid = indexList[ii];
			tracklet.clear();
			for (int nf = 0; nf < rawTrackletVec[tid].size(); nf++)
				tracklet.push_back(rawTrackletVec[tid][nf]);
			TrackletVec.push_back(tracklet);
		}

		sprintf(Fname, "%s/%d/CleanTracklet_%d_%d.txt", Path, cid, RefstartF, RefstopF); fp = fopen(Fname, "w");
		for (int tid = 0; tid < TrackletVec.size(); tid++)
		{
			fprintf(fp, "%d %d ", TrackletVec[tid].size(), TrackletVec[tid][0].x);
			for (int nf = 0; nf < TrackletVec[tid].size(); nf++)
				fprintf(fp, "%d ", TrackletVec[tid][nf].y);
			fprintf(fp, "\n");
		}
		fclose(fp);
	}

	//Visualize the tracker
	if (debug > 0)
	{
		const int nJoints = 18;
		const double resizeFactor = 0.5;
		float u, v, s;

		vector<Scalar> colors;
		colors.push_back(Scalar(0, 0, 255));
		colors.push_back(Scalar(0, 128, 255));
		colors.push_back(Scalar(0, 255, 255));
		colors.push_back(Scalar(0, 255, 0));
		colors.push_back(Scalar(255, 128, 0));
		colors.push_back(Scalar(255, 255, 0));
		colors.push_back(Scalar(255, 0, 0));
		colors.push_back(Scalar(255, 0, 255));
		colors.push_back(Scalar(255, 255, 255));

		printLOG("Visualization\n");
		for (auto sCamId : sCams)
		{
			sprintf(Fname, "%s/%d/CleanTracklet_%d_%d.txt", Path, sCamId, RefstartF, RefstopF); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
			{
				printLOG("Cannot load %s\n", Fname);
				continue;
			}
			vector<Point2i>tracklet;
			vector<vector<Point2i> > gtTracklets;
			vector<vector<Point2f> *> allPoses;
			vector<Mat> allImages; Mat img;
			while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
			{
				tracklet.clear();
				for (int f = 0; f < nf; f++)
				{
					fscanf(fp, "%d ", &pid);
					if (sf + f < stopF && sf + f >= startF)
						tracklet.push_back(Point2i(sf + f, pid));
				}
				gtTracklets.push_back(tracklet);
			}
			fclose(fp);

			int increP = 10;
			printLOG("Reading images #%d: ", sCamId);
			for (int fid = startF; fid <= stopF; fid++)
			{
				vector<Point2f> *PoseI = new vector<Point2f>[1];
				sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, sCamId, fid); fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					PoseI[0].push_back(Point2f(u, v));
				fclose(fp);
				allPoses.push_back(PoseI);

				sprintf(Fname, "%s/%d/%.4d.jpg", Path, sCamId, fid); img = imread(Fname);
				if (img.empty())
				{
					sprintf(Fname, "%s/%d/%.4d.png", Path, sCamId, fid); img = imread(Fname);
					if (img.empty())
						continue;
				}
				resize(img, img, Size(resizeFactor* img.cols, resizeFactor*img.rows), 0, 0, INTER_AREA);
				allImages.push_back(img);
				if (100 * (fid - startF) / (stopF - startF) > increP)
					printLOG("%d%%..", increP), increP += 10;
			}
			printLOG("100%%\n");
			if (allImages.size() == 0)
				return 0;

			for (int id = 0; id < (int)gtTracklets.size(); id++)
			{
				for (int tid = 0; tid < gtTracklets[id].size(); tid++)
				{
					int fid = gtTracklets[id][tid].x;
					if (fid - startF > allImages.size() - 1)
						continue;

					vector<Point2f> temp = allPoses[fid - startF][0];
					int pid = gtTracklets[id][tid].y;
					if (pid >= temp.size() / nJoints)
					{
						printLOG("Problem @ (cid, fid, pid): (%d, %d,%d)\n", sCamId, fid, pid);
						exit(1);
					}
					Point2f tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
					for (int jid = 0; jid < nJoints; jid++)
					{
						if (temp[pid * nJoints + jid].x > 0)
							tl.x = min(tl.x, temp[pid * nJoints + jid].x), tl.y = min(tl.y, temp[pid * nJoints + jid].y), br.x = max(br.x, temp[pid * nJoints + jid].x), br.y = max(br.y, temp[pid * nJoints + jid].y);
					}
					tl.x *= resizeFactor, tl.y *= resizeFactor, br.x *= resizeFactor, br.y *= resizeFactor;
					float bw = br.x - tl.x, bh = br.y - tl.y;
					tl.x = max(tl.x - bw / 10, 0.f), br.x = min(br.x + bw / 10, 1.f*allImages[fid - startF].cols - 1);
					tl.y = max(tl.y - bh / 10, 0.f), br.y = min(br.y + bh / 10, 1.f*allImages[fid - startF].rows - 1);

					rectangle(allImages[fid - startF], tl, br, colors[id % 9], 1, 8, 0);
					Draw2DCoCoJoints(allImages[fid - startF], &temp[pid * nJoints], resizeFactor*allImages[fid - startF].cols / 640, resizeFactor);
					sprintf(Fname, "%d", id); putText(allImages[fid - startF], Fname, Point2i(tl.x, br.y - resizeFactor * allImages[fid - startF].cols / 60), CV_FONT_HERSHEY_SIMPLEX, 0.5*allImages[fid - startF].cols / 640, colors[id % 9], 1.0*resizeFactor);
				}
			}

			sprintf(Fname, "%s/Vis", Path); makeDir(Fname);
			sprintf(Fname, "%s/Vis/Tracklet", Path); makeDir(Fname);

			printLOG("\nwriting images : "); increP = 10;
			VideoWriter writer;
			CvSize size; size.width = allImages[0].cols, size.height = allImages[0].rows;
			sprintf(Fname, "%s/Vis/Tracklet/GTTracklets_%d_%d_%d.avi", Path, sCamId, startF, stopF), writer.open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 25, size);
			for (int fid = startF; fid <= stopF; fid++)
			{
				if (fid - startF > allImages.size() - 1)
					continue;
				CvPoint text_origin = { allImages[fid - startF].cols / 20, allImages[fid - startF].rows / 15 };
				sprintf(Fname, "%d", fid); putText(allImages[fid - startF], Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*allImages[fid - startF].cols / 640, colors[0], 1.0*resizeFactor);

				writer << allImages[fid - startF];
				if (100 * (fid - startF) / (stopF - startF) > increP)
					printLOG("%d%%..", increP), increP += 10;
			}
			writer.release();
			printLOG("100%%\n");
		}
	}

	return 0;
}
int GenerateSpatialPeopleMatchingFromGT(char *Path, vector<int> sCams, vector<int> TimeStamp, int startF, int stopF, int increF)
{
	int nCams = sCams.size();
	char Fname[512];

	int nMaxPeople = 0;
	vector<vector<Point2i> > *MergedTrackletVec = new vector<vector<Point2i> >[nCams];
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/%d/CleanedMergedTracklets_%d_%d.txt", Path, cid, startF, stopF);
		if (!IsFileExist(Fname))
		{
			sprintf(Fname, "%s/%d/MergedTracklets_%d_%d.txt", Path, cid, startF, stopF);
			if (!IsFileExist(Fname))
				return 1;
		}
		std::string line, item;
		std::ifstream file(Fname);
		while (std::getline(file, line))
		{
			StringTrim(&line);//remove white space
			if (line.empty())
				break;
			std::stringstream line_stream(line);
			std::getline(line_stream, item, ' ');  //# pairs

			vector<Point2i> jointTrack;
			int fid, did;
			while (!line_stream.eof())
			{
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				fid = atoi(item.c_str());
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				did = atoi(item.c_str());
				jointTrack.push_back(Point2i(fid, did));
			}
			MergedTrackletVec[cid].push_back(jointTrack);
		}
		file.close();

		nMaxPeople = max(nMaxPeople, (int)MergedTrackletVec[cid].size());
	}
	nMaxPeople--;//last one is trash category

	sprintf(Fname, "%s/GeoA", Path); makeDir(Fname);
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		//find all the tracklets of that instance
		const int nMaxPeople = 60;
		vector<Point3i>  allDetections[nMaxPeople];
		for (int ii = 0; ii < sCams.size(); ii++)
		{
			int cid = sCams[ii];
			for (int tid = 0; tid < MergedTrackletVec[cid].size() - 1; tid++) //last one is trash
			{
				for (int jj = 0; jj < MergedTrackletVec[cid][tid].size(); jj++)
				{
					int lfid = MergedTrackletVec[cid][tid][jj].x, pid = MergedTrackletVec[cid][tid][jj].y;
					if (lfid + TimeStamp[cid] > fid)
						break;
					if (lfid + TimeStamp[cid] < fid)
						continue;
					allDetections[tid].push_back(Point3i(cid, lfid, pid));
				}
			}
		}

		//find same people
		sprintf(Fname, "%s/GeoA/%.4d.txt", Path, fid); FILE *fp = fopen(Fname, "w");
		for (int ii = 0; ii < nMaxPeople; ii++)
		{
			if (allDetections[ii].size() > 0)
				fprintf(fp, "%d ", allDetections[ii].size());
			for (int jj = 0; jj < allDetections[ii].size(); jj++)
				fprintf(fp, "%d %d %d ", allDetections[ii][jj].x, allDetections[ii][jj].y, allDetections[ii][jj].z);
			if (allDetections[ii].size() > 0)
				fprintf(fp, "\n");
		}
		fclose(fp);
	}

	return 0;
}
int GenerateSTM4SemPeopleDataGT(char *Path, vector<int> &sCams, vector<int> &TimeStamp, int refStartF, int refStopF, int startF, int stopF, int increF, double SpatialSamplingRate = 0.0, double IntraDifSamplingChance = 1.0, int TripletLoss = 1, int debug = 0)
{
	size_t offset = 0;
	const int nJoints = 18, maxW = 1920, maxH = 1080;
	double expDisplacement = maxW / 20; //per consec sample of 1 person
	char Fname[512]; sprintf(Fname, "%s/STM4SemPeople", Path), makeDir(Fname);

	//Tracklet
	int gtid_found = -1;
	printLOG("Reading trackets...\n");
	int nf, sf, pid, nCams = sCams.size();
	vector<Point2i> tracklet, GTid2CidLTid;
	vector<vector<Point2i> > *trackletVec = new vector<vector<Point2i> >[nCams];
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/%d/CleanTracklet_%d_%d.txt", Path, cid, refStartF, refStopF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/Tracklet_%d_%d.txt", Path, cid, refStartF, refStopF);
		FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		printLOG("Load %s\n", Fname);
		while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
		{
			tracklet.clear();
			for (int f = 0; f < nf; f++)
			{
				fscanf(fp, "%d ", &pid);
				if (sf + f < stopF && sf + f >= startF)
					tracklet.push_back(Point2i(sf + f, pid));
			}
			GTid2CidLTid.push_back(Point2i(cid, trackletVec[cid].size()));
			trackletVec[cid].push_back(tracklet);
		}
		fclose(fp);
	}


	printLOG("Reading pose data: ");
	vector<int> *allPoseFrameID = new vector<int>[nCams];
	vector<vector<bool> *> *allValidDetections = new vector<vector<bool> *>[nCams];
	vector<vector<int> *> *allgIDPerCam = new vector<vector<int> *>[nCams];
	vector<vector<int> *> *allUsedDetections = new vector<vector<int> *>[nCams];
	vector<vector<Point2f> *> *allPoses = new vector<vector<Point2f> *>[nCams];
	for (auto cid : sCams)
	{
		printLOG("%d: ", cid);
		int increP = 10;
		for (int fid = 0; fid < startF; fid++)
		{
			vector<bool> *valid = new vector<bool>[1];
			vector<Point2f> *PoseI = new vector<Point2f>[1];
			vector<int> *used = new vector<int>[1];
			vector<int> *gIDPerCam = new vector<int>[1];
			allValidDetections[cid].push_back(valid);
			allPoseFrameID[cid].push_back(fid);
			allPoses[cid].push_back(PoseI);
			allUsedDetections[cid].push_back(used);
			allgIDPerCam[cid].push_back(gIDPerCam);
		}
		for (int fid = startF; fid <= stopF; fid++)
		{
			vector<bool> *valid = new vector<bool>[1];
			vector<Point2f> *PoseI = new vector<Point2f>[1];
			vector<int> *used = new vector<int>[1];
			vector<int> *gIDPerCam = new vector<int>[1];

			sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				float u, v, s;
				while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					PoseI[0].push_back(Point2f(u, v));
				fclose(fp);

				for (size_t pid = 0; pid < PoseI[0].size() / nJoints; pid++)
				{
					used[0].push_back(-1), gIDPerCam[0].push_back(-1);

					Point2i br(0, 0), tl(maxW, maxH); int np = 0;
					for (int jid = 0; jid < nJoints; jid++)
					{
						if (PoseI[0][pid * nJoints + jid].x > 0)
						{
							tl.x = min(tl.x, (int)(PoseI[0][pid * nJoints + jid].x));
							tl.y = min(tl.y, (int)(PoseI[0][pid * nJoints + jid].y));
							br.x = max(br.x, (int)(PoseI[0][pid * nJoints + jid].x));
							br.y = max(br.y, (int)(PoseI[0][pid * nJoints + jid].y));
							np++;
						}
					}
					if (br.x - tl.x < maxW / 30 || br.y - tl.y < maxH / 30 || (br.x - tl.x < maxW / 20 && br.y - tl.y < maxH / 20) || np < 8)
						valid[0].push_back(0);
					else
						valid[0].push_back(1);
				}

				allValidDetections[cid].push_back(valid);
				allPoseFrameID[cid].push_back(fid);
				allPoses[cid].push_back(PoseI);
				allUsedDetections[cid].push_back(used);
				allgIDPerCam[cid].push_back(gIDPerCam);
			}
			else
			{
				allValidDetections[cid].push_back(valid);
				allPoseFrameID[cid].push_back(fid);
				allPoses[cid].push_back(PoseI);
				allUsedDetections[cid].push_back(used);
				allgIDPerCam[cid].push_back(gIDPerCam);
				printLOG("%s is missing\n", Fname);
			}
			if (100 * (fid - startF) / (stopF - startF + 1) > increP)
				printLOG("%d%%..", increP), increP += 10;
		}
		printLOG("100%%\n");
	}


	int nimages = 0;
	vector<Point3i> Sim; Sim.reserve(10000000);

	printLOG("Spatial clustering\n");
	Mat rimg, Img;
	vector<int> posID, negID;
	vector<Mat> PosImg, NegImg;
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		int ninliers, cid, lfid, pid;
		vector<Point3i> Corres;
		vector<	vector<Point3i> > allCorres;
		sprintf(Fname, "%s/GeoA/%.4d.txt", Path, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
			continue;
		while (fscanf(fp, "%d ", &ninliers) != EOF)
		{
			Corres.clear();
			for (int jj = 0; jj < ninliers; jj++)
			{
				fscanf(fp, "%d %d %d ", &cid, &lfid, &pid);
				Corres.push_back(Point3i(cid, lfid, pid));
			}
			allCorres.push_back(Corres);
		}
		fclose(fp);

		for (int ii = 0; ii < allCorres.size(); ii++)
		{
			posID.clear(), negID.clear();
			for (int jj = 0; jj < allCorres[ii].size(); jj++)
			{
				int cid = allCorres[ii][jj].x, lfid = allCorres[ii][jj].y, pid = allCorres[ii][jj].z;
				std::vector<int>::iterator it = find(sCams.begin(), sCams.end(), cid);
				if (it == sCams.end())
					continue;
				if (lfid<startF || lfid>stopF)
					continue;
				if (allValidDetections[cid][lfid][0][pid] == 0)
					continue;
				if (allUsedDetections[cid][lfid][0][pid] == -1)
					posID.push_back(nimages), allgIDPerCam[cid][lfid][0][pid] = posID.back(), allUsedDetections[cid][lfid][0][pid] = nimages, nimages++;
				else
					posID.push_back(allUsedDetections[cid][lfid][0][pid]);

				for (size_t pidn = 0; pidn < allPoses[cid][lfid][0].size() / nJoints; pidn++)
				{
					if ((int)pidn != pid && allValidDetections[cid][lfid][0][pidn] > 0 && 1.0*rand() / RAND_MAX < IntraDifSamplingChance)
					{
						if (allUsedDetections[cid][lfid][0][pidn] == -1)
							negID.push_back(nimages), allgIDPerCam[cid][lfid][0][pidn] = negID.back(), allUsedDetections[cid][lfid][0][pidn] = nimages, nimages++;
						else
							negID.push_back(allUsedDetections[cid][lfid][0][pidn]);
					}
				}
			}

			int num = (int)((posID.size() - 1)*posID.size() / 2 * negID.size());
			double prob = 2.0*(1.0 / (1 + exp(-(num / 25000))) - 0.5);
			for (int jj = 0; jj < (int)posID.size() - 1; jj++)
			{
				for (int kk = jj + 1; kk < (int)posID.size(); kk++)
				{
					if (jj == kk)
						continue;
					for (int ll = 0; ll < (int)negID.size(); ll++)
					{
						if (SpatialSamplingRate > 0 && 1.0*rand() / RAND_MAX < 1.0 - SpatialSamplingRate)
							continue;
						else if (SpatialSamplingRate == 0.0 && 1.0*rand() / RAND_MAX < prob)
							continue;
						Sim.push_back(Point3i(posID[jj], posID[kk], negID[ll]));
					}
				}
			}
		}
	}

	printLOG("Temporal clustering\n");
	for (auto cid : sCams)
	{
		for (int tid = 0; tid < trackletVec[cid].size(); tid++)
		{
			Point2f cenStart(0, 0), cenStop(0, 0);
			if (trackletVec[cid][tid].size() > 3)
			{
				int kk = 3, lfid = trackletVec[cid][tid][kk].x, pid = trackletVec[cid][tid][kk].y, cnt = 0;
				vector<Point2f> *PoseI = allPoses[cid][lfid];
				for (int ll = 0; ll < nJoints; ll++)
					if (PoseI[0][pid*nJoints + ll].x > 0)
						cenStart.x += PoseI[0][pid*nJoints + ll].x, cenStart.y += PoseI[0][pid*nJoints + ll].y, cnt++;
				cenStart.x /= cnt, cenStart.y /= cnt;

				kk = trackletVec[cid][tid].size() - 3, lfid = trackletVec[cid][tid][kk].x, pid = trackletVec[cid][tid][kk].y, cnt = 0;
				PoseI = allPoses[cid][lfid];

				if (PoseI[0].size() == 0)
					continue;

				for (int ll = 0; ll < nJoints; ll++)
					if (PoseI[0][pid*nJoints + ll].x > 0)
						cenStop.x += PoseI[0][pid*nJoints + ll].x, cenStop.y += PoseI[0][pid*nJoints + ll].y, cnt++;
				cenStop.x /= cnt, cenStop.y /= cnt;
			}
			else
				continue;

			double dist = sqrt(pow(cenStart.x - cenStop.x, 2) + pow(cenStart.y - cenStop.y, 2));
			int increID1 = max(1, (int)(1.0*expDisplacement *  trackletVec[cid][tid].size() / (0.001 + dist) + 0.5));
			int increID2 = max(trackletVec[cid][tid].size() / 30, 1); //I want 30 samples only
			int increID = increID1;

			posID.clear(), negID.clear();
			for (int id = 3; id < trackletVec[cid][tid].size() - 3; id += increID)
			{
				int lfid = trackletVec[cid][tid][id].x, pid = trackletVec[cid][tid][id].y;
				if (allValidDetections[cid][lfid][0][pid] == 0)
					continue;
				if (allUsedDetections[cid][lfid][0][pid] == -1)
					posID.push_back(nimages), allgIDPerCam[cid][lfid][0][pid] = posID.back(), allUsedDetections[cid][lfid][0][pid] = nimages, nimages++;
				else
					posID.push_back(allUsedDetections[cid][lfid][0][pid]);

				for (size_t pidn = 0; pidn < allPoses[cid][lfid][0].size() / nJoints; pidn++)
				{
					if ((int)pidn != pid && allValidDetections[cid][lfid][0][pidn] > 0 && 1.0*rand() / RAND_MAX < IntraDifSamplingChance)
					{
						if (allUsedDetections[cid][lfid][0][pidn] == -1)
							negID.push_back(nimages), allgIDPerCam[cid][lfid][0][pidn] = negID.back(), allUsedDetections[cid][lfid][0][pidn] = nimages, nimages++;
						else
							negID.push_back(allUsedDetections[cid][lfid][0][pidn]);
					}
				}
			}

			int num = (int)((posID.size() - 1)*posID.size() / 2 * negID.size());
			double prob = 2.0*(1.0 / (1 + exp(-(num / 10000))) - 0.5);
			for (int jj = 0; jj < (int)posID.size() - 1; jj++)
			{
				for (int kk = jj + 1; kk < (int)posID.size(); kk++)
				{
					if (jj == kk)
						continue;
					for (int ll = 0; ll < (int)negID.size(); ll++)
					{
						if (1.0*rand() / RAND_MAX < prob)
							continue;
						Sim.push_back(Point3i(posID[jj], posID[kk], negID[ll]));
					}
				}
			}
		}
	}
	printLOG("Done!\n");

	sprintf(Fname, "%s/STM4SemPeople/gSimilarity.txt", Path); FILE *fp = fopen(Fname, "w");
	for (size_t ii = 0; ii < Sim.size(); ii++)
		fprintf(fp, "%d %d %d\n", Sim[ii].x, Sim[ii].y, Sim[ii].z);
	fclose(fp);

	vector<int> imgID;
	vector < std::string > allNames;
	for (auto cid : sCams)
	{
		for (int fid = startF; fid < stopF; fid++)
		{
			for (size_t ii = 0; ii < allUsedDetections[cid][fid][0].size(); ii++)
			{
				if (allUsedDetections[cid][fid][0][ii] > -1)
				{
					sprintf(Fname, "%d/%d_%.4d.png", cid, fid, allUsedDetections[cid][fid][0][ii]);
					allNames.push_back(std::string(Fname));
					imgID.push_back(allUsedDetections[cid][fid][0][ii]);
				}
			}
		}
	}
	vector<int> sorted; vector<size_t> indexList;
	SortWithIndex(imgID, sorted, indexList);

	sprintf(Fname, "%s/STM4SemPeople/gImageList.txt", Path); fp = fopen(Fname, "w");
	for (int ii = 0; ii < nimages; ii++)
		fprintf(fp, "%s\n", allNames[indexList[ii]].c_str());
	fclose(fp);

	printLOG("Writing images...");
	Mat img;
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/STM4SemPeople/%d", Path, cid); makeDir(Fname);
		sprintf(Fname, "%s/STM4SemPeople/_%d", Path, cid); makeDir(Fname);
		for (int fid = startF; fid < stopF; fid++)
		{
			int nused = 0;
			for (size_t ii = 0; ii < allUsedDetections[cid][fid][0].size(); ii++)
				if (allUsedDetections[cid][fid][0][ii] > -1)
					nused++;
			if (nused == 0)
				continue;

			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n. Error", Fname);
					exit(1);
				}
			}
			img = imread(Fname);
			if (img.cols < 1 || img.rows < 1)
				printLOG("Cannot load %s\n. Error", Fname);

			vector<Point2f> *PoseI = allPoses[cid][fid];
			for (size_t pid = 0; pid < allgIDPerCam[cid][fid][0].size(); pid++)
			{
				if (allgIDPerCam[cid][fid][0][pid] == -1)
					continue;
				Point2i br(0, 0), tl(maxW, maxH);
				for (int jid = 0; jid < nJoints; jid++)
				{
					if (PoseI[0][pid * nJoints + jid].x > 0)
					{
						tl.x = min(tl.x, (int)(PoseI[0][pid * nJoints + jid].x));
						tl.y = min(tl.y, (int)(PoseI[0][pid * nJoints + jid].y));
						br.x = max(br.x, (int)(PoseI[0][pid * nJoints + jid].x));
						br.y = max(br.y, (int)(PoseI[0][pid * nJoints + jid].y));
					}
				}
				int w = br.x - tl.x, h = br.y - tl.y;
				tl.x = max(tl.x - w / 15, 0), tl.y = max(tl.y - h / 15, 0), br.x = min(br.x + w / 15, img.cols - 1), br.y = min(br.y + h / 15, img.rows - 1);
				w = br.x - tl.x, h = br.y - tl.y;

				sprintf(Fname, "%d/%d_%d_%.4d.png", cid, fid, pid, allUsedDetections[cid][fid][0][pid]);
				if (w < 1 || h < 1)
					printLOG("%s ", Fname);

				cv::Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
				Mat cimg = img(myROI).clone();

				sprintf(Fname, "%s/STM4SemPeople/%d/%d_%.4d.png", Path, cid, fid, allUsedDetections[cid][fid][0][pid]);
				imwrite(Fname, cimg);

				if (0)
				{
					Draw2DCoCoJoints(cimg, &PoseI[0][pid * nJoints], nJoints, 1, 1.0, NULL, Point2f(tl.x, tl.y));
					sprintf(Fname, "%s/STM4SemPeople/_%d/%d_%.4d.jpg", Path, cid, fid, allUsedDetections[cid][fid][0][pid]);
					imwrite(Fname, cimg);
				}
			}
		}
	}
	printLOG("Done!\n");

	if (debug)
	{
		char Fname[512], Fname2[512];
		Mat rimg;
		vector<bool> Avail;
		vector<Mat> allCropImages;
		sprintf(Fname, "%s/STM4SemPeople/gImageList.txt", Path); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%s ", Fname2) != EOF)
		{
			sprintf(Fname, "%s/STM4SemPeople/%s", Path, Fname2);
			//if (IsFileExist(Fname))
			//	Avail.push_back(1);
			//else
			//	Avail.push_back(0);

			Mat img = imread(Fname);
			if (img.empty() == 1)
			{
				Avail.push_back(0);
				allCropImages.push_back(img);
			}
			else
			{
				//resize(img, rimg, Size(128, 256), 0, 0, INTER_AREA);
				rimg = resizeKeepAspectRatio(img, Size(112, 288), Scalar(0, 0, 0));
				Avail.push_back(1);
				allCropImages.push_back(rimg);
			}
		}
		fclose(fp);

		Point3i sim;
		vector<Point3i> Sim; Sim.reserve(10000000);
		sprintf(Fname, "%s/STM4SemPeople/gSimilarity.txt", Path); fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %d ", &sim.x, &sim.y, &sim.z) != EOF)
			Sim.push_back(sim);
		fclose(fp);

		vector<bool> ToDel; ToDel.resize(Sim.size());
		for (size_t ii = 0; ii < Sim.size(); ii++)
			ToDel[ii] = false;

		bool autoPlay = false;
		int cnt = 0, bmode = 0, iSliderValue = 0, oiSliderValue = iSliderValue, playBackSpeed = 5;

		/*printLOG("start\n");
		for (size_t ii = 0; ii < Sim.size(); ii++)
		{
		if (!Avail[Sim[ii].x] || !Avail[Sim[ii].y] || !Avail[Sim[ii].z])
		{
		ToDel[ii] = true;
		//printLOG("(%d %d)..", ii, cnt++);
		}
		}
		printLOG("Write\n");
		sprintf(Fname, "%s/STM4SemPeople/gSimilarityClean.txt", Path); fp = fopen(Fname, "w");
		for (size_t ii = 0; ii < Sim.size(); ii++)
		if (!ToDel[ii])
		fprintf(fp, "%d %d %d\n", Sim[ii].x, Sim[ii].y, Sim[ii].z);
		fclose(fp);
		return 0;*/

		vector<Mat> vcimgs;
		cv::namedWindow("Triplets", CV_WINDOW_NORMAL);
		createTrackbar("TripletID", "Triplets", &iSliderValue, Sim.size() - 1);
		createTrackbar("Speed (16ms)", "Triplets", &playBackSpeed, 10, NULL);
		createTrackbar("Brief mode", "Triplets", &bmode, 1, NULL);

		int incre = 0;
		while (true)
		{
			Mat timg(122 * 3, 288, CV_8UC3, Scalar(0, 0, 0));
			if (!Avail[Sim[iSliderValue].x] || !Avail[Sim[iSliderValue].y] || !Avail[Sim[iSliderValue].z])
			{
				ToDel[iSliderValue] = true;
				if (iSliderValue < Sim.size() - 1)
					iSliderValue++;
				cvSetTrackbarPos("TripletID", "Triplets", iSliderValue);
				printLOG("(%d %d)..", iSliderValue, cnt++);
				continue;
			}
			else
			{
				vcimgs.clear();
				vcimgs.push_back(allCropImages[Sim[iSliderValue].x]), vcimgs.push_back(allCropImages[Sim[iSliderValue].y]), vcimgs.push_back(allCropImages[Sim[iSliderValue].z]);
				timg = DrawTitleImages(vcimgs, 1.5);
			}

			CvPoint text_origin = { timg.cols / 30, timg.rows / 30 };
			sprintf(Fname, "%d", iSliderValue), cv::putText(timg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.75*timg.cols / 640, Scalar(0, 255, 0), 1);
			cv::imshow("Triplets", timg);

			int iKey = cv::waitKey(playBackSpeed * 16);
			if (iKey == 32)//space
				autoPlay = !autoPlay;

			if (!autoPlay &&bmode == 1)
			{
				incre = 0;
				if (iSliderValue > oiSliderValue)
				{
					while (iSliderValue + incre < Sim.size() - 1)
					{
						if (Sim[iSliderValue + incre].x == Sim[iSliderValue - 1].x && Sim[iSliderValue + incre].y == Sim[iSliderValue - 1].y)
							incre++;
						else
							break;
					}
				}
				else if (iSliderValue < oiSliderValue)
				{
					while (iSliderValue + incre >= 0)
					{
						if (Sim[iSliderValue + incre].x == Sim[iSliderValue].x && Sim[iSliderValue + incre].y == Sim[iSliderValue].y)
							incre--;
						else
							break;
					}
				}

				if (iSliderValue != oiSliderValue)
				{
					if (iSliderValue > oiSliderValue)
						iSliderValue += incre;
					else if (iSliderValue < oiSliderValue)
						iSliderValue += incre + 1;

					if (iSliderValue > Sim.size() - 1)
						iSliderValue = Sim.size() - 1;
					else if (iSliderValue < 0)
						iSliderValue = 0;

					oiSliderValue = iSliderValue;
					cvSetTrackbarPos("TripletID", "Triplets", iSliderValue);
				}

				if (iKey == 13) //enter
				{
					incre = 0;
					while (iSliderValue + incre < Sim.size() - 1)
					{
						if (Sim[iSliderValue + incre].x == Sim[iSliderValue].x && Sim[iSliderValue + incre].y == Sim[iSliderValue].y)
						{
							ToDel[iSliderValue + incre] = true, printLOG("%d...", iSliderValue + incre);
							incre++;
						}
						else
							break;
					}
				}
			}
			else
			{
				if (iKey == 13) //enter
				{
					ToDel[iSliderValue] = true;
					printLOG("%d...", iSliderValue);
				}

				if (autoPlay)
				{
					iSliderValue++;
					if (iSliderValue > Sim.size() - 1)
						iSliderValue = Sim.size() - 1;
					cvSetTrackbarPos("TripletID", "Triplets", iSliderValue);
				}
			}

			if (iKey == 27)
				break;
		}

		sprintf(Fname, "%s/STM4SemPeople/gSimilarityClean.txt", Path); fp = fopen(Fname, "w");
		for (size_t ii = 0; ii < Sim.size(); ii++)
			if (!ToDel[ii])
				fprintf(fp, "%d %d %d\n", Sim[ii].x, Sim[ii].y, Sim[ii].z);
		fclose(fp);
	}

	return 0;
}
int GenerateSTM4SemPeopleData(char *Path, vector<int> &sCams, vector<int> &TimeStamp, int refStartF, int refStopF, int startF, int stopF, int increF, int minVotes = 4, double IntraDifSamplingChance = 1.0, int TripletLoss = 1, int debug = 0)
{
	size_t offset = 0;
	const int nJoints = 18, maxW = 1920, maxH = 1080;
	double expDisplacement = maxW / 10; //per consec sample of 1 person
	char Fname[512]; sprintf(Fname, "%s/STM4SemPeople", Path), makeDir(Fname);

	//Tracklet
	int gtid_found = -1;
	printLOG("Reading trackets...\n");
	int nf, sf, pid, nCams = sCams.size();
	vector<Point2i> tracklet, GTid2CidLTid;
	vector<vector<Point2i> > *trackletVec = new vector<vector<Point2i> >[nCams];
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/%d/CleanTracklet_%d_%d.txt", Path, cid, refStartF, refStopF);
		if (IsFileExist(Fname) == 0)
			sprintf(Fname, "%s/%d/Tracklet_%d_%d.txt", Path, cid, refStartF, refStopF);
		FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		printLOG("Load %s\n", Fname);
		while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
		{
			tracklet.clear();
			for (int f = 0; f < nf; f++)
			{
				fscanf(fp, "%d ", &pid);
				if (sf + f < stopF && sf + f >= startF)
				{
					tracklet.push_back(Point2i(sf + f, pid));

					if (cid == 2 && tracklet.back().x == 1648 && tracklet.back().y == 1)
						gtid_found = GTid2CidLTid.size();
				}
			}
			GTid2CidLTid.push_back(Point2i(cid, trackletVec[cid].size()));
			trackletVec[cid].push_back(tracklet);
		}
		fclose(fp);
	}

	int nGtraj = (int)GTid2CidLTid.size();
	int *GTrajMatrix = new int[nGtraj*nGtraj];
	for (size_t ii = 0; ii < nGtraj*nGtraj; ii++)
		GTrajMatrix[ii] = 0;


	vector<Point2i> correspondingTrackletGid;
	vector<vector<Point2i> > VcorrespondingTrackletGid;
	sprintf(Fname, "%s/STM4SemPeople/VcorrespondingTrackletGid.txt", Path);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/STM4SemPeople/clusterMatrix.txt", Path);
		if (IsFileExist(Fname) == 0)
		{
			for (int fid = startF; fid <= stopF; fid += increF)
			{
				int ninliers, cid, lfid, pid;
				vector<Point3i> Corres;
				vector<	vector<Point3i> > allCorres;
				sprintf(Fname, "%s/GeoA/%.4d.txt", Path, fid); FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				while (fscanf(fp, "%d ", &ninliers) != EOF)
				{
					Corres.clear();
					for (int jj = 0; jj < ninliers; jj++)
					{
						fscanf(fp, "%d %d %d ", &cid, &lfid, &pid);
						Corres.push_back(Point3i(cid, lfid, pid));
					}
					allCorres.push_back(Corres);
				}
				fclose(fp);

				//find tracklet contain the corres and vote GTrajMatrix
				for (size_t ii = 0; ii < allCorres.size(); ii++)
				{
					vector<int> vgtid;
					for (size_t jj = 0; jj < allCorres[ii].size(); jj++)
					{
						int gtid = -1;
						int cid = allCorres[ii][jj].x, lfid = allCorres[ii][jj].y, pid = allCorres[ii][jj].z;
						for (size_t kk = 0; kk < trackletVec[cid].size() && gtid == -1; kk++)
						{
							for (size_t ll = 0; ll < trackletVec[cid][kk].size() && gtid == -1; ll++)
							{
								if (trackletVec[cid][kk][ll].x < lfid)
									continue;
								if (trackletVec[cid][kk][ll].x > lfid)
									break;
								if (trackletVec[cid][kk][ll].y == pid) //found local tracklet id (ll)
									for (size_t mm = 0; mm < GTid2CidLTid.size() && gtid == -1; mm++)
										if (GTid2CidLTid[mm].x == cid && GTid2CidLTid[mm].y == kk)
										{
											gtid = mm, vgtid.push_back(gtid);
											if (mm == gtid_found)
												int a = 0;
										}
							}
						}
					}

					for (size_t jj = 0; jj < vgtid.size(); jj++)
						for (size_t kk = 0; kk < vgtid.size(); kk++)
							if (kk != jj)
								GTrajMatrix[vgtid[jj] + vgtid[kk] * nGtraj] += 1, GTrajMatrix[vgtid[kk] + vgtid[jj] * nGtraj] += 1;
				}
			}
			sprintf(Fname, "%s/STM4SemPeople/clusterMatrix.txt", Path); FILE *fp = fopen(Fname, "w");
			for (int ii = 0; ii < nGtraj; ii++)
			{
				for (int jj = 0; jj < nGtraj; jj++)
					fprintf(fp, "%d ", GTrajMatrix[ii + jj * nGtraj]);
				fprintf(fp, "\n");
			}
			fclose(fp);
		}
		else
		{
			FILE *fp = fopen(Fname, "r");
			for (int ii = 0; ii < nGtraj; ii++)
				for (int jj = 0; jj < nGtraj; jj++)
					fscanf(fp, "%d ", &GTrajMatrix[ii + jj * nGtraj]);
			fclose(fp);
		}

		for (int ii = 0; ii < nGtraj; ii++)
		{
			correspondingTrackletGid.clear();
			for (int jj = 0; jj < nGtraj; jj++)
				if (GTrajMatrix[ii + jj * nGtraj] >= minVotes)
					correspondingTrackletGid.push_back(Point2i(jj, 0));
			if (correspondingTrackletGid.size() > 1)
				correspondingTrackletGid.push_back(Point2i(ii, 0));
			if (correspondingTrackletGid.size() > 0)
				VcorrespondingTrackletGid.push_back(correspondingTrackletGid);
		}
		sprintf(Fname, "%s/STM4SemPeople/VcorrespondingTrackletGid.txt", Path); FILE *fp = fopen(Fname, "w");
		for (size_t ii = 0; ii < VcorrespondingTrackletGid.size(); ii++)
		{
			fprintf(fp, "%d ", VcorrespondingTrackletGid[ii].size());
			for (size_t jj = 0; jj < VcorrespondingTrackletGid[ii].size(); jj++)
				fprintf(fp, "%d ", VcorrespondingTrackletGid[ii][jj].x);
			fprintf(fp, "\n");
		}
		fclose(fp);
	}
	else
	{
		int nc, p;
		sprintf(Fname, "%s/STM4SemPeople/VcorrespondingTrackletGid.txt", Path); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d ", &nc) != EOF)
		{
			correspondingTrackletGid.clear();
			for (int jj = 0; jj < nc; jj++)
			{
				fscanf(fp, "%d ", &p), correspondingTrackletGid.push_back(Point2i(p, 0));
				if (p == gtid_found)
					int a = 0;
			}
			VcorrespondingTrackletGid.push_back(correspondingTrackletGid);
		}
		fclose(fp);
	}

	printLOG("Reading pose data: ");
	vector<int> *allPoseFrameID = new vector<int>[nCams];
	vector<vector<bool> *> *allValidDetections = new vector<vector<bool> *>[nCams];
	vector<vector<int> *> *allgIDPerCam = new vector<vector<int> *>[nCams];
	vector<vector<int> *> *allUsedDetections = new vector<vector<int> *>[nCams];
	vector<vector<Point2f> *> *allPoses = new vector<vector<Point2f> *>[nCams];
	for (auto cid : sCams)
	{
		printLOG("%d: ", cid);
		int increP = 10;
		for (int fid = 0; fid < startF; fid++)
		{
			vector<bool> *valid = new vector<bool>[1];
			vector<Point2f> *PoseI = new vector<Point2f>[1];
			vector<int> *used = new vector<int>[1];
			vector<int> *gIDPerCam = new vector<int>[1];
			allValidDetections[cid].push_back(valid);
			allPoseFrameID[cid].push_back(fid);
			allPoses[cid].push_back(PoseI);
			allUsedDetections[cid].push_back(used);
			allgIDPerCam[cid].push_back(gIDPerCam);
		}
		for (int fid = startF; fid <= stopF; fid++)
		{
			vector<bool> *valid = new vector<bool>[1];
			vector<Point2f> *PoseI = new vector<Point2f>[1];
			vector<int> *used = new vector<int>[1];
			vector<int> *gIDPerCam = new vector<int>[1];

			sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				float u, v, s;
				while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					PoseI[0].push_back(Point2f(u, v));
				fclose(fp);

				for (size_t pid = 0; pid < PoseI[0].size() / nJoints; pid++)
				{
					used[0].push_back(-1), gIDPerCam[0].push_back(-1);

					Point2i br(0, 0), tl(maxW, maxH); int np = 0;
					for (int jid = 0; jid < nJoints; jid++)
					{
						if (PoseI[0][pid * nJoints + jid].x > 0)
						{
							tl.x = min(tl.x, (int)(PoseI[0][pid * nJoints + jid].x));
							tl.y = min(tl.y, (int)(PoseI[0][pid * nJoints + jid].y));
							br.x = max(br.x, (int)(PoseI[0][pid * nJoints + jid].x));
							br.y = max(br.y, (int)(PoseI[0][pid * nJoints + jid].y));
							np++;
						}
					}
					if (br.x - tl.x < maxW / 30 || br.y - tl.y < maxH / 30 || (br.x - tl.x < maxW / 20 && br.y - tl.y < maxH / 20) || np < 4)
						valid[0].push_back(0);
					else
						valid[0].push_back(1);
				}

				allValidDetections[cid].push_back(valid);
				allPoseFrameID[cid].push_back(fid);
				allPoses[cid].push_back(PoseI);
				allUsedDetections[cid].push_back(used);
				allgIDPerCam[cid].push_back(gIDPerCam);
			}
			else
			{
				allValidDetections[cid].push_back(valid);
				allPoseFrameID[cid].push_back(fid);
				allPoses[cid].push_back(PoseI);
				allUsedDetections[cid].push_back(used);
				allgIDPerCam[cid].push_back(gIDPerCam);
				printLOG("%s is missing\n", Fname);
			}
			if (100 * (fid - startF) / (stopF - startF + 1) > increP)
				printLOG("%d%%..", increP), increP += 10;
		}
		printLOG("100%%\n");
	}



	int nimages = 0;
	vector<Point3i> Sim; Sim.reserve(10000000);
	//vector<vector<Point3i>* > gpos, gneg; Sim.reserve(10000000);
	//vector<Point2i> *gposePerCam = new vector<Point2i>[nCams];

	Mat rimg, Img;
	vector<Mat> PosImg, NegImg;
	for (int ii = 0; ii < VcorrespondingTrackletGid.size(); ii++)
	{
		vector<int> posID, negID;
		//vector<Point3i> *pos = new vector<Point3i>[1], *neg = new vector<Point3i>[1];
		for (int jj = 0; jj < (int)VcorrespondingTrackletGid[ii].size(); jj++)
		{
			int gtid = VcorrespondingTrackletGid[ii][jj].x;
			int cid = GTid2CidLTid[gtid].x, ltid = GTid2CidLTid[gtid].y;

			Point2f cenStart(0, 0), cenStop(0, 0);
			if (trackletVec[cid][ltid].size() > 3)
			{
				int kk = 3, lfid = trackletVec[cid][ltid][kk].x, pid = trackletVec[cid][ltid][kk].y, cnt = 0;
				vector<Point2f> *PoseI = allPoses[cid][lfid];
				for (int ll = 0; ll < nJoints; ll++)
					if (PoseI[0][pid*nJoints + ll].x > 0)
						cenStart.x += PoseI[0][pid*nJoints + ll].x, cenStart.y += PoseI[0][pid*nJoints + ll].y, cnt++;
				cenStart.x /= cnt, cenStart.y /= cnt;

				kk = trackletVec[cid][ltid].size() - 3, lfid = trackletVec[cid][ltid][kk].x, pid = trackletVec[cid][ltid][kk].y, cnt = 0;
				PoseI = allPoses[cid][lfid];

				for (int ll = 0; ll < nJoints; ll++)
					if (PoseI[0][pid*nJoints + ll].x > 0)
						cenStop.x += PoseI[0][pid*nJoints + ll].x, cenStop.y += PoseI[0][pid*nJoints + ll].y, cnt++;
				cenStop.x /= cnt, cenStop.y /= cnt;
			}
			else
				continue;

			double dist = sqrt(pow(cenStart.x - cenStop.x, 2) + pow(cenStart.y - cenStop.y, 2));
			int increID = max(1, (int)(1.0*expDisplacement *  trackletVec[cid][ltid].size() / (0.001 + dist) + 0.5));

			for (int kk = 3; kk < (int)trackletVec[cid][ltid].size() - 3; kk += increID) //begining and end may be noisy
			{
				int lfid = trackletVec[cid][ltid][kk].x, pid = trackletVec[cid][ltid][kk].y;
				if (allValidDetections[cid][lfid][0][pid] == 0)
					continue;
				//pos[0].push_back(Point3i(cid, lfid, pid));
				if (allUsedDetections[cid][lfid][0][pid] == -1)
					posID.push_back(nimages), allgIDPerCam[cid][lfid][0][pid] = posID.back(), allUsedDetections[cid][lfid][0][pid] = nimages, nimages++;
				else
					posID.push_back(allUsedDetections[cid][lfid][0][pid]);

				if (0)
				{
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, lfid); Img = imread(Fname);
					vector<Point2f> *PoseI = allPoses[cid][lfid];

					Point2i br(0, 0), tl(maxW, maxH);
					for (int jid = 0; jid < nJoints; jid++)
					{
						if (PoseI[0][pid * nJoints + jid].x > 0)
						{
							tl.x = min(tl.x, (int)(PoseI[0][pid * nJoints + jid].x));
							tl.y = min(tl.y, (int)(PoseI[0][pid * nJoints + jid].y));
							br.x = max(br.x, (int)(PoseI[0][pid * nJoints + jid].x));
							br.y = max(br.y, (int)(PoseI[0][pid * nJoints + jid].y));
						}
					}
					int w = br.x - tl.x, h = br.y - tl.y;
					tl.x = max(tl.x - w / 15, 0), tl.y = max(tl.y - h / 15, 0), br.x = min(br.x + w / 15, 1920 - 1), br.y = min(br.y + h / 15, 1080 - 1);

					cv::Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
					sprintf(Fname, "E:/p_%.6d_%d_%.4d.jpg", posID.back(), cid, lfid); imwrite(Fname, Img(myROI));
				}

				for (size_t pidn = 0; pidn < allPoses[cid][lfid][0].size() / nJoints; pidn++)
				{
					if ((int)pidn != pid && allValidDetections[cid][lfid][0][pidn] > 0 && 1.0*rand() / RAND_MAX < IntraDifSamplingChance)
					{
						//neg[0].push_back(Point3i(cid, lfid, pidn));
						if (allUsedDetections[cid][lfid][0][pidn] == -1)
							negID.push_back(nimages), allgIDPerCam[cid][lfid][0][pidn] = negID.back(), allUsedDetections[cid][lfid][0][pidn] = nimages, nimages++;
						else
							negID.push_back(allUsedDetections[cid][lfid][0][pidn]);

						if (0)
						{
							vector<Point2f> *PoseI = allPoses[cid][lfid];
							Point2i br(0, 0), tl(maxW, maxH);
							for (int jid = 0; jid < nJoints; jid++)
							{
								if (PoseI[0][pidn * nJoints + jid].x > 0)
								{
									tl.x = min(tl.x, (int)(PoseI[0][pidn * nJoints + jid].x));
									tl.y = min(tl.y, (int)(PoseI[0][pidn * nJoints + jid].y));
									br.x = max(br.x, (int)(PoseI[0][pidn * nJoints + jid].x));
									br.y = max(br.y, (int)(PoseI[0][pidn * nJoints + jid].y));
								}
							}
							int w = br.x - tl.x, h = br.y - tl.y;
							tl.x = max(tl.x - w / 15, 0), tl.y = max(tl.y - h / 15, 0), br.x = min(br.x + w / 15, 1920 - 1), br.y = min(br.y + h / 15, 1080 - 1);

							cv::Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
							sprintf(Fname, "E:/n_%.6d_%d_%.4d.jpg", negID.back(), cid, lfid); imwrite(Fname, Img(myROI));
						}
					}
				}
			}
		}

		int num = (int)((posID.size() - 1)*posID.size() / 2 * negID.size());
		double prob = 2.0*(1.0 / (1 + exp(-(num / 25000))) - 0.5);
		for (int jj = 0; jj < (int)posID.size() - 1; jj++)
		{
			for (int kk = jj + 1; kk < (int)posID.size(); kk++)
			{
				if (jj == kk)
					continue;
				for (int ll = 0; ll < (int)negID.size(); ll++)
				{
					if (1.0*rand() / RAND_MAX < prob)
						continue;
					Sim.push_back(Point3i(posID[jj], posID[kk], negID[ll]));
				}
			}
		}
		if (ii % 100 == 0)
			printLOG("%d/%d: %zd ", ii, VcorrespondingTrackletGid.size() - 1, Sim.size());
		//gpos.push_back(pos), gneg.push_back(neg);
		//delete[]pos, delete []neg;
	}
	sprintf(Fname, "%s/STM4SemPeople/gSimilarity.txt", Path); FILE *fp = fopen(Fname, "w");
	for (size_t ii = 0; ii < Sim.size(); ii++)
		fprintf(fp, "%d %d %d\n", Sim[ii].x, Sim[ii].y, Sim[ii].z);
	fclose(fp);

	vector<int> imgID;
	vector < std::string > allNames;
	for (auto cid : sCams)
	{
		for (int fid = startF; fid < stopF; fid++)
		{
			for (size_t ii = 0; ii < allUsedDetections[cid][fid][0].size(); ii++)
			{
				if (allUsedDetections[cid][fid][0][ii] > -1)
				{
					sprintf(Fname, "%d/%d_%.4d.png", cid, fid, allUsedDetections[cid][fid][0][ii]);
					allNames.push_back(std::string(Fname));
					imgID.push_back(allUsedDetections[cid][fid][0][ii]);
				}
			}
		}
	}
	vector<int> sorted; vector<size_t> indexList;
	SortWithIndex(imgID, sorted, indexList);

	sprintf(Fname, "%s/STM4SemPeople/gImageList.txt", Path); fp = fopen(Fname, "w");
	for (int ii = 0; ii < nimages; ii++)
		fprintf(fp, "%s\n", allNames[indexList[ii]].c_str());
	fclose(fp);

	printLOG("Writing images...");
	Mat img;
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/STM4SemPeople/%d", Path, cid); makeDir(Fname);
		for (int fid = startF; fid < stopF; fid++)
		{
			int nused = 0;
			for (size_t ii = 0; ii < allUsedDetections[cid][fid][0].size(); ii++)
				if (allUsedDetections[cid][fid][0][ii] > -1)
					nused++;
			if (nused == 0)
				continue;

			sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid);
				if (IsFileExist(Fname) == 0)
				{
					printLOG("Cannot load %s\n. Error", Fname);
					exit(1);
				}
			}
			img = imread(Fname);
			if (img.cols < 1 || img.rows < 1)
				printLOG("Cannot load %s\n. Error", Fname);

			vector<Point2f> *PoseI = allPoses[cid][fid];
			for (size_t pid = 0; pid < allgIDPerCam[cid][fid][0].size(); pid++)
			{
				if (allgIDPerCam[cid][fid][0][pid] == -1)
					continue;
				Point2i br(0, 0), tl(maxW, maxH);
				for (int jid = 0; jid < nJoints; jid++)
				{
					if (PoseI[0][pid * nJoints + jid].x > 0)
					{
						tl.x = min(tl.x, (int)(PoseI[0][pid * nJoints + jid].x));
						tl.y = min(tl.y, (int)(PoseI[0][pid * nJoints + jid].y));
						br.x = max(br.x, (int)(PoseI[0][pid * nJoints + jid].x));
						br.y = max(br.y, (int)(PoseI[0][pid * nJoints + jid].y));
					}
				}
				int w = br.x - tl.x, h = br.y - tl.y;
				tl.x = max(tl.x - w / 15, 0), tl.y = max(tl.y - h / 15, 0), br.x = min(br.x + w / 15, img.cols - 1), br.y = min(br.y + h / 15, img.rows - 1);
				w = br.x - tl.x, h = br.y - tl.y;

				sprintf(Fname, "%d/%d_%d_%.4d.png", cid, fid, pid, allUsedDetections[cid][fid][0][pid]);
				if (w < 1 || h < 1)
					printLOG("%s ", Fname);

				cv::Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
				sprintf(Fname, "%s/STM4SemPeople/%d/%d_%.4d.png", Path, cid, fid, allUsedDetections[cid][fid][0][pid]);
				imwrite(Fname, img(myROI));
			}
		}
	}
	printLOG("Done!\n");
	if (debug)
	{
		char Fname2[512];
		Mat rimg;
		vector<Mat> allCropImages;
		sprintf(Fname, "%s/STM4SemPeople/gImageList.txt", Path); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%s ", Fname2) != EOF)
		{
			sprintf(Fname, "%s/STM4SemPeople/%s", Path, Fname2);
			Mat img = imread(Fname);
			//resize(img, rimg, Size(128, 256), 0, 0, INTER_AREA);
			rimg = resizeKeepAspectRatio(img, Size(112, 288), Scalar(0, 0, 0));
			allCropImages.push_back(rimg);
		}
		fclose(fp);

		/*Point3i sim;
		vector<Point3i> Sim; Sim.reserve(10000000);
		sprintf(Fname, "%s/STM4SemPeople/gSimilarity.txt", Path); fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %d ", &sim.x, &sim.y, &sim.z) != EOF)
		Sim.push_back(sim);
		fclose(fp);*/

		vector<Mat> vcimgs;
		cv::namedWindow("Triplets", CV_WINDOW_NORMAL);
		int iSliderValue = 0;
		createTrackbar("TripletID", "Triplets", &iSliderValue, Sim.size() - 1);
		while (true)
		{
			vcimgs.clear();
			vcimgs.push_back(allCropImages[Sim[iSliderValue].x]), vcimgs.push_back(allCropImages[Sim[iSliderValue].y]), vcimgs.push_back(allCropImages[Sim[iSliderValue].z]);

			Mat timg = DrawTitleImages(vcimgs, 1.5);
			CvPoint text_origin = { timg.cols / 30, timg.rows / 30 };
			sprintf(Fname, "%d", iSliderValue), cv::putText(timg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.75*timg.cols / 640, Scalar(0, 255, 0), 1);
			cv::imshow("Triplets", timg);

			int iKey = cv::waitKey(1);
			if (iKey == 27)
				break;
		}
	}

	return 0;
}
int GreedyTrackletCluster(char *Path, int nCams, int startF, int stopF, int increF, int nViewPlus)
{
	int preNormedFeat = 1, metric = 0;//0:cosine, 1: l2

	int nValidJointsThresh = 10;
	double overlapA_thresh = 0.4;
	const int max_width = 1920, max_height = 1080;

	const int featDim = 256;
	char Fname[512];

	sprintf(Fname, "%s/MergedTracklet", Path); makeDir(Fname);

	int *frameTimeStamp = new int[nCams];
	for (int ii = 0; ii < nCams; ii++)
		frameTimeStamp[ii] = 0;

	int selected; double fps, temp;
	sprintf(Fname, "%s/FMotionPriorSync.txt", Path);
	FILE *fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		for (int ii = 0; ii < nCams; ii++)
		{
			fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp);
			frameTimeStamp[ii] = int(temp + 0.5);
		}
		fclose(fp);
	}
	else
	{
		sprintf(Fname, "%s/FGeoSync.txt", Path); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
			for (int ii = 0; ii < nCams; ii++)
			{
				fscanf(fp, "%d %lf ", &selected, &temp);
				frameTimeStamp[ii] = (int)(temp + 0.5);
			}
			fclose(fp);
		}
		else
		{
			sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				double fps;
				for (int ii = 0; ii < nCams; ii++)
				{
					fscanf(fp, "%d %lf %lf ", &selected, &fps, &temp);
					frameTimeStamp[ii] = (int)(temp + 0.5);
				}
				fclose(fp);
			}
			else
				printLOG("Cannot load time stamp info. Assume no frame offsets!");
		}
	}

	//Tracklet
	printLOG("Reading trackets for all cameras...\n");
	int nf, sf, ntracklets = 0;
	Point2i pid_fid;
	vector<Point2i> PersonId, AllTracletVec;
	vector<vector<Point2i> > *AllCameras_AllTrackletVec = new vector<vector<Point2i> >[nCams]; //cid, tid, pid, fid
	for (int cid = 0; cid < nCams; cid++)
	{
		sprintf(Fname, "%s/%d/Tracklet_%d_%d.txt", Path, cid, startF, stopF); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d ", &nf, &sf) != EOF)
		{
			PersonId.clear();
			for (int fid = 0; fid < nf; fid++)
			{
				fscanf(fp, "%d ", &pid_fid.x);
				pid_fid.y = sf + fid;
				if (pid_fid.y >= startF && pid_fid.y <= stopF)
					PersonId.push_back(pid_fid);
			}
			AllTracletVec.push_back(Point2i(cid, (int)AllCameras_AllTrackletVec[cid].size()));
			AllCameras_AllTrackletVec[cid].push_back(PersonId);
			ntracklets++;
			if (sf > stopF)
				break;
		}
		fclose(fp);

		sprintf(Fname, "%s/AllTrackletVec.txt", Path);
		if (IsFileExist(Fname) == 0)
		{
			fp = fopen(Fname, "w");
			for (int ii = 0; ii < ntracklets; ii++)
				fprintf(fp, "%d %d\n", AllTracletVec[ii].x, AllTracletVec[ii].y);
			fclose(fp);
		}
	}

	//Multiview
	printLOG("Reading spatial assocation for all cameras...\n");
	int nasso, cid, pid;
	vector<Point2i> AssoID;
	vector<vector<Point2i> > *allAssoID = new vector<vector<Point2i> >[stopF + 1];
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		sprintf(Fname, "%s/VoxelVoting/A/%.4d.txt", Path, fid); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d ", &nasso) != EOF)
		{
			AssoID.clear();
			for (int id = 0; id < nasso; id++)
			{
				fscanf(fp, "%d %d  ", &cid, &pid);
				AssoID.push_back(Point2i(cid, pid));
			}
			if (nasso >= nViewPlus)
				allAssoID[fid].push_back(AssoID);
		}
		fclose(fp);
	}

	const int nJoints = 18;
	printLOG("Reading pose data:\n");
	vector<int> *allPoseFrameID = new vector<int>[nCams];
	vector<vector<Point2f> *> *allPoses = new vector<vector<Point2f> *>[nCams];
	for (int cid = 0; cid < nCams; cid++)
	{
		printLOG("%d: ", cid);
		int increP = 10;
		for (int fid = 0; fid < startF; fid++)
		{
			vector<Point2f> *PoseI = new vector<Point2f>[1];
			allPoseFrameID[cid].push_back(fid);
			allPoses[cid].push_back(PoseI);
		}
		for (int fid = startF; fid <= stopF; fid++)
		{
			vector<Point2f> *PoseI = new vector<Point2f>[1];
			sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				float u, v, s;
				while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
					PoseI[0].push_back(Point2f(u, v));
				fclose(fp);

				allPoseFrameID[cid].push_back(fid);
				allPoses[cid].push_back(PoseI);
			}
			else
			{
				allPoseFrameID[cid].push_back(fid);
				allPoses[cid].push_back(PoseI);
				printLOG("%s is missing\n", Fname);
			}
			if (100 * (fid - startF) / (stopF - startF) > increP)
				printLOG("%d%%..", increP), increP += 10;
		}
		printLOG("100%%\n");
	}

	//Merge tracklet using geocue
	printLOG("Merge tracklet using spatial matches\n");
	vector<vector<Point2i> > AllTrackletsToMerge;

	sprintf(Fname, "%s/AllTrackletsToMerge.txt", Path);
	if (IsFileExist(Fname) == 0)
	{
		vector<int> *AllCameras_UsedTracklets = new vector<int>[nCams];
		for (int cid = 0; cid < nCams; cid++)
			for (size_t tid = 0; tid < AllCameras_AllTrackletVec[cid].size(); tid++)
				AllCameras_UsedTracklets[cid].push_back(-1);

		vector<int> tracklet2MergeID;
		for (int cid = 0; cid < nCams; cid++)
			for (size_t kk = 0; kk < AllCameras_AllTrackletVec[cid].size(); kk++)
				tracklet2MergeID.push_back(-1);

		for (int fid = startF; fid <= stopF; fid += increF)
		{
			for (size_t hh = 0; hh < allAssoID[fid].size(); hh++)
			{
				if (allAssoID[fid][hh].size() < nViewPlus)
					continue;

				int usedTrackletID = -1;
				vector<int> temp;
				vector<Vec4i> TempTrackletsToMerge;
				vector<Point2i> AssoID = allAssoID[fid][hh];

				for (size_t ll = 0; ll < AssoID.size(); ll++)  //for every spatial correspondence
				{
					int cid = AssoID[ll].x, pid = AssoID[ll].y;
					int localFid = fid - frameTimeStamp[cid];
					if (localFid<startF || localFid>stopF)
						continue;

					//compute overlapping rate with near-by people --> Association may be unreliable when people stay very close to each other
					bool HighOverlapping = false;
					vector<Point2f> *PoseI = allPoses[cid][localFid];
					vector<Point2i> vbr, vtl;
					vector<int> vnValidPoints;
					double A_pid = 0;
					for (int ii = 0; ii < (int)PoseI[0].size() / nJoints; ii++)
					{
						int nValidPoints = 0;
						Point2i br(0, 0), tl(max_width, max_height);
						for (int jid = 0; jid < nJoints; jid++)
						{
							if (PoseI[0][ii * nJoints + jid].x > 0)
							{
								tl.x = min(tl.x, (int)(PoseI[0][ii * nJoints + jid].x)), tl.y = min(tl.y, (int)(PoseI[0][ii * nJoints + jid].y)), br.x = max(br.x, (int)(PoseI[0][ii * nJoints + jid].x)), br.y = max(br.y, (int)(PoseI[0][ii * nJoints + jid].y));
								nValidPoints++;
							}
						}
						vnValidPoints.push_back(nValidPoints), vbr.push_back(br), vtl.push_back(tl);

						if (ii == pid)
							A_pid = (vbr[ii].x - vtl[ii].x)*(vbr[ii].y - vtl[ii].y);
					}
					for (int ii = 0; ii < (int)PoseI[0].size() / nJoints && !HighOverlapping; ii++)
					{
						if (ii == pid)
							continue;

						double A_ii = (vbr[ii].x - vtl[ii].x)*(vbr[ii].y - vtl[ii].y);

						double oA = OverlappingArea(vtl[pid], vbr[pid], vtl[ii], vbr[ii]);
						if ((oA / A_pid > overlapA_thresh || oA / A_ii > overlapA_thresh) && (vnValidPoints[pid] < nValidJointsThresh || vnValidPoints[ii] < nValidJointsThresh))
							HighOverlapping = true;
					}
					if (HighOverlapping)
						continue;

					bool foundTracket = false;
					vector<vector<Point2i> > *AllTrackletVecC = &AllCameras_AllTrackletVec[cid];
					for (size_t kk = 0; kk < AllTrackletVecC[0].size(); kk++)  //look into every of its tracklets
					{
						vector<Point2i> *trackletVec = &AllTrackletVecC[0][kk];
						for (size_t ii = 0; ii < trackletVec[0].size() && !foundTracket; ii++) //look into every element of the tracklet
						{
							if (pid == trackletVec[0][ii].x && localFid == trackletVec[0][ii].y) //found
							{
								if (AllCameras_UsedTracklets[cid][kk] != -1) //check if it belongs to previous cluster --> chance of setting it to that cluster
									temp.push_back(AllCameras_UsedTracklets[cid][kk]),
									usedTrackletID = AllCameras_UsedTracklets[cid][kk]; //just need to find one instance
								TempTrackletsToMerge.push_back(Vec4i(cid, kk, pid, localFid)); //add into temp
								foundTracket = true;
							}
						}
						if (foundTracket)
							break;
					}
				}

				if (temp.size() > 0)
				{
					sort(temp.begin(), temp.end());
					std::vector<int>::iterator it = unique(temp.begin(), temp.end());
					temp.resize(std::distance(temp.begin(), it));
					if (temp.size() > 1)
						int a = 0;
				}

				if (usedTrackletID == -1 && TempTrackletsToMerge.size() > 0) //totally new tracklets group
				{
					vector<Point2i> temp;
					for (int nn = 0; nn < (int)TempTrackletsToMerge.size(); nn++)
					{
						int cid = TempTrackletsToMerge[nn](0), tid = TempTrackletsToMerge[nn](1);
						AllCameras_UsedTracklets[cid][tid] = (int)AllTrackletsToMerge.size();
						temp.push_back(Point2i(cid, tid));

						//DEBUG
						int pid = TempTrackletsToMerge[nn](2), localFid = TempTrackletsToMerge[nn](3);
						sprintf(Fname, "%s/%d/%.4d.png", Path, cid, localFid); Mat img = imread(Fname);
						int width = img.cols, height = img.rows, bound = max(width / 50, height / 50);

						vector<Point2f> *PoseI = allPoses[cid][localFid];
						Point2i br(0, 0), tl(width, height);
						for (int jid = 0; jid < nJoints; jid++)
							if (PoseI[0][pid * nJoints + jid].x > 0)
								tl.x = min(tl.x, (int)(PoseI[0][pid * nJoints + jid].x)), tl.y = min(tl.y, (int)(PoseI[0][pid * nJoints + jid].y)), br.x = max(br.x, (int)(PoseI[0][pid * nJoints + jid].x)), br.y = max(br.y, (int)(PoseI[0][pid * nJoints + jid].y));
						tl.x = max(tl.x - bound, 0), tl.y = max(tl.y - bound, 0), br.x = min(br.x + bound, width - 1), br.y = min(br.y + bound, height - 1);
						cv::Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
						Mat croppedImage = img(myROI);
						sprintf(Fname, "%s/MergedTracklet/%d", Path, AllTrackletsToMerge.size()); makeDir(Fname);
						sprintf(Fname, "%s/MergedTracklet/%d/%d_%d_%d_%d.jpg", Path, AllTrackletsToMerge.size(), nn, cid, localFid, pid); imwrite(Fname, croppedImage);
					}
					AllTrackletsToMerge.push_back(temp);
				}
				else
				{
					for (int nn = 0; nn < (int)TempTrackletsToMerge.size(); nn++)
					{
						bool found = false;
						int cid = TempTrackletsToMerge[nn](0), tid = TempTrackletsToMerge[nn](1), pid = TempTrackletsToMerge[nn](2), localFid = TempTrackletsToMerge[nn](3);
						for (int mm = 0; mm < AllTrackletsToMerge[usedTrackletID].size() && !found; mm++) //check if this spatial corres has been included
						{
							if (AllTrackletsToMerge[usedTrackletID][mm].x == cid && AllTrackletsToMerge[usedTrackletID][mm].y == tid)
								found = true;
						}
						if (!found)
						{
							//DEBUG
							pid = TempTrackletsToMerge[nn](2);
							int lfid = TempTrackletsToMerge[nn](3);
							sprintf(Fname, "%s/%d/%.4d.png", Path, cid, lfid); Mat img = imread(Fname);
							int width = img.cols, height = img.rows, bound = max(width / 50, height / 50);

							vector<Point2f> *PoseI = allPoses[cid][lfid];
							Point2i br(0, 0), tl(width, height);
							for (int jid = 0; jid < nJoints; jid++)
								if (PoseI[0][pid * nJoints + jid].x > 0)
									tl.x = min(tl.x, (int)(PoseI[0][pid * nJoints + jid].x)), tl.y = min(tl.y, (int)(PoseI[0][pid * nJoints + jid].y)), br.x = max(br.x, (int)(PoseI[0][pid * nJoints + jid].x)), br.y = max(br.y, (int)(PoseI[0][pid * nJoints + jid].y));
							tl.x = max(tl.x - bound, 0), tl.y = max(tl.y - bound, 0), br.x = min(br.x + bound, width - 1), br.y = min(br.y + bound, height - 1);
							cv::Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
							Mat croppedImage = img(myROI);
							sprintf(Fname, "%s/MergedTracklet/%d/%d_%d_%d_%d.jpg", Path, usedTrackletID, AllTrackletsToMerge[usedTrackletID].size(), cid, lfid, pid); imwrite(Fname, croppedImage);


							AllTrackletsToMerge[usedTrackletID].push_back(Point2i(cid, tid));
							AllCameras_UsedTracklets[cid][tid] = usedTrackletID;
						}
					}
				}
			}
		}
		delete[]AllCameras_UsedTracklets;

		FILE* fp = fopen(Fname, "w+");
		for (int ii = 0; ii < (int)AllTrackletsToMerge.size(); ii++)
		{
			fprintf(fp, "%d ", AllTrackletsToMerge[ii].size());
			for (int jj = 0; jj < (int)AllTrackletsToMerge[ii].size(); jj++)
				fprintf(fp, "%d %d ", AllTrackletsToMerge[ii][jj].x, AllTrackletsToMerge[ii][jj].y);
			fprintf(fp, "\n");
		}
		fclose(fp);
	}
	else
	{
		int nt, cid, tid, pid, lfid;
		FILE* fp = fopen(Fname, "r");
		while (fscanf(fp, "%d ", &nt) != EOF)
		{
			vector<Point2i> TrackletsToMerge;
			for (int ii = 0; ii < nt; ii++)
			{
				fscanf(fp, "%d %d", &cid, &tid);
				TrackletsToMerge.push_back(Point2i(cid, tid));
			}
			AllTrackletsToMerge.push_back(TrackletsToMerge);
		}
		fclose(fp);
	}

	if (1)
	{
		/*const int nJoints = 18;
		printLOG("Reading pose data:\n");
		vector<int> *allPoseFrameID = new vector<int>[nCams];
		vector<vector<Point2f> *> *allPoses = new vector<vector<Point2f> *>[nCams];
		for (int cid = 0; cid < nCams; cid++)
		{
		printLOG("%d: ", cid);
		int increP = 10;
		for (int fid = 0; fid < startF; fid++)
		{
		vector<Point2f> *PoseI = new vector<Point2f>[1];
		allPoseFrameID[cid].push_back(fid);
		allPoses[cid].push_back(PoseI);
		}
		for (int fid = startF; fid <= stopF; fid++)
		{
		vector<Point2f> *PoseI = new vector<Point2f>[1];
		sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); fp = fopen(Fname, "r");
		if (fp != NULL)
		{
		float u, v, s;
		while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
		PoseI[0].push_back(Point2f(u, v));
		fclose(fp);

		allPoseFrameID[cid].push_back(fid);
		allPoses[cid].push_back(PoseI);
		}
		else
		{
		allPoseFrameID[cid].push_back(fid);
		allPoses[cid].push_back(PoseI);
		printLOG("%s is missing\n", Fname);
		}
		if (100 * (fid - startF) / (stopF - startF) > increP)
		printLOG("%d%%..", increP), increP += 10;
		}
		printLOG("100%%\n");
		}*/


		vector<vector<Point3i> *> *allPoses2Tid = new vector<vector<Point3i> *>[nCams];
		for (int cid = 0; cid < nCams; cid++)
		{
			for (int fid = 0; fid < startF; fid++)
			{
				vector<Point3i> *Pose2ImgID = new vector<Point3i>[1];
				allPoses2Tid[cid].push_back(Pose2ImgID);
			}
			for (int fid = startF; fid <= stopF; fid++)
			{
				vector<Point2f> *PoseI = allPoses[cid][fid];
				vector<Point3i> *Pose2ImgID = new vector<Point3i>[1];
				for (int ii = 0; ii < PoseI[0].size() / nJoints; ii++)
					Pose2ImgID[0].push_back(Point3i(-1, -1, -1));
				allPoses2Tid[cid].push_back(Pose2ImgID);
			}
		}


		vector<Point3i> *AllTrackletsToMergeDetails = new vector<Point3i>[AllTrackletsToMerge.size()];
		for (int ii = 0; ii < (int)AllTrackletsToMerge.size(); ii++)
		{
			for (int jj = 0; jj < (int)AllTrackletsToMerge[ii].size(); jj++)
			{
				int cid = AllTrackletsToMerge[ii][jj].x, tid = AllTrackletsToMerge[ii][jj].y;
				for (int kk = 0; kk < (int)AllCameras_AllTrackletVec[cid][tid].size(); kk++)
				{
					int pid = AllCameras_AllTrackletVec[cid][tid][kk].x, fid = AllCameras_AllTrackletVec[cid][tid][kk].y;
					AllTrackletsToMergeDetails[ii].push_back(Point3i(cid, fid, pid));

					vector<Point3i> *Pose2ImgID = allPoses2Tid[cid][fid];
					Pose2ImgID[0][pid] = Point3i(ii, cid, fid);
				}
			}
		}

		printLOG("write images...");
		sprintf(Fname, "%s/MergedTracklet", Path); makeDir(Fname);
		for (int ii = 0; ii < (int)AllTrackletsToMerge.size(); ii++)
			sprintf(Fname, "%s/MergedTracklet/%d", Path, ii), makeDir(Fname);

		for (int cid = 0; cid < nCams; cid++)
		{
			printLOG("%d..", cid);
			for (int fid = startF; fid <= stopF; fid++)
			{
				bool hasImage = false;
				for (int pid = 0; pid < allPoses2Tid[cid][fid][0].size() && !hasImage; pid++)
					if (allPoses2Tid[cid][fid][0][pid].x > -1)
						hasImage = true;

				if (hasImage)
				{
					sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid);
					if (IsFileExist(Fname) == 0)
					{
						sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid);
						if (IsFileExist(Fname) == 0)
						{
							printLOG("Cannot load %s. Exit\n", Fname);
							exit(1);
						}
					}
					Mat img = imread(Fname);
					int width = img.cols, height = img.rows, bound = max(width / 50, height / 50);

					vector<Point2f> *PoseI = allPoses[cid][fid];
					for (int pid = 0; pid < allPoses2Tid[cid][fid][0].size(); pid++) //extract person box
					{
						if (allPoses2Tid[cid][fid][0][pid].x > -1)
						{
							Point2i br(0, 0), tl(width, height);
							for (int jid = 0; jid < nJoints; jid++)
							{
								if (PoseI[0][pid * nJoints + jid].x > 0)
									tl.x = min(tl.x, (int)(PoseI[0][pid * nJoints + jid].x)), tl.y = min(tl.y, (int)(PoseI[0][pid * nJoints + jid].y)), br.x = max(br.x, (int)(PoseI[0][pid * nJoints + jid].x)), br.y = max(br.y, (int)(PoseI[0][pid * nJoints + jid].y));
							}
							tl.x = max(tl.x - bound, 0), tl.y = max(tl.y - bound, 0), br.x = min(br.x + bound, width - 1), br.y = min(br.y + bound, height - 1);
							cv::Rect myROI(tl.x, tl.y, br.x - tl.x, br.y - tl.y);
							Mat croppedImage = img(myROI);
							sprintf(Fname, "%s/MergedTracklet/%d/%d_%.4d_%d.jpg", Path, allPoses2Tid[cid][fid][0][pid].x, allPoses2Tid[cid][fid][0][pid].y, allPoses2Tid[cid][fid][0][pid].z, pid);
							imwrite(Fname, croppedImage);
						}
					}
				}
			}
		}
		printLOG("All done!\n");
	}

	//Get Desc
	printLOG("Reading all Desc: ");
	struct Feat {
		float feat[featDim];
	};
	Feat desci;
	vector<vector<Feat> *> *AllDesc = new vector<vector<Feat> *>[nCams];
	for (int cid = 0; cid < nCams; cid++)
	{
		printLOG("%d: ", cid);

		vector<Feat> *Desc = new vector<Feat>[stopF + 1];
		for (int fid = 0; fid < startF; fid++)
		{
			vector<Feat> *desc = new vector<Feat>[1];
			AllDesc[cid].push_back(desc);
		}

		for (int fid = startF; fid <= stopF; fid++)
		{
			sprintf(Fname, "%s/MP/Desc256/%d.txt", Path, fid); FILE *fp = fopen(Fname, "r");
			if (fp != NULL)
			{
				vector<Feat> *desc = new vector<Feat>[1];
				while (fscanf(fp, "%f ", &desci.feat[0]) != EOF)
				{
					for (int jj = 1; jj < featDim; jj++)
						fscanf(fp, "%f ", &desci.feat[jj]);

					if (preNormedFeat == 0)
					{
						float norm = 0;
						for (int jj = 0; jj < featDim; jj++)
							norm += desci.feat[jj] * desci.feat[jj];
						norm = sqrt(norm);
						for (int jj = 0; jj < featDim; jj++)
							desci.feat[jj] = desci.feat[jj] / norm;
					}
					desc[0].push_back(desci);
				}
				AllDesc[cid].push_back(desc);
			}
		}
	}

	sprintf(Fname, "%s/TrackletDistance.txt", Path);
	float *Dist = new float[ntracklets*ntracklets];
	if (IsFileExist(Fname) == 0)
	{
		printLOG("Compute tracklet desc distance\n");

		for (int tid0 = 0; tid0 < ntracklets - 1; tid0++)
		{
			Dist[tid0 + tid0 * ntracklets] = 0; //diagonal term
			for (int tid1 = tid0 + 1; tid1 < ntracklets; tid1++)
			{
				int cid0 = AllTracletVec[tid0].x, loc0 = AllTracletVec[tid0].y, cid1 = AllTracletVec[tid1].x, loc1 = AllTracletVec[tid0].y;

				//detecting trackles with element appears in 1 frame at once t and set to huge value -->sure negative
				bool breakflag = false;
				for (int e0 = 0; e0 < (int)AllCameras_AllTrackletVec[cid0][loc0].size() && !breakflag; e0++)
				{
					int pid0 = AllCameras_AllTrackletVec[cid0][loc0][e0].x, fid0 = AllCameras_AllTrackletVec[cid0][loc0][e0].y;
					for (int e1 = 0; e1 < (int)AllCameras_AllTrackletVec[cid1][loc1].size() && !breakflag; e1++)
					{
						int pid1 = AllCameras_AllTrackletVec[cid1][loc1][e1].x, fid1 = AllCameras_AllTrackletVec[cid1][loc1][e1].y;
						if (cid0 == cid1 && fid0 == fid1) //found
							Dist[tid0 + tid1 * ntracklets] = 9e9, Dist[tid1 + tid0 * ntracklets] = 9e9, breakflag = true;
					}
				}

				if (breakflag)
					continue;

				vector<double> Vscore;
				for (int e0 = 0; e0 < (int)AllCameras_AllTrackletVec[cid0][loc0].size(); e0++)
				{
					int pid0 = AllCameras_AllTrackletVec[cid0][loc0][e0].x, fid0 = AllCameras_AllTrackletVec[cid0][loc0][e0].y;
					for (int e1 = 0; e1 < (int)AllCameras_AllTrackletVec[cid1][loc1].size(); e1++)
					{
						double score = 0;
						int pid1 = AllCameras_AllTrackletVec[cid1][loc1][e1].x, fid1 = AllCameras_AllTrackletVec[cid1][loc1][e1].y;
						if (metric == 0)//cosine
						{
							for (int ii = 0; ii < featDim; ii++)
								score += AllDesc[cid0][fid0][0][pid0].feat[ii] * AllDesc[cid1][fid1][0][pid1].feat[ii];
							Vscore.push_back(1.0 - score);
						}
						else
						{
							for (int ii = 0; ii < featDim; ii++)
								score += pow(AllDesc[cid0][fid0][0][pid0].feat[ii] - AllDesc[cid1][fid1][0][pid1].feat[ii], 2);
							Vscore.push_back(score);
						}
					}
				}
				std::sort(Vscore.begin(), Vscore.end());

				int mid = Vscore.size() / 2;
				Dist[tid0 + tid1 * ntracklets] = Vscore[mid], Dist[tid1 + tid0 * ntracklets] = Vscore[mid];
			}
		}


		sprintf(Fname, "%s/TrackletDistance.txt", Path);  fp = fopen(Fname, "w");
		for (int ii = 0; ii < ntracklets; ii++)
		{
			for (int jj = 0; jj < ntracklets; jj++)
				fprintf(fp, "%.4e ", Dist[ii + jj * ntracklets]);
			fprintf(fp, "\n");
		}
		fclose(fp);
	}
	else
	{
		printLOG("Loading tracklets distance matrix from cache\n");
		sprintf(Fname, "%s/TrackletDistance.txt", Path);  FILE *fp = fopen(Fname, "r");
		for (int ii = 0; ii < ntracklets*ntracklets; ii++)
			fscanf(fp, "%f ", &Dist[ii]);
		fclose(fp);
	}

	return 0;
}
int ValidateRCcluster(char *Path, vector<int> &sCams, int startF, int stopF)
{
	char Fname[512];
	int nCams = *std::max_element(std::begin(sCams), std::end(sCams)) + 1;

	int nf, fid, pid, nPeople = 0;
	vector<Point2i> tracklet, GTid2CidLTid;
	vector<vector<Point2i> > *trackletVec = new vector<vector<Point2i> >[nCams];
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/%d/CleanedMergedTracklets_%d_%d.txt", Path, cid, startF, stopF); FILE*fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		int np = 0;
		while (fscanf(fp, "%d ", &nf) != EOF)
		{
			tracklet.clear();
			for (int f = 0; f < nf; f++)
			{
				fscanf(fp, "%d %d ", &fid, &pid);
				tracklet.push_back(Point2i(fid, pid));
			}
			GTid2CidLTid.push_back(Point2i(cid, trackletVec[cid].size()));
			trackletVec[cid].push_back(tracklet);
			np++;
		}
		fclose(fp);

		nPeople = max(nPeople, np);
	}

	const int nJoints = 18;
	vector<vector<int> *> *allPersonID = new vector<vector<int> *>[nCams];
	vector<vector<Point2f> *> *allPoses = new vector<vector<Point2f> *>[nCams];

	sprintf(Fname, "%s/MP/allPersonID.txt", Path);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/MP/allPersonID_creation.txt", Path); FILE *fp1 = fopen(Fname, "w");
		for (auto cid : sCams)
		{
			printLOG("%d: ", cid);
			fprintf(fp1, "%d %d ", cid, stopF);
			for (int fid = 0; fid <= stopF; fid++)
			{
				vector<int> *PersonID = new vector<int>[1];
				vector<Point2f> *PoseI = new vector<Point2f>[1];
				if (fid >= startF && fid <= stopF)
				{
					sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
					if (fp != NULL)
					{
						float u, v, s;
						while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
							PoseI[0].push_back(Point2f(u, v));
						fclose(fp);
					}
					for (int ii = 0; ii < PoseI[0].size() / nJoints; ii++)
						PersonID[0].push_back(-1);
				}
				allPoses[cid].push_back(PoseI);
				allPersonID[cid].push_back(PersonID);
				fprintf(fp1, "%d %d ", fid, PersonID[0].size());
			}
			fprintf(fp1, "\n");
		}
		fclose(fp1);


		sprintf(Fname, "%s/MP/allPersonID.txt", Path); FILE *fp = fopen(Fname, "w");
		for (auto cid : sCams)
		{
			for (int gpid = 0; gpid < trackletVec[cid].size(); gpid++)
			{
				for (int ii = 0; ii < trackletVec[cid][gpid].size(); ii++)
				{
					int fid = trackletVec[cid][gpid][ii].x, lpid = trackletVec[cid][gpid][ii].y;
					allPersonID[cid][fid][0][lpid] = gpid;
					fprintf(fp, "%d %d %d %d\n", cid, fid, lpid, allPersonID[cid][fid][0][lpid]);
				}
			}
		}
		fclose(fp);
	}
	else
	{
		int cid, lpid, gpid, nf, np;
		sprintf(Fname, "%s/MP/allPersonID_creation.txt", Path); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d ", &cid, &nf) != EOF)
		{
			for (int ii = 0; ii <= nf; ii++)
			{
				fscanf(fp, "%d %d ", &fid, &np);
				vector<int> *PersonID = new vector<int>[1];
				for (int jj = 0; jj < np; jj++)
					PersonID[0].push_back(-1);
				allPersonID[cid].push_back(PersonID);
			}
		}
		fclose(fp);

		sprintf(Fname, "%s/MP/allPersonID.txt", Path); fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %d %d ", &cid, &fid, &lpid, &gpid) != EOF)
			allPersonID[cid][fid][0][lpid] = gpid;
		fclose(fp);
	}

	//read cluster results
	vector<vector<Point2i> *> *allTracklets = new vector<vector<Point2i> *>[nCams];
	int tid, nLinks, dummy;
	for (int ii = 0; ii < sCams.size(); ii++)
	{
		int cid = sCams[ii];
		sprintf(Fname, "%s/%d/Softmax_RCC_tracklets.txt", Path, cid); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %d ", &tid, &nLinks, &nf) != EOF)
		{
			vector<Point2i> *tracklet = new vector<Point2i>[1];
			for (int jj = 0; jj < nLinks; jj++)
				fscanf(fp, "%d ", &dummy);
			for (int jj = 0; jj < nf; jj++)
			{
				fscanf(fp, "%d %d ", &fid, &pid);
				tracklet[0].push_back(Point2i(fid, pid));
			}
			allTracklets[cid].push_back(tracklet);
		}
		fclose(fp);
	}

	int *ConfusionMat = new int[nPeople*nPeople];
	for (int ii = 0; ii < sCams.size(); ii++)
	{
		int cid = sCams[ii];
		for (int tid = 0; tid < allTracklets[cid].size(); tid++)
		{
			for (int jj = 0; jj < allTracklets[cid][tid][0].size(); jj++)
			{
				fid = allTracklets[cid][tid][0][jj].x, pid = allTracklets[cid][tid][0][jj].y;

			}
		}
	}

	return 0;
}
int GenPerCamPeopleGTLabel(char *Path, vector<int> &sCams, int startF, int stopF)
{
	char Fname[512];
	int nCams = *std::max_element(std::begin(sCams), std::end(sCams)) + 1;

	int nf, fid, pid, nPeople = 0;
	vector<Point2i> tracklet, GTid2CidLTid;
	vector<vector<Point2i> > *trackletVec = new vector<vector<Point2i> >[nCams];
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/%d/CleanedMergedTracklets_%d_%d.txt", Path, cid, startF, stopF); FILE*fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		int np = 0;
		while (fscanf(fp, "%d ", &nf) != EOF)
		{
			tracklet.clear();
			for (int f = 0; f < nf; f++)
			{
				fscanf(fp, "%d %d ", &fid, &pid);
				tracklet.push_back(Point2i(fid, pid));
			}
			GTid2CidLTid.push_back(Point2i(cid, trackletVec[cid].size()));
			trackletVec[cid].push_back(tracklet);
			np++;
		}
		fclose(fp);

		nPeople = max(nPeople, np);
	}

	const int nJoints = 18;
	vector<vector<int> *> *allPersonID = new vector<vector<int> *>[nCams];
	vector<vector<Point2f> *> *allPoses = new vector<vector<Point2f> *>[nCams];

	sprintf(Fname, "%s/MP/allPersonID.txt", Path);
	if (IsFileExist(Fname) == 0)
	{
		sprintf(Fname, "%s/MP/allPersonID_creation.txt", Path); FILE *fp1 = fopen(Fname, "w");
		for (auto cid : sCams)
		{
			printLOG("%d: ", cid);
			fprintf(fp1, "%d %d ", cid, stopF);
			for (int fid = 0; fid <= stopF; fid++)
			{
				vector<int> *PersonID = new vector<int>[1];
				vector<Point2f> *PoseI = new vector<Point2f>[1];
				if (fid >= startF && fid <= stopF)
				{
					sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
					if (fp != NULL)
					{
						float u, v, s;
						while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
							PoseI[0].push_back(Point2f(u, v));
						fclose(fp);
					}
					for (int ii = 0; ii < PoseI[0].size() / nJoints; ii++)
						PersonID[0].push_back(-1);
				}
				allPoses[cid].push_back(PoseI);
				allPersonID[cid].push_back(PersonID);
				fprintf(fp1, "%d %d ", fid, PersonID[0].size());
			}
			fprintf(fp1, "\n");
		}
		fclose(fp1);


		sprintf(Fname, "%s/MP/allPersonID.txt", Path); FILE *fp = fopen(Fname, "w");
		for (auto cid : sCams)
		{
			for (int gpid = 0; gpid < trackletVec[cid].size(); gpid++)
			{
				for (int ii = 0; ii < trackletVec[cid][gpid].size(); ii++)
				{
					int fid = trackletVec[cid][gpid][ii].x, lpid = trackletVec[cid][gpid][ii].y;
					allPersonID[cid][fid][0][lpid] = gpid;
					fprintf(fp, "%d %d %d %d\n", cid, fid, lpid, allPersonID[cid][fid][0][lpid]);
				}
			}
		}
		fclose(fp);
	}
	else
	{
		int cid, lpid, gpid, nf, np;
		sprintf(Fname, "%s/MP/allPersonID_creation.txt", Path); FILE *fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d ", &cid, &nf) != EOF)
		{
			for (int ii = 0; ii <= nf; ii++)
			{
				fscanf(fp, "%d %d ", &fid, &np);
				vector<int> *PersonID = new vector<int>[1];
				for (int jj = 0; jj < np; jj++)
					PersonID[0].push_back(-1);
				allPersonID[cid].push_back(PersonID);
			}
		}
		fclose(fp);

		sprintf(Fname, "%s/MP/allPersonID.txt", Path); fp = fopen(Fname, "r");
		while (fscanf(fp, "%d %d %d %d ", &cid, &fid, &lpid, &gpid) != EOF)
			allPersonID[cid][fid][0][lpid] = gpid;
		fclose(fp);
	}

	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/MP/allPersonID_%d.txt", Path, cid); FILE *fp = fopen(Fname, "w");
		for (int fid = startF; fid <= stopF; fid++)
		{
			vector<int> *PersonID = allPersonID[cid][fid];
			for (int np = 0; np < PersonID[0].size(); np++)
				fprintf(fp, "%d\n", PersonID[0][np]);
		}
		fclose(fp);
	}

	return 0;
}

int FmatSyncRobustBruteForceKeypoints(char *Path, VideoData &CamI, VideoData &CamJ, vector<vector<ImgPoseEle> > &trackletVecPosI, vector<vector<ImgPoseEle> > &trackletVecPosJ, int cidI, int cidJ, int startF, int stopF, int increF, int *frameTimeStamp, int SearchRange, bool silent)
{
	//The goad is to accumulate all info from all instances for sync. This function only looks at points where there is a valley in the cost(offset) to sync and filter points
	int nCOCOJoints = 18;
	char Fname[512]; FILE *fp = 0;
	const int nCams = 2;
	int minStamp = min(frameTimeStamp[0], frameTimeStamp[1]), maxStamp = max(frameTimeStamp[0], frameTimeStamp[1]);

	ImgPtEle ptEle;

	//Start sliding
	int nPeople = trackletVecPosI.size() - 1;
	int *aOffset = new int[2 * SearchRange + 1], *badPoints = new int[nPeople];
	double *aError = new double[2 * SearchRange + 1], *saError = new double[2 * SearchRange + 1];
	for (int pid = 0; pid < nPeople; pid++)
	{
		int count = 0;
		double maxError = 0, minError = 9e9;
		for (int off = -SearchRange; off <= SearchRange; off += increF)
		{
			double Fmat[9], cumError = 0.0, usedPointsCount = 0;
			for (int fid1 = 0; fid1 < trackletVecPosI[pid].size(); fid1++)
			{
				double error = 0.0;
				int ref1 = trackletVecPosI[pid][fid1].frameID; //the point has been tracked at the offset frame already
				for (int fid2 = 0; fid2 < trackletVecPosJ[pid].size(); fid2++)
				{
					int ref2 = trackletVecPosJ[pid][fid2].frameID; //the point has been tracked at the offset frame already
					if (ref1 + frameTimeStamp[0] == ref2 + frameTimeStamp[1] + off) //see if the corresponding frame in the other camera has point. Use addition to fake the refframe:
					{
						if (CamI.VideoInfo[ref1].valid == 0 || CamJ.VideoInfo[ref2].valid == 0)
							continue;

						double K1[9], K2[9], R1[9], T1[3], R2[9], T2[3];
						for (int kk = 0; kk < 9; kk++)
							K1[kk] = CamI.VideoInfo[ref1].K[kk], K2[kk] = CamJ.VideoInfo[ref2].K[kk];
						for (int jid = 0; jid < nCOCOJoints; jid++)
						{
							if (trackletVecPosI[pid][fid1].pt2D[jid].x < 1 || trackletVecPosJ[pid][fid2].pt2D[jid].x < 1)
								continue;

							if (CamI.VideoInfo[ref1].ShutterModel == GLOBAL_SHUTTER)
							{
								for (int kk = 0; kk < 9; kk++)
									R1[kk] = CamI.VideoInfo[ref1].R[kk];
								for (int kk = 0; kk < 3; kk++)
									T1[kk] = CamI.VideoInfo[ref1].T[kk];
							}
							else if (CamI.VideoInfo[ref1].ShutterModel == ROLLING_SHUTTER)
								AssembleRT_RS(trackletVecPosI[pid][fid1].pt2D[jid], CamI.VideoInfo[ref1], R1, T1);

							if (CamJ.VideoInfo[ref2].ShutterModel == 0)
							{
								for (int kk = 0; kk < 9; kk++)
									R2[kk] = CamJ.VideoInfo[ref2].R[kk];
								for (int kk = 0; kk < 3; kk++)
									T2[kk] = CamJ.VideoInfo[ref2].T[kk];
							}
							else  if (CamJ.VideoInfo[ref2].ShutterModel == ROLLING_SHUTTER)
								AssembleRT_RS(trackletVecPosJ[pid][fid2].pt2D[jid], CamJ.VideoInfo[ref2], R2, T2);

							computeFmat(K1, K2, R1, T1, R2, T2, Fmat);

							error = FmatPointError(Fmat, trackletVecPosI[pid][fid1].pt2D[jid], trackletVecPosJ[pid][fid2].pt2D[jid]);
							cumError += error;
							usedPointsCount++;
						}
						break;
					}
				}
			}

			if (usedPointsCount > 0)
			{
				maxError = max(maxError, cumError);
				minError = min(minError, cumError);
			}
			aError[count] = cumError / (0.0000001 + usedPointsCount);
			count++;
		}

		if (minError / maxError > 0.25 || minError == 0) //there is a valley in the cost function -->almost always corredponding trajectory
			badPoints[pid] = 1;
		else
		{
			badPoints[pid] = 0;
			if (!silent)
				printLOG("%d ...", pid);
		}
	}

	int count = 0, BestOffset = 9e9;
	double minError = 9e9;
	for (int off = -SearchRange; off <= SearchRange; off += increF)
	{
		double Fmat[9], cumError = 0.0, usedPointsCount = 0;
		for (int pid = 0; pid < nPeople; pid++)
		{
			if (badPoints[pid] == 1)
				continue;
			for (int fid1 = 0; fid1 < trackletVecPosI[pid].size(); fid1++)
			{
				double error = 0.0;
				int ref1 = trackletVecPosI[pid][fid1].frameID; //the point has been tracked at the offset frame already
				for (int fid2 = 0; fid2 < trackletVecPosJ[pid].size(); fid2++)
				{
					int ref2 = trackletVecPosJ[pid][fid2].frameID; //the point has been tracked at the offset frame already
					if (ref1 + frameTimeStamp[0] == ref2 + frameTimeStamp[1] + off) //see if the corresponding frame in the other camera has point. Use addition to fake the refframe:
					{
						if (CamI.VideoInfo[ref1].valid == 0 || CamJ.VideoInfo[ref2].valid == 0)
							continue;

						for (int jid = 0; jid < nCOCOJoints; jid++)
						{
							if (trackletVecPosI[pid][fid1].pt2D[jid].x < 1 || trackletVecPosJ[pid][fid2].pt2D[jid].x < 1)
								continue;

							double K1[9], K2[9], R1[9], T1[3], R2[9], T2[3];
							for (int kk = 0; kk < 9; kk++)
								K1[kk] = CamI.VideoInfo[ref1].K[kk], K2[kk] = CamJ.VideoInfo[ref2].K[kk];
							if (CamI.VideoInfo[ref1].ShutterModel == 0)
							{
								for (int kk = 0; kk < 9; kk++)
									R1[kk] = CamI.VideoInfo[ref1].R[kk];
								for (int kk = 0; kk < 3; kk++)
									T1[kk] = CamI.VideoInfo[ref1].T[kk];
							}
							else
								AssembleRT_RS(trackletVecPosI[pid][fid1].pt2D[jid], CamI.VideoInfo[ref1], R1, T1);

							if (CamJ.VideoInfo[ref2].ShutterModel == 0)
							{
								for (int kk = 0; kk < 9; kk++)
									R2[kk] = CamJ.VideoInfo[ref2].R[kk];
								for (int kk = 0; kk < 3; kk++)
									T2[kk] = CamJ.VideoInfo[ref2].T[kk];
							}
							else
								AssembleRT_RS(trackletVecPosJ[pid][fid2].pt2D[jid], CamJ.VideoInfo[ref2], R2, T2);

							computeFmat(K1, K2, R1, T1, R2, T2, Fmat);
							error = FmatPointError(Fmat, trackletVecPosI[pid][fid1].pt2D[jid], trackletVecPosJ[pid][fid2].pt2D[jid]);
							usedPointsCount++;
						}
						break;
					}
				}
				cumError += error;
			}
		}

		if (usedPointsCount == 0)
			cumError = 9e9;
		cumError = cumError / (0.0000001 + usedPointsCount);
		if (cumError < minError)
			minError = cumError, BestOffset = off;

		aError[count] = cumError;
		aOffset[count] = off;
		if (!silent)
			printLOG("@off %d (id: %d): %.5e -- Best offset: %d\n", off, count, cumError, BestOffset);
		count++;
	}
	Quick_Sort_Double(aError, aOffset, 0, count - 1);
	printLOG("Pair (%d, %d): %d: %.3e  ... %d: %.3e \n", cidI, cidJ, aOffset[0], aError[0], aOffset[1], aError[1]);

	frameTimeStamp[1] = frameTimeStamp[1] + BestOffset;

	delete[]aOffset, delete[]aError, delete[]saError, delete[]badPoints;

	return 0;
}
int PairSyncRobustBruteForceKeypoints(char *Path, VideoData &CamI, VideoData &CamJ, vector<vector<ImgPoseEle> > &trackletVecPosI, vector<vector<ImgPoseEle> > &trackletVecPosJ, int cidI, int cidJ, int startF, int stopF, int increF, int *frameTimeStamp, int SearchRange, bool Triangulation, bool silent)
{
	//The goad is to accumulate all info from all instances for sync. This function only looks at points where there is a valley in the cost(offset) to sync and filter points
	int nCOCOJoints = 18;
	char Fname[512];
	const int nCams = 2;
	int minStamp = min(frameTimeStamp[0], frameTimeStamp[1]), maxStamp = max(frameTimeStamp[0], frameTimeStamp[1]);

	ImgPtEle ptEle;

	//Start sliding
	double P[24];
	Point2d StereoPair[2];
	int nPeople = trackletVecPosI.size();
	int *badPoints = new int[nPeople];
	for (int pid = 0; pid < nPeople; pid++)
		badPoints[pid] = 0;
	/*for (int pid = 0; pid < nPeople; pid++)
	{
	int count = 0;
	double maxError = 0, minError = 9e9;
	for (int off = -SearchRange; off <= SearchRange; off += increF)
	{
	int usedPointsCount = 0;
	double Fmat[9], cumError = 0.0;
	for (int fid1 = 0; fid1 < trackletVecPosI[pid].size(); fid1++)
	{
	double error = 0.0;
	int ref1 = trackletVecPosI[pid][fid1].frameID; //the point has been tracked at the offset frame already
	for (int fid2 = 0; fid2 < trackletVecPosJ[pid].size(); fid2++)
	{
	int ref2 = trackletVecPosJ[pid][fid2].frameID; //the point has been tracked at the offset frame already
	if (ref1 + frameTimeStamp[0] == ref2 + frameTimeStamp[1] + off) //see if the corresponding frame in the other camera has point. Use addition to fake the refframe:
	{
	if (CamI.VideoInfo[ref1].valid == 0 || CamJ.VideoInfo[ref2].valid == 0)
	continue;

	double K1[9], K2[9], R1[9], T1[3], R2[9], T2[3];
	if (!Triangulation)
	for (int kk = 0; kk < 9; kk++)
	K1[kk] = CamI.VideoInfo[ref1].K[kk], K2[kk] = CamJ.VideoInfo[ref2].K[kk];
	for (int jid = 0; jid < nCOCOJoints; jid++)
	{
	StereoPair[0] = trackletVecPosI[pid][fid1].pt2D[jid];
	StereoPair[1] = trackletVecPosJ[pid][fid2].pt2D[jid];

	if (StereoPair[0].x < 1 || StereoPair[1].x < 1)
	continue;
	if (CamI.VideoInfo[ref1].ShutterModel == GLOBAL_SHUTTER)
	{
	if (!Triangulation)
	{
	for (int kk = 0; kk < 9; kk++)
	R1[kk] = CamI.VideoInfo[ref1].R[kk];
	for (int kk = 0; kk < 3; kk++)
	T1[kk] = CamI.VideoInfo[ref1].T[kk];
	}
	else
	for (int kk = 0; kk < 12; kk++)
	P[kk] = CamI.VideoInfo[ref1].P[kk];
	}
	else if (CamI.VideoInfo[ref1].ShutterModel == ROLLING_SHUTTER)
	{
	//if (CamI.VideoInfo[ref1].LensModel == RADIAL_TANGENTIAL_PRISM)
	//	LensCorrectionPoint(&StereoPair[0], CamI.VideoInfo[ref1].K, CamI.VideoInfo[ref1].distortion);
	//else
	//	FishEyeCorrectionPoint(&StereoPair[0], CamI.VideoInfo[ref1].K, CamI.VideoInfo[ref1].distortion[0]);

	if (!Triangulation)
	AssembleRT_RS(StereoPair[0], CamI.VideoInfo[ref1], R1, T1);
	else
	AssembleP_RS(StereoPair[0], CamI.VideoInfo[ref1], P);
	}

	if (CamJ.VideoInfo[ref2].ShutterModel == 0)
	{
	if (!Triangulation)
	{
	for (int kk = 0; kk < 9; kk++)
	R2[kk] = CamJ.VideoInfo[ref2].R[kk];
	for (int kk = 0; kk < 3; kk++)
	T2[kk] = CamJ.VideoInfo[ref2].T[kk];
	}
	else
	for (int kk = 0; kk < 12; kk++)
	P[kk + 12] = CamJ.VideoInfo[ref2].P[kk];
	}
	else  if (CamJ.VideoInfo[ref2].ShutterModel == ROLLING_SHUTTER)
	{
	//if (CamJ.VideoInfo[ref2].LensModel == RADIAL_TANGENTIAL_PRISM)
	//	LensCorrectionPoint(&StereoPair[1], CamJ.VideoInfo[ref2].K, CamJ.VideoInfo[ref2].distortion);
	//else
	//	FishEyeCorrectionPoint(&StereoPair[1], CamJ.VideoInfo[ref2].K, CamJ.VideoInfo[ref2].distortion[0]);

	if (!Triangulation)
	AssembleRT_RS(StereoPair[1], CamJ.VideoInfo[ref2], R2, T2);
	else
	AssembleP_RS(StereoPair[1], CamJ.VideoInfo[ref2], P + 12);
	}

	if (!Triangulation)
	{
	computeFmat(K1, K2, R1, T1, R2, T2, Fmat);
	error = FmatPointError(Fmat, trackletVecPosI[pid][fid1].pt2D[jid], trackletVecPosJ[pid][fid2].pt2D[jid]);
	}
	else
	{
	Point3d WC;
	TwoViewTriangulation(&StereoPair[0], &StereoPair[1], P, P + 12, &WC);

	error = 0.0;
	for (int ll = 0; ll < 2; ll++)
	{
	double numX = P[ll * 12 + 0] * WC.x + P[ll * 12 + 1] * WC.y + P[ll * 12 + 2] * WC.z + P[ll * 12 + 3];
	double numY = P[ll * 12 + 4] * WC.x + P[ll * 12 + 5] * WC.y + P[ll * 12 + 6] * WC.z + P[ll * 12 + 7];
	double denum = P[ll * 12 + 8] * WC.x + P[ll * 12 + 9] * WC.y + P[ll * 12 + 10] * WC.z + P[ll * 12 + 11];

	error += pow(StereoPair[ll].x - numX / denum, 2) + pow(StereoPair[ll].y - numY / denum, 2);
	}
	error = sqrt(error / 2);
	}

	cumError += error;
	usedPointsCount++;
	}
	break;
	}
	}
	}

	if (usedPointsCount > 0)
	{
	maxError = max(maxError, cumError);
	minError = min(minError, cumError);
	}
	//printLOG("@off %d %.3e\n", off,  cumError / (0.0000001 + usedPointsCount));
	count++;
	}

	if (minError / maxError > 0.25 || minError == 0) //there is a valley in the cost function -->almost always corredponding trajectory
	badPoints[pid] = 1;
	}*/

	sprintf(Fname, "%s/GeoSynDebug.txt", Path);
	FILE *fp = fopen(Fname, "a");

	int count = 0, BestOffset = 9e9;
	double minError = 9e9;
	int *aOffset = new int[2 * SearchRange + 1];
	double *aError = new double[2 * SearchRange + 1], *saError = new double[2 * SearchRange + 1];
	for (int off = -SearchRange; off <= SearchRange; off += increF)
	{
		int usedPointsCount = 0;
		double Fmat[9], cumError = 0.0;
		for (int pid = 0; pid < nPeople; pid++)
		{
			if (badPoints[pid] == 1)
				continue;
			for (int fid1 = 0; fid1 < trackletVecPosI[pid].size(); fid1++)
			{
				double error = 0.0;
				int ref1 = trackletVecPosI[pid][fid1].frameID; //the point has been tracked at the offset frame already
				for (int fid2 = 0; fid2 < trackletVecPosJ[pid].size(); fid2++)
				{
					int ref2 = trackletVecPosJ[pid][fid2].frameID; //the point has been tracked at the offset frame already
					if (ref1 + frameTimeStamp[0] == ref2 + frameTimeStamp[1] + off) //see if the corresponding frame in the other camera has point. Use addition to fake the refframe:
					{
						if (CamI.VideoInfo[ref1].valid == 0 || CamJ.VideoInfo[ref2].valid == 0)
							continue;

						for (int jid = 0; jid < nCOCOJoints; jid++)
						{
							StereoPair[0] = trackletVecPosI[pid][fid1].pt2D[jid];
							StereoPair[1] = trackletVecPosJ[pid][fid2].pt2D[jid];
							if (StereoPair[0].x < 1 || StereoPair[1].x < 1)
								continue;

							double K1[9], K2[9], R1[9], T1[3], R2[9], T2[3];
							if (!Triangulation)
								for (int kk = 0; kk < 9; kk++)
									K1[kk] = CamI.VideoInfo[ref1].K[kk], K2[kk] = CamJ.VideoInfo[ref2].K[kk];

							if (CamI.VideoInfo[ref1].ShutterModel == 0)
							{
								if (!Triangulation)
								{
									for (int kk = 0; kk < 9; kk++)
										R1[kk] = CamI.VideoInfo[ref1].R[kk];
									for (int kk = 0; kk < 3; kk++)
										T1[kk] = CamI.VideoInfo[ref1].T[kk];
								}
								else
									for (int kk = 0; kk < 12; kk++)
										P[kk] = CamI.VideoInfo[ref1].P[kk];
							}
							else
							{
								if (!Triangulation)
									AssembleRT_RS(StereoPair[0], CamI.VideoInfo[ref1], R1, T1);
								else
									AssembleP_RS(StereoPair[0], CamI.VideoInfo[ref1], P);
							}

							if (CamJ.VideoInfo[ref2].ShutterModel == 0)
							{
								if (!Triangulation)
								{
									for (int kk = 0; kk < 9; kk++)
										R2[kk] = CamJ.VideoInfo[ref2].R[kk];
									for (int kk = 0; kk < 3; kk++)
										T2[kk] = CamJ.VideoInfo[ref2].T[kk];
								}
								else
									for (int kk = 0; kk < 12; kk++)
										P[kk + 12] = CamJ.VideoInfo[ref2].P[kk];
							}
							else
							{
								if (!Triangulation)
									AssembleRT_RS(StereoPair[1], CamJ.VideoInfo[ref2], R2, T2);
								else
									AssembleP_RS(StereoPair[1], CamJ.VideoInfo[ref2], P + 12);
							}

							if (!Triangulation)
							{
								computeFmat(K1, K2, R1, T1, R2, T2, Fmat);
								error = FmatPointError(Fmat, trackletVecPosI[pid][fid1].pt2D[jid], trackletVecPosJ[pid][fid2].pt2D[jid]);
							}
							else
							{
								Point3d WC;
								TwoViewTriangulation(&StereoPair[0], &StereoPair[1], P, P + 12, &WC);

								error = 0.0;
								for (int ll = 0; ll < 2; ll++)
								{
									double numX = P[ll * 12 + 0] * WC.x + P[ll * 12 + 1] * WC.y + P[ll * 12 + 2] * WC.z + P[ll * 12 + 3];
									double numY = P[ll * 12 + 4] * WC.x + P[ll * 12 + 5] * WC.y + P[ll * 12 + 6] * WC.z + P[ll * 12 + 7];
									double denum = P[ll * 12 + 8] * WC.x + P[ll * 12 + 9] * WC.y + P[ll * 12 + 10] * WC.z + P[ll * 12 + 11];

									error += pow(StereoPair[ll].x - numX / denum, 2) + pow(StereoPair[ll].y - numY / denum, 2);
								}
								error = sqrt(error / 2);
							}
							cumError += error;
							usedPointsCount++;
						}
						break;
					}
				}
			}
		}

		if (usedPointsCount == 0)
			cumError = 9e9;
		cumError = cumError / (0.0000001 + usedPointsCount);
		if (cumError < minError)
			minError = cumError, BestOffset = off;

		aError[count] = cumError;
		aOffset[count] = off;
		if (!silent)
		{
			if (count % 4 == 0)
				printLOG("\n");
			printLOG("@off %d (id: %d): %.5e -- Best: %d\t", off, count, cumError, BestOffset);
		}
		fprintf(fp, "@off %d (id: %d): %.5e -- Best offset: %d\n", off, count, cumError, BestOffset);
		count++;
	}
	fclose(fp);
	Quick_Sort_Double(aError, aOffset, 0, count - 1);
	printLOG("\nPair (%d, %d): %d: %.3e  ... %d: %.3e \n", cidI, cidJ, aOffset[0], aError[0], aOffset[1], aError[1]);

	frameTimeStamp[1] = frameTimeStamp[1] + BestOffset;

	delete[]aOffset, delete[]aError, delete[]saError, delete[]badPoints;

	return 0;
}
int AllPairSyncKeyPointsDriver(char *Path, vector<int> &sCams, int refStartF, int refStopF, int startF, int stopF, int increF, int SearchRange)
{
	char Fname[512]; FILE *fp = 0;
	int nCams = *std::max_element(std::begin(sCams), std::end(sCams)) + 1;

	int *frameTimeStamp = new int[nCams];
	for (int ii = 0; ii < nCams; ii++)
		frameTimeStamp[ii] = 0;

	double fps;
	sprintf(Fname, "%s/InitSync.txt", Path); fp = fopen(Fname, "r");
	if (fp != NULL)
	{
		int selected, ts;
		for (int ii = 0; ii < nCams; ii++)
		{
			fscanf(fp, "%d %lf %d ", &selected, &fps, &ts);
			frameTimeStamp[selected] = ts;
		}
		fclose(fp);
	}
	else
		printLOG("Cannot load time stamp info. Assume no frame offsets!");

	//Read calib info
	VideoData *VideoInfo = new VideoData[nCams];
	for (auto cid : sCams)
		if (ReadVideoDataI(Path, VideoInfo[cid], cid, startF, stopF) == 1)
			return 1;

	vector<Point2i> tracklet, GTid2CidLTid;
	vector<vector<Point2i> > *trackletVec = new vector<vector<Point2i> >[nCams];
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/%d/CleanedMergedTracklets_%d_%d.txt", Path, cid, refStartF, refStopF); FILE*fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		int nf, fid, pid;
		while (fscanf(fp, "%d ", &nf) != EOF)
		{
			tracklet.clear();
			for (int f = 0; f < nf; f++)
			{
				fscanf(fp, "%d %d ", &fid, &pid);
				tracklet.push_back(Point2i(fid, pid));
			}
			GTid2CidLTid.push_back(Point2i(cid, trackletVec[cid].size()));
			trackletVec[cid].push_back(tracklet);
		}
		fclose(fp);
	}

	const int nCocoJoints = 18;
	vector<vector<Point2f> *> *allPoses = new vector<vector<Point2f> *>[nCams];
	for (auto cid : sCams)
	{
		printLOG("%d: ", cid);
		sprintf(Fname, "%s/MP/allPose_%d.txt", Path, cid);
		if (IsFileExist(Fname) == 0)
		{
			for (int fid = 0; fid < startF; fid++)
			{
				vector<Point2f> *PoseI = new vector<Point2f>[1];
				allPoses[cid].push_back(PoseI);
			}
			for (int fid = startF; fid <= stopF; fid++)
			{
				vector<Point2f> *PoseI = new vector<Point2f>[1];
				if (fid >= startF && fid <= stopF)
				{
					sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
					if (fp != NULL)
					{
						float u, v, s;
						while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
							PoseI[0].push_back(Point2f(u, v));
						fclose(fp);
					}
				}
				allPoses[cid].push_back(PoseI);
			}

			sprintf(Fname, "%s/MP/allPose_%d.txt", Path, cid); FILE *fp = fopen(Fname, "w");
			for (int fid = 0; fid <= stopF; fid++)
			{
				int npeople = (int)allPoses[cid][fid][0].size() / nCocoJoints;
				fprintf(fp, "%d %d\n", fid, npeople);
				for (int pid = 0; pid < npeople; pid++)
				{
					for (int jid = 0; jid < nCocoJoints; jid++)
						fprintf(fp, "%.3f %.3f ", allPoses[cid][fid][0][pid*nCocoJoints + jid].x, allPoses[cid][fid][0][pid*nCocoJoints + jid].y);
					fprintf(fp, "\n");
				}
			}
			fclose(fp);
		}
		else
		{
			int fid, npeople;
			float u, v;
			FILE *fp = fopen(Fname, "r");
			while (fscanf(fp, "%d %d ", &fid, &npeople) != EOF)
			{
				vector<Point2f> *PoseI = new vector<Point2f>[1];
				for (int pid = 0; pid < npeople; pid++)
				{
					for (int jid = 0; jid < nCocoJoints; jid++)
					{
						fscanf(fp, "%f %f ", &u, &v);
						PoseI[0].push_back(Point2f(u, v));
					}
				}
				allPoses[cid].push_back(PoseI);
			}
			fclose(fp);
		}
	}

	int pointFormat = 18;
	ImgPoseEle pose(pointFormat);
	vector<vector<ImgPoseEle> > *trackletVecPose = new vector<vector<ImgPoseEle> >[nCams];
	for (auto cid : sCams)
	{
		for (int tid = 0; tid < trackletVec[cid].size() - 1; tid++)
		{
			vector<ImgPoseEle> trackletPose;
			for (int f = 0; f < trackletVec[cid][tid].size(); f++)
			{
				int fid = trackletVec[cid][tid][f].x, pid = trackletVec[cid][tid][f].y;
				if (!VideoInfo[cid].VideoInfo[fid].valid)
					continue; //camera not localized

				vector<Point2f> *PoseI = allPoses[cid][fid];
				for (int jid = 0; jid < nCocoJoints; jid++)
				{
					if (PoseI[0][jid + pid * nCocoJoints].x > 1)
					{
						if (VideoInfo[cid].VideoInfo[fid].LensModel == RADIAL_TANGENTIAL_PRISM)
							LensCorrectionPoint(&PoseI[0][jid + pid * nCocoJoints], VideoInfo[cid].VideoInfo[fid].K, VideoInfo[cid].VideoInfo[fid].distortion);
						else
							FishEyeCorrectionPoint(&PoseI[0][jid + pid * nCocoJoints], VideoInfo[cid].VideoInfo[fid].K, VideoInfo[cid].VideoInfo[fid].distortion[0]);
					}
					pose.pt2D[jid] = Point2d(PoseI[0][jid + pid * nCocoJoints].x, PoseI[0][jid + pid * nCocoJoints].y);
				}
				pose.frameID = fid, pose.viewID = cid;
				trackletPose.push_back(pose);
			}
			trackletVecPose[cid].push_back(trackletPose);
		}
	}

	printLOG("Geometric sync:\n");
	sprintf(Fname, "%s/GeoSynDebug.txt", Path); fp = fopen(Fname, "w"); fclose(fp);
	sprintf(Fname, "%s/GeoSync.txt", Path); 	fp = fopen(Fname, "w");
	for (int ii = 0; ii < (int)sCams.size() - 1; ii++)
	{
		for (int jj = ii + 1; jj < (int)sCams.size(); jj++)
		{
			int cidI = sCams[ii], cidJ = sCams[jj];
			int TimeStamp[2] = { frameTimeStamp[cidI], frameTimeStamp[cidJ] };
			PairSyncRobustBruteForceKeypoints(Path, VideoInfo[cidI], VideoInfo[cidJ], trackletVecPose[cidI], trackletVecPose[cidJ], cidI, cidJ, startF, stopF, increF, TimeStamp, SearchRange, true, false);
			printLOG("Between (%d, %d): %d\n\n", jj, ii, TimeStamp[0] - TimeStamp[1]);
			fprintf(fp, "%d %d %d\n", jj, ii, TimeStamp[0] - TimeStamp[1]);
		}
	}
	fclose(fp);

	double *dTimeStamp = new double[sCams.size()];
	for (int ii = 0; ii < sCams.size(); ii++)
		dTimeStamp[ii] = frameTimeStamp[ii];

	PrismMST(Path, "GeoSync", nCams);
	AssignOffsetFromMST(Path, "GeoSync", nCams, dTimeStamp);
	printLOG("Done.\n\n***NOTE: FGeoSync is in time stamp format (f = f_ref - offset) ***\n");

	//delete[]dTimeStamp, delete[]frameTimeStamp, delete[]VideoInfo, delete[]trackletVec, delete[]allPoses, delete[]trackletVecPose;

	return 0;
}


int Convert_STPeopleTracking_PerFrameSfM_Input(char *Path, vector<int> &sCams, vector<int> &TimeStamp, int startF, int stopF, int increF)
{
	char Fname[512];

	const int nJoints = 18;
	int nCams = TimeStamp.size();
	vector<vector<Point2i> >*MultiviewTracketVec = new vector<vector< Point2i> >[nCams];
	for (auto cid : sCams)
	{
		sprintf(Fname, "%s/%d/CleanedMergedTracklets_%d_%d.txt", Path, cid, startF, stopF);
		if (!IsFileExist(Fname)) {
			sprintf(Fname, "%s/%d/MergedTracklets_%d_%d.txt", Path, cid, startF, stopF);
			if (!IsFileExist(Fname)) {
				return 1;
			}
		}
		std::string line, item;
		std::ifstream file(Fname);
		while (std::getline(file, line)) {
			StringTrim(&line);//remove white space
			if (line.empty())
				break;
			std::stringstream line_stream(line);
			std::getline(line_stream, item, ' ');  //# pairs

			vector<Point2i> jointTrack;
			int fid, pid;
			while (!line_stream.eof()) {
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				fid = atoi(item.c_str());
				std::getline(line_stream, item, ' ');
				StringTrim(&item);
				pid = atoi(item.c_str());
				jointTrack.push_back(Point2i(fid, pid));
			}
			MultiviewTracketVec[cid].push_back(jointTrack);
		}
		file.close();
		MultiviewTracketVec[cid].pop_back(); //last one is trash
	}
	vector<Point3f> ***allBodyLandmarks = new vector<Point3f> **[nCams];
	for (auto cid : sCams)
	{
		printLOG("Reading data for Cam %d...\n", cid);
		allBodyLandmarks[cid] = new vector<Point3f> *[stopF + 1];
		for (int fid = startF; fid <= stopF; fid++)
		{
			vector<Point3f> uvs;
			sprintf(Fname, "%s/MP/%d/%.4d.txt", Path, cid, fid); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			float u, v, s;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				uvs.push_back(Point3f(u, v, s));
			fclose(fp);

			allBodyLandmarks[cid][fid] = new vector<Point3f>[1];
			allBodyLandmarks[cid][fid][0] = uvs;
		}
	}

	vector<Scalar> colors;
	colors.push_back(Scalar(0, 0, 0));
	colors.push_back(Scalar(128, 128, 0));
	colors.push_back(Scalar(0, 0, 255));
	colors.push_back(Scalar(128, 0, 128));
	colors.push_back(Scalar(0, 128, 255));
	colors.push_back(Scalar(0, 255, 255));
	colors.push_back(Scalar(255, 0, 128));
	colors.push_back(Scalar(0, 0, 128));
	colors.push_back(Scalar(0, 255, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(255, 255, 0));
	colors.push_back(Scalar(255, 0, 0));
	colors.push_back(Scalar(0, 128, 0));
	colors.push_back(Scalar(255, 128, 0));
	colors.push_back(Scalar(0, 128, 128));
	colors.push_back(Scalar(255, 0, 255));
	colors.push_back(Scalar(255, 255, 255));
	colors.push_back(Scalar(128, 0, 0));
	Point2f *joints = new Point2f[nJoints * 100];
	sprintf(Fname, "%s/JBC", Path); makeDir(Fname);
	for (int kk = 0; kk < sCams.size(); kk++)
	{
		int cid = sCams[kk];
		for (int fid = startF; fid <= stopF; fid++)
		{
			int npeople = allBodyLandmarks[cid][fid][0].size() / nJoints;
			vector<Point3f> uvs = allBodyLandmarks[cid][fid][0];
			for (int ii = 0; ii < uvs.size(); ii++)
				joints[ii] = Point2f(uvs[ii].x, uvs[ii].y);

			//convert to sync frame
			sprintf(Fname, "%s/JBC/%.4d", Path, fid + TimeStamp[cid]); makeDir(Fname);
			sprintf(Fname, "%s/JBC/%.4d/%d.txt", Path, fid + TimeStamp[cid], cid); FILE *fp = fopen(Fname, "w");

			//sprintf(Fname, "%s/%d/%.4d.png", Path, cid, fid); Mat img = imread(Fname);

			for (int pid = 0; pid < npeople; pid++)
			{
				int realPid = -1;
				for (size_t tid = 0; tid < MultiviewTracketVec[cid].size() && realPid == -1; tid++) //people track ID: consistent accross all views
				{
					for (size_t lpid = 0; lpid < MultiviewTracketVec[cid][tid].size() && realPid == -1; lpid++) //temporal location of the person in the track
					{
						if (fid == MultiviewTracketVec[cid][tid][lpid].x && pid == MultiviewTracketVec[cid][tid][lpid].y)
						{
							realPid = tid;
						}
					}
				}
				if (realPid != -1)
				{
					for (int jid = 0; jid < nJoints; jid++)
						fprintf(fp, "%d %.3f %.3f %.3f\n", realPid*nJoints + jid, uvs[jid + pid * nJoints].x, uvs[jid + pid * nJoints].y, uvs[jid + pid * nJoints].z);

					/*float minX = 9e9, minY = 9e9, maxX = 0, maxY = 0;
					for (int jid = 0; jid < nJoints; jid++)
					if (joints[pid*nJoints + jid].x>0)
					minX = min(minX, joints[pid*nJoints + jid].x), maxX = max(maxX, joints[pid*nJoints + jid].x), minY = min(minY, joints[pid*nJoints + jid].y), maxY = max(maxY, joints[pid*nJoints + jid].y);

					Draw2DCoCoJoints(img, joints + nJoints*pid, 1, 1);

					rectangle(img, Point2i(minX - img.cols / 50, minY - img.cols / 50), Point2i(maxX + img.rows / 50, maxY + img.rows / 50), colors[realPid % colors.size()], 2, 8, 0);
					CvPoint text_origin = { minX, maxY - img.rows / 20 };
					sprintf(Fname, "%d", realPid), putText(img, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5 * img.cols / 640, colors[realPid % colors.size()], 2);*/
				}
			}
			fclose(fp);

			//sprintf(Fname, "%s/JBC/%.4d/%d.jpg", Path, fid + TimeStamp[cid], cid); imwrite(Fname, img);
		}
	}

	return 0;
}
int SpatioTemporalPeopleTrackingDriver(char *Path, vector<int> &sCams, vector<int> &TimeStamp, int startF, int stopF, int SegmentLength, int increF)
{
	omp_set_num_threads(omp_get_max_threads());
	//MatchPeopleDescAllPairs(Path, sCams.size(), startF, stopF, increF, TimeStamp);

	int maxCamId = *std::max_element(sCams.begin(), sCams.end());
	if (TimeStamp.size() + 1 < maxCamId)
	{
		printLOG("TimeStamp must contain info of all cameras, not just the selected ones\n");
		return 1;
	}

	int debugVis = 1;
	printLOG("Track pose landmark all all videos\n");
	for (int startFi = startF; startFi <= stopF; startFi += SegmentLength)
	{
		int stopFi = min(startFi + SegmentLength, stopF);
		if (startFi == stopFi)
			break;

#pragma omp parallel for schedule(dynamic,1)
		for (int ii = 0; ii < (int)sCams.size(); ii++)
			TrackBody_Landmark_BiDirectLK(Path, sCams[ii], startFi, stopFi, increF, debugVis);
	}

	printLOG("Form tracklets using tracked landmarks\n");
	/*for (int startFi = startF; startFi <= stopF; startFi += SegmentLength)
	{
	int stopFi = min(startFi + SegmentLength, stopF);
	if (startFi == stopFi)
	break;

	printLOG("\n*******Working on (%d, %d)*******\n", startFi, stopFi);
	#pragma omp parallel for schedule(dynamic,1)
	for (int ii = 0; ii < (int)sCams.size(); ii++)
	PerVideoMultiPeopleTracklet(Path, sCams[ii], startFi, stopFi, increF, 20, debugVis);
	}*/

	printLOG("Associate Skeletons using Trifocal Tensor and reID features\nASSUME APPROX SYNCED DATA\n");
	int increFMultiplier = 5;
	/*#ifdef EC2
	int alreadyComputed = 0;
	vector<int> njobs;
	char buffer[512];
	myGetCurDir(512, buffer);

	sprintf(Fname, "%s/availableCameras.txt", Path); FILE *fp = fopen(Fname, "w");
	for (size_t ii = 0; ii < sCams.size(); ii++)
	fprintf(fp, "%d ", sCams[ii]);
	fclose(fp);

	for (int fid = startF; fid <= stopF; fid += increF*increFMultiplier * 2)
	{
	sprintf(Fname, "%s/Logs/MultiviewPeopleAssociationTrifocal_%d_%d_%d.txt", Path, fid, fid + increF*increFMultiplier * 2, increF*increFMultiplier);
	if (IsFileExist(Fname) == 0)
	{
	#ifdef _WINDOWS
	sprintf(Fname, "%s/EnRecon.exe 20 %d %d %d", "C:/Research/DevSoft/EnRecon/build/Release", fid, fid + increF*increFMultiplier * 2, increF*increFMultiplier);
	#else
	#ifdef EC2
	sprintf(Fname, "qsub -b y -cwd -pe orte 2 ./EnRecon 20 %d %d %d", fid, fid + increF*increFMultiplier * 2, increF*increFMultiplier);
	#else
	sprintf(Fname, "./EnRecon 20 %d %d %d", fid, fid + increF*increFMultiplier * 2, increF*increFMultiplier);
	#endif
	#endif
	printLOG(Fname); printLOG("\n");
	system(Fname);
	}
	else
	alreadyComputed++;
	njobs.push_back(0);
	}
	int bestSum = 0, once = 1;

	double startWaitTime = omp_get_wtime(), appStopTime = 9e9, appMeanTime = 9e9;
	while (omp_get_wtime() - startWaitTime < appStopTime)//wait for it to finish
	{
	mySleep(30e3);
	int count = 0;
	for (int fid = startF; fid <= stopF; fid += increF*increFMultiplier * 2)
	{
	sprintf(Fname, "%s/Logs/MultiviewPeopleAssociationTrifocal_%d_%d_%d.txt", Path, fid, fid + increF*increFMultiplier * 2, increF*increFMultiplier);
	if (IsFileExist(Fname) == 1)
	{
	appMeanTime = omp_get_wtime() - startWaitTime;
	njobs[count] = 1;
	}
	count++;
	}

	int sumRes = 0;
	for (int ii = 0; ii < (int)njobs.size(); ii++)
	sumRes += njobs[ii];

	if (sumRes - alreadyComputed > ((int)njobs.size() - alreadyComputed) / 2 && once == 1)
	{
	once = 2;
	appStopTime = appMeanTime * 3;
	printLOG("\nSet max waiting time: %.2fs\n", appStopTime);
	}

	if (sumRes == (int)njobs.size())
	break;
	if (bestSum < sumRes)
	{
	bestSum = sumRes;
	printLOG("(%d/%d) .. ", sumRes, (int)njobs.size());
	}
	}
	printLOG("Done\n");
	#else
	for (int startFi = startF; startFi <= stopF; startFi += SegmentLength)
	{
	int stopFi = min(startFi + SegmentLength, stopF);
	if (startFi == stopFi)
	break;
	//MultiviewPeopleAssociationTrifocal(Path, sCams, TimeStamp, startFi, stopFi, increF * increFMultiplier);
	//VisualizeExtraReassignedPeople(Path, 4, 30, 1500);
	}
	#endif*/

	//MultiviewPeopleAssociationTrifocal(Path, sCams, TimeStamp, 30, 30, increF * increFMultiplier);
	//VisualizeExtraReassignedPeoplePerTriplet(Path, sCams, TimeStamp, 30, 30, increFMultiplier*increF, 0);
	for (int startFi = startF; startFi <= stopF; startFi += SegmentLength)
	{
		int stopFi = min(startFi + SegmentLength, stopF);
		if (startFi == stopFi)
			break;

		//VisualizeExtraReassignedPeoplePerTriplet(Path, sCams, TimeStamp, startF, stopF, increFMultiplier*increF, 0);
		/*#pragma omp parallel for
		for (int ii = 0; ii < (int)sCams.size(); ii++)
		ReAssociateTracklets(Path, sCams[ii], startFi, stopFi, 1);
		// VisualizeIntraReAssignedPeople(Path, 3, 5, 500);

		#pragma omp parallel for
		for (int ii = 0; ii < (int)sCams.size(); ii++)
		//Visualize_Spacetime_ReassignedPeople(Path, 4, 30, 500, 1);*/
	}

	return 0;
}
int JointCalibrationAndHumanEstiationDriver(char *Path, vector<int> &sCams, vector<int> &TimeStamp, int startF, int stopF, int increF)
{
	int nCams = (int)TimeStamp.size(), nPeople = 60;

	Convert_STPeopleTracking_PerFrameSfM_Input(Path, sCams, TimeStamp, startF, stopF, increF);
	return 0;
	Corpus CorpusInfo;
	CorpusInfo.nCameras = nCams;
	CorpusInfo.camera = new CameraData[nCams];

	startF = 800; stopF = 800;
	for (int fid = startF; fid <= stopF; fid++)
	{
		printLOG("********************************************************\nWorking on Frame %d\n", fid);
		//SimpleBodyPoseSfM(Path, fid, CorpusInfo, nPeople, 1);
	}
	return 0;
}

int AlignedPerFrameBodySfM(char *Path, int nCams, int startF, int stopF, int increF, int nMaxPeople)
{
	char Fname[512];
	const int nJoints = 18;
	int npts = nJoints * nMaxPeople;

	int *nProjections = new int[stopF + 1];
	Corpus *AllCorpus = new Corpus[stopF + 1];
	vector<int> *AvailCams = new vector<int>[stopF + 1];
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		AllCorpus[fid].nCameras = nCams, AllCorpus[fid].n3dPoints = npts;
		AllCorpus[fid].camera = new CameraData[nCams];
		AllCorpus[fid].xyz.resize(npts);
		AvailCams[fid].resize(nCams);
	}

	int nBestProjection = 0;
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		sprintf(Fname, "%s/JBC/%.4d/BA.txt", Path, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		int nproj, cid, pid, LensModel, ShutterModel, width, height, dummy;
		double  rt[6];

		fscanf(fp, "%d %d ", &dummy, &nproj); nProjections[fid] = nproj;
		while (fscanf(fp, "%d %d %d %d %d", &cid, &LensModel, &ShutterModel, &width, &height) != EOF)
		{
			AvailCams[fid][cid] = 1, AllCorpus[fid].camera[cid].LensModel = LensModel, AllCorpus[fid].camera[cid].ShutterModel = ShutterModel, AllCorpus[fid].camera[cid].width = width, AllCorpus[fid].camera[cid].height = height;
			if (AllCorpus[fid].camera[cid].LensModel == RADIAL_TANGENTIAL_PRISM)
				fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf ", &AllCorpus[fid].camera[cid].intrinsic[0], &AllCorpus[fid].camera[cid].intrinsic[1], &AllCorpus[fid].camera[cid].intrinsic[2], &AllCorpus[fid].camera[cid].intrinsic[3], &AllCorpus[fid].camera[cid].intrinsic[4],
					&AllCorpus[fid].camera[cid].distortion[0], &AllCorpus[fid].camera[cid].distortion[1], &AllCorpus[fid].camera[cid].distortion[2], &AllCorpus[fid].camera[cid].distortion[3], &AllCorpus[fid].camera[cid].distortion[4], &AllCorpus[fid].camera[cid].distortion[5], &AllCorpus[fid].camera[cid].distortion[6],
					&rt[0], &rt[1], &rt[2], &rt[3], &rt[4], &rt[5]);
			else
				fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf ", &AllCorpus[fid].camera[cid].intrinsic[0], &AllCorpus[fid].camera[cid].intrinsic[1], &AllCorpus[fid].camera[cid].intrinsic[2], &AllCorpus[fid].camera[cid].intrinsic[3], &AllCorpus[fid].camera[cid].intrinsic[4],
					&AllCorpus[fid].camera[cid].distortion[0], &AllCorpus[fid].camera[cid].distortion[1], &AllCorpus[fid].camera[cid].distortion[2], &rt[0], &rt[1], &rt[2], &rt[3], &rt[4], &rt[5]);
			for (int jj = 0; jj < 6; jj++)
				AllCorpus[fid].camera[cid].rt[jj] = rt[jj];
			GetRTFromrt(AllCorpus[fid].camera[cid].rt, AllCorpus[fid].camera[cid].R, AllCorpus[fid].camera[cid].T);
			GetCfromT(AllCorpus[fid].camera[cid].R, AllCorpus[fid].camera[cid].T, AllCorpus[fid].camera[cid].camCenter);
		}
		fclose(fp);

		sprintf(Fname, "%s/JBC/%.4d/3dGL.txt", Path, fid); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		Point3d xyz;
		while (fscanf(fp, "%d %lf %lf %lf ", &pid, &xyz.x, &xyz.y, &xyz.z) != EOF)
			AllCorpus[fid].xyz[pid] = xyz;
		fclose(fp);
	}

	double R[9], T[3], R1[9], T1[3], s, Terror;
	vector<Point3d> refPts, nonRefPts;
	for (int fid = startF; fid < stopF; fid++)
	{
		refPts.clear(), nonRefPts.clear();
		for (int cid = 0; cid < nCams; cid++)
		{
			if (AvailCams[fid][cid] == 1 && AvailCams[fid + 1][cid] == 1)
			{
				refPts.push_back(Point3d(AllCorpus[fid].camera[cid].camCenter[0], AllCorpus[fid].camera[cid].camCenter[1], AllCorpus[fid].camera[cid].camCenter[2]));
				nonRefPts.push_back(Point3d(AllCorpus[fid + 1].camera[cid].camCenter[0], AllCorpus[fid + 1].camera[cid].camCenter[1], AllCorpus[fid + 1].camera[cid].camCenter[2]));
			}
		}
		for (int pid = 0; pid < npts; pid++)
		{
			if (abs(AllCorpus[fid].xyz[pid].x) > 1e-16 && abs(AllCorpus[fid + 1].xyz[pid].x) > 1e-16)
				refPts.push_back(AllCorpus[fid].xyz[pid]), nonRefPts.push_back(AllCorpus[fid + 1].xyz[pid]);
		}


		Terror = computeProcrustesTransform(nonRefPts, refPts, R, T, s, true); //sR*nonRefPts + T = refPts
																			   //printLOG("(%d->%d): %.3f...", fid + 1, fid, Terror);

																			   /*{
																			   FILE *fp = fopen("C:/temp/b_nonref.txt", "w");
																			   for (auto pid : nonRefPts)
																			   fprintf(fp, "%f %f %f\n", pid.x, pid.y, pid.z);
																			   fclose(fp);

																			   fp = fopen("C:/temp/a_nonref.txt", "w");
																			   for (auto pid : nonRefPts)
																			   {
																			   double tx = s*(pid.x *R[0] + pid.y * R[1] + pid.z*R[2]) + T[0];
																			   double ty = s*(pid.x *R[3] + pid.y * R[4] + pid.z*R[5]) + T[1];
																			   double tz = s*(pid.x *R[6] + pid.y * R[7] + pid.z*R[8]) + T[2];
																			   fprintf(fp, "%f %f %f\n", tx, ty, tz);
																			   }
																			   fclose(fp);
																			   fp = fopen("C:/temp/ref.txt", "w");
																			   for (auto pid : refPts)
																			   fprintf(fp, "%f %f %f\n", pid.x, pid.y, pid.z);
																			   fclose(fp);
																			   }*/

		double rt[6];  GetrtFromRT(rt, R, T);
		sprintf(Fname, "%s/JBC/%.4d/%d_%d.txt", Path, fid + 1, fid + 1, fid);  FILE *fp = fopen(Fname, "w+");
		fprintf(fp, "%.16f %.16f %.16f %.16f %.16f %.16f %.16f", s, rt[0], rt[1], rt[2], rt[3], rt[4], rt[5]); fclose(fp);

		//sR*X2 + T = X1 --> X2 = R^T(X1-T)/s; amda*[u,v,1] = K*[R2X+T2]; -->s*lamda*[u,v,1] = K*[R2 * R^T *X1 - R2*R^T *T+ T2s]
		for (int cid = 0; cid < nCams; cid++)
		{
			Map < Vector3d > eT(T, 3), eT2(AllCorpus[fid + 1].camera[cid].T, 3), eT1(T1, 3);
			Map < Matrix < double, 3, 3, RowMajor > > eR(R, 3, 3), eR2(AllCorpus[fid + 1].camera[cid].R, 3, 3), eR1(R1, 3, 3);
			eR1 = eR2 * eR.transpose(), eT1 = -eR2 * eR.transpose()*eT + eT2 * s;
			GetrtFromRT(AllCorpus[fid + 1].camera[cid].rt, R1, T1);  //transform fid+1 to fid
		}


		/*sprintf(Fname, "%s/JBC/%.4d/tBA.txt", Path, fid + 1);  fp = fopen(Fname, "w+");
		fprintf(fp, "%d %d\n", nCams, nProjections[fid + 1]);
		for (int cid = 0; cid < nCams; cid++)
		{
		if (AvailCams[fid + 1][cid] == 0)
		continue;

		CameraData *camI = &AllCorpus[fid + 1].camera[cid];
		fprintf(fp, "%.4d %d %d %d %d ", cid, camI->LensModel, camI->ShutterModel, camI->width, camI->height);

		double fx, fy, skew, u0, v0, r1, r2, r3, t1, t2, p1, p2, omega, DistCtrX, DistCtrY, rt[6];
		fx = camI->intrinsic[0], fy = camI->intrinsic[1], skew = camI->intrinsic[2], u0 = camI->intrinsic[3], v0 = camI->intrinsic[4];
		if (camI->LensModel == RADIAL_TANGENTIAL_PRISM)
		{
		r1 = camI->distortion[0], r2 = camI->distortion[1], r3 = camI->distortion[2], t1 = camI->distortion[3], t2 = camI->distortion[4], p1 = camI->distortion[5], p2 = camI->distortion[6];
		fprintf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %.16f %.16f %.16f %.16f %.16f %.16f\n", fx, fy, skew, u0, v0, r1, r2, r3, t1, t2, p1, p2, camI->rt[0], camI->rt[1], camI->rt[2], camI->rt[3], camI->rt[4], camI->rt[5]);
		}
		else
		{
		omega = camI->distortion[0], DistCtrX = camI->distortion[1], DistCtrY = camI->distortion[2];
		fprintf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %.16f %.16f %.16f %.16f %.16f %.16f\n", fx, fy, skew, u0, v0, omega, DistCtrX, DistCtrY, camI->rt[0], camI->rt[1], camI->rt[2], camI->rt[3], camI->rt[4], camI->rt[5]);
		}
		}
		fclose(fp);*/

		{
			//Test:
			Corpus CorpusInfo;
			CorpusInfo.n3dPoints = npts;
			CorpusInfo.xyz.clear(), CorpusInfo.viewIdAll3D.clear(), CorpusInfo.uvAll3D.clear(), CorpusInfo.scaleAll3D.clear();
			CorpusInfo.viewIdAll3D.resize(npts), CorpusInfo.uvAll3D.resize(npts), CorpusInfo.scaleAll3D.resize(npts);
			for (int cid = 0; cid < nCams; cid++)
			{
				sprintf(Fname, "%s/JBC/%.4d/%d.txt", Path, fid + 1, cid); FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				int pid; float u, v, s;
				while (fscanf(fp, "%d %f %f %f ", &pid, &u, &v, &s) != EOF)
				{
					CorpusInfo.viewIdAll3D[pid].push_back(cid);
					if (s > 0.5) //weighting based on conf score does not work well
						CorpusInfo.uvAll3D[pid].push_back(Point2d(u, v));
					else
						CorpusInfo.uvAll3D[pid].push_back(Point2d(0, 0));
					CorpusInfo.scaleAll3D[pid].push_back(1.0);// -min(s, 1.f) + 1e-16); //larger conf -> more trusted
				}
				fclose(fp);
			}

			double error = 9e9;
			vector<int> id, id2;
			Point2d *allPts = new Point2d[nCams * 2];
			double *A = new double[6 * nCams * 2], *B = new double[2 * nCams * 2], *allP = new double[12 * nCams * 2];
			vector<int> addedCameras; //assume all cameras are processed for the reference frame
			for (int cid = 0; cid < nCams; cid++)
			{
				addedCameras.push_back(cid);
				GetKFromIntrinsic(AllCorpus[fid + 1].camera[cid]);
				GetRTFromrt(AllCorpus[fid + 1].camera[cid].rt, AllCorpus[fid + 1].camera[cid].R, AllCorpus[fid + 1].camera[cid].T);
				AssembleP(AllCorpus[fid + 1].camera[cid].K, AllCorpus[fid + 1].camera[cid].R, AllCorpus[fid + 1].camera[cid].T, AllCorpus[fid + 1].camera[cid].P);
			}

			int nBad = 0;
			vector<double> allError;
			for (int pid = 0; pid < npts; pid++)
			{
				id.clear(), id2.clear();
				for (int ii = 0; ii < CorpusInfo.viewIdAll3D[pid].size(); ii++)
				{
					for (int jj = 0; jj < (int)addedCameras.size(); jj++)
					{
						if (CorpusInfo.viewIdAll3D[pid][ii] == addedCameras[jj])
						{
							if (CorpusInfo.uvAll3D[pid][ii].x > 0 && CorpusInfo.uvAll3D[pid][ii].y > 0)
							{
								id.push_back(ii), id2.push_back(jj);
								break;
							}
						}
					}
				}

				CorpusInfo.xyz.push_back(Point3d(0, 0, 0));
				if (id.size() > 1)
				{
					for (int ii = 0; ii < (int)id.size(); ii++)
					{
						int cid = CorpusInfo.viewIdAll3D[pid][id[ii]];
						allPts[ii] = CorpusInfo.uvAll3D[pid][id[ii]];
						for (int jj = 0; jj < 12; jj++)
							allP[12 * ii + jj] = AllCorpus[fid + 1].camera[cid].P[jj];
					}

					NviewTriangulation(allPts, allP, &CorpusInfo.xyz.back(), (int)id.size(), 1, NULL, A, B);
					NviewTriangulationNonLinear(allP, allPts, &CorpusInfo.xyz.back(), &error, (int)id.size(), 1);
					allError.push_back(error);
				}
				else
					nBad++;
			}
			double mini = *min_element(allError.begin(), allError.end());
			double maxi = *max_element(allError.begin(), allError.end());
			double avg = MeanArray(allError);
			double var = sqrt(VarianceArray(allError, avg));
			printLOG("Frame %d: (%d/%d) good points. Reprojection error: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f\n", fid + 1, npts - nBad, npts, mini, maxi, avg, var);

			sprintf(Fname, "%s/JBC/%.4d/t3dGL.txt", Path, 1 + fid); fp = fopen(Fname, "w+");
			for (size_t ii = 0; ii < CorpusInfo.xyz.size(); ii++)
				fprintf(fp, "%d %.16f %.16f %.16f\n", ii, CorpusInfo.xyz[ii].x, CorpusInfo.xyz[ii].y, CorpusInfo.xyz[ii].z);
			fclose(fp);
			int a = 0;
		}
	}

	return 0;
}
int ComposeAlignedBodySfm(char *Path, int nCams, int startF, int stopF, int increF, int nMaxPeople)
{
	char Fname[512];
	const int nJoints = 18;
	int npts = nJoints * nMaxPeople;

	struct srt {
		double s, rt[6];
	};
	srt*allSrt = new srt[stopF + 1];
	allSrt[startF].s = 1.0;
	for (int ii = 0; ii < 6; ii++)
		allSrt[startF].rt[ii] = 0;

	int *nProjections = new int[stopF + 1];
	Corpus *AllCorpus = new Corpus[stopF + 1];
	vector<int> *AvailCams = new vector<int>[stopF + 1];
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		AllCorpus[fid].nCameras = nCams, AllCorpus[fid].n3dPoints = npts;
		AllCorpus[fid].camera = new CameraData[nCams];
		AllCorpus[fid].xyz.resize(npts);
		AvailCams[fid].resize(nCams);
	}


	for (int fid = startF; fid <= stopF; fid += increF)
	{
		sprintf(Fname, "%s/JBC/%.4d/BA.txt", Path, fid); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		int nproj, cid, pid, LensModel, ShutterModel, width, height, dummy;
		double rt[6];

		fscanf(fp, "%d %d ", &dummy, &nproj); nProjections[fid] = nproj;
		while (fscanf(fp, "%d %d %d %d %d", &cid, &LensModel, &ShutterModel, &width, &height) != EOF)
		{
			AvailCams[fid][cid] = 1, AllCorpus[fid].camera[cid].LensModel = LensModel, AllCorpus[fid].camera[cid].ShutterModel = ShutterModel, AllCorpus[fid].camera[cid].width = width, AllCorpus[fid].camera[cid].height = height;
			if (AllCorpus[fid].camera[cid].LensModel == RADIAL_TANGENTIAL_PRISM)
				fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf ", &AllCorpus[fid].camera[cid].intrinsic[0], &AllCorpus[fid].camera[cid].intrinsic[1], &AllCorpus[fid].camera[cid].intrinsic[2], &AllCorpus[fid].camera[cid].intrinsic[3], &AllCorpus[fid].camera[cid].intrinsic[4],
					&AllCorpus[fid].camera[cid].distortion[0], &AllCorpus[fid].camera[cid].distortion[1], &AllCorpus[fid].camera[cid].distortion[2], &AllCorpus[fid].camera[cid].distortion[3], &AllCorpus[fid].camera[cid].distortion[4], &AllCorpus[fid].camera[cid].distortion[5], &AllCorpus[fid].camera[cid].distortion[6],
					&rt[0], &rt[1], &rt[2], &rt[3], &rt[4], &rt[5]);
			else
				fscanf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf ", &AllCorpus[fid].camera[cid].intrinsic[0], &AllCorpus[fid].camera[cid].intrinsic[1], &AllCorpus[fid].camera[cid].intrinsic[2], &AllCorpus[fid].camera[cid].intrinsic[3], &AllCorpus[fid].camera[cid].intrinsic[4],
					&AllCorpus[fid].camera[cid].distortion[0], &AllCorpus[fid].camera[cid].distortion[1], &AllCorpus[fid].camera[cid].distortion[2], &rt[0], &rt[1], &rt[2], &rt[3], &rt[4], &rt[5]);
			for (int jj = 0; jj < 6; jj++)
				AllCorpus[fid].camera[cid].rt[jj] = rt[jj];
			GetRTFromrt(AllCorpus[fid].camera[cid].rt, AllCorpus[fid].camera[cid].R, AllCorpus[fid].camera[cid].T);
			GetCfromT(AllCorpus[fid].camera[cid].R, AllCorpus[fid].camera[cid].T, AllCorpus[fid].camera[cid].camCenter);
		}
		fclose(fp);

		sprintf(Fname, "%s/JBC/%.4d/3dGL.txt", Path, fid); fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		Point3d xyz;
		while (fscanf(fp, "%d %lf %lf %lf ", &pid, &xyz.x, &xyz.y, &xyz.z) != EOF)
			AllCorpus[fid].xyz[pid] = xyz;
		fclose(fp);

		if (fid > startF)
		{
			double rt_2to1[6], s_1to0, R_1to0[9], T_1to0[9], s_2to0, R_2to0[9], T_2to0[3], s_2to1, R_2to1[9], T_2to1[3];
			sprintf(Fname, "%s/JBC/%.4d/%d_%d.txt", Path, fid + 1, fid + 1, fid);  fp = fopen(Fname, "r");
			fprintf(fp, "%lf %lf %lf %lf %lf %lf %lf", &s_2to1, &rt_2to1[0], &rt_2to1[1], &rt_2to1[2], &rt_2to1[3], &rt_2to1[4], &rt_2to1[5]); fclose(fp);

			GetRTFromrt(rt_2to1, R_2to1, T_2to1);
			GetRTFromrt(allSrt[fid - 1].rt, R_1to0, T_1to0); s_1to0 = allSrt[fid - 1].s;

			Map < Vector3d > eT_2to1(T_2to1, 3), eT_1to0(T_1to0, 1), eT_2to0(T_2to0, 3);
			Map < Matrix < double, 3, 3, RowMajor > > eR_2to1(R_2to1, 3, 3), eR_1to0(R_1to0, 3, 3), eR_2to0(R_2to0, 3, 3);

			eR_2to0 = s_2to1 * eR_2to1 * s_1to0*eR_1to0; eT_2to0 = s_2to1 * eR_2to1*eT_1to0 + eT_2to1;
			s_2to0 = eR_2to0.norm(); eR_2to0 = eR_2to0 / s_2to0;

			allSrt[fid].s = s_2to0;
			GetrtFromRT(allSrt[fid].rt, R_2to0, T_2to0);

			//GetrtFromRT(AllCorpus[fid + 1].camera[cid].rt, R1, T1);  //transform fid+1 to fid
		}
	}

	for (int fid = startF; fid < stopF; fid++)
	{
		//sR*X2 + T = X1 --> X2 = R^T(X1-T)/s; amda*[u,v,1] = K*[R2X+T2]; -->s*lamda*[u,v,1] = K*[R2 * R^T *X1 - R2*R^T *T+ T2s]
		double R1[9], T1[3], R[9], T[3], s;
		GetRTFromrt(allSrt[fid].rt, R, T); s = allSrt[fid].s;
		for (int cid = 0; cid < nCams; cid++)
		{
			Map < Vector3d > eT(T, 3), eT2(AllCorpus[fid + 1].camera[cid].T, 3), eT1(T1, 3);
			Map < Matrix < double, 3, 3, RowMajor > > eR(R, 3, 3), eR2(AllCorpus[fid + 1].camera[cid].R, 3, 3), eR1(R1, 3, 3);
			eR1 = eR2 * eR.transpose(), eT1 = -eR2 * eR.transpose()*eT + eT2 * s;
			GetrtFromRT(AllCorpus[fid + 1].camera[cid].rt, R1, T1);  //transform fid+1 to fid
		}

		sprintf(Fname, "%s/JBC/%.4d/tBA.txt", Path, fid + 1);  FILE *fp = fopen(Fname, "w+");
		fprintf(fp, "%d %d\n", nCams, nProjections[fid + 1]);
		for (int cid = 0; cid < nCams; cid++)
		{
			if (AvailCams[fid + 1][cid] == 0)
				continue;

			CameraData *camI = &AllCorpus[fid + 1].camera[cid];
			fprintf(fp, "%.4d %d %d %d %d ", cid, camI->LensModel, camI->ShutterModel, camI->width, camI->height);

			double fx, fy, skew, u0, v0, r1, r2, r3, t1, t2, p1, p2, omega, DistCtrX, DistCtrY;
			fx = camI->intrinsic[0], fy = camI->intrinsic[1], skew = camI->intrinsic[2], u0 = camI->intrinsic[3], v0 = camI->intrinsic[4];
			if (camI->LensModel == RADIAL_TANGENTIAL_PRISM)
			{
				r1 = camI->distortion[0], r2 = camI->distortion[1], r3 = camI->distortion[2], t1 = camI->distortion[3], t2 = camI->distortion[4], p1 = camI->distortion[5], p2 = camI->distortion[6];
				fprintf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %.16f %.16f %.16f %.16f %.16f %.16f\n", fx, fy, skew, u0, v0, r1, r2, r3, t1, t2, p1, p2, camI->rt[0], camI->rt[1], camI->rt[2], camI->rt[3], camI->rt[4], camI->rt[5]);
			}
			else
			{
				omega = camI->distortion[0], DistCtrX = camI->distortion[1], DistCtrY = camI->distortion[2];
				fprintf(fp, "%lf %lf %lf %lf %lf %lf %lf %lf %.16f %.16f %.16f %.16f %.16f %.16f\n", fx, fy, skew, u0, v0, omega, DistCtrX, DistCtrY, camI->rt[0], camI->rt[1], camI->rt[2], camI->rt[3], camI->rt[4], camI->rt[5]);
			}
		}
		fclose(fp);

		{
			//Test:
			Corpus CorpusInfo;
			CorpusInfo.n3dPoints = npts;
			CorpusInfo.xyz.clear(), CorpusInfo.viewIdAll3D.clear(), CorpusInfo.uvAll3D.clear(), CorpusInfo.scaleAll3D.clear();
			CorpusInfo.viewIdAll3D.resize(npts), CorpusInfo.uvAll3D.resize(npts), CorpusInfo.scaleAll3D.resize(npts);
			for (int cid = 0; cid < nCams; cid++)
			{
				sprintf(Fname, "%s/JBC/%.4d/%d.txt", Path, fid + 1, cid); FILE *fp = fopen(Fname, "r");
				if (fp == NULL)
					continue;
				int pid; float u, v, s;
				while (fscanf(fp, "%d %f %f %f ", &pid, &u, &v, &s) != EOF)
				{
					CorpusInfo.viewIdAll3D[pid].push_back(cid);
					if (s > 0.5) //weighting based on conf score does not work well
						CorpusInfo.uvAll3D[pid].push_back(Point2d(u, v));
					else
						CorpusInfo.uvAll3D[pid].push_back(Point2d(0, 0));
					CorpusInfo.scaleAll3D[pid].push_back(1.0);// -min(s, 1.f) + 1e-16); //larger conf -> more trusted
				}
				fclose(fp);
			}

			double error = 9e9;
			vector<int> id, id2;
			Point2d *allPts = new Point2d[nCams * 2];
			double *A = new double[6 * nCams * 2], *B = new double[2 * nCams * 2], *allP = new double[12 * nCams * 2];
			vector<int> addedCameras; //assume all cameras are processed for the reference frame
			for (int cid = 0; cid < nCams; cid++)
			{
				addedCameras.push_back(cid);
				GetKFromIntrinsic(AllCorpus[fid + 1].camera[cid]);
				GetRTFromrt(AllCorpus[fid + 1].camera[cid].rt, AllCorpus[fid + 1].camera[cid].R, AllCorpus[fid + 1].camera[cid].T);
				AssembleP(AllCorpus[fid + 1].camera[cid].K, AllCorpus[fid + 1].camera[cid].R, AllCorpus[fid + 1].camera[cid].T, AllCorpus[fid + 1].camera[cid].P);
			}

			int nBad = 0;
			vector<double> allError;
			for (int pid = 0; pid < npts; pid++)
			{
				id.clear(), id2.clear();
				for (int ii = 0; ii < CorpusInfo.viewIdAll3D[pid].size(); ii++)
				{
					for (int jj = 0; jj < (int)addedCameras.size(); jj++)
					{
						if (CorpusInfo.viewIdAll3D[pid][ii] == addedCameras[jj])
						{
							if (CorpusInfo.uvAll3D[pid][ii].x > 0 && CorpusInfo.uvAll3D[pid][ii].y > 0)
							{
								id.push_back(ii), id2.push_back(jj);
								break;
							}
						}
					}
				}

				CorpusInfo.xyz.push_back(Point3d(0, 0, 0));
				if (id.size() > 1)
				{
					for (int ii = 0; ii < (int)id.size(); ii++)
					{
						int cid = CorpusInfo.viewIdAll3D[pid][id[ii]];
						allPts[ii] = CorpusInfo.uvAll3D[pid][id[ii]];
						for (int jj = 0; jj < 12; jj++)
							allP[12 * ii + jj] = AllCorpus[fid + 1].camera[cid].P[jj];
					}

					NviewTriangulation(allPts, allP, &CorpusInfo.xyz.back(), (int)id.size(), 1, NULL, A, B);
					NviewTriangulationNonLinear(allP, allPts, &CorpusInfo.xyz.back(), &error, (int)id.size(), 1);
					allError.push_back(error);
				}
				else
					nBad++;
			}
			double mini = *min_element(allError.begin(), allError.end());
			double maxi = *max_element(allError.begin(), allError.end());
			double avg = MeanArray(allError);
			double var = sqrt(VarianceArray(allError, avg));
			printLOG("(%d/%d) good points. Reprojection error: Min: %.2f. Max: %.2f. Mean: %.2f. Std: %.2f\n\n", npts - nBad, npts, mini, maxi, avg, var);

			sprintf(Fname, "%s/JBC/%.4d/t3dGL.txt", Path, 1 + fid); fp = fopen(Fname, "w+");
			for (size_t ii = 0; ii < CorpusInfo.xyz.size(); ii++)
				fprintf(fp, "%d %.16f %.16f %.16f\n", ii, CorpusInfo.xyz[ii].x, CorpusInfo.xyz[ii].y, CorpusInfo.xyz[ii].z);
			fclose(fp);
		}
	}

	return 0;
}
int GenerateCameraPairwisePeopleMatching(char *Path, vector<int> &sCams, vector<int> &TimeStamp, int refStartF, int refStopF, int startF, int stopF)
{
	char Fname[512];
	sprintf(Fname, "%s/MP/Matches", Path); makeDir(Fname);

	struct pidIJS {
		int pid1, pid2; float s;
	};

	int nCams = TimeStamp.size();
	const int maxNCams = 20;

	vector<Point2i> cidpid;
	pidIJS pidijs;
	vector<pidIJS> CidCid_PidPid[maxNCams * maxNCams];
	vector<pidIJS> CidCid_PidPid_cleaned[maxNCams * maxNCams];
	int nPairwiseMatches, cidR, pidR, cid, pid; float score;
	for (int fid = startF; fid <= stopF; fid++)
	{
		for (int ii = 0; ii < maxNCams*maxNCams; ii++)
			CidCid_PidPid[ii].clear(), CidCid_PidPid_cleaned[ii].clear();

		printLOG("%d..", fid);
		sprintf(Fname, "%s/MP/PersonDescTpoolSmatching_WithTPooling/%d.txt", Path, fid); FILE*fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			continue;
		}
		while (fscanf(fp, "%d ", &nPairwiseMatches) != EOF)
		{
			fscanf(fp, "%d %d %f ", &cidR, &pidR, &score);
			for (int ii = 1; ii < nPairwiseMatches; ii++)
			{
				fscanf(fp, "%d %d %f ", &cid, &pid, &pidijs.s);
				pidijs.pid1 = min(pidR, pid); pidijs.pid2 = max(pidR, pid);
				if (cid == cidR)
					int a = 0;
				if (cid > cidR)
					CidCid_PidPid[cidR + cid * nCams].push_back(pidijs);
				else
					CidCid_PidPid[cid + cidR * nCams].push_back(pidijs);
			}
		}
		fclose(fp);

		//remove duplicate
		for (int pairID = 0; pairID < nCams * nCams; pairID++)
		{
			vector<int> good;
			for (int ii = 0; ii < CidCid_PidPid[pairID].size(); ii++)
			{
				bool found = false;
				for (int jj = 0; jj < CidCid_PidPid[pairID].size() && !found; jj++)
				{
					if (jj == ii)
						continue;
					if (CidCid_PidPid[pairID][ii].pid1 == CidCid_PidPid[pairID][jj].pid1 && CidCid_PidPid[pairID][ii].pid2 == CidCid_PidPid[pairID][jj].pid2)
					{
						good.push_back(min(ii, jj));
						found = true;
					}
				}
				if (!found)
					good.push_back(ii);
			}
			sort(good.begin(), good.end());
			std::vector<int>::iterator it = unique(good.begin(), good.end());
			good.resize(std::distance(good.begin(), it));
			for (auto g : good)
				CidCid_PidPid_cleaned[pairID].push_back(CidCid_PidPid[pairID][g]);
		}

		for (auto cidI : sCams)
		{
			for (auto cidJ : sCams)
			{
				if (cidI == cidJ || CidCid_PidPid_cleaned[cidI + cidJ * nCams].size() == 0)
					continue;
				sprintf(Fname, "%s/MP/Matches/%d_%d_%d.txt", Path, fid, cidI, cidJ); FILE *fp = fopen(Fname, "w");
				for (int ii = 0; ii < (int)CidCid_PidPid_cleaned[cidI + cidJ * nCams].size(); ii++)
					fprintf(fp, "%d %d %.3f\n", CidCid_PidPid_cleaned[cidI + cidJ * nCams][ii].pid1, CidCid_PidPid_cleaned[cidI + cidJ * nCams][ii].pid2, CidCid_PidPid_cleaned[cidI + cidJ * nCams][ii].s);
				fclose(fp);
			}
		}

	}

	return 0;
}


//Small driver: Test + demo
int Test()
{
	char Path[] = "H:/Snow", Fname[512];

	int nCams = 18, startF = 31, stopF = 1999, increF = 1, kNN = 50;
	vector<int> sCams;
	for (int ii = 0; ii < nCams; ii++)
		sCams.push_back(ii);

	VideoData *VideoInfo = new VideoData[nCams];
	vector<int>*allVrFid = new vector<int>[nCams];
	vector<Point2i> **allNearestKeyFrames = new vector<Point2i>*[nCams];

	for (auto cid : sCams)
	{
		allNearestKeyFrames[cid] = new vector<Point2i>[stopF + 1];

		sprintf(Fname, "%s/%d/kNN4IRB.txt", Path, cid); FILE *fp = fopen(Fname, "r");
		for (int fid = startF; fid <= stopF; fid++)
		{
			int fidi, nn;  fscanf(fp, "%d %d ", &fidi, &nn);
			Point2i cid_fid;
			for (int ii = 0; ii < nn; ii++)
			{
				fscanf(fp, "%d %d ", &cid_fid.x, &cid_fid.y);
				if (ii < kNN)
					allNearestKeyFrames[cid][fid].push_back(cid_fid);
			}
		}
		fclose(fp);
	}

	int maxFeatures = 50000;
	char * argv[] = { "-fo", "-1", "-v", "0", "-tc", "7680", "-nomc", "-p", "1920x1080", "-maxd", "1920", "-mo", "1", "-da" }; //one orienation and smaller expected # feats
																															   //unable to apply to video seq because ffmpeg does not allow precise frame seeking
	int siftGPU = 1;
#ifdef USESIFTGPU
#ifdef _WINDOWS
#ifdef _DEBUG
	HMODULE  hsiftgpu = LoadLibrary("siftgpu_d.dll");
#else
	HMODULE  hsiftgpu = LoadLibrary("siftgpu.dll");
#endif
#else
	void * hsiftgpu = dlopen("libsiftgpu.so", RTLD_LAZY);
#endif

	if (hsiftgpu == NULL)
		return 0;

	SiftGPU* (*pCreateNewSiftGPU)(int) = NULL;
	pCreateNewSiftGPU = (SiftGPU* (*) (int)) GET_MYPROC(hsiftgpu, "CreateNewSiftGPU");
	SiftGPU* sift = pCreateNewSiftGPU(1);

	int argc = sizeof(argv) / sizeof(char*);
	sift->ParseParam(argc, argv);
	if (sift->CreateContextGL() != SiftGPU::SIFTGPU_FULL_SUPPORTED)
		siftGPU = 0;
#else
	siftGPU = 0;
	successConsecutiveTrackingRatio = successConsecutiveTrackingRatio - 0.2; //vlsift does not have darkness adaptation feature
#endif

	int ref_cid = 0, ref_fid = startF, nnId = 0, ref_cid0 = ref_cid - 1, ref_fid0 = ref_fid - 1, nnId0 = nnId, change = 1, modelID = 0, modelID0 = modelID, drawLine = 0, drawAll = 1, drawBox = 1, arun = 1;
	namedWindow("Image", CV_WINDOW_NORMAL | CV_WINDOW_KEEPRATIO);
	createTrackbar("Ref_Cid", "Image", &ref_cid, nCams, NULL);
	createTrackbar("Ref_Fid", "Image", &ref_fid, stopF, NULL);
	createTrackbar("kNN", "Image", &nnId, kNN - 1, NULL);
	createTrackbar("All", "Image", &drawAll, 1, NULL);
	createTrackbar("ModelID", "Image", &modelID, 10, NULL);
	createTrackbar("Line", "Image", &drawLine, 1, NULL);
	createTrackbar("Box", "Image", &drawBox, 1, NULL);
	createTrackbar("Auto", "Image", &arun, 1, NULL);

	namedWindow("BlendImage", CV_WINDOW_NORMAL | CV_WINDOW_KEEPRATIO);
	createTrackbar("ModelID", "BlendImage", &modelID, nCams, NULL);


	Mat Img1, Img2;
	vector<Point2f> lm1, lm2;
	vector<Point2d> Keys1, Keys2;
	vector<SiftKeypoint> kpts1, kpts2;
	vector<uchar> descU1, descU2;
	vector<Point2i> RawPairWiseMatchID;
	vector<Point2i> convexHullRange;
	vector<vector<Point2d> > AllMultiInlierKeys1, AllMultiInlierKeys2;

	vector<Mat> *AllNN_vImg2to1 = new vector<Mat>[kNN];
	vector<Mat> *AllNN_vbImg = new vector<Mat>[kNN];
	vector < Eigen::Matrix3d > *AllNN_AlleHomo = new vector < Eigen::Matrix3d >[kNN];

	vector<Scalar> vcolors;
	static cv::Scalar colors[] = { Scalar(0, 0, 255), Scalar(0, 128, 255), Scalar(0, 255, 255), Scalar(0, 255, 0), Scalar(255, 128, 0), Scalar(255, 255, 0), Scalar(255, 0, 0), Scalar(255, 0, 255), Scalar(255, 255, 255) };

	ref_fid = 40;
	while (true)
	{
		int change = 0;

		if (ref_cid0 != ref_cid || ref_fid0 != ref_fid)
		{
			sprintf(Fname, "%s/Warp", Path); makeDir(Fname);
			sprintf(Fname, "%s/Warp/%d/%.4d", Path, ref_cid, ref_fid); makeDir(Fname);
			printLOG("\n\n%d %.4d\n", ref_cid, ref_fid);
			printLOG("NN %d\n", 0);

			ref_cid0 = ref_cid, ref_fid0 = ref_fid, nnId = 0, modelID = 0, change = 1;
			for (int ii = 0; ii < kNN; ii++)
				AllNN_vImg2to1[ii].clear(), AllNN_vbImg[ii].clear(), AllNN_AlleHomo[ii].clear();

			sprintf(Fname, "%s/%d/%.4d.sift", Path, ref_cid, ref_fid);
			if (IsFileExist(Fname))
				readVisualSFMSiftGPU(Fname, kpts1, descU1);
			else
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, ref_cid, ref_fid);
				if (IsFileExist(Fname) == 0)
				{
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, ref_cid, ref_fid);
					if (IsFileExist(Fname) == 0)
						return 0;
				}
				Img1 = imread(Fname, 0);
				ExtractSiftGPU(Path, ref_cid, ref_fid, Img1, kpts1, descU1, sift);

				sprintf(Fname, "%s/%d/%.4d.sift", Path, ref_cid, ref_fid);
				writeVisualSFMSiftGPU(Fname, kpts1, &descU1[0]);
			}
			sprintf(Fname, "%s/%d/%.4d.png", Path, ref_cid, ref_fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, ref_cid, ref_fid);
				if (IsFileExist(Fname) == 0)
					return 0;
			}
			Img1 = imread(Fname, 1);

			float u, v, s;
			lm1.clear();
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, ref_cid, ref_fid); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				lm1.push_back(Point2f(u, v));
			fclose(fp);

			sprintf(Fname, "%s/%d/%.4d.sift", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
			if (IsFileExist(Fname))
				readVisualSFMSiftGPU(Fname, kpts2, descU2);
			else
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
				if (IsFileExist(Fname) == 0)
				{
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
					if (IsFileExist(Fname) == 0)
						return 0;
				}
				Img2 = imread(Fname, 0);
				ExtractSiftGPU(Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y, Img2, kpts2, descU2, sift);

				sprintf(Fname, "%s/%d/%.4d.sift", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
				writeVisualSFMSiftGPU(Fname, kpts2, &descU2[0]);
			}
			sprintf(Fname, "%s/%d/%.4d.png", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
				if (IsFileExist(Fname) == 0)
					return 0;
			}
			Img2 = imread(Fname, 1);

			lm2.clear();
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y); fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				lm2.push_back(Point2f(u, v));
			fclose(fp);
		}
		else if (nnId0 != nnId)
		{
			printLOG("NN %d\n", nnId);
			nnId0 = nnId, modelID = 0, change = 1;

			sprintf(Fname, "%s/%d/%.4d.sift", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
			if (IsFileExist(Fname))
				readVisualSFMSiftGPU(Fname, kpts2, descU2);
			else
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
				if (IsFileExist(Fname) == 0)
				{
					sprintf(Fname, "%s/%d/%.4d.jpg", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
					if (IsFileExist(Fname) == 0)
						return 0;
				}
				Img2 = imread(Fname, 0);
				ExtractSiftGPU(Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y, Img2, kpts2, descU2, sift);

				sprintf(Fname, "%s/%d/%.4d.sift", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
				writeVisualSFMSiftGPU(Fname, kpts2, &descU2[0]);
			}

			sprintf(Fname, "%s/%d/%.4d.png", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/%d/%.4d.jpg", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
				if (IsFileExist(Fname) == 0)
					return 0;
			}
			Img2 = imread(Fname, 1);

			float u, v, s;
			lm2.clear();
			sprintf(Fname, "%s/MP/%d/%d.txt", Path, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y); FILE *fp = fopen(Fname, "r");
			if (fp == NULL)
				continue;
			while (fscanf(fp, "%f %f %f ", &u, &v, &s) != EOF)
				lm2.push_back(Point2f(u, v));
			fclose(fp);
		}

		if (change == 1 && AllNN_AlleHomo[nnId].size() == 0)
		{
			sprintf(Fname, "%s/Warp/%d/%.4d/%d.txt", Path, ref_cid, ref_fid, nnId);
			if (IsFileExist(Fname) == 1)
			{
				nnId++;
				if (nnId == allNearestKeyFrames[ref_cid][ref_fid].size())
					nnId = 0, ref_fid += 3;
				if (ref_fid > stopF)
					ref_fid = startF, nnId = 0, ref_cid++;
				if (ref_fid == stopF && ref_cid == nCams)
					break;

				continue;
			}

			//Finding nearest neighbor
			printLOG("Running feature matching...\n");
			double start = omp_get_wtime();
			RawPairWiseMatchID.clear(), RawPairWiseMatchID.reserve(10000);
			RawPairWiseMatchID = MatchTwoViewSIFTBruteForce(descU1, descU2, 128);

			Keys1.clear(), Keys2.clear();
			for (int i = 0; i < RawPairWiseMatchID.size(); ++i)
			{
				int id1 = RawPairWiseMatchID[i].x, id2 = RawPairWiseMatchID[i].y;
				Keys1.push_back(Point2d(kpts1[id1].x - 0.5, kpts1[id1].y - 0.5));
				Keys2.push_back(Point2d(kpts2[id2].x - 0.5, kpts2[id2].y - 0.5));
			}
			printLOG("%d matches found... in %.2fs\n", Keys1.size(), omp_get_wtime() - start);

			int ninlierThresh = 30;
			ConfigParamsHomog cfg;
			cfg.common.confThreshold = 0.99, cfg.common.minSampleSize = 4, cfg.common.inlierThreshold = 4.0;
			cfg.common.maxHypotheses = 850000, cfg.common.maxSolutionsPerSample = 1;
			cfg.common.prevalidateSample = true, cfg.common.prevalidateModel = true, cfg.common.testDegeneracy = true;
			cfg.common.randomSamplingMethod = USACConfig::SAMP_UNIFORM, cfg.common.verifMethod = USACConfig::VERIF_SPRT, cfg.common.localOptMethod = USACConfig::LO_LOSAC;

			cfg.prosac.sortedPointIndices = NULL;
			cfg.sprt.tM = 100.0, cfg.sprt.mS = 1.0, cfg.sprt.delta = 0.01, cfg.sprt.epsilon = 0.2;
			cfg.losac.innerSampleSize = 12, cfg.losac.innerRansacRepetitions = 3, cfg.losac.thresholdMultiplier = 2.0, cfg.losac.numStepsIterative = 4;

			AllMultiInlierKeys1.clear(), AllMultiInlierKeys2.clear();
			vector<Point2d> aKey1, aKey2;
			aKey1 = Keys1, aKey2 = Keys2;
			int iter = 0;

			while (true)
			{
				if (aKey1.size() < ninlierThresh)
					break;

				int ninliers = 0;
				double Hmat[9];
				vector<int> InlierIndicator;
				cfg.common.numDataPoints = aKey1.size();
				USAC_FindHomography(cfg, aKey1, aKey2, Hmat, InlierIndicator, ninliers);

				if (ninliers > ninlierThresh)
				{
					Eigen::Matrix3d eHomo;
					eHomo << Hmat[0], Hmat[1], Hmat[2],
						Hmat[3], Hmat[4], Hmat[5],
						Hmat[6], Hmat[7], Hmat[8];

					AllNN_AlleHomo[nnId].push_back(eHomo);

					vector<Point2d> AllInlierKeys1, AllInlierKeys2;
					for (int ii = cfg.common.numDataPoints - 1; ii >= 0; ii--)
					{
						if (InlierIndicator[ii] == 1)
						{
							AllInlierKeys1.push_back(aKey1[ii]), AllInlierKeys2.push_back(aKey2[ii]);
							aKey1.erase(aKey1.begin() + ii), aKey2.erase(aKey2.begin() + ii);
						}
					}
					AllMultiInlierKeys1.push_back(AllInlierKeys1), AllMultiInlierKeys2.push_back(AllInlierKeys2);
				}
				else
					break;

				printLOG("Round %d..%d/%d inliers\n", iter, ninliers, ninliers + aKey1.size());
				iter++;
			}
			for (size_t jj = 0; jj < AllNN_AlleHomo[nnId].size(); jj++)
				vcolors.push_back(Scalar(rand() % 255, rand() % 255, rand() % 255));

			//Warp images
			sprintf(Fname, "%s/Warp/%d/%.4d/%d.txt", Path, ref_cid, ref_fid, nnId); FILE *fp = fopen(Fname, "w+");
			for (size_t jj = 0; jj < AllNN_AlleHomo[nnId].size(); jj++)
			{
				Mat cImg2 = Mat::zeros(Img2.size(), CV_8UC1), mask = Mat::zeros(Img2.size(), CV_8UC1);
				convexHullRange.clear();
				vector<Point2i> pts(AllMultiInlierKeys1[jj].size());
				for (int kk = 0; kk < AllMultiInlierKeys1[jj].size(); kk++)
					pts[kk].x = (int)(AllMultiInlierKeys1[jj][kk].x + 0.5), pts[kk].y = (int)(AllMultiInlierKeys1[jj][kk].y + .5);

				convexHull(pts, convexHullRange, false);
				fillConvexPoly(mask, convexHullRange, Scalar(255, 255, 255));
				Img2.copyTo(cImg2, mask);

				Mat Img2to1, bImg;
				Mat warp_matrix = (Mat_<double>(3, 3) << AllNN_AlleHomo[nnId][jj](0, 0), AllNN_AlleHomo[nnId][jj](0, 1), AllNN_AlleHomo[nnId][jj](0, 2), AllNN_AlleHomo[nnId][jj](1, 0), AllNN_AlleHomo[nnId][jj](1, 1), AllNN_AlleHomo[nnId][jj](1, 2), AllNN_AlleHomo[nnId][jj](2, 0), AllNN_AlleHomo[nnId][jj](2, 1), AllNN_AlleHomo[nnId][jj](2, 2));
				warpPerspective(cImg2, Img2to1, warp_matrix, Img2to1.size(), INTER_LINEAR + WARP_INVERSE_MAP);
				addWeighted(Img1, 0.5, Img2to1, 0.5, 0, bImg);

				AllNN_vImg2to1[nnId].push_back(Img2to1), AllNN_vbImg[nnId].push_back(bImg);

				sprintf(Fname, "%s/Warp/%d/%.4d/%d_%d_%.4d_%d.png", Path, ref_cid, ref_fid, nnId, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y, jj);	imwrite(Fname, Img2to1);
				//sprintf(Fname, "%s/Warp/%d_%.4d/b_%d_%d_%.4d_%d.png", Path, ref_cid, ref_fid, nnId, allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y, jj);	imwrite(Fname, bImg);

				fprintf(fp, "%d ", jj);
				for (int kk = 0; kk < 9; kk++)
					fprintf(fp, "%f ", AllNN_AlleHomo[nnId][jj](kk));
				fprintf(fp, "\n%zd ", convexHullRange.size());
				for (auto pt : convexHullRange)
					fprintf(fp, "%d %d ", pt.x, pt.y);
				fprintf(fp, "\n");
			}
			fclose(fp);

			printLOG("\n");
		}
		if (AllNN_AlleHomo[nnId].size() == 0)
		{
			nnId++;
			if (nnId == allNearestKeyFrames[ref_cid][ref_fid].size())
				nnId = 0, ref_fid += 3;
			if (ref_fid > stopF)
				ref_fid = startF, nnId = 0, ref_cid++;
			if (ref_fid == stopF && ref_cid == nCams)
				break;
			continue;
		}

		if (modelID > AllNN_AlleHomo[nnId].size() - 1)
			modelID = AllNN_AlleHomo[nnId].size() - 1, cvSetTrackbarPos("ModelID", "Image", modelID);

		CvPoint text_origin = { Img2.rows / 20, Img2.cols / 20 };
		sprintf(Fname, "%d %d", allNearestKeyFrames[ref_cid][ref_fid][nnId].x, allNearestKeyFrames[ref_cid][ref_fid][nnId].y);
		putText(Img2, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 0.5*Img2.cols / 640, cv::Scalar(0, 255, 0), 3);

		cv::Mat BImage(Img1.rows, Img1.cols * 2, Img1.type());
		Img1.copyTo(BImage(cv::Rect(0, 0, Img1.cols, Img1.rows)));
		Img2.copyTo(BImage(cv::Rect(Img1.cols, 0, Img1.cols, Img1.rows)));

		cv::Mat BImage2(Img1.rows, Img1.cols * 2, Img1.type());
		Img1.copyTo(BImage2(cv::Rect(0, 0, Img1.cols, Img1.rows)));
		AllNN_vbImg[nnId][modelID].copyTo(BImage2(cv::Rect(Img1.cols, 0, Img1.cols, Img1.rows)));
		imshow("BlendImage", BImage2);

		if (drawBox == 1)
		{
			const int nJoints = 18;
			for (int pid = 0; pid < lm1.size() / nJoints; pid++)
			{
				Point2f tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (size_t jid = 0; jid < nJoints; jid++)
					if (lm1[pid*nJoints + jid].x > 0)
						tl.x = min(tl.x, lm1[pid*nJoints + jid].x), tl.y = min(tl.y, lm1[pid*nJoints + jid].y), br.x = max(br.x, lm1[pid*nJoints + jid].x), br.y = max(br.y, lm1[pid*nJoints + jid].y);
				rectangle(BImage, tl, br, colors[pid], 8, 8, 0);
			}

			for (int pid = 0; pid < lm2.size() / nJoints; pid++)
			{
				Point2f tl = Point2f(9e9, 9e9), br = Point2f(0, 0);
				for (size_t jid = 0; jid < nJoints; jid++)
					if (lm2[pid*nJoints + jid].x > 0)
						tl.x = min(tl.x, lm2[pid*nJoints + jid].x), tl.y = min(tl.y, lm2[pid*nJoints + jid].y), br.x = max(br.x, lm2[pid*nJoints + jid].x), br.y = max(br.y, lm2[pid*nJoints + jid].y);
				rectangle(BImage, tl + Point2f(Img1.cols, 0), br + Point2f(Img1.cols, 0), colors[pid], 8, 8, 0);
			}
		}
		if (drawAll == 1)
		{
			for (size_t jj = 0; jj < AllNN_AlleHomo[nnId].size(); jj++)
			{
				for (size_t ii = 0; ii < AllMultiInlierKeys1[jj].size(); ii++)
				{
					circle(BImage, cv::Point(AllMultiInlierKeys1[jj][ii].x, AllMultiInlierKeys1[jj][ii].y), 1, vcolors[jj], 8);
					circle(BImage, cv::Point(AllMultiInlierKeys2[jj][ii].x + Img1.cols, AllMultiInlierKeys2[jj][ii].y), 1, vcolors[jj], 8);
					if (drawLine == 1)
						line(BImage, cv::Point(AllMultiInlierKeys1[modelID][ii].x, AllMultiInlierKeys1[modelID][ii].y), cv::Point(AllMultiInlierKeys2[modelID][ii].x + Img1.cols, AllMultiInlierKeys2[modelID][ii].y), vcolors[jj], 2);
				}
			}
		}
		else
		{
			for (size_t ii = 0; ii < AllMultiInlierKeys1[modelID].size(); ii++)
			{
				circle(BImage, cv::Point(AllMultiInlierKeys1[modelID][ii].x, AllMultiInlierKeys1[modelID][ii].y), 1, colors[ii % 8], 8);
				circle(BImage, cv::Point(AllMultiInlierKeys2[modelID][ii].x + Img1.cols, AllMultiInlierKeys2[modelID][ii].y), 1, colors[ii % 8], 8);
				if (drawLine == 1)
					line(BImage, cv::Point(AllMultiInlierKeys1[modelID][ii].x, AllMultiInlierKeys1[modelID][ii].y), cv::Point(AllMultiInlierKeys2[modelID][ii].x + Img1.cols, AllMultiInlierKeys2[modelID][ii].y), colors[ii % 8], 2);
			}
		}

		imshow("Image", BImage);

		int key = waitKey(1);
		if (key == 27)
			break;

		if (arun == 1)
		{
			nnId++;
			if (nnId == allNearestKeyFrames[ref_cid][ref_fid].size())
				nnId = 0, ref_fid += 3;
			if (ref_fid > stopF)
				ref_fid = startF, nnId = 0, ref_cid++;
			if (ref_fid == stopF && ref_cid == nCams)
				break;
		}
	}

	delete[]AllNN_vImg2to1, delete[]AllNN_vbImg, delete[]AllNN_AlleHomo;

	return 0;
}
int VLFeatFeatureDemo()
{
	char Fname[512];
	int MaxFeatures = 50000;
	float*            fSiftKpts = new float[4 * MaxFeatures];
	uchar * SiftDesc = new uchar[128 * MaxFeatures];

	SiftFeature SF;
	for (int iid = 0; iid < 27; iid++)
	{
		int npts = 0;
		sprintf(Fname, "C:/temp/X/%.4d.jpg", iid);
		if (VLSIFT(Fname, SF, npts) == 1)
			return 1;
		else
			printLOG("Frame %d: %d\n", iid, npts);

		sprintf(Fname, "C:/temp/X/%.4d.sift", iid);
		for (int ii = 0; ii < 4 * npts; ii++)
			fSiftKpts[ii] = (float)SF.Kpts[ii];
		writeVisualSFMSiftGPU(Fname, fSiftKpts, SF.Desc, npts);
	}
	return 0;

	CovFeature CovF;
	for (int iid = 0; iid < 27; iid++)
	{
		int npts = 0;
		sprintf(Fname, "C:/temp/X/%.4d.jpg", iid);
		if (VLCOVDET(Fname, CovF, npts) == 1)
			return 1;
		else
			printLOG("Frame %d: %d\n", iid, npts);

		sprintf(Fname, "C:/temp/X/%.4d.sift", iid);
		for (int ii = 0; ii < npts; ii++)
		{
			fSiftKpts[4 * ii] = (float)CovF.Kpts[6 * ii];
			fSiftKpts[4 * ii + 1] = (float)CovF.Kpts[6 * ii + 1];
			fSiftKpts[4 * ii + 2] = (float)max(CovF.Kpts[6 * ii + 4], CovF.Kpts[6 * ii + 5]);
			fSiftKpts[4 * ii + 3] = 1.0f;
		}
		for (int ii = 0; ii < npts; ii++)
			for (int jj = 0; jj < 128; jj++)
				SiftDesc[ii * 128 + jj] = (unsigned char)(int)(floor)(CovF.Desc[ii * 128 + jj] * 512);
		writeVisualSFMSiftGPU(Fname, fSiftKpts, SiftDesc, npts);
	}

	return 0;
}
int ECCMatchingDemo()
{
	double pts[8] = { 752.43, 339.24,
		769.33, 348.69,
		778.05, 322.93,
		762.73, 314.69 };

	Mat cvPattern = imread("C:/temp/x.png", 0);
	Mat cvImg = imread("E:/ARTag/0/63.png", 0);

	vector<Point2d> patternPts, imgPts;
	patternPts.push_back(Point2d(0, 339));
	patternPts.push_back(Point2d(339, 339));
	patternPts.push_back(Point2d(339, 0));
	patternPts.push_back(Point2d(0, 0));

	imgPts.push_back(Point2d(752.43, 339.24));
	imgPts.push_back(Point2d(769.33, 348.69));
	imgPts.push_back(Point2d(778.05, 322.93));
	imgPts.push_back(Point2d(762.73, 314.69));

	double Affine[9] = { 1, 0, 0, 0, 1, 0, 0, 0, 1 };
	Compute_AffineHomo(patternPts, imgPts, Affine);

	//Data initalization
	Mat templateFloat = Mat(cvPattern.rows, cvPattern.cols, CV_32F);// to store the (smoothed) template
	Mat imageFloat = Mat(cvImg.rows, cvImg.cols, CV_32F);// to store the (smoothed) input image

														 //gaussian filtering is optional
	cvPattern.convertTo(templateFloat, templateFloat.type());
	cvImg.convertTo(imageFloat, imageFloat.type());
	GaussianBlur(templateFloat, templateFloat, Size(5, 5), 0, 0);
	GaussianBlur(imageFloat, imageFloat, Size(5, 5), 0, 0);

	// needed matrices for gradients and warped gradients
	Mat gradientX = Mat::zeros(cvImg.rows, cvImg.cols, CV_32FC1);
	Mat gradientY = Mat::zeros(cvImg.rows, cvImg.cols, CV_32FC1);
	Mat gradientXWarped = Mat(cvPattern.rows, cvPattern.cols, CV_32FC1);
	Mat gradientYWarped = Mat(cvPattern.rows, cvPattern.cols, CV_32FC1);

	// calculate first order image derivatives
	Matx13f dx(-0.5f, 0.0f, 0.5f);
	filter2D(imageFloat, gradientX, -1, dx);
	filter2D(imageFloat, gradientY, -1, dx.t());

	// Define the motion model
	const int warp_mode = 3;
	int number_of_iterations = 30;
	double termination_eps = 1e-6;
	TermCriteria criteria(TermCriteria::COUNT + TermCriteria::EPS, number_of_iterations, termination_eps);

	Mat wMat = Mat::eye(3, 3, CV_32F);
	for (int ii = 0; ii < 6; ii++)
		wMat.at<float>(ii) = Affine[ii];

	double score = findTransformECC_Optimized(templateFloat, imageFloat, gradientX, gradientY, gradientXWarped, gradientYWarped, wMat, warp_mode, criteria);

	for (int ii = 0; ii < 4; ii++)
	{
		double denum = patternPts[ii].x*wMat.at<float>(2, 0) + patternPts[ii].y*wMat.at<float>(2, 1) + wMat.at<float>(2, 2);
		imgPts[ii].x = (patternPts[ii].x*wMat.at<float>(0, 0) + patternPts[ii].y*wMat.at<float>(0, 1) + wMat.at<float>(0, 2)) / denum;
		imgPts[ii].y = (patternPts[ii].x*wMat.at<float>(1, 0) + patternPts[ii].y*wMat.at<float>(1, 1) + wMat.at<float>(1, 2)) / denum;
	}

	// Storage for warped image.
	Mat warped_image = Mat(cvPattern.rows, cvPattern.cols, CV_32F);
	if (warp_mode != MOTION_HOMOGRAPHY)
		warpAffine(cvImg, warped_image, wMat, warped_image.size(), INTER_LINEAR + WARP_INVERSE_MAP);
	else
		warpPerspective(cvImg, warped_image, wMat, warped_image.size(), INTER_LINEAR + WARP_INVERSE_MAP);
	imwrite("C:/temp/y.png", warped_image);

	return 0;
}

//Blob detection
int DetectBalls(char *Path, int camID, const int startF, const int stopF, int search_area, double threshold)
{
	char Fname[100];
	int width = 1920, height = 1080, nchannels = 3, length = width * height, patternSizeMax = 50;
	double *Img1 = new double[length * 3];
	double *Para = new double[length * 3];
	double *PatternR = new double[patternSizeMax *patternSizeMax * 3];
	double *PatternG = new double[patternSizeMax *patternSizeMax * 3];
	double *PatternB = new double[patternSizeMax *patternSizeMax * 3];

	int t1, t2, t3;
	Point2i pti;
	Point2d pts[241 * 3], pt1, pt2, pt3;
	sprintf(Fname, "%s/%d/pts.txt", Path, camID);  FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	while (fscanf(fp, "%d %lf %lf %d %lf %lf %d %lf %lf", &t1, &pt1.x, &pt1.y, &t2, &pt2.x, &pt2.y, &t3, &pt3.x, &pt3.y) != EOF)
		pts[3 * t1] = pt1, pts[3 * t1 + 1] = pt2, pts[3 * t1 + 2] = pt3;
	fclose(fp);

	int patternSizeR, patternSizeG, patternSizeB;
	sprintf(Fname, "%s/%d/Red.png", Path, camID); GrabImage(Fname, PatternR, patternSizeR, patternSizeR, nchannels, true);
	sprintf(Fname, "%s/%d/Green.png", Path, camID); GrabImage(Fname, PatternG, patternSizeG, patternSizeG, nchannels, true);
	sprintf(Fname, "%s/%d/Blue.png", Path, camID); GrabImage(Fname, PatternB, patternSizeB, patternSizeB, nchannels, true);
	int hsubsetR = patternSizeR / 2 - 1, hsubsetG = patternSizeG / 2 - 1, hsubsetB = patternSizeB / 2 - 1;

	double score, start = omp_get_wtime();
	for (int frameID = startF; frameID <= stopF; frameID++)
	{
		printLOG("Working on %.4d. Time elapsed %.2f ....", frameID, omp_get_wtime() - start);
		sprintf(Fname, "%s/%d/%.4d.png", Path, camID, frameID); GrabImage(Fname, Img1, width, height, nchannels, true);
		for (int kk = 0; kk < nchannels; kk++)
			Generate_Para_Spline(Img1 + kk * length, Para + kk * length, width, height, 1);

		int detected = 0;
		pt1 = pts[3 * frameID]; pti = pt1;
		score = TMatchingSuperCoarse(PatternR, patternSizeR, hsubsetR, Img1, width, height, nchannels, pti, search_area, threshold);
		if (score < threshold)
			pts[3 * frameID] = Point2d(-1, -1);
		else
		{
			pt1 = pti;
			score = TMatchingFine_ZNCC(PatternR, patternSizeR, hsubsetR, Para, width, height, nchannels, pt1, 0, 1, threshold, 1);
			if (score < threshold)
				pts[3 * frameID] = Point2d(-1, -1);
			else
				pts[3 * frameID] = pt1, printLOG("got Red..."), detected++;
		}

		pt2 = pts[3 * frameID + 1]; pti = pt2;
		score = TMatchingSuperCoarse(PatternG, patternSizeG, hsubsetG, Img1, width, height, nchannels, pti, search_area, threshold);
		if (score < threshold)
			pts[3 * frameID + 1] = Point2d(-1, -1);
		else
		{
			pt2 = pti;
			score = TMatchingFine_ZNCC(PatternG, patternSizeG, hsubsetG, Para, width, height, nchannels, pt2, 0, 1, threshold, 1);
			if (score < threshold)
				pts[3 * frameID + 1] = Point2d(-1, -1);
			else
				pts[3 * frameID + 1] = pt2, printLOG("got Green..."), detected++;

		}

		pt3 = pts[3 * frameID + 2]; pti = pt3;
		score = TMatchingSuperCoarse(PatternB, patternSizeB, hsubsetB, Img1, width, height, nchannels, pti, search_area, threshold);
		if (score < threshold)
			pts[3 * frameID + 2] = Point2d(-1, -1);
		else
		{
			pt3 = pti;
			score = TMatchingFine_ZNCC(PatternB, patternSizeB, hsubsetB, Para, width, height, nchannels, pt3, 0, 1, threshold, 1);
			if (score < threshold)
				pts[3 * frameID + 2] = Point2d(-1, -1);
			else
				pts[3 * frameID + 2] = pt3, printLOG("got Blue..."), detected++;
		}
		if (detected == 0)
			printLOG("CAUTION!");
		printLOG("\n");
	}

	sprintf(Fname, "%s/%d/Rpts.txt", Path, camID);  fp = fopen(Fname, "w+");
	for (int ii = 0; ii < 241; ii++)
		fprintf(fp, "%d %f %f %f %f %f %f\n", ii, pts[3 * ii].x, pts[3 * ii].y, pts[3 * ii + 1].x, pts[3 * ii + 1].y, pts[3 * ii + 2].x, pts[3 * ii + 2].y);
	fclose(fp);

	return 0;
}
int DetectRedLaserCorrelationMultiScale(char *ImgName, int width, int height, unsigned char *MeanImg, vector<Point2d> &kpts, double sigma, int PatternSize, int nscales, int NMS_BW, double thresh, bool visualize, unsigned char *ColorImg, float *colorResponse, double *DImg, double *ImgPara, double *maskSmooth, double *Znssd_reqd)
{
	int length = width * height;

	bool createMem = false;
	if (ColorImg == NULL)
	{
		createMem = true;
		ColorImg = new unsigned char[length * 3];
		colorResponse = new float[width*height];
		DImg = new double[width*height];
		ImgPara = new double[width*height];
		Znssd_reqd = new double[9 * PatternSize*PatternSize];
		maskSmooth = new double[PatternSize*PatternSize*nscales];
	}

	if (createMem)
	{
		Mat view = imread(ImgName);
		if (view.data == NULL)
		{
			//cout << "Cannot load: " << ImgName << endl;
			return 1;
		}
		for (int kk = 0; kk < 3; kk++)
		{
			for (int jj = 0; jj < height; jj++)
			{
				for (int ii = 0; ii < width; ii++)
				{
					ColorImg[ii + jj * width + kk * length] = view.data[3 * ii + jj * 3 * width + kk];
				}
			}
		}
	}

	//Find places with red color through NMS
	float r, g, b;
	for (int jj = NMS_BW; jj < height - NMS_BW; jj++)
	{
		for (int ii = NMS_BW; ii < width - NMS_BW; ii++)
		{
			r = ColorImg[ii + jj * width + 2 * length] - MeanImg[ii + jj * width + 2 * length],
				g = ColorImg[ii + jj * width + length] - MeanImg[ii + jj * width + length],
				b = ColorImg[ii + jj * width] - MeanImg[ii + jj * width];
			colorResponse[ii + jj * width] = 2.0*(int)r - (int)g - (int)b;
		}
	}

	bool breakflag;
	for (int jj = NMS_BW; jj < height - NMS_BW; jj++)
	{
		for (int ii = NMS_BW; ii < width - NMS_BW; ii++)
		{
			breakflag = false;
			if (colorResponse[ii + jj * width] < 20)
				colorResponse[ii + jj * width] = 0.0;
			else
			{
				for (int j = -NMS_BW; j <= NMS_BW && !breakflag; j++)
				{
					for (int i = -NMS_BW; i <= NMS_BW && !breakflag; i++)
					{
						if (i == 0 && j == 0)
							continue;
						if (ii + i< 0 || ii + i>width || jj + j < 0 || jj + j>height)
							continue;
						if (colorResponse[ii + jj * width] <= colorResponse[(ii + i) + (jj + j)*width])
						{
							colorResponse[ii + jj * width] = 0.0;
							breakflag = true;
							break;
						}
					}
				}
			}
		}
	}

	//find points left:
	vector<Point2d> redPoints;
	for (int jj = NMS_BW; jj < height - NMS_BW; jj++)
	{
		for (int ii = NMS_BW; ii < width - NMS_BW; ii++)
		{
			if (colorResponse[ii + jj * width] > 0.0)
				redPoints.push_back(Point2d(ii, jj));
		}
	}

	if (visualize)
	{
		Mat view = imread(ImgName);
		if (view.data == NULL)
			cout << "Cannot load: " << ImgName << endl;
		else
		{
			for (int ii = 0; ii < redPoints.size(); ii++)
				rectangle(view, Point2i(redPoints[ii].x - 10, redPoints[ii].y - 10), cv::Point(redPoints[ii].x + 10, redPoints[ii].y + 10), CV_RGB(0, 255, 0), 2);
			namedWindow("result", CV_WINDOW_NORMAL);
			imshow("result", view); waitKey();
		}
	}

	//build template
	int PatternLength = PatternSize * PatternSize;
	int IntensityProfile[] = { 10, 240 };
	int *hsubset = new int[nscales];
	double *RingInfo = new double[nscales];
	double maxScale = 0.9, minScale = 0.1, step = (maxScale - minScale) / nscales;
	for (int ii = 0; ii < nscales; ii++)
		RingInfo[ii] = maxScale - ii * step, hsubset[ii] = RingInfo[ii] / 2 * PatternSize;

	//double *maskSmooth = new double[PatternLength*nscales];
	double orgmin, orgmax;
	for (int ii = 0; ii < nscales; ii++)
	{
		if (hsubset[ii] > 10)
			synthesize_concentric_circles_mask(maskSmooth + PatternLength * ii, IntensityProfile, PatternSize, 1, PatternSize, &RingInfo[ii], 0, 1);
		else
		{
			Gaussian(maskSmooth + PatternLength * ii, hsubset[ii], PatternSize);//LaplacianOfGaussian(maskSmooth + PatternLength*ii, hsubset[ii], PatternSize);
			RescaleMat(maskSmooth + PatternLength * ii, orgmin, orgmax, 0, 255, PatternLength);
		}

		//sprintf(Fname, "C:/temp/mask_%.4d.png", ii + 1);	SaveDataToImage(Fname, maskSmooth + PatternLength*ii, PatternSize, PatternSize);
	}

	//Refine the detection
	int InterpAlgo = 1;
	GrabImage(ImgName, DImg, width, height, 1, true); //Get gray-scale imge
	Generate_Para_Spline(DImg, ImgPara, width, height, InterpAlgo);

	Point2i POI;
	double zncc, bestzncc = 0.0;
	int bestscale = -1, bestPattern = -1;
	for (int kk = 0; kk < redPoints.size(); kk++)
	{
		//find the scale with the best response
		for (int jj = 0; jj < nscales; jj++)
		{
			POI.x = redPoints[kk].x, POI.y = redPoints[kk].y;
			zncc = TMatchingSuperCoarse(maskSmooth + jj * PatternLength, PatternSize, hsubset[jj], DImg, width, height, 1, POI, 3, 0.5);
			if (zncc > bestzncc)
				bestzncc = abs(zncc), bestscale = hsubset[jj], bestPattern = jj;
		}
		if (bestzncc < thresh)
			continue;

		Point2d pt = POI;
		bestzncc = TMatchingFine_ZNCC(maskSmooth + bestPattern * PatternLength, PatternSize, 2 * (bestscale + 2) > PatternSize ? bestscale : bestscale + 2, ImgPara, width, height, 1, pt, 0, 1, thresh, InterpAlgo, Znssd_reqd);
		if (bestzncc > thresh)
			kpts.push_back(pt);
	}

	if (createMem)
		delete[]ColorImg, delete[]colorResponse, delete[]DImg, delete[] ImgPara, delete[]Znssd_reqd, delete[]maskSmooth;

	//if (kpts.size() == 0)
	//	printLOG("Cannot find the laser point in %s\n", ImgName);

	if (visualize)
	{
		Mat view = imread(ImgName);
		if (view.data == NULL)
			cout << "Cannot load: " << ImgName << endl;
		else
		{
			for (int ii = 0; ii < kpts.size(); ii++)
				rectangle(view, Point2i(kpts[ii].x - 5, kpts[ii].y - 5), cv::Point(kpts[ii].x + 5, kpts[ii].y + 5), CV_RGB(0, 255, 0), 1);
			namedWindow("result", CV_WINDOW_NORMAL);
			imshow("result", view); waitKey();
		}
	}

	return 0;
}
int DetectRGBBallCorrelation(char *ImgName, vector<KeyPoint> &kpts, vector<int> &ballType, int nOctaveLayers, int nScalePerOctave, double sigma, int PatternSize, int NMS_BW, double thresh, bool visualize)
{
	char Fname[512];
	int nscales = nOctaveLayers * nScalePerOctave + 1;
	ImgPyr imgpyrad;
	double starttime = omp_get_wtime();
	if (BuildImgPyr(ImgName, imgpyrad, nOctaveLayers, nScalePerOctave, false, 1, 1.0) == 1)
		return 1;
	for (int ii = 0; ii < imgpyrad.ImgPyrImg.size() && visualize; ii++)
	{
		sprintf(Fname, "C:/temp/L%.4d.png", ii);
		SaveDataToImage(Fname, imgpyrad.ImgPyrImg[ii], imgpyrad.wh[ii].x, imgpyrad.wh[ii].y, 1);
	}
	printLOG("Building Image pyramid: %.fs\n", omp_get_wtime() - starttime);

	//build template
	int hsubset = PatternSize / 2, PatternLength = PatternSize * PatternSize;
	int IntensityProfile[] = { 10, 240 };
	double RingInfo[1] = { 0.9 };
	double *maskSmooth = new double[PatternLength*nscales*nscales];
	synthesize_concentric_circles_mask(maskSmooth, IntensityProfile, PatternSize, 1, PatternSize, RingInfo, 0, 1);
	SaveDataToImage("C:/temp/mask.png", maskSmooth, PatternSize, PatternSize);


	Mat tpl = Mat::zeros(PatternSize, PatternSize, CV_32F);
	for (int ii = 0; ii < PatternLength; ii++)
		tpl.at<float>(ii) = maskSmooth[ii];

	// Standard multiscale correlation detection
	vector<KeyPoint> potentialPts;
	int width = imgpyrad.wh[0].x, height = imgpyrad.wh[0].y, length = width * height;
	/*float *response = new float[width*height];
	for (int scaleID = 0; scaleID < imgpyrad.ImgPyrImg.size(); scaleID++)
	{
	starttime = omp_get_wtime();
	printLOG("Layer %d ....", scaleID);
	int width = imgpyrad.wh[scaleID].x, height = imgpyrad.wh[scaleID].y;

	Mat ref = Mat::zeros(height, width, CV_32F);
	for (int ii = 0; ii < width*height; ii++)
	ref.at<float>(ii) = (float)(int)imgpyrad.ImgPyrImg[scaleID][ii];

	Mat dst;
	cv::matchTemplate(ref, tpl, dst, CV_TM_CCOEFF_NORMED);
	for (int ii = 0; ii < dst.rows*dst.cols; ii++)
	response[ii] = dst.at<float>(ii);
	sprintf(Fname, "C:/temp/L_%.4d.dat", scaleID);	WriteGridBinary(Fname, response, dst.cols, dst.rows);

	//Non-max suppression:
	bool breakflag;
	int ScoreW = dst.cols, ScoreH = dst.rows;
	for (int jj = hsubset; jj < ScoreH - hsubset; jj ++)
	{
	for (int ii = hsubset; ii < ScoreW - hsubset; ii ++)
	{
	breakflag = false;
	if (response[ii + jj*ScoreW] < thresh)
	response[ii + jj*ScoreW] = 0.0;
	else
	{
	for (int j = -NMS_BW; j <= NMS_BW && !breakflag; j ++)
	{
	for (int i = -NMS_BW; i <= NMS_BW&& !breakflag; i ++)
	{
	if (i == 0 && j == 0)
	continue;
	if (ii + i< 0 || ii + i>ScoreW || jj + j < 0 || jj + j>ScoreH)
	continue;
	if (response[ii + jj*ScoreW] < response[(ii + i) + (jj + j)*ScoreW])
	{
	response[ii + jj*ScoreW] = 0.0;
	breakflag = true;
	break;
	}
	}
	}
	}
	}
	}


	Mat ref_gray = Mat::zeros(height, width, CV_8UC1);
	for (int ii = 0; ii < width*height; ii++)
	ref_gray.data[ii] = imgpyrad.ImgPyrImg[scaleID][ii];
	cv::cvtColor(ref_gray, ref_gray, CV_GRAY2BGR);

	for (int jj = hsubset; jj < ScoreH - hsubset; jj ++)
	{
	for (int ii = hsubset; ii < ScoreW - hsubset; ii ++)
	{
	if (response[ii + jj*ScoreW] > thresh)
	{
	KeyPoint kpt;
	kpt.pt.x = (1.0*ii + PatternSize / 2) / imgpyrad.factor[scaleID];
	kpt.pt.y = (1.0*jj + PatternSize / 2) / imgpyrad.factor[scaleID];
	kpt.size = 1.0*PatternSize / imgpyrad.factor[scaleID]; //size of what the template should be
	kpt.response = response[ii + jj*ScoreW];
	kpt.octave = scaleID;
	cv::rectangle(ref_gray, Point2i(ii, jj), cv::Point(ii + PatternSize, jj + PatternSize), CV_RGB(0, 255, 0), 2);
	potentialPts.push_back(kpt);
	}
	}
	}

	namedWindow("result", CV_WINDOW_NORMAL);
	imshow("result", ref_gray); waitKey();
	printLOG(" %.2fs\n", omp_get_wtime() - starttime);
	}
	delete[]response;

	FILE *fp = fopen("C:/temp/kpts.txt", "w+");
	for (int kk = 0; kk < potentialPts.size(); kk++)
	fprintf(fp, "%.1f %.1f %.3f %.1f %d\n", potentialPts[kk].pt.x, potentialPts[kk].pt.y, potentialPts[kk].response, potentialPts[kk].size, potentialPts[kk].octave);
	fclose(fp);*/


	FILE *fp = fopen("C:/temp/kpts.txt", "r");
	int oct;
	float x, y, s, r;
	while (fscanf(fp, "%f %f %f %f %d", &x, &y, &r, &s, &oct) != EOF)
	{
		KeyPoint kpt;
		kpt.pt.x = x, kpt.pt.y = y, kpt.response = r, kpt.size = s;
		kpt.octave = oct;
		potentialPts.push_back(kpt);
	}
	fclose(fp);

	//Prune close-by points with lower response;
	vector<int> pointsToBeRemoved;
	for (int ll = 0; ll < potentialPts.size() - 1; ll++)
	{
		for (int kk = ll + 1; kk < potentialPts.size(); kk++)
		{
			if (abs(potentialPts[ll].pt.x - potentialPts[kk].pt.x) < potentialPts[ll].size / 2 && abs(potentialPts[ll].pt.y - potentialPts[kk].pt.y) < potentialPts[ll].size / 2)
				if (potentialPts[ll].response > potentialPts[kk].response)
					pointsToBeRemoved.push_back(kk);
				else
					pointsToBeRemoved.push_back(ll);
		}
	}

	vector<KeyPoint> potentialPts2;
	for (int ii = 0; ii < potentialPts.size(); ii++)
	{
		int jj;
		for (jj = 0; jj < pointsToBeRemoved.size(); jj++)
			if (ii == pointsToBeRemoved[jj])
				break;
		if (jj == pointsToBeRemoved.size())
			potentialPts2.push_back(potentialPts[ii]);
	}

	//Figure out RGB Ball:  the small regions around the detected point must have good color matching
	width = imgpyrad.wh[0].x, height = imgpyrad.wh[0].y;
	unsigned char *Img = new unsigned char[width*height * 3];
	GrabImage(ImgName, Img, width, height, 3);

	int count = 0, bw = width > 640 ? 5 : 3;
	vector<KeyPoint>potentialPts3;
	vector<int> potentialBallType;
	for (int kk = 0; kk < potentialPts2.size(); kk++)
	{
		KeyPoint kpt = potentialPts2[kk];
		int startX = kpt.pt.x - bw, startY = kpt.pt.y - bw;
		int stopX = kpt.pt.x + bw, stopY = kpt.pt.y + bw;

		double r = 0, g = 0, b = 0;
		for (int jj = startY; jj < stopY; jj++)
		{
			for (int ii = startX; ii < stopX; ii++)
			{
				b += Img[ii + jj * width], //b
					g += Img[ii + jj * width + length],//g
					r += Img[ii + jj * width + 2 * length];//r
			}
		}
		if (r > 1.2*g && r > 1.2*b)
			potentialPts3.push_back(kpt), potentialBallType.push_back(0);
		if (g > 1.2*r && g > 1.2*b)
			potentialPts3.push_back(kpt), potentialBallType.push_back(1);
		if (b > 1.2*g && b > 1.2*r)
			potentialPts3.push_back(kpt), potentialBallType.push_back(2);
	}
	if (potentialPts3.size() < 3)
		printLOG("Cannot detect all the balls in %s\n", ImgName);

	//Refine the detection
	double *DImg = new double[width*height];
	GrabImage(ImgName, DImg, width, height, 1); //Get gray-scale imge

	int InterpAlgo = 1;
	double *ImgPara = new double[width*height];
	Generate_Para_Spline(DImg, ImgPara, width, height, InterpAlgo);

	double *Znssd_reqd = new double[9 * PatternLength*nscales*nscales];
	pointsToBeRemoved.clear();
	for (int kk = 0; kk < potentialPts3.size(); kk++)
	{
		int PatternSize = potentialPts3[kk].size, hsubset = PatternSize / 2, PatternLength = PatternSize * PatternSize;
		synthesize_concentric_circles_mask(maskSmooth, IntensityProfile, PatternSize, 1, PatternSize, RingInfo, 0, 1);
		//SaveDataToImage("C:/temp/mask.png", maskSmooth, PatternSize, PatternSize);

		Point2i POI(potentialPts3[kk].pt.x, potentialPts3[kk].pt.y);
		double zncc = TMatchingSuperCoarse(maskSmooth, PatternSize, hsubset - 1, DImg, width, height, 1, POI, 5, 0.5);
		if (zncc < thresh)
		{
			printLOG("Cannot refine the %d balls in %s\n", kk + 1, ImgName);
			pointsToBeRemoved.push_back(kk);
			continue;
		}

		Point2d pt = POI;
		zncc = TMatchingFine_ZNCC(maskSmooth, PatternSize, hsubset - 1, ImgPara, width, height, 1, pt, 0, 1, thresh, InterpAlgo, Znssd_reqd);
		if (zncc < thresh)
		{
			printLOG("Cannot refine the %d balls in %s\n", kk + 1, ImgName);
			pointsToBeRemoved.push_back(kk);
		}
		else
			potentialPts3[kk].pt.x = pt.x, potentialPts3[kk].pt.y = pt.y;
	}
	delete[]maskSmooth, delete[]DImg, delete[]ImgPara, delete[]Znssd_reqd;

	for (int ii = 0; ii < potentialPts3.size(); ii++)
	{
		int jj;
		for (jj = 0; jj < pointsToBeRemoved.size(); jj++)
			if (ii == pointsToBeRemoved[jj])
				break;
		if (jj == pointsToBeRemoved.size())
			kpts.push_back(potentialPts3[ii]), ballType.push_back(potentialBallType[ii]);
	}

	if (visualize)
	{
		Mat ref_gray = Mat::zeros(height, width, CV_8UC1);
		for (int ii = 0; ii < width*height; ii++)
			ref_gray.data[ii] = imgpyrad.ImgPyrImg[0][ii];
		cv::cvtColor(ref_gray, ref_gray, CV_GRAY2BGR);
		for (int ii = 0; ii < kpts.size(); ii++)
		{
			KeyPoint kpt = kpts[ii];
			int startX = kpt.pt.x - kpt.size / 2, startY = kpt.pt.y - kpt.size / 2;
			int stopX = kpt.pt.x + kpt.size / 2, stopY = kpt.pt.y + kpt.size / 2;
			circle(ref_gray, Point2i(kpt.pt.x, kpt.pt.y), 2, CV_RGB(0, 255, 0), 2);
			rectangle(ref_gray, Point2i(startX, startY), cv::Point(stopX, stopY), CV_RGB(0, 255, 0), 2);
		}
		namedWindow("result", CV_WINDOW_NORMAL);
		imshow("result", ref_gray); waitKey();
	}

	return 0;
}

int CornerDetectorDriver(char *Path, int checkerSize, double ZNCCThreshold, int startF, int stopF, int width, int height)
{
	char Fname[512];

	const int maxPts = 5000, SearchArea = 1, InterpAlgo = 1;
	double Gsigma = 1.0;
	vector<double> PatternAngles;
	for (int ii = 0; ii < 7; ii++)
		PatternAngles.push_back(10 * ii);
	int CheckerhSubset = (int)(0.5*checkerSize + 0.5);

	int nPts, nCCorres = maxPts;
	int CType[maxPts];
	Point2d Pts[maxPts];

	double *Img = new double[width*height];
	double *SImg = new double[width*height];
	double *IPara = new double[width*height];

	sprintf(Fname, "%s/Corner", Path), makeDir(Fname);
	for (int fid = startF; fid <= stopF; fid++)
	{
		sprintf(Fname, "%s/%.4d.png", Path, fid);
		if (!GrabImage(Fname, Img, width, height, 1))
			continue;

		Gaussian_smooth(Img, SImg, height, width, 255.0, 0.707);
		Generate_Para_Spline(SImg, IPara, width, height, InterpAlgo);
		//ShowDataAsImage("C:/temp/x.png", Img, width, height, 1);

		RunCheckerCornersDetector(Pts, CType, nPts, SImg, IPara, width, height, 1, PatternAngles, CheckerhSubset, CheckerhSubset, SearchArea, ZNCCThreshold - 0.35, ZNCCThreshold, InterpAlgo);

#pragma omp critical
		printLOG("%s: %d points\n", Fname, nPts);

		sprintf(Fname, "%s/Corner/%.4d.txt", Path, fid); FILE *fp = fopen(Fname, "w+");
		for (int ii = 0; ii < nPts; ii++)
		{
			if (Pts[ii].x<1.5*CheckerhSubset || Pts[ii].x > width - 1.5*CheckerhSubset || Pts[ii].y < 1.5*CheckerhSubset || Pts[ii].y > height - 1.5*CheckerhSubset)
				continue;
			fprintf(fp, "%d %.3f %.3f\n", CType[ii], Pts[ii].x, Pts[ii].y);
		}
		fclose(fp);
	}

	delete[]Img, delete[]SImg, delete[]IPara;

	return 0;
}

//ARtag tracker
int ARTag_GenerateVisibilityMatrix(char *Path, int nCams, int npts, int nframes)
{
	char Fname[512];

	float u, v;
	int ii, jj, nf, fid;

	int *CamIPts = new int[npts*nframes];
	int *VisRI = new int[npts*nframes];
	int *AllVis = new int[nCams*npts*nframes];

	for (int camID = 0; camID < nCams; camID++)
	{
		sprintf(Fname, "%s/Track2D/fb_%.4d.txt", Path, camID); FILE *fp = fopen(Fname, "r");
		if (fp == NULL)
		{
			printLOG("Cannot load %s\n", Fname);
			return 1;
		}
		for (ii = 0; ii < npts*nframes; ii++)
			CamIPts[ii] = 0;
		for (ii = 0; ii < npts; ii++)
		{
			fscanf(fp, "%d %d %d ", &jj, &jj, &nf);
			for (jj = 0; jj < nf; jj++)
			{
				fscanf(fp, "%d %f %f ", &fid, &u, &v);
				CamIPts[ii*nframes + fid] = 255;
			}
		}
		fclose(fp);

		for (ii = 0; ii < npts*nframes; ii++)
			if (CamIPts[ii] == 255)
				VisRI[ii] = camID % 2 == 0 ? 255 : 127;
			else
				VisRI[ii] = 0;

		Set_Sub_Mat(VisRI, AllVis, nframes, npts, nframes, 0, npts*camID);
	}

	sprintf(Fname, "%s/Track2D/VisMat.png", Path);
	SaveDataToImage(Fname, AllVis, nframes, npts*nCams);

	delete[]CamIPts, delete[]VisRI, delete[]AllVis;
	return 0;
}
int ARTag_TrackMissingMarkersIndiCorner(char *Path, int camID, int npts, int nframes, int subsetSize, int subsetStep, int subsetScale, double Dist2Thesh, int PryLevel)
{
	if (PryLevel < 1)
		PryLevel = 1;

	char Fname[512];

	int nf, fid;
	Point2f uv;
	vector<Point2i> markerID;

	Point2f *Pts = new Point2f[npts*nframes];
	for (int ii = 0; ii < npts*nframes; ii++)
		Pts[ii] = Point2f(-1, -1);

	sprintf(Fname, "%s/Track2D/%.4d.txt", Path, camID); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	for (int ii = 0; ii < npts; ii++)
	{
		int id, oid;
		fscanf(fp, "%d %d %d ", &id, &oid, &nf);
		markerID.push_back(Point2i(id, oid));
		for (int jj = 0; jj < nf; jj++)
		{
			fscanf(fp, "%d %f %f ", &fid, &uv.x, &uv.y);
			Pts[ii*nframes + fid] = uv;
		}
	}
	fclose(fp);

	//Track markers
	vector<float> err;
	vector<uchar> status;
	Mat cvNewImg, cvPreImg;
	Size winSize(subsetSize + subsetStep * (subsetScale - 1), subsetSize + subsetStep * (subsetScale - 1));
	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, 0.03);


	vector<Mat> cvPrePyr, cvNewPyr;
	int lastvalidFrame = 0;

	//Foreward track
	for (int fid = 0; fid < nframes - 1; fid++)
	{
		vector<Point2f> cvprePt, cvnewPt, cvbackPt, bestnewPt;
		vector<double> minDist2;
		vector<int>validID, validID2;
		for (int pid = 0; pid < npts; pid++)
		{
			if (Pts[pid*nframes + fid].x < 0 || Pts[pid*nframes + fid].y < 0)
				continue;
			if (Pts[pid*nframes + fid + 1].x > 0 || Pts[pid*nframes + fid + 1].y > 0)
				continue;

			validID.push_back(pid), validID2.push_back(0);
			minDist2.push_back(9e9);
			cvprePt.push_back(Pts[pid*nframes + fid]);
			cvnewPt.push_back(Pts[pid*nframes + fid]);
			bestnewPt.push_back(Pts[pid*nframes + fid]);
		}

		if (cvprePt.size() > 0)
		{
			if (lastvalidFrame == 0 || lastvalidFrame != fid - 1)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid);
				cvPreImg = imread(Fname, 0);
				if (cvPreImg.empty())
					continue;
				buildOpticalFlowPyramid(cvPreImg, cvPrePyr, winSize, PryLevel, true);
			}

			sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid + 1);
			cvNewImg = imread(Fname, 0);
			if (cvNewImg.empty())
				continue;
			buildOpticalFlowPyramid(cvNewImg, cvNewPyr, winSize, PryLevel, true);

			//BF-Consisteny track with multiple windows size
			for (int sid = 0; sid < 3; sid++)
			{
				Size winSi(subsetSize + subsetStep * (subsetScale - 1), subsetSize + subsetStep * (subsetScale - 1));

				cvbackPt = cvprePt;
				calcOpticalFlowPyrLK(cvPrePyr, cvNewPyr, cvprePt, cvnewPt, status, err, winSi, PryLevel, termcrit);
				calcOpticalFlowPyrLK(cvNewPyr, cvPrePyr, cvnewPt, cvbackPt, status, err, winSi, PryLevel, termcrit);

				for (int ii = 0; ii < (int)cvprePt.size(); ii++)
				{
					double Dist2 = status[ii] ? pow(cvprePt[ii].x - cvbackPt[ii].x, 2) + pow(cvprePt[ii].y - cvbackPt[ii].y, 2) : 9e9;
					if (Dist2 < minDist2[ii] && Dist2 < Dist2Thesh)
					{
						validID2[ii] += 1;
						minDist2[ii] = Dist2;
						bestnewPt[ii] = cvnewPt[ii];
					}
				}
			}

			//sort the result
			for (int ii = 0; ii < (int)cvprePt.size(); ii++)
			{
				if (validID2[ii] > 0)
				{
					int pid = validID[ii];
					Pts[pid*nframes + fid + 1] = bestnewPt[ii];
				}
			}

			//cvCalcAffineFlowPyrLK(cvPreImg, cvNewImg, cvPrePyr, cvNewPyr, cvprePt, cvnewPt, fmat, count, winSize, cvPryLevel, status, error, termcrit, 0);

			lastvalidFrame = fid + 1;
			cvPrePyr = cvNewPyr;
		}
	}

	//Backward track
	for (int fid = nframes - 1; fid >= 0; fid--)
	{
		vector<Point2f> cvprePt, cvnewPt, cvbackPt, bestnewPt;
		vector<double> minDist2;
		vector<int>validID, validID2;
		for (int pid = 0; pid < npts; pid++)
		{
			if (Pts[pid*nframes + fid].x < 0 || Pts[pid*nframes + fid].y < 0)
				continue;
			if (Pts[pid*nframes + fid - 1].x > 0 || Pts[pid*nframes + fid - 1].y > 0)
				continue;

			validID.push_back(pid), validID2.push_back(0);
			minDist2.push_back(9e9);
			cvprePt.push_back(Pts[pid*nframes + fid]);
			cvnewPt.push_back(Pts[pid*nframes + fid]);
			bestnewPt.push_back(Pts[pid*nframes + fid]);
		}

		if (cvprePt.size() > 0)
		{
			if (lastvalidFrame == 0 || lastvalidFrame != fid - 1)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid);
				cvPreImg = imread(Fname, 0);
				if (cvPreImg.empty())
					continue;
				buildOpticalFlowPyramid(cvPreImg, cvPrePyr, winSize, PryLevel, true);
			}

			sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid - 1);
			cvNewImg = imread(Fname, 0);
			if (cvNewImg.empty())
				continue;
			buildOpticalFlowPyramid(cvNewImg, cvNewPyr, winSize, PryLevel, true);

			//BF-Consisteny track with multiple windows size
			for (int sid = 0; sid < 3; sid++)
			{
				Size winSi(subsetSize + subsetStep * (subsetScale - 1), subsetSize + subsetStep * (subsetScale - 1));

				cvbackPt = cvprePt;
				calcOpticalFlowPyrLK(cvPrePyr, cvNewPyr, cvprePt, cvnewPt, status, err, winSi, PryLevel, termcrit);
				calcOpticalFlowPyrLK(cvNewPyr, cvPrePyr, cvnewPt, cvbackPt, status, err, winSi, PryLevel, termcrit);

				for (int ii = 0; ii < (int)cvprePt.size(); ii++)
				{
					double Dist2 = status[ii] ? pow(cvprePt[ii].x - cvbackPt[ii].x, 2) + pow(cvprePt[ii].y - cvbackPt[ii].y, 2) : 9e9;
					if (Dist2 < minDist2[ii] && Dist2 < Dist2Thesh)
					{
						validID2[ii] += 1;
						minDist2[ii] = Dist2;
						bestnewPt[ii] = cvnewPt[ii];
					}
				}
			}

			//sort the result
			for (int ii = 0; ii < (int)cvprePt.size(); ii++)
			{
				if (validID2[ii] > 0)
				{
					int pid = validID[ii];
					Pts[pid*nframes + fid + 1] = bestnewPt[ii];
				}
			}

			//cvCalcAffineFlowPyrLK(cvPreImg, cvNewImg, cvPrePyr, cvNewPyr, cvprePt, cvnewPt, fmat, count, winSize, cvPryLevel, status, error, termcrit, 0);

			lastvalidFrame = fid - 1;
			cvPrePyr = cvNewPyr;
		}
	}

	sprintf(Fname, "%s/Track2D/fb_%.4d.txt", Path, camID); fp = fopen(Fname, "w+");
	for (int ii = 0; ii < npts; ii++)
	{
		nf = 0;
		for (int fid = 0; fid < nframes; fid++)
			if (Pts[ii*nframes + fid].x > 0 && Pts[ii*nframes + fid].y > 0)
				nf++;

		fprintf(fp, "%d %d %d ", markerID[ii].x, markerID[ii].y, nf);
		for (int fid = 0; fid < nframes; fid++)
			if (Pts[ii*nframes + fid].x > 0 && Pts[ii*nframes + fid].y > 0)
				fprintf(fp, "%d %.4f %.4f ", fid, Pts[ii*nframes + fid].x, Pts[ii*nframes + fid].y);
		fprintf(fp, "\n");
	}
	fclose(fp);

	return 0;
}
int ARTag_TrackMissingMarkers(char *Path, int camID, int npts, int nframes, int backward, double ZNCCThresh, bool Debug)
{
	char Fname[512];
	int mid, lid, fid, nf;
	Point2f uv;

	Point2f *allpts = new Point2f[npts*(nframes + 1)];
	for (int ii = 0; ii < npts*(nframes + 1); ii++)
		allpts[ii] = Point2f(-1, -1);

	vector<Point2i> markerID;
	sprintf(Fname, "%s/Track2D/%.4d.txt", Path, camID); FILE *fp = fopen(Fname, "r");
	for (int pid = 0; pid < npts; pid++)
	{
		fscanf(fp, "%d %d %d ", &mid, &lid, &nf);
		markerID.push_back(Point2i(mid, lid));
		for (int ii = 0; ii < nf; ii++)
		{
			fscanf(fp, "%d %f %f ", &fid, &uv.x, &uv.y);
			allpts[pid*(nframes + 1) + fid] = uv;
		}
	}
	fclose(fp);


	//For PryLK tracking
	Mat cvPreImg, cvNewImg, cvPreImgC, cvNewImgC;
	vector<Mat> PrePyramid, NewPyramid;

	int pyrLevel = 3;
	Size winSize(31, 31);
	TermCriteria termcrit(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, 0.03);

	vector<float> err;
	vector<uchar> status;
	vector<Point2f> prePts, newPts, backPts, bestNewPts;

	//for ECC template matching
	Mat cvPattern[41], templateFloat[41];
	for (int ii = 0; ii < npts / 4; ii++)
	{
		sprintf(Fname, "%s/Tag/%.4d.png", Path, ii);	cvPattern[ii] = imread(Fname, 0);
		if (!cvPattern[ii].empty())
		{
			templateFloat[ii] = Mat(cvPattern[ii].rows, cvPattern[ii].cols, CV_32F);// to store the (smoothed) template
			cvPattern[ii].convertTo(templateFloat[ii], templateFloat[ii].type());
			GaussianBlur(templateFloat[ii], templateFloat[ii], Size(5, 5), 0, 0);
		}
	}
	Mat cvNewImgFloat = Mat(cvNewImg.rows, cvNewImg.cols, CV_32F);// to store the (smoothed) input image
	Mat gradientX = Mat::zeros(cvNewImg.rows, cvNewImg.cols, CV_32FC1);
	Mat gradientY = Mat::zeros(cvNewImg.rows, cvNewImg.cols, CV_32FC1);
	Mat gradientXWarped = Mat(cvPattern[0].rows, cvPattern[0].cols, CV_32FC1);
	Mat gradientYWarped = Mat(cvPattern[0].rows, cvPattern[0].cols, CV_32FC1);
	TermCriteria criteria(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 30, 1e-6);

	//Run the tracking&detection
	for (int fid = 0; fid < nframes - 1; fid++)
	{
		int nvalid = 0;
		for (int pid = 0; pid < npts; pid += 4)
		{
			if (allpts[pid*(nframes + 1) + fid].x > 0 && allpts[pid*(nframes + 1) + fid].y > 0 && allpts[pid*(nframes + 1) + fid + 1].x < 0 && allpts[pid*(nframes + 1) + fid + 1].y < 0)
				nvalid++;
		}

		if (nvalid == 0)
			continue;

		sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid);	cvPreImg = imread(Fname, 0);
		if (cvPreImg.empty())
			continue;

		sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid + 1);	cvNewImg = imread(Fname, 0);
		if (cvNewImg.empty())
			continue;

		//Data initalization
		buildOpticalFlowPyramid(cvPreImg, PrePyramid, winSize, pyrLevel);
		buildOpticalFlowPyramid(cvNewImg, NewPyramid, winSize, pyrLevel);

		cvNewImg.convertTo(cvNewImgFloat, cvNewImgFloat.type());
		//GaussianBlur(cvNewImgFloat, cvNewImgFloat, Size(5, 5), 0, 0);
		Matx13f dx(-0.5f, 0.0f, 0.5f);
		filter2D(cvNewImgFloat, gradientX, -1, dx);
		filter2D(cvNewImgFloat, gradientY, -1, dx.t());

		int succces = 0;
		for (int pid = 0; pid < npts; pid += 4)
		{
			if (allpts[pid*(nframes + 1) + fid].x > 0 && allpts[pid*(nframes + 1) + fid].y > 0 && allpts[pid*(nframes + 1) + fid + 1].x < 0 && allpts[pid*(nframes + 1) + fid + 1].y < 0)
			{
				err.clear(), status.clear(), prePts.clear(), newPts.clear();
				for (int ii = 0; ii < 4; ii++)
				{
					backPts.push_back(allpts[(pid + ii)*(nframes + 1) + fid]);
					prePts.push_back(allpts[(pid + ii)*(nframes + 1) + fid]);
					newPts.push_back(allpts[(pid + ii)*(nframes + 1) + fid]);
					bestNewPts.push_back(allpts[(pid + ii)*(nframes + 1) + fid]);
				}

				double Dist, minDist = 9e9;
				for (int jj = 0; jj < 3; jj++)
				{
					Size winSizei(31 - jj * 3, 31 - jj * 3);
					calcOpticalFlowPyrLK(PrePyramid, NewPyramid, prePts, newPts, status, err, winSizei, pyrLevel, termcrit);
					calcOpticalFlowPyrLK(NewPyramid, PrePyramid, newPts, backPts, status, err, winSizei, pyrLevel, termcrit);

					int successcount = 0;
					Dist = 0.0;
					for (int ii = 0; ii < 4; ii++)
					{
						if (status[ii])
							successcount++;
						Dist += pow(prePts[ii].x - backPts[ii].x, 2) + pow(prePts[ii].y - backPts[ii].y, 2);
					}

					if (successcount == 4 && Dist < minDist && Dist < 4.0)
					{
						minDist = Dist;
						for (int ii = 0; ii < 4; ii++)
							bestNewPts[ii] = newPts[ii];
					}
				}

				if (minDist < 4.0)//4/4 = 1
				{
					//run template matching to prevent drift
					if (templateFloat[pid / 4].empty())
						continue;

					bool stopFlag = false;
					for (int ii = 0; ii < 4; ii++)
						if (bestNewPts[ii].x<40 || bestNewPts[ii].x > cvNewImg.cols - 40 || bestNewPts[ii].y< 40 || bestNewPts[ii].y>cvNewImg.rows - 40)
						{
							stopFlag = true; break;
						}
					if (stopFlag)
						continue;

					vector<Point2d> patternPts, imgPts;
					patternPts.push_back(Point2d(0, 339));
					patternPts.push_back(Point2d(339, 339));
					patternPts.push_back(Point2d(339, 0));
					patternPts.push_back(Point2d(0, 0));

					for (int ii = 0; ii < 4; ii++)
						imgPts.push_back(Point2d(bestNewPts[ii].x, bestNewPts[ii].y));

					double denum, u, v, A[12], B[4], Affine[9] = { 1, 0, 0, 0, 1, 0, 0, 0, 1 };
					Compute_AffineHomo(patternPts, imgPts, Affine, A, B);
					Mat wMat = Mat::eye(3, 3, CV_32F);
					for (int ii = 0; ii < 6; ii++)
						wMat.at<float>(ii) = Affine[ii];

					double score = findTransformECC_Optimized(templateFloat[pid / 4], cvNewImgFloat, gradientX, gradientY, gradientXWarped, gradientYWarped, wMat, 3, criteria);
					if (score > ZNCCThresh)
					{
						succces++;
						for (int ii = 0; ii < 4; ii++)
						{
							denum = patternPts[ii].x*wMat.at<float>(2, 0) + patternPts[ii].y*wMat.at<float>(2, 1) + wMat.at<float>(2, 2);
							u = (patternPts[ii].x*wMat.at<float>(0, 0) + patternPts[ii].y*wMat.at<float>(0, 1) + wMat.at<float>(0, 2)) / denum;
							v = (patternPts[ii].x*wMat.at<float>(1, 0) + patternPts[ii].y*wMat.at<float>(1, 1) + wMat.at<float>(1, 2)) / denum;
							allpts[(pid + ii)*(nframes + 1) + fid + 1] = Point2f(u, v);
						}
					}
				}
			}
		}
		if (succces > 0)
			printLOG("%d_%d ... ", camID, fid + 1);

		if (succces > 0 && Debug)
		{
			sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid + 1);	cvNewImgC = imread(Fname, 1);
			int Xmax = -1, Xmin = 10000, Ymax = -1, Ymin = 10000;
			for (int pid = 0; pid < npts; pid++)
			{
				if (allpts[pid*(nframes + 1) + fid + 1].x > 0 && allpts[pid*(nframes + 1) + fid + 1].y > 0)
				{
					if (allpts[pid*(nframes + 1) + fid + 1].x > Xmax)
						Xmax = allpts[pid*(nframes + 1) + fid + 1].x;
					if (allpts[pid*(nframes + 1) + fid + 1].x < Xmin)
						Xmin = allpts[pid*(nframes + 1) + fid + 1].x;
					if (allpts[pid*(nframes + 1) + fid + 1].y > Ymax)
						Ymax = allpts[pid*(nframes + 1) + fid + 1].y;
					if (allpts[pid*(nframes + 1) + fid + 1].x < Ymin)
						Ymin = allpts[pid*(nframes + 1) + fid + 1].y;
				}
			}
			Xmin = Xmin > 80 ? Xmin - 80 : Xmin;
			Ymin = Ymin > 80 ? Ymin - 80 : Ymin;
			Xmax = Xmax < cvPreImgC.cols - 80 ? Xmax + 80 : Xmax;
			Ymax = Ymax < cvPreImgC.rows - 80 ? Ymax + 80 : Ymax;

			Rect roiN(Xmin, Ymin, Xmax - Xmin, Ymax - Ymin);
			Mat image_roiN = cvNewImgC(roiN);

			for (int pid = 0; pid < npts; pid++)
			{
				sprintf(Fname, "%d_%d", markerID[pid].x, markerID[pid].y);
				if (allpts[pid*(nframes + 1) + fid + 1].x > 0 && allpts[pid*(nframes + 1) + fid + 1].y > 0)
				{
					circle(image_roiN, Point2i(allpts[pid*(nframes + 1) + fid + 1].x - Xmin, allpts[pid*(nframes + 1) + fid + 1].y - Ymin), 1, Scalar(0, 255, 0), 1, 8);
					putText(image_roiN, Fname, Point2i(allpts[pid*(nframes + 1) + fid + 1].x - Xmin, allpts[pid*(nframes + 1) + fid + 1].y - Ymin), FONT_HERSHEY_SIMPLEX, 0.2, Scalar(0, 0, 255), 1, 8);
				}
			}
			sprintf(Fname, "%s/Track2D/%d_%d_2.png", Path, camID, fid), imwrite(Fname, image_roiN);
		}
	}

	if (backward)
	{
		for (int fid = nframes - 1; fid > 0; fid--)
		{
			int nvalid = 0;
			for (int pid = 0; pid < npts; pid += 4)
			{
				if (allpts[pid*(nframes + 1) + fid].x > 0 && allpts[pid*(nframes + 1) + fid].y > 0 && allpts[pid*(nframes + 1) + fid - 1].x < 0 && allpts[pid*(nframes + 1) + fid - 1].y < 0)
					nvalid++;
			}

			if (nvalid == 0)
				continue;

			sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid);	cvPreImg = imread(Fname, 0);
			if (cvPreImg.empty())
				continue;

			sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid - 1);	cvNewImg = imread(Fname, 0);
			if (cvNewImg.empty())
				continue;

			//Data initalization
			buildOpticalFlowPyramid(cvPreImg, PrePyramid, winSize, pyrLevel);
			buildOpticalFlowPyramid(cvNewImg, NewPyramid, winSize, pyrLevel);

			cvNewImg.convertTo(cvNewImgFloat, cvNewImgFloat.type());
			//GaussianBlur(cvNewImgFloat, cvNewImgFloat, Size(5, 5), 0, 0);
			Matx13f dx(-0.5f, 0.0f, 0.5f);
			filter2D(cvNewImgFloat, gradientX, -1, dx);
			filter2D(cvNewImgFloat, gradientY, -1, dx.t());

			int succces = 0;
			for (int pid = 0; pid < npts; pid += 4)
			{
				if (allpts[pid*(nframes + 1) + fid].x > 0 && allpts[pid*(nframes + 1) + fid].y > 0 && allpts[pid*(nframes + 1) + fid - 1].x < 0 && allpts[pid*(nframes + 1) + fid - 1].y < 0)
				{
					err.clear(), status.clear(), prePts.clear(), newPts.clear();
					for (int ii = 0; ii < 4; ii++)
					{
						backPts.push_back(allpts[(pid + ii)*(nframes + 1) + fid]);
						prePts.push_back(allpts[(pid + ii)*(nframes + 1) + fid]);
						newPts.push_back(allpts[(pid + ii)*(nframes + 1) + fid]);
						bestNewPts.push_back(allpts[(pid + ii)*(nframes + 1) + fid]);
					}

					double Dist, minDist = 9e9;
					for (int jj = 0; jj < 3; jj++)
					{
						Size winSizei(31 - jj * 3, 31 - jj * 3);
						calcOpticalFlowPyrLK(PrePyramid, NewPyramid, prePts, newPts, status, err, winSizei, pyrLevel, termcrit);
						calcOpticalFlowPyrLK(NewPyramid, PrePyramid, newPts, backPts, status, err, winSizei, pyrLevel, termcrit);

						int successcount = 0;
						Dist = 0.0;
						for (int ii = 0; ii < 4; ii++)
						{
							if (status[ii])
								successcount++;
							Dist += pow(prePts[ii].x - backPts[ii].x, 2) + pow(prePts[ii].y - backPts[ii].y, 2);
						}

						if (successcount == 4 && Dist < minDist && Dist < 4.0)
						{
							minDist = Dist;
							for (int ii = 0; ii < 4; ii++)
								bestNewPts[ii] = newPts[ii];
						}
					}

					if (minDist < 4.0)
					{
						//run template matching to prevent drift
						if (templateFloat[pid / 4].empty())
							continue;

						bool stopFlag = false;
						for (int ii = 0; ii < 4; ii++)
							if (bestNewPts[ii].x<40 || bestNewPts[ii].x > cvNewImg.cols - 40 || bestNewPts[ii].y< 40 || bestNewPts[ii].y>cvNewImg.rows - 40)
							{
								stopFlag = true; break;
							}
						if (stopFlag)
							continue;

						vector<Point2d> patternPts, imgPts;
						patternPts.push_back(Point2d(0, 339));
						patternPts.push_back(Point2d(339, 339));
						patternPts.push_back(Point2d(339, 0));
						patternPts.push_back(Point2d(0, 0));

						for (int ii = 0; ii < 4; ii++)
							imgPts.push_back(Point2d(bestNewPts[ii].x, bestNewPts[ii].y));

						double denum, u, v, A[12], B[4], Affine[9] = { 1, 0, 0, 0, 1, 0, 0, 0, 1 };
						Compute_AffineHomo(patternPts, imgPts, Affine, A, B);
						Mat wMat = Mat::eye(3, 3, CV_32F);
						for (int ii = 0; ii < 6; ii++)
							wMat.at<float>(ii) = (float)Affine[ii];

						double score = findTransformECC_Optimized(templateFloat[pid / 4], cvNewImgFloat, gradientX, gradientY, gradientXWarped, gradientYWarped, wMat, 3, criteria);
						if (score > ZNCCThresh)
						{
							succces++;
							for (int ii = 0; ii < 4; ii++)
							{
								denum = patternPts[ii].x*wMat.at<float>(2, 0) + patternPts[ii].y*wMat.at<float>(2, 1) + wMat.at<float>(2, 2);
								u = (patternPts[ii].x*wMat.at<float>(0, 0) + patternPts[ii].y*wMat.at<float>(0, 1) + wMat.at<float>(0, 2)) / denum;
								v = (patternPts[ii].x*wMat.at<float>(1, 0) + patternPts[ii].y*wMat.at<float>(1, 1) + wMat.at<float>(1, 2)) / denum;
								allpts[(pid + ii)*(nframes + 1) + fid - 1] = Point2f(u, v);
							}
						}
					}
				}
			}
			if (succces > 0)
				printLOG("%d_%d ... ", camID, fid - 1);

			if (succces > 0 && Debug)
			{
				sprintf(Fname, "%s/%d/%.4d.png", Path, camID, fid - 1);	cvNewImgC = imread(Fname, 1);
				int Xmax = -1, Xmin = 10000, Ymax = -1, Ymin = 10000;
				for (int pid = 0; pid < npts; pid++)
				{
					if (allpts[pid*(nframes + 1) + fid - 1].x > 0 && allpts[pid*(nframes + 1) + fid - 1].y > 0)
					{
						if (allpts[pid*(nframes + 1) + fid - 1].x > Xmax)
							Xmax = (int)allpts[pid*(nframes + 1) + fid - 1].x;
						if (allpts[pid*(nframes + 1) + fid - 1].x < Xmin)
							Xmin = (int)allpts[pid*(nframes + 1) + fid - 1].x;
						if (allpts[pid*(nframes + 1) + fid - 1].y > Ymax)
							Ymax = (int)allpts[pid*(nframes + 1) + fid - 1].y;
						if (allpts[pid*(nframes + 1) + fid - 1].x < Ymin)
							Ymin = (int)allpts[pid*(nframes + 1) + fid - 1].y;
					}
				}
				Xmin = Xmin > 80 ? Xmin - 80 : Xmin;
				Ymin = Ymin > 80 ? Ymin - 80 : Ymin;
				Xmax = Xmax < cvPreImgC.cols - 80 ? Xmax + 80 : Xmax;
				Ymax = Ymax < cvPreImgC.rows - 80 ? Ymax + 80 : Ymax;

				Rect roiN(Xmin, Ymin, Xmax - Xmin, Ymax - Ymin);
				Mat image_roiN = cvNewImgC(roiN);

				for (int pid = 0; pid < npts; pid++)
				{
					sprintf(Fname, "%d_%d", markerID[pid].x, markerID[pid].y);
					if (allpts[pid*(nframes + 1) + fid - 1].x > 0 && allpts[pid*(nframes + 1) + fid - 1].y > 0)
					{
						circle(image_roiN, Point2i(allpts[pid*(nframes + 1) + fid - 1].x - Xmin, allpts[pid*(nframes + 1) + fid - 1].y - Ymin), 1, Scalar(0, 255, 0), 1, 8);
						putText(image_roiN, Fname, Point2i(allpts[pid*(nframes + 1) + fid - 1].x - Xmin, allpts[pid*(nframes + 1) + fid - 1].y - Ymin), FONT_HERSHEY_SIMPLEX, 0.2, Scalar(0, 0, 255), 1, 8);
					}
				}
				sprintf(Fname, "%s/Track2D/b_%d_%d_2.png", Path, camID, fid); imwrite(Fname, image_roiN);
			}
		}
	}
	printLOG("\nDone\n");
	sprintf(Fname, "%s/Track2D/fb_%.4d.txt", Path, camID);  fp = fopen(Fname, "w+");
	for (int pid = 0; pid < npts; pid++)
	{
		nf = 0;
		for (int fid = 0; fid < nframes; fid++)
			if (allpts[pid*(nframes + 1) + fid].x > 0 && allpts[pid*(nframes + 1) + fid].y > 0)
				nf++;

		fprintf(fp, "%d %d %d ", markerID[pid].x, markerID[pid].y, nf);
		for (int fid = 0; fid < nframes; fid++)
			if (allpts[pid*(nframes + 1) + fid].x > 0 && allpts[pid*(nframes + 1) + fid].y > 0)
				fprintf(fp, "%d %.4f %.4f ", fid, allpts[pid*(nframes + 1) + fid].x, allpts[pid*(nframes + 1) + fid].y);
		fprintf(fp, "\n");
	}
	fclose(fp);

	return 0;
}


//Motion prior sync
int SimulateCamerasAnd2DPointsForMoCap(char *Path, int nCams, int n3DTracks, double *Intrinsic, double *distortion, int width, int height, double radius = 5e3, bool saveGT3D = true, bool show2DImage = false, int Rate = 1, double PMissingData = 0.0, double Noise2D = 2.0, int *UnSyncFrameTimeStamp = NULL, bool backgroundPoints = false)
{
	if (UnSyncFrameTimeStamp == NULL)
	{
		UnSyncFrameTimeStamp = new int[nCams];
		for (int ii = 0; ii < nCams; ii++)
			UnSyncFrameTimeStamp[ii] = 0;
	}

	char Fname[512];
	double noise3D_CamShake = 20 / 60;
	double x, y, z, cx = 0, cy = 0, cz = 0;
	vector<Point3d> XYZ;
	sprintf(Fname, "%s/Track3D/%.4d.txt", Path, 0); FILE *fp = fopen(Fname, "r");
	if (fp == NULL)
	{
		printLOG("Cannot load %s\n", Fname);
		return 1;
	}
	while (fscanf(fp, "%lf %lf %lf", &x, &y, &z) != EOF)
	{
		XYZ.push_back(Point3d(x, y, z));
		cx += x, cy += y, cz += z;
	}
	fclose(fp);
	int nframes = (int)XYZ.size();
	cx /= nframes, cy /= nframes, cz /= nframes;

	CameraData *Camera = new CameraData[nframes*nCams];
	vector<int> angleList;
	vector<Point3d> Center;
	for (int frameID = 0; frameID < nframes; frameID++)
	{
		angleList.clear(), Center.clear();
		for (int camID = 0; camID < nCams; camID++)
		{
			int count, angleID;
			while (true)
			{
				count = 0, angleID = 5.0*cos(2.0*Pi / 100 * frameID) + 360 * camID / nCams;
				for (int ii = 0; ii < angleList.size(); ii++)
					if (angleID == angleList[ii])
						count++;
				if (count == 0)
					break;
			}
			angleList.push_back(angleID);

			double theta = 1.0*angleID / 180 * Pi;
			Point3d Noise3D(gaussian_noise(0.0, noise3D_CamShake), gaussian_noise(0.0, noise3D_CamShake), gaussian_noise(0.0, noise3D_CamShake));
			if (Noise3D.x > 3.0*noise3D_CamShake)
				Noise3D.x = 3.0*noise3D_CamShake;
			else if (Noise3D.x < -3.0 *noise3D_CamShake)
				Noise3D.x = -3.0*noise3D_CamShake;
			if (Noise3D.y > 3.0*noise3D_CamShake)
				Noise3D.y = 3.0*noise3D_CamShake;
			else if (Noise3D.y < -3.0 *noise3D_CamShake)
				Noise3D.y = -3.0*noise3D_CamShake;
			if (Noise3D.z > 3.0*noise3D_CamShake)
				Noise3D.z = 3.0*noise3D_CamShake;
			else if (Noise3D.z < -3.0 *noise3D_CamShake)
				Noise3D.z = -3.0*noise3D_CamShake;

			Camera[frameID + nframes * camID].valid = true;
			GenerateCamerasExtrinsicOnCircle(Camera[frameID + nframes * camID], theta, radius, XYZ[frameID], XYZ[frameID], Noise3D);
			SetIntrinisc(Camera[frameID + nframes * camID], Intrinsic);
			GetKFromIntrinsic(Camera[frameID + nframes * camID]);
			for (int ii = 0; ii < 7; ii++)
				Camera[frameID + nframes * camID].distortion[ii] = distortion[ii];
			AssembleP(Camera[frameID + nframes * camID]);
			Center.push_back(Point3d(Camera[frameID + nframes * camID].camCenter[0], Camera[frameID + nframes * camID].camCenter[1], Camera[frameID + nframes * camID].camCenter[2]));
		}
		angleList;
		Center;
	}

	Point2d pt;
	Point3d p3d;
	vector<Point3d> *allXYZ = new vector<Point3d>[n3DTracks];
	for (int trackID = 0; trackID < n3DTracks; trackID++)
	{
		sprintf(Fname, "%s/Track3D/%.4d.txt", Path, trackID); fp = fopen(Fname, "r");
		if (fp == NULL)
			printLOG("Cannot load %s\n", Fname);
		while (fscanf(fp, "%lf %lf %lf", &x, &y, &z) != EOF)
			allXYZ[trackID].push_back(Point3d(x, y, z));
		fclose(fp);
	}

	vector<int> UsedFrames;
	for (int camID = 0; camID < nCams; camID++)
	{
		sprintf(Fname, "%s/Intrinsic_%.4d.txt", Path, camID); fp = fopen(Fname, "w+");
		for (int frameID = 0; frameID < nframes; frameID += Rate)
		{
			if (frameID + UnSyncFrameTimeStamp[camID] > nframes || !Camera[frameID + UnSyncFrameTimeStamp[camID] + nframes * camID].valid)
				continue;

			UsedFrames.push_back(frameID + UnSyncFrameTimeStamp[camID]);
			fprintf(fp, "%d 0 0 %d %d ", frameID / Rate, width, height);
			for (int ii = 0; ii < 5; ii++)
				fprintf(fp, "%f ", Camera[frameID + UnSyncFrameTimeStamp[camID] + nframes * camID].intrinsic[ii]);
			for (int ii = 0; ii < 7; ii++)
				fprintf(fp, "%f ", distortion[ii]);
			fprintf(fp, "\n");
		}
		fclose(fp);
	}

	for (int camID = 0; camID < nCams; camID++)
	{
		sprintf(Fname, "%s/CamPose_%.4d.txt", Path, camID); fp = fopen(Fname, "w+");
		for (int frameID = 0; frameID < nframes; frameID += Rate)
		{
			if (frameID + UnSyncFrameTimeStamp[camID] > nframes || !Camera[frameID + UnSyncFrameTimeStamp[camID] + nframes * camID].valid)
				continue;

			GetrtFromRT(Camera[frameID + UnSyncFrameTimeStamp[camID] + nframes * camID].rt, Camera[frameID + UnSyncFrameTimeStamp[camID] + nframes * camID].R, Camera[frameID + UnSyncFrameTimeStamp[camID] + nframes * camID].T);

			fprintf(fp, "%d ", frameID / Rate);
			for (int jj = 0; jj < 6; jj++)
				fprintf(fp, "%.16f ", Camera[frameID + UnSyncFrameTimeStamp[camID] + nframes * camID].rt[jj]);
			fprintf(fp, "\n");
		}
		fclose(fp);
	}

	vector<ImgPtEle> *PerCam_UV = new vector<ImgPtEle>[nCams*n3DTracks];
	for (int camID = 0; camID < nCams; camID++)
	{
		for (int trackID = 0; trackID < n3DTracks; trackID++)
		{
			int nf = 0;
			for (int frameID = 0; frameID < nframes; frameID += Rate)
			{
				if (frameID + UnSyncFrameTimeStamp[camID] > allXYZ[trackID].size() - 1)
					continue;
				if (frameID + UnSyncFrameTimeStamp[camID] > nframes)
					continue;
				nf++;
			}

			//Simulate random missing data
			vector<int> randomNumber;
			for (int ii = 0; ii < nf; ii++)
				randomNumber.push_back(ii);
			random_shuffle(randomNumber.begin(), randomNumber.end());

			int nMissingData = (int)(PMissingData*nf);
			sort(randomNumber.begin(), randomNumber.begin() + nMissingData);

			for (int frameID = 0; frameID < nframes; frameID += Rate)
			{
				if (frameID + UnSyncFrameTimeStamp[camID] > allXYZ[trackID].size() - 1)
					continue;
				if (frameID + UnSyncFrameTimeStamp[camID] > nframes)
					continue;

				bool missed = false;
				for (int ii = 0; ii < nMissingData; ii++)
				{
					if (randomNumber[ii] == frameID / Rate)
					{
						missed = true; break;
					}
				}
				if (missed)
					continue;

				ProjectandDistort(allXYZ[trackID][frameID + UnSyncFrameTimeStamp[camID]], &pt, Camera[frameID + UnSyncFrameTimeStamp[camID] + camID * nframes].P, Camera[frameID + UnSyncFrameTimeStamp[camID] + camID * nframes].K, Camera[frameID + UnSyncFrameTimeStamp[camID] + camID * nframes].distortion);
				Point2d Noise(gaussian_noise(0.0, Noise2D), gaussian_noise(0.0, Noise2D));
				if (Noise.x > 3.0*Noise2D)
					Noise.x = 3.0*Noise2D;
				else if (Noise.x < -3.0 *Noise2D)
					Noise.x = -3.0*Noise2D;
				if (Noise.y > 3.0*Noise2D)
					Noise.y = 3.0*Noise2D;
				else if (Noise.y < -3.0 *Noise2D)
					Noise.y = -3.0*Noise2D;
				pt.x += Noise.x, pt.y += Noise.y;

				if (pt.x < 0 || pt.x > width - 1 || pt.y < 0 || pt.y > height - 1)
					continue;

				ImgPtEle ptEle;
				ptEle.pt2D = pt, ptEle.viewID = camID, ptEle.frameID = frameID / Rate,
					ptEle.imWidth = width, ptEle.imHeight = height;
				ptEle.pt3D = allXYZ[trackID][frameID + UnSyncFrameTimeStamp[camID]];
				ptEle.timeStamp = frameID + UnSyncFrameTimeStamp[camID];
				PerCam_UV[camID*n3DTracks + trackID].push_back(ptEle);
			}
		}
	}

	int nStatPts = 3000;
	Corpus CorpusInfo; CorpusInfo.nCameras = nCams, CorpusInfo.n3dPoints = nStatPts;
	if (backgroundPoints)
	{
		CorpusInfo.xyz.reserve(nStatPts);
		for (int ii = 0; ii < nStatPts; ii++)
		{
			double angle = 2.0*Pi*rand() / RAND_MAX;
			Point3d bg(XYZ[0].x + 15.0*radius*cos(angle), XYZ[0].y + 5.0*radius*sin(0.5*Pi*rand() / RAND_MAX - 0.25*Pi), XYZ[0].z + 15.0*radius*sin(angle));
			CorpusInfo.xyz.push_back(bg);
		}

		vector<int> selectedCamID3D;
		vector<Point2d> uv3D;
		vector<double> scale3D;
		CorpusInfo.viewIdAll3D.reserve(nStatPts);
		CorpusInfo.uvAll3D.reserve(nStatPts);
		CorpusInfo.scaleAll3D.reserve(nStatPts);
		for (int ii = 0; ii < nStatPts; ii++)
		{
			CorpusInfo.viewIdAll3D.push_back(selectedCamID3D); CorpusInfo.viewIdAll3D.back().reserve(nframes*nCams);
			CorpusInfo.uvAll3D.push_back(uv3D); CorpusInfo.uvAll3D.back().reserve(nframes*nCams);
			CorpusInfo.scaleAll3D.push_back(scale3D); CorpusInfo.scaleAll3D.back().reserve(nframes*nCams);
		}

		for (int cid = 0; cid < nCams; cid++)
		{
			sprintf(Fname, "%s/%d", Path, cid);
			makeDir(Fname);
		}

		for (int fid = 0; fid < nframes; fid += Rate)
		{
			for (int cid = 0; cid < nCams; cid++)
			{
				sprintf(Fname, "%s/%d/PnP/Inliers_%.4d.txt", Path, cid, fid / Rate); fp = fopen(Fname, "w+");
				for (int pid = 0; pid < nStatPts; pid++)
				{
					if (fid + UnSyncFrameTimeStamp[cid] > allXYZ[0].size() - 1)
						continue;
					if (fid + UnSyncFrameTimeStamp[cid] > nframes)
						continue;

					CameraData *cam = &Camera[fid + UnSyncFrameTimeStamp[cid] + cid * nframes];
					ProjectandDistort(CorpusInfo.xyz[pid], &pt, cam[0].P, cam[0].K, cam[0].distortion);
					Point2d Noise(gaussian_noise(0.0, Noise2D), gaussian_noise(0.0, Noise2D));
					if (Noise.x > 3.0*Noise2D)
						Noise.x = 3.0*Noise2D;
					else if (Noise.x < -3.0 *Noise2D)
						Noise.x = -3.0*Noise2D;
					if (Noise.y > 3.0*Noise2D)
						Noise.y = 3.0*Noise2D;
					else if (Noise.y < -3.0 *Noise2D)
						Noise.y = -3.0*Noise2D;
					pt.x += Noise.x, pt.y += Noise.y;

					if (pt.x < 0 || pt.x > width - 1 || pt.y < 0 || pt.y > height - 1)
						continue;

					CorpusInfo.viewIdAll3D[pid].push_back(cid*nframes + fid / Rate);
					CorpusInfo.uvAll3D[pid].push_back(pt);
					CorpusInfo.scaleAll3D[pid].push_back(1.0);

					fprintf(fp, "%d %.4f %.4f %.4f %.8e %.8e 1.0\n", pid, CorpusInfo.xyz[pid].x, CorpusInfo.xyz[pid].y, CorpusInfo.xyz[pid].z, pt.x, pt.y);
				}
				fclose(fp);
			}
		}

		sprintf(Fname, "%s/Corpus", Path); makeDir(Fname);

		//xyz rgb viewid3D pointid3D 3dId2D cumpoint
		sprintf(Fname, "%s/Corpus/n3dGL.xyz", Path);	fp = fopen(Fname, "w+");
		for (int jj = 0; jj < CorpusInfo.xyz.size(); jj++)
			fprintf(fp, "%d %lf %lf %lf \n", jj, CorpusInfo.xyz[jj].x, CorpusInfo.xyz[jj].y, CorpusInfo.xyz[jj].z);
		fclose(fp);

		sprintf(Fname, "%s/Corpus/Corpus_3D.txt", Path);
		fp = fopen(Fname, "w+");
		CorpusInfo.n3dPoints = (int)CorpusInfo.xyz.size();
		fprintf(fp, "%d %d ", CorpusInfo.nCameras, CorpusInfo.n3dPoints);

		//xyz rgb viewid3D pointid3D 3dId2D cumpoint
		fprintf(fp, "0\n");
		for (int jj = 0; jj < CorpusInfo.xyz.size(); jj++)
			fprintf(fp, "%lf %lf %lf \n", CorpusInfo.xyz[jj].x, CorpusInfo.xyz[jj].y, CorpusInfo.xyz[jj].z);
		fclose(fp);

		sprintf(Fname, "%s/Corpus/Corpus_viewIdAll3D.txt", Path); fp = fopen(Fname, "w+");
		for (int jj = 0; jj < CorpusInfo.n3dPoints; jj++)
		{
			int nviews = (int)CorpusInfo.viewIdAll3D[jj].size();
			fprintf(fp, "%d ", nviews);
			for (int ii = 0; ii < nviews; ii++)
				fprintf(fp, "%d ", CorpusInfo.viewIdAll3D[jj][ii]);
			fprintf(fp, "\n");
		}
		fclose(fp);

		sprintf(Fname, "%s/Corpus/Corpus_uvAll3D.txt", Path); fp = fopen(Fname, "w+");
		for (int jj = 0; jj < CorpusInfo.n3dPoints; jj++)
		{
			int npts = (int)CorpusInfo.uvAll3D[jj].size();
			fprintf(fp, "%d ", npts);
			for (int ii = 0; ii < npts; ii++)
				fprintf(fp, "%8f %8f %.2f ", CorpusInfo.uvAll3D[jj][ii].x, CorpusInfo.uvAll3D[jj][ii].y, CorpusInfo.scaleAll3D[jj][ii]);
			fprintf(fp, "\n");
		}
		fclose(fp);
	}

	sprintf(Fname, "%s/Track2D", Path), makeDir(Fname);
	for (int camID = 0; camID < nCams; camID++)
	{
		sprintf(Fname, "%s/Track2D/Ultimate_%.4d.txt", Path, camID); fp = fopen(Fname, "w+");
		fprintf(fp, "%d\n", n3DTracks);
		for (int trackID = 0; trackID < n3DTracks; trackID++)
		{
			fprintf(fp, "%d %d ", trackID, (int)PerCam_UV[camID*n3DTracks + trackID].size());
			for (int fid = 0; fid < (int)PerCam_UV[camID*n3DTracks + trackID].size(); fid++)
				fprintf(fp, "%d %.16f %.16f 1.0 ", PerCam_UV[camID*n3DTracks + trackID][fid].frameID, PerCam_UV[camID*n3DTracks + trackID][fid].pt2D.x, PerCam_UV[camID*n3DTracks + trackID][fid].pt2D.y);
			fprintf(fp, "\n");
		}
		fclose(fp);
	}

	if (saveGT3D)
	{
		for (int trackID = 0; trackID < n3DTracks; trackID++)
		{
			sprintf(Fname, "%s/GTTrack_%.4d.txt", Path, trackID); remove(Fname);	fp = fopen(Fname, "w+");
			for (int camID = 0; camID < nCams; camID++)
			{
				for (int ii = 0; ii < (int)PerCam_UV[camID*n3DTracks + trackID].size(); ii++)
				{
					ImgPtEle &x = PerCam_UV[camID*n3DTracks + trackID][ii];
					fprintf(fp, "%.4f %.4f %.4f %.4f %d %d\n", PerCam_UV[camID*n3DTracks + trackID][ii].pt3D.x, PerCam_UV[camID*n3DTracks + trackID][ii].pt3D.y, PerCam_UV[camID*n3DTracks + trackID][ii].pt3D.z,
						PerCam_UV[camID*n3DTracks + trackID][ii].timeStamp, PerCam_UV[camID*n3DTracks + trackID][ii].viewID, PerCam_UV[camID*n3DTracks + trackID][ii].frameID);
				}
			}
			fclose(fp);
		}
	}

	/*sprintf(Fname, "%s/Track2D", Path), makeDir(Fname);
	for (int camID = 0; camID < nCams; camID++)
	{
	sprintf(Fname, "%s/Track2D/%.4d.txt", Path, camID); fp = fopen(Fname, "w+");
	for (int trackID = 0; trackID < n3DTracks; trackID++)
	{
	int nf = 0;
	for (int frameID = 0; frameID < nframes; frameID += Rate)
	{
	if (frameID + UnSyncFrameTimeStamp[camID] > allXYZ[trackID].size() - 1)
	continue;
	if (frameID + UnSyncFrameTimeStamp[camID] > nframes)
	continue;
	nf++;
	}

	//Simulate random missing data
	vector<int> randomNumber;
	for (int ii = 0; ii < nf; ii++)
	randomNumber.push_back(ii);
	random_shuffle(randomNumber.begin(), randomNumber.end());

	int nMissingData = (int)(PMissingData*nf);
	sort(randomNumber.begin(), randomNumber.begin() + nMissingData);

	fprintf(fp, "%d %d ", trackID, nf - nMissingData);
	for (int frameID = 0; frameID < nframes; frameID += Rate)
	{
	if (frameID + UnSyncFrameTimeStamp[camID] > allXYZ[trackID].size() - 1)
	continue;
	if (frameID + UnSyncFrameTimeStamp[camID] > nframes)
	continue;

	bool missed = false;
	for (int ii = 0; ii < nMissingData; ii++)
	{
	if (randomNumber[ii] == frameID / Rate)
	{
	missed = true; break;
	}
	}
	if (missed)
	continue;

	ProjectandDistort(allXYZ[trackID][frameID + UnSyncFrameTimeStamp[camID]], &pt, Camera[frameID + UnSyncFrameTimeStamp[camID] + camID*nframes].P, Camera[frameID + UnSyncFrameTimeStamp[camID] + camID*nframes].K, Camera[frameID + UnSyncFrameTimeStamp[camID] + camID*nframes].distortion);
	Point2d Noise(gaussian_noise(0.0, Noise2D), gaussian_noise(0.0, Noise2D));
	if (Noise.x > 3.0*Noise2D)
	Noise.x = 3.0*Noise2D;
	else if (Noise.x < -3.0 *Noise2D)
	Noise.x = -3.0*Noise2D;
	if (Noise.y > 3.0*Noise2D)
	Noise.y = 3.0*Noise2D;
	else if (Noise.y < -3.0 *Noise2D)
	Noise.y = -3.0*Noise2D;
	pt.x += Noise.x, pt.y += Noise.y;
	fprintf(fp, "%d %.16f %.16f ", frameID / Rate, pt.x, pt.y);
	}
	fprintf(fp, "\n");
	}
	fclose(fp);
	}*/

	if (show2DImage)
	{
		Mat Img(height, width, CV_8UC3, Scalar(0, 0, 0)), displayImg;
		vector<Scalar> colors;
		colors.push_back(Scalar(0, 0, 255));
		colors.push_back(Scalar(0, 128, 255));
		colors.push_back(Scalar(0, 255, 255));
		colors.push_back(Scalar(0, 255, 0));
		colors.push_back(Scalar(255, 128, 0));
		colors.push_back(Scalar(255, 255, 0));
		colors.push_back(Scalar(255, 0, 0));
		colors.push_back(Scalar(255, 0, 255));
		colors.push_back(Scalar(255, 255, 255));
		namedWindow("Image", CV_WINDOW_NORMAL);

		for (int camID = 0; camID < nCams; camID++)
		{
			for (int frameID = 0; frameID < nframes; frameID++)
			{
				if (frameID + UnSyncFrameTimeStamp[camID] > allXYZ[0].size() - 1)
					continue;
				if (frameID + UnSyncFrameTimeStamp[camID] > nframes)
					continue;

				displayImg = Img.clone();
				for (int trackID = 0; trackID < n3DTracks; trackID++)
				{
					ProjectandDistort(allXYZ[trackID][frameID + UnSyncFrameTimeStamp[camID]], &pt, Camera[frameID + nframes * camID].P, Camera[frameID + UnSyncFrameTimeStamp[camID] + camID * nframes].K, Camera[frameID + UnSyncFrameTimeStamp[camID] + camID * nframes].distortion);
					circle(displayImg, pt, 4, colors[trackID % 9], 1, 8, 0);
				}
				for (int statID = 0; statID < nStatPts && backgroundPoints; statID++)
				{
					CameraData *cam = &Camera[frameID + UnSyncFrameTimeStamp[camID] + camID * nframes];
					ProjectandDistort(CorpusInfo.xyz[statID], &pt, cam[0].P, cam[0].K, cam[0].distortion);
					if (pt.x < 0 || pt.x > width - 1 || pt.y < 0 || pt.y > height - 1)
						continue;
					circle(displayImg, pt, 4, colors[0], 1, 8, 0);
				}

				sprintf(Fname, "Cam %d: frame %d", camID, frameID);
				CvPoint text_origin = { width / 30, height / 30 };
				putText(displayImg, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 3.0 * 640 / Img.cols, CV_RGB(255, 0, 0), 2);
				imshow("Image", displayImg);
				waitKey(1);
			}
		}
	}
	return 0;
}
int TestMotionPriorSTBA(char *Path)
{

	//Mocap
	{
		const int nCams = 10, width = 1920, height = 1080, startF = 0, stopF = 1000, rate = 10, npts = 31;
		double Intrinsic[5] = { 1500, 1500, 0, 960, 540 }, distortion[7] = { 0, 0, 0, 0, 0, 0, 0 }, radius = 3000, RealOverSfm = 1.0, PMissingData = 0.0, noise2D = 2.0;
		int UnSyncFrameTimeStamp[] = { 0, 1, 29, 5, 16, 3, 27, 2, 18, 4 };
		//SimulateCamerasAnd2DPointsForMoCap(Path, nCams, npts, Intrinsic, distortion, width, height, radius, true, false, rate, PMissingData, noise2D, UnSyncFrameTimeStamp, true);

		//SpatialTemporalCalibInTheWildDriver(Path, nCams, startF, stopF, 1, startF, stopF, stopF + 1, 1, 6);

		double lamda = 1.3, searchStep = 0.1;
		int SearchRange = 10;
		MotionPriorSTReconstructionDriver(Path, nCams, startF, stopF, npts, 1.0, lamda, SearchRange, searchStep, 2);

		//visualizationDriver(Path, nCams, startF, stopF, 1, false, 1, false, true, false, startF, 0);
	}

	//Checker
	{
		const int nCams = 7, allNpts = 88, startF = 0, stopF = 1200;
		int SearchRange = 10; double SearchStep = 0.1;
		double lamdaData = 8.0e-1, scaleReal2Sfm = 1.0;

		//const double square_size = 88;
		//const int width = 1920, height = 1080, bh = 8, bw = 11;
		//int sampleCalibFrameStep = 1, boardType = 1;
		//for (int camID = 0; camID < nCams; camID++)
		//SingleCameraCalibration(Path, camID, startF, stopF, bw, bh, true, sampleCalibFrameStep, square_size, boardType, width, height);

		//SpatialTemporalCalibInTheWildDriver(Path, nCams, startF, stopF, 1, startF, stopF, stopF + 1, 1, 60, 2, 6);
		//MotionPriorSTReconstructionDriver(Path, nCams, startF, stopF, allNpts, scaleReal2Sfm, lamdaData, SearchRange, SearchStep, 2);

		vector<int> vCams;
		for (int ii = 0; ii < nCams; ii++)
			vCams.push_back(ii);
		//visualizationDriver(Path, vCams, startF, stopF, 1, true, 1, false, true, false, 0, 1);
	}
	//Jump
	{
		int nCams = 8, startF = 100, stopF = 600, allNpts = 3172;
		double real2sfm = 1.0, lamda = 0.8, searchStep = 0.1;
		int SearchRange = 20;
		int frameTimeStamp[] = { 0, -6, -51, -6, -44, -10, -12, -2 };//for jump rough

																	 //vector<int> sCams;
																	 //for (int ii = 0; ii < nCams; ii++)
																	 //sCams.push_back(ii);
																	 //DownSampleTracking(Path, sCams, startF, stopF, 4);
																	 //DownSampleVideoCameraPose(Path, sCams, startF, stopF, 4);
																	 //DownSampleImageSequence(Path, sCams, startF, stopF, 4);
																	 //return 0;

																	 //SpatialTemporalCalibInTheWildDriver(Path, nCams, startF, stopF, 1, 460, 560, 10, 1, 2);
																	 //SpatialTemporalCalibInTheWildDriver(Path, nCams, startF, stopF, 1, 460, 560, 10, 1, 3);
																	 //SpatialTemporalCalibInTheWildDriver(Path, nCams, startF, stopF, 1, 460, 560, 10, 1, 4);
																	 //SpatialTemporalCalibInTheWildDriver(Path, nCams, startF, stopF, 1, 460, 560, 10, 1, 5);
																	 //SpatialTemporalCalibInTheWildDriver(Path, nCams, startF, stopF, 1, 460, 560, 10, 1, 6);

																	 //#pragma omp parallel for
																	 //for (int cid = 0; cid < nCams; cid++)
																	 //VisualizeTracking(Path, cid, startF, 1, 150, 4, 2);

																	 //RenderSuperCameraFromMultipleUnSyncedCameras(Path, 0, stopF, 1, true);
																	 //MotionPriorSTReconstructionDriver(Path, nCams, startF, stopF, allNpts, real2sfm, lamda, SearchRange, searchStep, 2);
																	 //MotionPriorSTReconstructionDriver(Path, nCams, startF, stopF, allNpts, real2sfm, lamda, SearchRange, searchStep, 4);
																	 //visualizationDriver(Path, nCams, startF, stopF, 1, true, 1, false, true, false, 10000, 1);
	}


	//Dance
	{
		int startF = 100, stopF = 400, increF = 1,
			startTF = 500, stopTF = 1490, Tstep = 30, increTF = 1,
			nCams = 10, allNpts = 4146;
		double real2sfm = 1.0, lamda = 1.0e-8, searchStep = 0.1;
		int SearchRange = 20;

		//vector<int> sCams;
		//for (int ii = 0; ii < 10; ii++)
		//sCams.push_back(ii);
		//DownSampleTracking(Path, sCams, 0, 1600, 4);
		//DownSampleVideoCameraPose(Path, sCams, 0, 1600, 4);

		//#pragma omp parallel for
		//for (int cid = 0; cid < nCams; cid++)
		//VisualizeTracking(Path, cid, startF, increF, 60, 20, 2);

		//SpatialTemporalCalibInTheWildDriver(Path, nCams, startF, stopF, increF, startTF, stopTF, Tstep, increTF, 3);
		MotionPriorSTReconstructionDriver(Path, nCams, startF, stopF, allNpts, real2sfm, lamda, SearchRange, searchStep, 2);

		vector<int> vCams;
		for (int ii = 0; ii < nCams; ii++)
			vCams.push_back(ii);
		//visualizationDriver(Path, vCams, startF, stopF, 1, true, 1, false, true, false, startF, 1);
	}
	return 0;
}


int GroundPlanFittingDriver(char *FnameIn, char *FnameOut)
{
	if (!IsFileExist(FnameIn))
		return 1;

	Vector3d xyz;
	vector<int> Samp, selected;
	vector<Vector3d> Vxyz;
	Vxyz.reserve(1000000); Samp.reserve(1000000), selected.reserve(100000);
	FILE *fp = fopen(FnameIn, "r");
	while (fscanf(fp, "%lf %lf %lf ", &xyz(0), &xyz(1), &xyz(2)) != EOF)
		Vxyz.emplace_back(xyz), Samp.push_back(Vxyz.size());
	fclose(fp);

	int nBest = 0;
	double norm_normal, error = 0;
	double *A = new double[Vxyz.size() * 3], *B = new double[Vxyz.size()];
	Vector3d normal_best, normal;
	vector<Vector3d> sPoints;
	for (int kk = 0; kk < 100; kk++)
	{
		if (kk % 100 == 0)
			printf("%d..", kk);
		selected.clear();
		random_shuffle(Samp.begin(), Samp.end());

		//fit plane
		for (int ii = 0; ii < 3; ii++)
			selected.push_back(Samp[ii]);
		best_plane_from_points(Vxyz, selected, normal, A, B);

		//test hypo
		norm_normal = normal.norm();
		for (int ii = 0; ii < (int)Vxyz.size(); ii++)
		{
			error = abs(Vxyz[ii].dot(normal) + 1) / norm_normal;
			if (error < 0.01)//1cm
				selected.push_back(ii);
		}

		if (selected.size() > nBest)
		{
			nBest = selected.size();
			best_plane_from_points(Vxyz, selected, normal_best, A, B);

			//test hypo
			norm_normal = normal_best.norm();
			for (int ii = 0; ii < (int)Vxyz.size(); ii++)
			{
				error = abs(Vxyz[ii].dot(normal_best) + 1) / norm_normal;
				if (error < 0.01)//1cm
					nBest++;
			}

			if (nBest > 8 * Vxyz.size() / 10)
				break;
		}
	}
	printLOG("NBest: %d/%zd\n", nBest, Vxyz.size());

	fp = fopen(FnameOut, "w");
	fprintf(fp, "%.16e %.16e %.16e\n", normal_best(0), normal_best(1), normal_best(2));
	fclose(fp);

	delete[]A, delete[]B;

	return 0;
}



namespace constants {
	const unsigned char UNKNOWN = 0;
	const unsigned char DIRICHLET_BD = 1;
	const unsigned char NEUMANN_BD = 2;
}
enum CloneType {
	CLONE_FOREGROUND_GRADIENTS,
	CLONE_AVERAGED_GRADIENTS,
	CLONE_MIXED_GRADIENTS
};

using namespace Eigen;

bool findOverlap(cv::InputArray background, cv::InputArray foreground, int offsetX, int offsetY, cv::Rect &rBackground, cv::Rect &rForeground)
{
	cv::Mat bg = background.getMat();
	cv::Mat fg = foreground.getMat();


	rBackground = cv::Rect(0, 0, bg.cols, bg.rows) &
		cv::Rect(offsetX, offsetY, fg.cols, fg.rows);


	// Compensate for negative offsets. If offset < 0, offset in foreground is positive.
	rForeground = cv::Rect(std::max<int>(-offsetX, 0),
		std::max<int>(-offsetY, 0),
		rBackground.width,
		rBackground.height);


	return rForeground.area() > 0;

}
void computeMixedGradientVectorField(cv::InputArray background, cv::InputArray foreground, cv::OutputArray vx_, cv::OutputArray vy_)
{
	cv::Mat bg = background.getMat();
	cv::Mat fg = foreground.getMat();

	const int channels = bg.channels();

	vx_.create(bg.size(), CV_MAKETYPE(CV_32F, channels));
	vy_.create(bg.size(), CV_MAKETYPE(CV_32F, channels));

	cv::Mat vx = vx_.getMat();
	cv::Mat vy = vy_.getMat();

	cv::Mat kernelx = (cv::Mat_<float>(1, 3) << -0.5, 0, 0.5);
	cv::Mat kernely = (cv::Mat_<float>(3, 1) << -0.5, 0, 0.5);

	cv::Mat vxf, vyf, vxb, vyb;
	cv::filter2D(fg, vxf, CV_32F, kernelx, cv::Point(-1, -1), 0, cv::BORDER_REPLICATE);
	cv::filter2D(fg, vyf, CV_32F, kernely, cv::Point(-1, -1), 0, cv::BORDER_REPLICATE);
	cv::filter2D(bg, vxb, CV_32F, kernelx, cv::Point(-1, -1), 0, cv::BORDER_REPLICATE);
	cv::filter2D(bg, vyb, CV_32F, kernely, cv::Point(-1, -1), 0, cv::BORDER_REPLICATE);


	for (int id = 0; id <= (vx.rows * vx.cols * channels - channels); ++id)
	{
		const cv::Vec2f g[2] = {
			cv::Vec2f(vxf.ptr<float>()[id], vyf.ptr<float>()[id]),
			cv::Vec2f(vxb.ptr<float>()[id], vyb.ptr<float>()[id])
		};

		int which = (g[0].dot(g[0]) > g[1].dot(g[1])) ? 0 : 1;

		vx.ptr<float>()[id] = g[which][0];
		vy.ptr<float>()[id] = g[which][1];
	}
}
void computeWeightedGradientVectorField(cv::InputArray background, cv::InputArray foreground, cv::OutputArray vx, cv::OutputArray vy, float weightForeground)
{

	cv::Mat bg = background.getMat();
	cv::Mat fg = foreground.getMat();

	cv::Mat kernelx = (cv::Mat_<float>(1, 3) << -0.5, 0, 0.5);
	cv::Mat kernely = (cv::Mat_<float>(3, 1) << -0.5, 0, 0.5);

	cv::Mat vxf, vyf, vxb, vyb;
	cv::filter2D(fg, vxf, CV_32F, kernelx, cv::Point(-1, -1), 0, cv::BORDER_REPLICATE);
	cv::filter2D(fg, vyf, CV_32F, kernely, cv::Point(-1, -1), 0, cv::BORDER_REPLICATE);
	cv::filter2D(bg, vxb, CV_32F, kernelx, cv::Point(-1, -1), 0, cv::BORDER_REPLICATE);
	cv::filter2D(bg, vyb, CV_32F, kernely, cv::Point(-1, -1), 0, cv::BORDER_REPLICATE);

	cv::addWeighted(vxf, weightForeground, vxb, 1.f - weightForeground, 0, vx);
	cv::addWeighted(vyf, weightForeground, vyb, 1.f - weightForeground, 0, vy);
}

bool isSameSize(cv::Size a, cv::Size b) {
	return a.width == b.width && a.height == b.height;
}
cv::Mat makeContinuous(cv::Mat m) {
	if (!m.isContinuous()) {
		m = m.clone();
	}
	return m;
}

//Build a one dimensional index lookup for element in mask. 
cv::Mat buildPixelToIndexLookup(cv::InputArray mask, int &npixel)
{
	cv::Mat_<uchar> m = makeContinuous(mask.getMat());

	cv::Mat_<int> pixelToIndex(mask.size());
	npixel = 0;

	int *pixelToIndexPtr = pixelToIndex.ptr<int>();
	const uchar *maskPtr = m.ptr<uchar>();

	for (int id = 0; id < (m.rows * m.cols); ++id) {
		pixelToIndexPtr[id] = (maskPtr[id] == constants::DIRICHLET_BD) ? -1 : npixel++;
	}

	return pixelToIndex;
}
void solvePoissonEquations(cv::InputArray f_, cv::InputArray bdMask_, cv::InputArray bdValues_, cv::OutputArray result_)
{
	// Input validation

	CV_Assert(
		!f_.empty() &&
		isSameSize(f_.size(), bdMask_.size()) &&
		isSameSize(f_.size(), bdValues_.size())
	);

	CV_Assert(
		f_.depth() == CV_32F &&
		bdMask_.depth() == CV_8U &&
		bdValues_.depth() == CV_32F &&
		f_.channels() == bdValues_.channels() &&
		bdMask_.channels() == 1);

	// We assume continuous memory on input
	cv::Mat f = makeContinuous(f_.getMat());
	cv::Mat_<uchar> bm = makeContinuous(bdMask_.getMat());
	cv::Mat bv = makeContinuous(bdValues_.getMat());

	// Allocate output
	result_.create(f.size(), f.type());
	cv::Mat r = result_.getMat();
	bv.copyTo(r, bm == constants::DIRICHLET_BD);

	// The number of unknowns correspond to the number of pixels on the rectangular region 
	// that don't have a Dirichlet boundary condition.
	int nUnknowns = 0;
	cv::Mat_<int> unknownIdx = buildPixelToIndexLookup(bm, nUnknowns);

	if (nUnknowns == 0) {
		// No unknowns left, we're done
		return;
	}
	else if (nUnknowns == f.size().area()) {
		// All unknowns, will not lead to a unique solution
		// TODO emit warning
	}

	const cv::Rect bounds(0, 0, f.cols, f.rows);

	// Directional indices
	const int center = 0;
	const int north = 1;
	const int east = 2;
	const int south = 3;
	const int west = 4;

	// Neighbor offsets in all directions
	const int offsets[5][2] = { { 0, 0 },{ 0, -1 },{ 1, 0 },{ 0, 1 },{ -1, 0 } };

	// Directional opposite
	const int opposite[5] = { center, south, west, north, east };
	const int channels = f.channels();

	std::vector< Eigen::Triplet<float> > lhsTriplets;
	lhsTriplets.reserve(nUnknowns * 5);

	Eigen::MatrixXf rhs(nUnknowns, channels);
	rhs.setZero();

	// Loop over domain once. The coefficient matrix A is the same for all
	// channels, the right hand side is channel dependent.

	for (int y = 0; y < f.rows; ++y) {
		for (int x = 0; x < r.cols; ++x) {

			const cv::Point p(x, y);
			const int pid = unknownIdx(p);

			if (pid == -1) {
				// Current pixel is not an unknown, skip
				continue;
			}

			// Start coefficients of left hand side. Based on discrete Laplacian with central difference.
			float lhs[] = { -4.f, 1.f, 1.f, 1.f, 1.f };

			const bool hasNeumann = (bm(p) == constants::NEUMANN_BD);

			if (hasNeumann) {

				// Implementation note:
				//
				// We first sweep over all neighbors and apply Neumann boundary (NB) conditions if necessary.
				// NBs are currently only applied if the neighbor is not in the domain or it has Dirichlet
				// boundary condition (DB).
				//
				// When the neighbor is not available we introduce ghost points which are immediately
				// removed by substitution. Assume that we are at a pixel C at the top border (not corner)
				// and that pixel is assigned a NB = 1. Denoting the pixels C, N, E, S, W we have for C
				// the Laplacian
				//      1: -4C + N + E + S + W = f(x)
				// From NB we have
				//      2: (N - S) * 0.5 = 1
				// As N is not in the domain we need to get rid of it through substitution. Rewriting 2:
				//      N = 2 + S
				// and substituting in 1:
				//      -4C + (2 + S) + E + S + W = f(x)
				//      -4C + E + 2S + W = f(x) - 2

				for (int n = 1; n < 5; ++n) {
					const cv::Point q(x + offsets[n][0], y + offsets[n][1]);

					if (!bounds.contains(q) || bm(q) == constants::DIRICHLET_BD) {
						lhs[opposite[n]] += 1.0f;
						lhs[n] = 0.f;
						rhs.row(pid) += 2.f * Eigen::Map<Eigen::VectorXf>(bv.ptr<float>(p.y, p.x), channels);
					}
				}
			}

			for (int n = 1; n < 5; ++n) {
				const cv::Point q(x + offsets[n][0], y + offsets[n][1]);

				const bool hasNeighbor = bounds.contains(q);
				const bool isNeighborDirichlet = hasNeighbor && (bm(q) == constants::DIRICHLET_BD);

				if (!hasNeumann && !hasNeighbor) {
					lhs[center] += lhs[n];
					lhs[n] = 0.f;
				}
				else if (isNeighborDirichlet) {

					// Implementation note:
					//
					// Dirichlet boundary conditions (DB) turn neighbor unknowns into knowns (data) and
					// are therefore moved to the right hand side. Alternatively, we could add more
					// equations for these pixels setting the lhs 1 and rhs to the Dirichlet value, but
					// that would unnecessarily blow up the equation system.

					rhs.row(pid) -= lhs[n] * Eigen::Map<Eigen::VectorXf>(bv.ptr<float>(q.y, q.x), channels);
					lhs[n] = 0.f;
				}
			}


			// Add f to rhs.
			rhs.row(pid) += Eigen::Map<Eigen::VectorXf>(f.ptr<float>(p.y, p.x), channels);

			// Build triplets for row              
			for (int n = 0; n < 5; ++n) {
				if (lhs[n] != 0.f) {
					const cv::Point q(x + offsets[n][0], y + offsets[n][1]);
					lhsTriplets.push_back(Eigen::Triplet<float>(pid, unknownIdx(q), lhs[n]));
				}
			}

		}
	}

	// Solve the sparse linear system of equations

	Eigen::SparseMatrix<float> A(nUnknowns, nUnknowns);
	A.setFromTriplets(lhsTriplets.begin(), lhsTriplets.end());

	Eigen::SparseLU< Eigen::SparseMatrix<float> > solver;
	solver.analyzePattern(A);
	solver.factorize(A);

	Eigen::MatrixXf result(nUnknowns, channels);
	for (int c = 0; c < channels; ++c)
		result.col(c) = solver.solve(rhs.col(c));


	// Copy results back

	for (int y = 0; y < f.rows; ++y) {
		for (int x = 0; x < f.cols; ++x) {
			const cv::Point p(x, y);
			const int pid = unknownIdx(p);

			if (pid > -1) {
				Eigen::Map<Eigen::VectorXf>(r.ptr<float>(p.y, p.x), channels) = result.row(pid);
			}

		}
	}

}
void seamlessClone(cv::InputArray background, cv::InputArray foreground, cv::InputArray foregroundMask, int offsetX, int offsetY, cv::OutputArray destination, CloneType type)
{
	// Copy original background as we only solve for the overlapping area of the translated foreground mask.
	background.getMat().copyTo(destination);

	// Find overlapping region. We will only perform on this region
	cv::Rect rbg, rfg;
	if (!findOverlap(background, foreground, offsetX, offsetY, rbg, rfg))
		return;

	// Compute the guidance vector field
	cv::Mat vx, vy;
	switch (type) {
	case CLONE_FOREGROUND_GRADIENTS:
		computeWeightedGradientVectorField(background.getMat()(rbg), foreground.getMat()(rfg), vx, vy, 1.f);
		break;

	case CLONE_AVERAGED_GRADIENTS:
		computeWeightedGradientVectorField(background.getMat()(rbg), foreground.getMat()(rfg), vx, vy, 0.5f);
		break;

	case CLONE_MIXED_GRADIENTS:
		computeMixedGradientVectorField(background.getMat()(rbg), foreground.getMat()(rfg), vx, vy);
		break;

	default:
		break;
	}


	// For the Poisson equation the divergence of the guidance field is necessary.
	cv::Mat vxx, vyy;
	cv::Mat kernelx = (cv::Mat_<float>(1, 3) << -0.5, 0, 0.5);
	cv::Mat kernely = (cv::Mat_<float>(3, 1) << -0.5, 0, 0.5);
	cv::filter2D(vx, vxx, CV_32F, kernelx);
	cv::filter2D(vy, vyy, CV_32F, kernely);

	cv::Mat f = vxx + vyy;

	cv::Mat boundaryMask(rfg.size(), CV_8UC1);
	cv::threshold(foregroundMask.getMat()(rfg), boundaryMask, constants::UNKNOWN, constants::DIRICHLET_BD, cv::THRESH_BINARY_INV);
	cv::rectangle(boundaryMask, cv::Rect(0, 0, boundaryMask.cols, boundaryMask.rows), constants::DIRICHLET_BD, 1);

	cv::Mat boundaryValues(rfg.size(), CV_MAKETYPE(CV_32F, background.channels()));
	background.getMat()(rbg).convertTo(boundaryValues, CV_32F);

	// Solve Poisson equation
	cv::Mat result;
	solvePoissonEquations(f, boundaryMask, boundaryValues, result);

	// Copy result to destination image.
	result.convertTo(destination.getMat()(rbg), CV_8U);
}
int AllBackgroundButHumanBlurring(char *Path, int cid, int startF, int stopF, int increF, int nPeople, int w, int h, double resizeFactor)
{
	char Fname[512];
	sprintf(Fname, "%s/Vis/Feather", Path); makeDir(Fname);
	for (int pid = 0; pid < nPeople; pid++)
	{
		sprintf(Fname, "%s/Vis/Feather/%d", Path, pid), makeDir(Fname);
		sprintf(Fname, "%s/Vis/Feather/%d/%d", Path, pid, cid), makeDir(Fname);
	}

	int offsetx = 0, offsety = 0;
	Mat img, rimg, _mask, __mask, mask, background, foreground, result, rbackground, rresult;

	int dilation_size = 61;
	Mat element = getStructuringElement(MORPH_RECT, Size(2 * dilation_size + 1, 2 * dilation_size + 1), Point(dilation_size, dilation_size));

	CvSize size;
	size.width = (int)(resizeFactor*w), size.height = (int)(resizeFactor*h);
	VideoWriter *writer = new VideoWriter[nPeople];
	for (int pid = 0; pid < nPeople; pid++)
	{
		sprintf(Fname, "%s/Vis/Feather/P%.2d_C%.2d.avi", Path, pid, cid);
		writer[pid].open(Fname, CV_FOURCC('X', 'V', 'I', 'D'), 30, size);
	}

	cuda::GpuMat src, dst;
	for (int fid = startF; fid <= stopF; fid += increF)
	{
		printf("%d_%.4d..", cid, fid);

		sprintf(Fname, "%s/%d/%.4d.jpg", Path, cid, fid);
		if (IsFileExist(Fname) == 0)
			continue;
		img = imread(Fname);

		resize(img, rimg, Size(resizeFactor* w, resizeFactor*h), 0, 0, INTER_AREA);
		GaussianBlur(rimg, background, Size((int)(resizeFactor * 181 + 0.5), (int)(resizeFactor * 181 + 0.5)), 0, 0);

		for (int pid = 0; pid < nPeople; pid++)
		{
			sprintf(Fname, "%s/Vis/Feather/%d/%d/%.4d.jpg", Path, pid, cid, fid);
			if (IsFileExist(Fname) == 1)
				continue;

			sprintf(Fname, "%s/Vis/FitBody/%d/%d/%.4d.png", Path, pid, cid, fid);
			if (IsFileExist(Fname) == 0)
			{
				sprintf(Fname, "%s/Vis/Feather/%d/%d/%.4d.jpg", Path, pid, cid, fid), cv::imwrite(Fname, background);

				CvPoint text_origin = { background.rows / 30, background.cols / 30 };
				sprintf(Fname, "#%d", fid), putText(background, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0*background.cols / 640, Scalar(0, 0, 255), 3);
				writer[pid] << background;
			}
			else
			{
				_mask = imread(Fname, 0);
				resize(_mask, __mask, Size(resizeFactor* w, resizeFactor*h), 0, 0, INTER_AREA);
				dilate(__mask, mask, element);

				foreground = rimg.clone(); sprintf(Fname, "%s/Vis/Feather/%d/%d/%.4d.jpg", Path, pid, cid, fid), cv::imwrite(Fname, rresult);

				//seamlessClone(background, foreground, mask, offsetx, offsety, rresult, CLONE_MIXED_GRADIENTS);
				//seamlessClone(background, foreground, mask, offsetx, offsety, rresult, CLONE_FOREGROUND_GRADIENTS);
				seamlessClone(background, foreground, mask, offsetx, offsety, rresult, CLONE_AVERAGED_GRADIENTS);

				sprintf(Fname, "%s/Vis/Feather/%d/%d/%.4d.jpg", Path, pid, cid, fid), cv::imwrite(Fname, rresult);

				CvPoint text_origin = { rresult.rows / 30, rresult.cols / 30 };
				sprintf(Fname, "#%d", fid), putText(rresult, Fname, text_origin, CV_FONT_HERSHEY_SIMPLEX, 1.0*rresult.cols / 640, Scalar(0, 255, 0), 3);
				writer[pid] << rresult;
			}
		}
	}

	for (int pid = 0; pid <= nPeople; pid++)
		writer[pid].release();

	return 0;
}